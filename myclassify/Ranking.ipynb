{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For training classifiers to predict/rank answers\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import arff\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "#import data\n",
    "def importData(path):\n",
    "    dataset = arff.load(open(path, 'rb'))\n",
    "    data = np.array(dataset['data'])\n",
    "    #print data[:10]\n",
    "\n",
    "    #extract features and labels\n",
    "    features = []\n",
    "    labels = []\n",
    "    for d in data:\n",
    "        f = []\n",
    "        for i in range(len(d) - 1):\n",
    "            num = float(d[i])\n",
    "            if int(num) == num:\n",
    "                num = int(num)\n",
    "            f.append(num)\n",
    "        features.append(f)\n",
    "\n",
    "        if d[-1] == \"positive\":\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "    return np.asarray(features), np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_similarity_features(filepath):\n",
    "    features = []\n",
    "    labels = []\n",
    "    map_label = {\"positive\": 1, \"negative\": 0}\n",
    "    with open(filepath) as infile:\n",
    "        for line in infile:\n",
    "            label, score = line.strip().split(',')\n",
    "            score = float(score)\n",
    "            label = map_label[label]\n",
    "            features.append(score)\n",
    "            labels.append(label)\n",
    "            \n",
    "    return np.asarray(features).reshape(-1, 1), np.asarray(labels)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "def predict_for_test(test, predict, probability, path):\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(\"=== Predictions on test data ===\\n\")\n",
    "        f.write(\" inst#     actual  predicted error prediction\\n\")\n",
    "        for i in range(len(test)):\n",
    "            string = [str(i + 1)]\n",
    "            if test[i] == 1:\n",
    "                string.append(\"1:positive\")\n",
    "            else:\n",
    "                string.append(\"2:negative\")\n",
    "            if predict[i] == 1:\n",
    "                string.append(\"1:positive\")\n",
    "            else:\n",
    "                string.append(\"2:negative\")\n",
    "            if test[i] == predict[i]:\n",
    "                string.append(\" \" * 5)\n",
    "            else:\n",
    "                string.append(\" \" * 2 + \"+\" + \" \" * 2)\n",
    "            if predict[i] == 1:\n",
    "                string.append(str(probability[i][1]))\n",
    "            else:\n",
    "                string.append(str(probability[i][0]))\n",
    "            string = \" \".join(string) + \"\\n\"\n",
    "            f.write(string)\n",
    "    f.close()         \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jacana features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import training data and test data\n",
    "train_datapath = \"./qa.train.arff\"\n",
    "test_datapath = \"./qa.test.arff\"\n",
    "\n",
    "X_train, y_train = importData(train_datapath)\n",
    "X_test, y_test = importData(test_datapath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add GloVe vectors question answer similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Qn answer similarity scores\n",
    "X_sim_train, y_sim_train = load_similarity_features(\"../data/features/glove_embedding_sentence_similarities_train_100.txt\")\n",
    "X_sim_test, y_sim_test = load_similarity_features(\"../data/features/glove_embedding_sentence_similarities_test_100.txt\")\n",
    "\n",
    "X_combined_train = np.hstack((X_train, X_sim_train))\n",
    "X_combined_test = np.hstack((X_test, X_sim_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add type features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize data\n",
    "\n",
    "NOTE: Might not want to do this for Random Forest-like classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Scale combined data\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(X_combined_train)\n",
    "X_comb_scaled_train = scaler.transform(X_combined_train)\n",
    "X_comb_scaled_test = scaler.transform(X_combined_test)\n",
    "\n",
    "# Scale Jacana features only\n",
    "# scaler = RobustScaler()\n",
    "# scaler.fit(X_train)\n",
    "# X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# Only normalize the similarity scores\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(X_sim_train)\n",
    "X_sim_train = scaler.transform(X_sim_train)\n",
    "X_sim_test = scaler.transform(X_sim_test)\n",
    "X_comb_scaledsim_train = np.hstack((X_train, X_sim_train))\n",
    "X_comb_scaledsim_test = np.hstack((X_test, X_sim_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply dim reduction to denoise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=30)\n",
    "pca.fit(X_combined_train)\n",
    "X_pca_train = pca.transform(X_combined_train)\n",
    "X_pca_test = pca.transform(X_combined_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x10beaf290>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109cc8810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pca.explained_variance_)\n",
    "plt.title(\"PCA explained variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.99      0.91      1233\n",
      "          1       0.82      0.17      0.28       284\n",
      "\n",
      "avg / total       0.83      0.84      0.79      1517\n",
      "\n",
      "[[1222   11]\n",
      " [ 235   49]]\n",
      "Accuracy: 0.837837837838\n"
     ]
    }
   ],
   "source": [
    "# Jacana features only\n",
    "logreg = linear_model.LogisticRegression(C=0.01,\n",
    "#                                          penalty=\"l1\"\n",
    "                                        )\n",
    "logreg = logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "y_prob = logreg.predict_proba(X_test)\n",
    "\n",
    "#write result to file\n",
    "predict_for_test(y_test, y_pred, y_prob, \"./test_res/jacana-log-qa-test.txt\")\n",
    "\n",
    "# Compute metrics\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.98      0.91      1233\n",
      "          1       0.73      0.21      0.32       284\n",
      "\n",
      "avg / total       0.82      0.84      0.80      1517\n",
      "\n",
      "[[1211   22]\n",
      " [ 225   59]]\n",
      "Accuracy: 0.837178642057\n"
     ]
    }
   ],
   "source": [
    "#logistic regression with qn similarity features\n",
    "\n",
    "# Jacana + similarity features (no scaling)\n",
    "logreg = linear_model.LogisticRegression(C=0.2,\n",
    "                                         penalty=\"l1\"\n",
    "                                        )\n",
    "logreg = logreg.fit(X_combined_train, y_train)\n",
    "y_pred = logreg.predict(X_combined_test)\n",
    "\n",
    "y_prob = logreg.predict_proba(X_combined_test)\n",
    "\n",
    "#write result to file\n",
    "predict_for_test(y_test, y_pred, y_prob, \"./test_res/jasim-log-qa-test.txt\")\n",
    "\n",
    "# Compute metrics\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.98      0.91      1233\n",
      "          1       0.72      0.21      0.33       284\n",
      "\n",
      "avg / total       0.82      0.84      0.80      1517\n",
      "\n",
      "[[1209   24]\n",
      " [ 223   61]]\n",
      "Accuracy: 0.837178642057\n"
     ]
    }
   ],
   "source": [
    "#logistic regression with qn similarity features\n",
    "# Jacana + similarity features (scale similarity only)\n",
    "logreg = linear_model.LogisticRegression(C=2,\n",
    "                                        )\n",
    "logreg = logreg.fit(X_comb_scaledsim_train, y_train)\n",
    "y_pred = logreg.predict(X_comb_scaledsim_test)\n",
    "\n",
    "y_prob = logreg.predict_proba(X_comb_scaledsim_test)\n",
    "\n",
    "#write result to file\n",
    "predict_for_test(y_test, y_pred, y_prob, \"./test_res/scaledsim-log-qa-test.txt\")\n",
    "\n",
    "# Compute metrics\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.99      0.91      1233\n",
      "          1       0.86      0.15      0.26       284\n",
      "\n",
      "avg / total       0.84      0.84      0.79      1517\n",
      "\n",
      "[[1226    7]\n",
      " [ 241   43]]\n",
      "Accuracy: 0.836519446276\n"
     ]
    }
   ],
   "source": [
    "#logistic regression with qn similarity features\n",
    "# Jacana + similarity + PCA reduced\n",
    "\n",
    "clf = linear_model.LogisticRegression(C=0.002,\n",
    "                                        )\n",
    "clf.fit(X_pca_train, y_train)\n",
    "y_pred = clf.predict(X_pca_test)\n",
    "\n",
    "y_prob = clf.predict_proba(X_pca_test)\n",
    "\n",
    "#write result to file\n",
    "predict_for_test(y_test, y_pred, y_prob, \"./test_res/pca-log-qa-test.txt\")\n",
    "\n",
    "# Compute metrics\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 4.52 seconds for 10 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.932 (std: 0.013)\n",
      "Parameters: {'C': 0.1}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.932 (std: 0.016)\n",
      "Parameters: {'C': 1}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.932 (std: 0.008)\n",
      "Parameters: {'C': 0.01}\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.98      0.91      1233\n",
      "          1       0.69      0.21      0.32       284\n",
      "\n",
      "avg / total       0.81      0.83      0.80      1517\n",
      "\n",
      "[[1206   27]\n",
      " [ 225   59]]\n",
      "Accuracy: 0.833882663151\n"
     ]
    }
   ],
   "source": [
    "# Randomized search with cross validation to find best set of params\n",
    "\n",
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"C\": [10, 5, 2, 1, 0.5, 0.3, 0.1, 0.05, 0.03, 0.01, 0.005, 0.003, 0.001, 0.0005]}\n",
    "clf = linear_model.LogisticRegression()\n",
    "\n",
    "n_iter_search = 10\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search,\n",
    "                                   cv=5,\n",
    "                                   random_state=457319)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X_comb_scaledsim_train, y_train)\n",
    "y_pred = random_search.predict(X_comb_scaledsim_test)\n",
    "\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)\n",
    "\n",
    "y_prob = random_search.predict_proba(X_comb_scaledsim_test)\n",
    "\n",
    "#write result to file\n",
    "predict_for_test(y_test, y_pred, y_prob, \"./test_res/rand1-log-qa-test.txt\")\n",
    "\n",
    "\n",
    "# Compute metrics\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 1.71 seconds for 10 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.930 (std: 0.012)\n",
      "Parameters: {'C': 0.1}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.929 (std: 0.011)\n",
      "Parameters: {'C': 0.01}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.929 (std: 0.011)\n",
      "Parameters: {'C': 2}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.929 (std: 0.011)\n",
      "Parameters: {'C': 10}\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.98      0.90      1233\n",
      "          1       0.66      0.15      0.25       284\n",
      "\n",
      "avg / total       0.80      0.83      0.78      1517\n",
      "\n",
      "[[1210   23]\n",
      " [ 240   44]]\n",
      "Accuracy: 0.826631509558\n"
     ]
    }
   ],
   "source": [
    "# Randomized search with cross validation to find best set of params\n",
    "\n",
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"C\": [10, 5, 2, 1, 0.5, 0.3, 0.1, 0.05, 0.03, 0.01, 0.005, 0.003, 0.001, 0.0005]}\n",
    "clf = linear_model.LogisticRegression()\n",
    "\n",
    "n_iter_search = 10\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search,\n",
    "                                   cv=5,\n",
    "                                   random_state=457319)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X_pca_train, y_train)\n",
    "y_pred = random_search.predict(X_pca_test)\n",
    "\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)\n",
    "\n",
    "y_prob = random_search.predict_proba(X_pca_test)\n",
    "\n",
    "#write result to file\n",
    "predict_for_test(y_test, y_pred, y_prob, \"./test_res/rand2-log-qa-test.txt\")\n",
    "\n",
    "# Compute metrics\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.98      0.90      1233\n",
      "          1       0.66      0.20      0.31       284\n",
      "\n",
      "avg / total       0.81      0.83      0.79      1517\n",
      "\n",
      "Accuracy score: 0.831245880026\n"
     ]
    }
   ],
   "source": [
    "# Jacana only\n",
    "clf = RandomForestClassifier(n_estimators=300,\n",
    "                             max_depth=12,\n",
    "#                              min_samples_split=4,\n",
    "                             criterion=\"entropy\",\n",
    "                             random_state=3471,\n",
    "                             class_weight=\"balanced\"\n",
    "                            )\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "y_prob = clf.predict_proba(X_test)\n",
    "\n",
    "#write result to file\n",
    "predict_for_test(y_test, y_pred, y_prob, \"./test_res/jacana-rf-qa-test.txt\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy score: {}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.98      0.91      1233\n",
      "          1       0.69      0.22      0.33       284\n",
      "\n",
      "avg / total       0.82      0.84      0.80      1517\n",
      "\n",
      "Accuracy score: 0.835201054713\n"
     ]
    }
   ],
   "source": [
    "# Jacana with similarity scores features. Both types of features scaled.\n",
    "clf = RandomForestClassifier(n_estimators=400,\n",
    "                             max_depth=12,\n",
    "                             min_samples_split=4,\n",
    "                             criterion=\"entropy\",\n",
    "                             random_state=3471,\n",
    "                             class_weight=\"balanced_subsample\"\n",
    "                            )\n",
    "clf = clf.fit(X_combined_train, y_train)\n",
    "y_pred = clf.predict(X_combined_test)\n",
    "\n",
    "y_prob = clf.predict_proba(X_combined_test)\n",
    "\n",
    "#write result to file\n",
    "predict_for_test(y_test, y_pred, y_prob, \"./test_res/scaledsim-rf-qa-test.txt\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy score: {}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use randomized search to find good parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 88.44 seconds for 10 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.929 (std: 0.003)\n",
      "Parameters: {'min_samples_leaf': 2, 'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 2, 'max_depth': 16, 'class_weight': None}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.929 (std: 0.002)\n",
      "Parameters: {'min_samples_leaf': 2, 'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 6, 'max_depth': 16, 'class_weight': None}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.928 (std: 0.002)\n",
      "Parameters: {'min_samples_leaf': 2, 'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 6, 'max_depth': 8, 'class_weight': None}\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90      1233\n",
      "          1       0.76      0.05      0.09       284\n",
      "\n",
      "avg / total       0.81      0.82      0.75      1517\n",
      "\n",
      "[[1229    4]\n",
      " [ 271   13]]\n",
      "Accuracy: 0.818721160185\n"
     ]
    }
   ],
   "source": [
    "# Jacana only\n",
    "from time import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": [8, 12, 16],\n",
    "              \"min_samples_split\": [2, 4, 6],\n",
    "              \"criterion\": [\"gini\", \"entropy\"],\n",
    "              \"min_samples_leaf\": [1, 2, 3],\n",
    "              \"n_estimators\": [200, 250, 300],\n",
    "              \"class_weight\": [None, \"balanced\", \"balanced_subsample\"]}\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "n_iter_search = 10\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search,\n",
    "                                   cv=5,\n",
    "                                   random_state=83716)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X_train, y_train)\n",
    "y_pred = random_search.predict(X_test)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)\n",
    "\n",
    "y_prob = random_search.predict_proba(X_test)\n",
    "\n",
    "#write result to file\n",
    "predict_for_test(y_test, y_pred, y_prob, \"./test_res/rand1-rf-qa-test.txt\")\n",
    "\n",
    "# Compute metrics\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 92.87 seconds for 10 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.928 (std: 0.002)\n",
      "Parameters: {'min_samples_leaf': 2, 'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 6, 'max_depth': 8, 'class_weight': None}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.928 (std: 0.003)\n",
      "Parameters: {'min_samples_leaf': 2, 'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 2, 'max_depth': 16, 'class_weight': None}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.928 (std: 0.003)\n",
      "Parameters: {'min_samples_leaf': 2, 'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 6, 'max_depth': 16, 'class_weight': None}\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90      1233\n",
      "          1       0.74      0.06      0.11       284\n",
      "\n",
      "avg / total       0.81      0.82      0.75      1517\n",
      "\n",
      "[[1227    6]\n",
      " [ 267   17]]\n",
      "Accuracy: 0.820039551747\n"
     ]
    }
   ],
   "source": [
    "# Jacana with similarity scores features. Only similarity scores are scaled.\n",
    "start = time()\n",
    "random_search.fit(X_comb_scaledsim_train, y_train)\n",
    "y_pred = random_search.predict(X_comb_scaledsim_test)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)\n",
    "\n",
    "y_prob = random_search.predict_proba(X_comb_scaledsim_test)\n",
    "\n",
    "#write result to file\n",
    "predict_for_test(y_test, y_pred, y_prob, \"./test_res/rand2-rf-qa-test.txt\")\n",
    "\n",
    "# Compute metrics\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using GradientBoostingMachine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use RF to embed features then train using LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
