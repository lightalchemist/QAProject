{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "import cvxpy\n",
    "\n",
    "def ensure_dir_exists(path):\n",
    "    dirpath = os.path.dirname(path)\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output in Weka format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "def predict_for_test(test, predict, probability, path):\n",
    "    \n",
    "    ensure_dir_exists(path)\n",
    "    \n",
    "    with open(path, 'w') as f:\n",
    "        f.write(\"=== Predictions on test data ===\\n\")\n",
    "        f.write(\" inst#     actual  predicted error prediction\\n\")\n",
    "        for i in range(len(test)):\n",
    "            string = [str(i + 1)]\n",
    "            if test[i] == 1:\n",
    "                string.append(\"1:positive\")\n",
    "            else:\n",
    "                string.append(\"2:negative\")\n",
    "            if predict[i] == 1:\n",
    "                string.append(\"1:positive\")\n",
    "            else:\n",
    "                string.append(\"2:negative\")\n",
    "            if test[i] == predict[i]:\n",
    "                string.append(\" \" * 5)\n",
    "            else:\n",
    "                string.append(\" \" * 2 + \"+\" + \" \" * 2)\n",
    "            if predict[i] == 1:\n",
    "                string.append(str(probability[i][1]))\n",
    "            else:\n",
    "                string.append(str(probability[i][0]))\n",
    "            string = \" \".join(string) + \"\\n\"\n",
    "            f.write(string)   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import arff\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "#import data\n",
    "def importData(path):\n",
    "#     dataset = arff.load(open(path, 'rb'))\n",
    "    dataset = arff.load(open(path))    \n",
    "    data = np.array(dataset['data'])\n",
    "    #print data[:10]\n",
    "\n",
    "    #extract features and labels\n",
    "    features = []\n",
    "    labels = []\n",
    "    for d in data:\n",
    "        f = []\n",
    "        for i in range(len(d) - 1):\n",
    "            num = float(d[i])\n",
    "            if int(num) == num:\n",
    "                num = int(num)\n",
    "            f.append(num)\n",
    "        features.append(f)\n",
    "\n",
    "        if d[-1] == \"positive\":\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "    return np.asarray(features), np.asarray(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Word embedding vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map each word to an index\n",
    "ndim = 300\n",
    "glove_path = \"../data/glove_embeddings/glove.6B.{}d.txt\".format(ndim)\n",
    "with open(glove_path, \"rb\") as lines:\n",
    "    w2idx = {line.split()[0].decode(\"utf-8\"): i for i, line in enumerate(lines)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = np.empty((len(w2idx), ndim), dtype=np.float)\n",
    "with open(glove_path, \"rb\") as lines:\n",
    "    for i, line in enumerate(lines):\n",
    "        # Fix for Python 3\n",
    "        vectors[i] = np.asarray(list(map(float, line.split()[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "words_to_exclude = frozenset(string.punctuation) | frozenset([\"..\", \"...\"])\n",
    "words_to_exclude |= frozenset(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Rank propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_QA_group_count(infile):        \n",
    "    line = infile.readline().strip()\n",
    "    if line == \"\":\n",
    "        return None\n",
    "    \n",
    "    if not line.startswith(\"<QApairs\"):\n",
    "        raise Exception(\"Invalid data format: {}<-----\".format(line))\n",
    "    \n",
    "    sentence_count = 0\n",
    "    while not line.strip().startswith(\"</QApairs\"):\n",
    "        line = infile.readline().replace('\\t', ' ')                    \n",
    "        if line.strip().lower().startswith(\"<positive\") or line.strip().lower().startswith(\"<negative\"):\n",
    "            sentence_count += 1\n",
    "    \n",
    "    return sentence_count\n",
    "\n",
    "def get_QA_group_indicators(filepath):\n",
    "    \"\"\"Get vector indicating which example belongs to which question group\n",
    "    \"\"\"\n",
    "    with open(filepath) as infile:\n",
    "        indicators = []\n",
    "        qn_number = 0\n",
    "        while infile:\n",
    "            count = get_QA_group_count(infile)\n",
    "\n",
    "            # Check for EOF\n",
    "            if count == None:\n",
    "                break\n",
    "\n",
    "            if count > 0:\n",
    "                indicators += ([qn_number] * count)\n",
    "                qn_number += 1\n",
    "        \n",
    "    return np.asarray(indicators)\n",
    "\n",
    "# Get a question and its candidate answers\n",
    "def get_QA_group(infile):\n",
    "    question = []\n",
    "    answers = []\n",
    "    line = infile.readline().strip()\n",
    "    if line == \"\":\n",
    "        return None\n",
    "    \n",
    "    if not line.startswith(\"<QApairs\"):\n",
    "        raise Exception(\"Invalid data format: {}<-----\".format(line))\n",
    "        \n",
    "    while not line.strip().startswith(\"</QApairs\"):\n",
    "        line = infile.readline().replace('\\t', ' ')\n",
    "        if line.strip().lower().startswith(\"<question\"):\n",
    "            line = infile.readline().replace('\\t', ' ')\n",
    "            question.append(line.strip())\n",
    "        elif line.strip().lower().startswith(\"<positive\"):\n",
    "            line = infile.readline().replace('\\t', ' ')\n",
    "            answers.append((\"positive\", line.strip()))\n",
    "        elif line.strip().lower().startswith(\"<negative\"):\n",
    "            line = infile.readline().replace('\\t', ' ')\n",
    "            answers.append((\"negative\", line.strip()))\n",
    "    \n",
    "    return {\"question\": question, \"answers\": answers}                \n",
    "\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "def extract_vector(sentence, exclude, w2idx, wordvectors):\n",
    "    \"\"\"Compute the vector for a sentence by averaging the words in the sentence that has word embeddings\"\"\"\n",
    "    # Tokenize sentence\n",
    "    splitter = WhitespaceTokenizer()\n",
    "    tokens = splitter.tokenize(sentence)    \n",
    "    # Remove stopwords and punctuation\n",
    "    words = [t.lower() for t in tokens if t.lower() not in exclude ]\n",
    "    \n",
    "    # If we cannot find any words, we can consider returning a vector of 0\n",
    "    # and set the resulting cosine similarity to 0 otherwise will result in nan\n",
    "    # because cosine similarity will divide by 0.\n",
    "    assert(len(words) > 0)\n",
    "            \n",
    "    # Average words in sentence that are in word matrix\n",
    "    try:\n",
    "        avg_vec = np.mean([wordvectors[w2idx[w]] for w in words if w in w2idx ] \n",
    "                                                 or [np.zeros(wordvectors.shape[1])], \n",
    "                           axis=0)\n",
    "        if not np.any(avg_vec):\n",
    "            print(\"Tokens cannot be found: {}\".format(words))\n",
    "        assert(np.any(avg_vec))\n",
    "        return avg_vec\n",
    "    except UnicodeDecodeError:\n",
    "        print(line.strip())\n",
    "        raise\n",
    "\n",
    "def compute_pairwise_distance_matrix(X, k, p=2):\n",
    "    \"\"\"Compute pairwise distances between each point in X\n",
    "    and its k-nearest neighbors.\"\"\"\n",
    "\n",
    "    from scipy.spatial import KDTree\n",
    "    kdtree = KDTree(X)\n",
    "    A = np.zeros((X.shape[0], X.shape[0]), dtype=np.float)\n",
    "    for i, x in enumerate(X):\n",
    "        distances, idxs = kdtree.query(x, k+1, p)  # k+1 as one pt is the pt itself.\n",
    "        for d, j in zip(distances, idxs):\n",
    "            A[i, j] = d\n",
    "\n",
    "    # p = 2 corresponds to gaussian kernel. p = 1 corresponds to Laplacian kernel.\n",
    "    if p == 2:  # Store squared euclidean for L2 distance otherwise if p = 1 just store absolute dist.\n",
    "        A = A ** 2\n",
    "\n",
    "            \n",
    "    return A\n",
    "\n",
    "import scipy as sp\n",
    "\n",
    "# Compute weight matrix (i.e., the Graph Laplacian) $L$ for each set of question and its candidate answers\n",
    "def get_weight_matrix(input_file, n_neighbors=5, sigma=1.0, eps=0.0001, p=2):\n",
    "    \"\"\"Compute weight matrix for question and answer sentences \n",
    "    \"\"\"\n",
    "    with open(input_file) as infile:\n",
    "        num_questions = 0\n",
    "        while infile:\n",
    "            group = get_QA_group(infile)\n",
    "\n",
    "            # Check for EOF\n",
    "            if group is None:\n",
    "                break\n",
    "                \n",
    "            # Extract question vector\n",
    "            question = group[\"question\"]\n",
    "            qvec = extract_vector(question[0], words_to_exclude, w2idx, vectors)\n",
    "\n",
    "            scores = []\n",
    "            answer_vectors = []\n",
    "            for (label, sentence) in group[\"answers\"]:\n",
    "                # Compute similarity with question vector\n",
    "                vec = extract_vector(sentence, words_to_exclude, w2idx, vectors) # TODO: Pass these in as args\n",
    "                answer_vectors.append(vec)\n",
    "                cosine_distance = sp.spatial.distance.cosine(qvec, vec)\n",
    "                scores.append((label, cosine_distance))\n",
    "\n",
    "            # Compute pairwise distances between the answer vectors for K nearest neighbor\n",
    "            k = min(n_neighbors, len(answer_vectors) - 1) # Minus 1 because have to exclude itself\n",
    "            # Not enough to do rank propagation. Just keep original scores.\n",
    "            if k < 0:\n",
    "                yield None, None\n",
    "            elif k == 0:\n",
    "                yield 1, None\n",
    "            else:                \n",
    "                answer_vectors = np.vstack(answer_vectors)\n",
    "                W = compute_pairwise_distance_matrix(answer_vectors, k, p)\n",
    "                W = np.maximum(W, W.T)  # Ensure W symmetric.\n",
    "                W[W > 0] = np.exp(- W[W > 0] / (2 * sigma**2))  # Apply gaussian kernel\n",
    "                D = np.diag(np.sum(W, axis=1))  # Row sum of W\n",
    "                L = D - W\n",
    "#                 L = L + eps * np.eye(len(answer_vectors))  # Improve the condition of the graph laplacian                \n",
    "                Dinvsqrt = np.sqrt(np.linalg.pinv(D))                \n",
    "                # Need to ensure that Dinvsqrt does not have NAN due to division by 0\n",
    "                assert(not np.any(np.isnan(Dinvsqrt)))                \n",
    "                L = Dinvsqrt.dot(L).dot(Dinvsqrt)  # Normalized graph laplacian\n",
    "                \n",
    "#                 assert(is_pos_def(Dinvsqrt))\n",
    "#                 assert(is_pos_def(L))\n",
    "                \n",
    "                yield L.shape[0], L\n",
    "            \n",
    "            num_questions += 1\n",
    "\n",
    "def load_similarity_features(filepath):\n",
    "    \"\"\"\n",
    "    Load question answer similarity values from file (probably should compute it here).\n",
    "\n",
    "    **NOTE**: Similarity is the wrong term to use here. The values in the file are actually cosine **distances**.\n",
    "    To convert it to similarity, we need to subtract it from 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    features = []\n",
    "    labels = []\n",
    "    map_label = {\"positive\": 1, \"negative\": 0}\n",
    "    with open(filepath) as infile:\n",
    "        for line in infile:\n",
    "            label, score = line.strip().split(',')\n",
    "            score = float(score)\n",
    "            label = map_label[label]\n",
    "            features.append(score)\n",
    "            labels.append(label)\n",
    "            \n",
    "    return np.asarray(features).reshape(-1, 1), np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_file = \"../data/answerSelectionExperiments/data/train-less-than-40.xml\"\n",
    "dev_file = \"../data/answerSelectionExperiments/data/dev-less-than-40.xml\"\n",
    "test_file = \"../data/answerSelectionExperiments/data/test-less-than-40.xml\"\n",
    "dev_qn_group_indicators = get_QA_group_indicators(dev_file)\n",
    "qn_group_indicators = get_QA_group_indicators(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import training data and test data. \n",
    "# These are the Jacana features for each qn/ans pair in the TREC dataset (XML files).\n",
    "train_datapath = \"../myclassify/qa.train.arff\"\n",
    "test_datapath = \"../myclassify/qa.test.arff\"\n",
    "dev_datapath = \"../myclassify/qa.dev.arff\"\n",
    "\n",
    "X_train, y_train = importData(train_datapath)\n",
    "X_test, y_test = importData(test_datapath)\n",
    "X_dev, y_dev = importData(dev_datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sim_train, y_sim_train = load_similarity_features(\"../data/features/glove_embedding_sentence_similarities_train_300.txt\")\n",
    "X_sim_dev, y_sim_dev = load_similarity_features(\"../data/features/glove_embedding_sentence_similarities_dev_300.txt\")\n",
    "X_sim_test, y_sim_test = load_similarity_features(\"../data/features/glove_embedding_sentence_similarities_test_300.txt\")\n",
    "\n",
    "X_combined_train = np.hstack((X_train, X_sim_train))\n",
    "X_combined_dev = np.hstack((X_dev, X_sim_dev))\n",
    "X_combined_test = np.hstack((X_test, X_sim_test))\n",
    "\n",
    "# Scale combined data\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(X_combined_train)\n",
    "X_comb_scaled_train = scaler.transform(X_combined_train)\n",
    "X_comb_scaled_dev = scaler.transform(X_combined_dev)\n",
    "X_comb_scaled_test = scaler.transform(X_combined_test)\n",
    "\n",
    "# Only normalize the similarity scores\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(X_sim_train)\n",
    "X_sim_train = scaler.transform(X_sim_train)\n",
    "X_sim_dev = scaler.transform(X_sim_dev)\n",
    "X_sim_test = scaler.transform(X_sim_test)\n",
    "X_comb_scaledsim_train = np.hstack((X_train, X_sim_train))\n",
    "X_comb_scaledsim_dev = np.hstack((X_dev, X_sim_dev))\n",
    "X_comb_scaledsim_test = np.hstack((X_test, X_sim_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Propagate rank score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cvxpy import Variable, Minimize, norm, quad_form, Problem\n",
    "\n",
    "def is_pos_def(x):\n",
    "    \"\"\"Check if a matrix is positive definite. For debugging purposes.\"\"\"\n",
    "    return np.all(np.linalg.eigvals(x) > 0)\n",
    "\n",
    "# Version 2 that uses the ans_type_match and question answer similarity weights\n",
    "def propagate_scores(r, L, ans_type_match, ans_sim_weights, alpha=1.0, gamma=1.0, loss_type=1):\n",
    "    \"\"\"Solve convex optimization problem to get new scores\"\"\"\n",
    "        \n",
    "    n = r.size\n",
    "    y = Variable(n)    \n",
    "    assert(len(ans_type_match) == n and len(ans_sim_weights) == n)\n",
    "    \n",
    "    # If no type match we just ignore the type term\n",
    "    if not np.any(ans_type_match):\n",
    "        objective = Minimize( norm(r - y, loss_type) + alpha * quad_form(y, L) )\n",
    "    else:\n",
    "        type_term = sum( ans_sim_weights[i] * cvxpy.abs(1 - y[i]) \n",
    "                        for i, match in enumerate(ans_type_match) if match == 1 )\n",
    "        objective = Minimize( norm(r - y, loss_type) + alpha * quad_form(y, L) + gamma * type_term)\n",
    "            \n",
    "    constraints = [0 <= y, y <= 1]\n",
    "    prob = Problem(objective, constraints)    \n",
    "\n",
    "    # The optimal objective is returned by prob.solve().\n",
    "    result = prob.solve(verbose=False)      \n",
    "    assert(prob.status == \"optimal\")\n",
    "    \n",
    "    return y.value.flatten().tolist()[0]\n",
    "\n",
    "def get_qn_answer_match_indicators(filepath):\n",
    "    with open(filepath) as infile:\n",
    "        return np.asarray([int(x.strip()) for x in infile])\n",
    "    \n",
    "def get_qn_answer_sim_weights(filepath):\n",
    "    with open(filepath) as infile:\n",
    "        return np.asarray([float(x.split(',')[1]) for x in infile])\n",
    "\n",
    "def rank_propagation(data_filepath, qn_match_filepath, qn_simweights_filepath, r, \n",
    "                     alpha=1.0, sigma=1.0, n_neighbors=5, gamma=1.0, \n",
    "                     loss_type=1, \n",
    "                     pair_similarity_type=2):\n",
    "    total_count = 0\n",
    "\n",
    "    # Get qn group indicator\n",
    "    qn_group_indicators = get_QA_group_indicators(data_filepath)\n",
    "    \n",
    "    # Get qn answer type match\n",
    "    qn_ans_type_match = get_qn_answer_match_indicators(qn_match_filepath)\n",
    "    \n",
    "    # Get qn answer similarity weights\n",
    "    # The weights are actually distances so we subtract them from 1 to convert distance to similarity\n",
    "    qn_ans_sim_weights = 1 - get_qn_answer_sim_weights(qn_simweights_filepath)\n",
    "    \n",
    "    qn_number = 0  # Current question number (NOTE: This is not ID in XML)\n",
    "\n",
    "    scores = []  # To store the final refined scores\n",
    "    # L is actually the graph Laplacian matrix\n",
    "    for (count, L) in get_weight_matrix(data_filepath, \n",
    "                                        n_neighbors, sigma, \n",
    "                                        p=pair_similarity_type):\n",
    "        # Skip question without candidate answers\n",
    "        if count is None:\n",
    "            continue\n",
    "\n",
    "        # Not enough points to propagate. Just use original value.\n",
    "        MIN_NUM_CANDIDATES = 1\n",
    "        if count <= MIN_NUM_CANDIDATES:\n",
    "            assert(r[qn_group_indicators == qn_number].size == count)\n",
    "            scores += r[qn_group_indicators == qn_number].tolist()\n",
    "        else:\n",
    "            # Get indicator vector for which answer has matching type\n",
    "            ans_type_match = qn_ans_type_match[qn_group_indicators == qn_number]\n",
    "            \n",
    "            # Get question / answer similarity weights\n",
    "            ans_sim_weights = qn_ans_sim_weights[qn_group_indicators == qn_number]                        \n",
    "            \n",
    "            # Propagate and append new scores\n",
    "            assert(r[qn_group_indicators == qn_number].size == L.shape[0])\n",
    "            new_scores = propagate_scores(r[qn_group_indicators == qn_number],\n",
    "                                          L, \n",
    "                                          ans_type_match, ans_sim_weights,\n",
    "                                          alpha, gamma, loss_type)                \n",
    "            scores += new_scores\n",
    "\n",
    "        qn_number += 1\n",
    "        total_count += count\n",
    "\n",
    "    return np.asarray(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train basic classifier to give input ranks for Rank Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.01\n",
      "accuracy: 0.7323665128543178\n",
      "f1: 0.3164983164983165\n",
      "alpha: 0.1\n",
      "accuracy: 0.7336849044166117\n",
      "f1: 0.31756756756756754\n",
      "alpha: 1\n",
      "accuracy: 0.7350032959789057\n",
      "f1: 0.3116438356164384\n",
      "alpha: 2\n",
      "accuracy: 0.7356624917600527\n",
      "f1: 0.3050259965337955\n",
      "alpha: 10\n",
      "accuracy: 0.7554383651944627\n",
      "f1: 0.2851637764932563\n",
      "alpha: 50\n",
      "accuracy: 0.8002636783124588\n",
      "f1: 0.15598885793871867\n",
      "alpha: 100\n",
      "accuracy: 0.8127883981542519\n",
      "f1: 0.08387096774193548\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "\n",
    "# nb = GaussianNB()\n",
    "paras = [0.01, 0.1, 1, 2, 10, 50, 100]\n",
    "for para in paras:\n",
    "    nb = BernoulliNB(alpha=para)\n",
    "    nb.fit(X_train, y_train)\n",
    "\n",
    "    #dev set\n",
    "    y_dev_pred = nb.predict(X_dev)\n",
    "    y_dev_prob = nb.predict_proba(X_dev)\n",
    "    dev_path = \"../myclassify/test_res/NB-dev/NB-\" + str(para) + \".txt\"\n",
    "    predict_for_test(y_dev, y_dev_pred, y_dev_prob, dev_path)\n",
    "\n",
    "    #test set\n",
    "    y_pred = nb.predict(X_test)\n",
    "    y_prob = nb.predict_proba(X_test)\n",
    "    test_path = \"../myclassify/test_res/NB-test/NB-\" + str(para) + \".txt\"\n",
    "    predict_for_test(y_test, y_pred, y_prob, test_path)\n",
    "\n",
    "    #test result\n",
    "    print(\"alpha: \" + str(para))\n",
    "    print(\"accuracy: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "    print(\"f1: {}\".format(f1_score(y_test, y_pred)))\n",
    "#     print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "#best MAP/MRR for dev when para = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 50; max_depth: 2\n",
      "accuracy: 0.8279499011206328\n",
      "f1: 0.25641025641025644\n",
      "n_estimators: 50; max_depth: 3\n",
      "accuracy: 0.8272907053394858\n",
      "f1: 0.3105263157894737\n",
      "n_estimators: 50; max_depth: 6\n",
      "accuracy: 0.8193803559657218\n",
      "f1: 0.30808080808080807\n",
      "n_estimators: 50; max_depth: 12\n",
      "accuracy: 0.8174027686222808\n",
      "f1: 0.2987341772151899\n",
      "n_estimators: 50; max_depth: 24\n",
      "accuracy: 0.7851021753460777\n",
      "f1: 0.32083333333333336\n",
      "n_estimators: 100; max_depth: 2\n",
      "accuracy: 0.8312458800263678\n",
      "f1: 0.31182795698924726\n",
      "n_estimators: 100; max_depth: 3\n",
      "accuracy: 0.8358602504943968\n",
      "f1: 0.38518518518518524\n",
      "n_estimators: 100; max_depth: 6\n",
      "accuracy: 0.8239947264337508\n",
      "f1: 0.327455919395466\n",
      "n_estimators: 100; max_depth: 12\n",
      "accuracy: 0.8259723137771918\n",
      "f1: 0.3333333333333333\n",
      "n_estimators: 100; max_depth: 24\n",
      "accuracy: 0.7864205669083718\n",
      "f1: 0.31932773109243695\n",
      "n_estimators: 400; max_depth: 2\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.3591022443890274\n",
      "n_estimators: 400; max_depth: 3\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.3836930455635491\n",
      "n_estimators: 400; max_depth: 6\n",
      "accuracy: 0.8174027686222808\n",
      "f1: 0.2879177377892031\n",
      "n_estimators: 400; max_depth: 12\n",
      "accuracy: 0.8259723137771918\n",
      "f1: 0.3333333333333333\n",
      "n_estimators: 400; max_depth: 24\n",
      "accuracy: 0.7864205669083718\n",
      "f1: 0.31932773109243695\n",
      "n_estimators: 800; max_depth: 2\n",
      "accuracy: 0.8279499011206328\n",
      "f1: 0.3523573200992556\n",
      "n_estimators: 800; max_depth: 3\n",
      "accuracy: 0.8246539222148979\n",
      "f1: 0.3696682464454977\n",
      "n_estimators: 800; max_depth: 6\n",
      "accuracy: 0.8147659854976929\n",
      "f1: 0.2813299232736573\n",
      "n_estimators: 800; max_depth: 12\n",
      "accuracy: 0.8259723137771918\n",
      "f1: 0.3333333333333333\n",
      "n_estimators: 800; max_depth: 24\n",
      "accuracy: 0.7864205669083718\n",
      "f1: 0.31932773109243695\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Probably don't try this.\n",
    "# GBM\n",
    "paras1 = [50, 100, 400, 800]\n",
    "paras2 = [2, 3, 6, 12, 24]\n",
    "for para1 in paras1:\n",
    "    for para2 in paras2:    \n",
    "        gbm = GradientBoostingClassifier(n_estimators=para1, max_depth=para2, random_state=47156)\n",
    "        gbm.fit(X_train, y_train)\n",
    "        \n",
    "        #dev set\n",
    "        y_dev_pred = gbm.predict(X_dev)\n",
    "        y_dev_prob = gbm.predict_proba(X_dev)\n",
    "        dev_path = \"../myclassify/test_res/GB-dev/GB-\" + str(para1) + \"-\" + str(para2) + \".txt\"\n",
    "        predict_for_test(y_dev, y_dev_pred, y_dev_prob, dev_path)\n",
    "\n",
    "        #test set\n",
    "        y_pred = gbm.predict(X_test)\n",
    "        y_prob = gbm.predict_proba(X_test)\n",
    "        test_path = \"../myclassify/test_res/GB-test/GB-\" + str(para1) + \"-\" + str(para2) + \".txt\"\n",
    "        predict_for_test(y_test, y_pred, y_prob, test_path)\n",
    "        \n",
    "        #test result\n",
    "        print(\"n_estimators: \" + str(para1) + \"; max_depth: \" + str(para2))\n",
    "        print(\"accuracy: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "        print(\"f1: {}\".format(f1_score(y_test, y_pred)))\n",
    "#         print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "#best MAP/MRR for dev when para1 = 100, para2 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100-gini-8-2-None\n",
      "accuracy: 0.8160843770599868\n",
      "f1: 0.054237288135593226\n",
      "100-gini-8-2-balanced\n",
      "accuracy: 0.8035596572181938\n",
      "f1: 0.4931972789115646\n",
      "100-gini-8-2-balanced_subsample\n",
      "accuracy: 0.7943309162821358\n",
      "f1: 0.47474747474747475\n",
      "100-gini-8-4-None\n",
      "accuracy: 0.8174027686222808\n",
      "f1: 0.07357859531772575\n",
      "100-gini-8-4-balanced\n",
      "accuracy: 0.7903757415952538\n",
      "f1: 0.4803921568627451\n",
      "100-gini-8-4-balanced_subsample\n",
      "accuracy: 0.7864205669083718\n",
      "f1: 0.4774193548387097\n",
      "100-gini-8-6-None\n",
      "accuracy: 0.8187211601845749\n",
      "f1: 0.06143344709897611\n",
      "100-gini-8-6-balanced\n",
      "accuracy: 0.7903757415952538\n",
      "f1: 0.4752475247524753\n",
      "100-gini-8-6-balanced_subsample\n",
      "accuracy: 0.7916941331575478\n",
      "f1: 0.471571906354515\n",
      "100-gini-8-8-None\n",
      "accuracy: 0.8167435728411339\n",
      "f1: 0.041379310344827586\n",
      "100-gini-8-8-balanced\n",
      "accuracy: 0.8002636783124588\n",
      "f1: 0.48903878583473864\n",
      "100-gini-8-8-balanced_subsample\n",
      "accuracy: 0.7930125247198417\n",
      "f1: 0.47840531561461797\n",
      "100-gini-11-2-None\n",
      "accuracy: 0.8167435728411339\n",
      "f1: 0.06711409395973156\n",
      "100-gini-11-2-balanced\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.3746958637469587\n",
      "100-gini-11-2-balanced_subsample\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.35820895522388063\n",
      "100-gini-11-4-None\n",
      "accuracy: 0.8187211601845749\n",
      "f1: 0.08026755852842811\n",
      "100-gini-11-4-balanced\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.3857142857142857\n",
      "100-gini-11-4-balanced_subsample\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.37772397094430993\n",
      "100-gini-11-6-None\n",
      "accuracy: 0.8187211601845749\n",
      "f1: 0.08026755852842811\n",
      "100-gini-11-6-balanced\n",
      "accuracy: 0.8312458800263678\n",
      "f1: 0.3786407766990291\n",
      "100-gini-11-6-balanced_subsample\n",
      "accuracy: 0.8345418589321029\n",
      "f1: 0.42298850574712643\n",
      "100-gini-11-8-None\n",
      "accuracy: 0.8187211601845749\n",
      "f1: 0.07407407407407408\n",
      "100-gini-11-8-balanced\n",
      "accuracy: 0.8253131179960448\n",
      "f1: 0.42764578833693306\n",
      "100-gini-11-8-balanced_subsample\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.43683083511777304\n",
      "100-gini-16-2-None\n",
      "accuracy: 0.8206987475280159\n",
      "f1: 0.09933774834437085\n",
      "100-gini-16-2-balanced\n",
      "accuracy: 0.8253131179960448\n",
      "f1: 0.19452887537993924\n",
      "100-gini-16-2-balanced_subsample\n",
      "accuracy: 0.8319050758075148\n",
      "f1: 0.22492401215805471\n",
      "100-gini-16-4-None\n",
      "accuracy: 0.8174027686222808\n",
      "f1: 0.09771986970684038\n",
      "100-gini-16-4-balanced\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.24927536231884057\n",
      "100-gini-16-4-balanced_subsample\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.2543352601156069\n",
      "100-gini-16-6-None\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.12297734627831713\n",
      "100-gini-16-6-balanced\n",
      "accuracy: 0.8365194462755439\n",
      "f1: 0.30726256983240224\n",
      "100-gini-16-6-balanced_subsample\n",
      "accuracy: 0.8312458800263678\n",
      "f1: 0.26857142857142857\n",
      "100-gini-16-8-None\n",
      "accuracy: 0.8160843770599868\n",
      "f1: 0.07920792079207921\n",
      "100-gini-16-8-balanced\n",
      "accuracy: 0.8345418589321029\n",
      "f1: 0.33421750663129973\n",
      "100-gini-16-8-balanced_subsample\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.32105263157894737\n",
      "100-gini-20-2-None\n",
      "accuracy: 0.8200395517468688\n",
      "f1: 0.099009900990099\n",
      "100-gini-20-2-balanced\n",
      "accuracy: 0.8226763348714569\n",
      "f1: 0.12377850162866448\n",
      "100-gini-20-2-balanced_subsample\n",
      "accuracy: 0.8226763348714569\n",
      "f1: 0.11803278688524589\n",
      "100-gini-20-4-None\n",
      "accuracy: 0.8160843770599868\n",
      "f1: 0.07308970099667773\n",
      "100-gini-20-4-balanced\n",
      "accuracy: 0.8239947264337508\n",
      "f1: 0.17337461300309598\n",
      "100-gini-20-4-balanced_subsample\n",
      "accuracy: 0.8312458800263678\n",
      "f1: 0.20987654320987653\n",
      "100-gini-20-6-None\n",
      "accuracy: 0.8167435728411339\n",
      "f1: 0.07947019867549668\n",
      "100-gini-20-6-balanced\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.2314540059347181\n",
      "100-gini-20-6-balanced_subsample\n",
      "accuracy: 0.8279499011206328\n",
      "f1: 0.21148036253776434\n",
      "100-gini-20-8-None\n",
      "accuracy: 0.8180619644034278\n",
      "f1: 0.09210526315789473\n",
      "100-gini-20-8-balanced\n",
      "accuracy: 0.8246539222148979\n",
      "f1: 0.2222222222222222\n",
      "100-gini-20-8-balanced_subsample\n",
      "accuracy: 0.8312458800263678\n",
      "f1: 0.28089887640449435\n",
      "100-entropy-8-2-None\n",
      "accuracy: 0.8180619644034278\n",
      "f1: 0.0738255033557047\n",
      "100-entropy-8-2-balanced\n",
      "accuracy: 0.7969676994067239\n",
      "f1: 0.48837209302325585\n",
      "100-entropy-8-2-balanced_subsample\n",
      "accuracy: 0.7969676994067239\n",
      "f1: 0.4917491749174917\n",
      "100-entropy-8-4-None\n",
      "accuracy: 0.8174027686222808\n",
      "f1: 0.054607508532423216\n",
      "100-entropy-8-4-balanced\n",
      "accuracy: 0.8022412656558998\n",
      "f1: 0.4983277591973244\n",
      "100-entropy-8-4-balanced_subsample\n",
      "accuracy: 0.7903757415952538\n",
      "f1: 0.4786885245901639\n",
      "100-entropy-8-6-None\n",
      "accuracy: 0.8187211601845749\n",
      "f1: 0.07407407407407408\n",
      "100-entropy-8-6-balanced\n",
      "accuracy: 0.7956493078444298\n",
      "f1: 0.495114006514658\n",
      "100-entropy-8-6-balanced_subsample\n",
      "accuracy: 0.7923533289386948\n",
      "f1: 0.4827586206896552\n",
      "100-entropy-8-8-None\n",
      "accuracy: 0.8180619644034278\n",
      "f1: 0.06756756756756757\n",
      "100-entropy-8-8-balanced\n",
      "accuracy: 0.7877389584706658\n",
      "f1: 0.4789644012944984\n",
      "100-entropy-8-8-balanced_subsample\n",
      "accuracy: 0.7857613711272248\n",
      "f1: 0.4715447154471545\n",
      "100-entropy-11-2-None\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.10561056105610561\n",
      "100-entropy-11-2-balanced\n",
      "accuracy: 0.8286090969017799\n",
      "f1: 0.336734693877551\n",
      "100-entropy-11-2-balanced_subsample\n",
      "accuracy: 0.8246539222148979\n",
      "f1: 0.3383084577114428\n",
      "100-entropy-11-4-None\n",
      "accuracy: 0.8193803559657218\n",
      "f1: 0.09868421052631579\n",
      "100-entropy-11-4-balanced\n",
      "accuracy: 0.8312458800263678\n",
      "f1: 0.38461538461538464\n",
      "100-entropy-11-4-balanced_subsample\n",
      "accuracy: 0.8286090969017799\n",
      "f1: 0.3627450980392157\n",
      "100-entropy-11-6-None\n",
      "accuracy: 0.8187211601845749\n",
      "f1: 0.09240924092409239\n",
      "100-entropy-11-6-balanced\n",
      "accuracy: 0.8338826631509558\n",
      "f1: 0.41935483870967744\n",
      "100-entropy-11-6-balanced_subsample\n",
      "accuracy: 0.8319050758075148\n",
      "f1: 0.41108545034642036\n",
      "100-entropy-11-8-None\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.09966777408637874\n",
      "100-entropy-11-8-balanced\n",
      "accuracy: 0.8253131179960448\n",
      "f1: 0.41501103752759383\n",
      "100-entropy-11-8-balanced_subsample\n",
      "accuracy: 0.8220171390903098\n",
      "f1: 0.3918918918918919\n",
      "100-entropy-16-2-None\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.11726384364820847\n",
      "100-entropy-16-2-balanced\n",
      "accuracy: 0.8220171390903098\n",
      "f1: 0.14556962025316456\n",
      "100-entropy-16-2-balanced_subsample\n",
      "accuracy: 0.8206987475280159\n",
      "f1: 0.12820512820512822\n",
      "100-entropy-16-4-None\n",
      "accuracy: 0.8206987475280159\n",
      "f1: 0.1111111111111111\n",
      "100-entropy-16-4-balanced\n",
      "accuracy: 0.8226763348714569\n",
      "f1: 0.1671826625386997\n",
      "100-entropy-16-4-balanced_subsample\n",
      "accuracy: 0.8220171390903098\n",
      "f1: 0.14556962025316456\n",
      "100-entropy-16-6-None\n",
      "accuracy: 0.8193803559657218\n",
      "f1: 0.09271523178807946\n",
      "100-entropy-16-6-balanced\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.25507246376811593\n",
      "100-entropy-16-6-balanced_subsample\n",
      "accuracy: 0.8319050758075148\n",
      "f1: 0.27762039660056653\n",
      "100-entropy-16-8-None\n",
      "accuracy: 0.8200395517468688\n",
      "f1: 0.11074918566775244\n",
      "100-entropy-16-8-balanced\n",
      "accuracy: 0.8286090969017799\n",
      "f1: 0.28571428571428575\n",
      "100-entropy-16-8-balanced_subsample\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.307277628032345\n",
      "100-entropy-20-2-None\n",
      "accuracy: 0.8226763348714569\n",
      "f1: 0.14603174603174604\n",
      "100-entropy-20-2-balanced\n",
      "accuracy: 0.8187211601845749\n",
      "f1: 0.08637873754152824\n",
      "100-entropy-20-2-balanced_subsample\n",
      "accuracy: 0.8220171390903098\n",
      "f1: 0.11764705882352941\n",
      "100-entropy-20-4-None\n",
      "accuracy: 0.8239947264337508\n",
      "f1: 0.14696485623003194\n",
      "100-entropy-20-4-balanced\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.13968253968253969\n",
      "100-entropy-20-4-balanced_subsample\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.134185303514377\n",
      "100-entropy-20-6-None\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.10561056105610561\n",
      "100-entropy-20-6-balanced\n",
      "accuracy: 0.8272907053394858\n",
      "f1: 0.23391812865497078\n",
      "100-entropy-20-6-balanced_subsample\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.22222222222222224\n",
      "100-entropy-20-8-None\n",
      "accuracy: 0.8200395517468688\n",
      "f1: 0.099009900990099\n",
      "100-entropy-20-8-balanced\n",
      "accuracy: 0.8332234673698088\n",
      "f1: 0.2913165266106443\n",
      "100-entropy-20-8-balanced_subsample\n",
      "accuracy: 0.8345418589321029\n",
      "f1: 0.3047091412742382\n",
      "150-gini-8-2-None\n",
      "accuracy: 0.8174027686222808\n",
      "f1: 0.054607508532423216\n",
      "150-gini-8-2-balanced\n",
      "accuracy: 0.8055372445616348\n",
      "f1: 0.49050086355785844\n",
      "150-gini-8-2-balanced_subsample\n",
      "accuracy: 0.7969676994067239\n",
      "f1: 0.4671280276816609\n",
      "150-gini-8-4-None\n",
      "accuracy: 0.8193803559657218\n",
      "f1: 0.06802721088435375\n",
      "150-gini-8-4-balanced\n",
      "accuracy: 0.7982860909690178\n",
      "f1: 0.4882943143812709\n",
      "150-gini-8-4-balanced_subsample\n",
      "accuracy: 0.7903757415952538\n",
      "f1: 0.4786885245901639\n",
      "150-gini-8-6-None\n",
      "accuracy: 0.8187211601845749\n",
      "f1: 0.06143344709897611\n",
      "150-gini-8-6-balanced\n",
      "accuracy: 0.7963085036255768\n",
      "f1: 0.4841402337228714\n",
      "150-gini-8-6-balanced_subsample\n",
      "accuracy: 0.7956493078444298\n",
      "f1: 0.4816053511705686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150-gini-8-8-None\n",
      "accuracy: 0.8180619644034278\n",
      "f1: 0.05479452054794521\n",
      "150-gini-8-8-balanced\n",
      "accuracy: 0.8009228740936059\n",
      "f1: 0.4932885906040268\n",
      "150-gini-8-8-balanced_subsample\n",
      "accuracy: 0.8009228740936059\n",
      "f1: 0.49498327759197325\n",
      "150-gini-11-2-None\n",
      "accuracy: 0.8174027686222808\n",
      "f1: 0.07357859531772575\n",
      "150-gini-11-2-balanced\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.3506172839506173\n",
      "150-gini-11-2-balanced_subsample\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.35820895522388063\n",
      "150-gini-11-4-None\n",
      "accuracy: 0.8200395517468688\n",
      "f1: 0.08695652173913043\n",
      "150-gini-11-4-balanced\n",
      "accuracy: 0.8338826631509558\n",
      "f1: 0.3883495145631068\n",
      "150-gini-11-4-balanced_subsample\n",
      "accuracy: 0.8319050758075148\n",
      "f1: 0.38554216867469887\n",
      "150-gini-11-6-None\n",
      "accuracy: 0.8174027686222808\n",
      "f1: 0.07357859531772575\n",
      "150-gini-11-6-balanced\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.3827751196172249\n",
      "150-gini-11-6-balanced_subsample\n",
      "accuracy: 0.8345418589321029\n",
      "f1: 0.42032332563510394\n",
      "150-gini-11-8-None\n",
      "accuracy: 0.8174027686222808\n",
      "f1: 0.061016949152542375\n",
      "150-gini-11-8-balanced\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.4142538975501113\n",
      "150-gini-11-8-balanced_subsample\n",
      "accuracy: 0.8286090969017799\n",
      "f1: 0.4222222222222222\n",
      "150-gini-16-2-None\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.09966777408637874\n",
      "150-gini-16-2-balanced\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.19076923076923077\n",
      "150-gini-16-2-balanced_subsample\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.2127659574468085\n",
      "150-gini-16-4-None\n",
      "accuracy: 0.8193803559657218\n",
      "f1: 0.11038961038961038\n",
      "150-gini-16-4-balanced\n",
      "accuracy: 0.8279499011206328\n",
      "f1: 0.23460410557184752\n",
      "150-gini-16-4-balanced_subsample\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.2507288629737609\n",
      "150-gini-16-6-None\n",
      "accuracy: 0.8193803559657218\n",
      "f1: 0.09868421052631579\n",
      "150-gini-16-6-balanced\n",
      "accuracy: 0.8365194462755439\n",
      "f1: 0.28735632183908044\n",
      "150-gini-16-6-balanced_subsample\n",
      "accuracy: 0.8345418589321029\n",
      "f1: 0.27665706051873196\n",
      "150-gini-16-8-None\n",
      "accuracy: 0.8160843770599868\n",
      "f1: 0.08524590163934426\n",
      "150-gini-16-8-balanced\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.324468085106383\n",
      "150-gini-16-8-balanced_subsample\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.31830238726790444\n",
      "150-gini-20-2-None\n",
      "accuracy: 0.8200395517468688\n",
      "f1: 0.09302325581395347\n",
      "150-gini-20-2-balanced\n",
      "accuracy: 0.8220171390903098\n",
      "f1: 0.12337662337662336\n",
      "150-gini-20-2-balanced_subsample\n",
      "accuracy: 0.8206987475280159\n",
      "f1: 0.1111111111111111\n",
      "150-gini-20-4-None\n",
      "accuracy: 0.8174027686222808\n",
      "f1: 0.09180327868852457\n",
      "150-gini-20-4-balanced\n",
      "accuracy: 0.8253131179960448\n",
      "f1: 0.17445482866043613\n",
      "150-gini-20-4-balanced_subsample\n",
      "accuracy: 0.8319050758075148\n",
      "f1: 0.2105263157894737\n",
      "150-gini-20-6-None\n",
      "accuracy: 0.8187211601845749\n",
      "f1: 0.0983606557377049\n",
      "150-gini-20-6-balanced\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.24404761904761904\n",
      "150-gini-20-6-balanced_subsample\n",
      "accuracy: 0.8319050758075148\n",
      "f1: 0.247787610619469\n",
      "150-gini-20-8-None\n",
      "accuracy: 0.8180619644034278\n",
      "f1: 0.09803921568627451\n",
      "150-gini-20-8-balanced\n",
      "accuracy: 0.8279499011206328\n",
      "f1: 0.24783861671469737\n",
      "150-gini-20-8-balanced_subsample\n",
      "accuracy: 0.8332234673698088\n",
      "f1: 0.28732394366197184\n",
      "150-entropy-8-2-None\n",
      "accuracy: 0.8180619644034278\n",
      "f1: 0.06756756756756757\n",
      "150-entropy-8-2-balanced\n",
      "accuracy: 0.8055372445616348\n",
      "f1: 0.5091514143094842\n",
      "150-entropy-8-2-balanced_subsample\n",
      "accuracy: 0.8068556361239289\n",
      "f1: 0.509212730318258\n",
      "150-entropy-8-4-None\n",
      "accuracy: 0.8174027686222808\n",
      "f1: 0.061016949152542375\n",
      "150-entropy-8-4-balanced\n",
      "accuracy: 0.7982860909690178\n",
      "f1: 0.47058823529411764\n",
      "150-entropy-8-4-balanced_subsample\n",
      "accuracy: 0.7969676994067239\n",
      "f1: 0.4779661016949152\n",
      "150-entropy-8-6-None\n",
      "accuracy: 0.8174027686222808\n",
      "f1: 0.061016949152542375\n",
      "150-entropy-8-6-balanced\n",
      "accuracy: 0.8009228740936059\n",
      "f1: 0.5\n",
      "150-entropy-8-6-balanced_subsample\n",
      "accuracy: 0.7943309162821358\n",
      "f1: 0.48172757475083056\n",
      "150-entropy-8-8-None\n",
      "accuracy: 0.8174027686222808\n",
      "f1: 0.061016949152542375\n",
      "150-entropy-8-8-balanced\n",
      "accuracy: 0.7963085036255768\n",
      "f1: 0.49093904448105435\n",
      "150-entropy-8-8-balanced_subsample\n",
      "accuracy: 0.7936717205009888\n",
      "f1: 0.4860426929392447\n",
      "150-entropy-11-2-None\n",
      "accuracy: 0.8220171390903098\n",
      "f1: 0.11184210526315788\n",
      "150-entropy-11-2-balanced\n",
      "accuracy: 0.8319050758075148\n",
      "f1: 0.35443037974683544\n",
      "150-entropy-11-2-balanced_subsample\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.34739454094292804\n",
      "150-entropy-11-4-None\n",
      "accuracy: 0.8180619644034278\n",
      "f1: 0.08609271523178808\n",
      "150-entropy-11-4-balanced\n",
      "accuracy: 0.8279499011206328\n",
      "f1: 0.3680387409200968\n",
      "150-entropy-11-4-balanced_subsample\n",
      "accuracy: 0.8246539222148979\n",
      "f1: 0.3383084577114428\n",
      "150-entropy-11-6-None\n",
      "accuracy: 0.8187211601845749\n",
      "f1: 0.08637873754152824\n",
      "150-entropy-11-6-balanced\n",
      "accuracy: 0.8384970336189849\n",
      "f1: 0.43155452436194897\n",
      "150-entropy-11-6-balanced_subsample\n",
      "accuracy: 0.8358602504943968\n",
      "f1: 0.42494226327944573\n",
      "150-entropy-11-8-None\n",
      "accuracy: 0.8187211601845749\n",
      "f1: 0.08026755852842811\n",
      "150-entropy-11-8-balanced\n",
      "accuracy: 0.8272907053394858\n",
      "f1: 0.41517857142857145\n",
      "150-entropy-11-8-balanced_subsample\n",
      "accuracy: 0.8259723137771918\n",
      "f1: 0.4054054054054054\n",
      "150-entropy-16-2-None\n",
      "accuracy: 0.8200395517468688\n",
      "f1: 0.10491803278688525\n",
      "150-entropy-16-2-balanced\n",
      "accuracy: 0.8220171390903098\n",
      "f1: 0.1346153846153846\n",
      "150-entropy-16-2-balanced_subsample\n",
      "accuracy: 0.8220171390903098\n",
      "f1: 0.1346153846153846\n",
      "150-entropy-16-4-None\n",
      "accuracy: 0.8220171390903098\n",
      "f1: 0.11764705882352941\n",
      "150-entropy-16-4-balanced\n",
      "accuracy: 0.8239947264337508\n",
      "f1: 0.17337461300309598\n",
      "150-entropy-16-4-balanced_subsample\n",
      "accuracy: 0.8233355306526038\n",
      "f1: 0.1625\n",
      "150-entropy-16-6-None\n",
      "accuracy: 0.8180619644034278\n",
      "f1: 0.08\n",
      "150-entropy-16-6-balanced\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.24117647058823527\n",
      "150-entropy-16-6-balanced_subsample\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.25507246376811593\n",
      "150-entropy-16-8-None\n",
      "accuracy: 0.8200395517468688\n",
      "f1: 0.10491803278688525\n",
      "150-entropy-16-8-balanced\n",
      "accuracy: 0.8272907053394858\n",
      "f1: 0.28804347826086957\n",
      "150-entropy-16-8-balanced_subsample\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.29508196721311475\n",
      "150-entropy-20-2-None\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.12297734627831713\n",
      "150-entropy-20-2-balanced\n",
      "accuracy: 0.8160843770599868\n",
      "f1: 0.07308970099667773\n",
      "150-entropy-20-2-balanced_subsample\n",
      "accuracy: 0.8193803559657218\n",
      "f1: 0.09271523178807946\n",
      "150-entropy-20-4-None\n",
      "accuracy: 0.8226763348714569\n",
      "f1: 0.12944983818770228\n",
      "150-entropy-20-4-balanced\n",
      "accuracy: 0.8233355306526038\n",
      "f1: 0.14102564102564102\n",
      "150-entropy-20-4-balanced_subsample\n",
      "accuracy: 0.8233355306526038\n",
      "f1: 0.1464968152866242\n",
      "150-entropy-20-6-None\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.11147540983606558\n",
      "150-entropy-20-6-balanced\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.22754491017964068\n",
      "150-entropy-20-6-balanced_subsample\n",
      "accuracy: 0.8253131179960448\n",
      "f1: 0.18960244648318042\n",
      "150-entropy-20-8-None\n",
      "accuracy: 0.8187211601845749\n",
      "f1: 0.08637873754152824\n",
      "150-entropy-20-8-balanced\n",
      "accuracy: 0.8338826631509558\n",
      "f1: 0.29213483146067415\n",
      "150-entropy-20-8-balanced_subsample\n",
      "accuracy: 0.8378378378378378\n",
      "f1: 0.32044198895027626\n",
      "200-gini-8-2-None\n",
      "accuracy: 0.8174027686222808\n",
      "f1: 0.061016949152542375\n",
      "200-gini-8-2-balanced\n",
      "accuracy: 0.8068556361239289\n",
      "f1: 0.4868651488616462\n",
      "200-gini-8-2-balanced_subsample\n",
      "accuracy: 0.8029004614370469\n",
      "f1: 0.48359240069084625\n",
      "200-gini-8-4-None\n",
      "accuracy: 0.8187211601845749\n",
      "f1: 0.06779661016949153\n",
      "200-gini-8-4-balanced\n",
      "accuracy: 0.7996044825313118\n",
      "f1: 0.4882154882154882\n",
      "200-gini-8-4-balanced_subsample\n",
      "accuracy: 0.8009228740936059\n",
      "f1: 0.4932885906040268\n",
      "200-gini-8-6-None\n",
      "accuracy: 0.8180619644034278\n",
      "f1: 0.05479452054794521\n",
      "200-gini-8-6-balanced\n",
      "accuracy: 0.7976268951878708\n",
      "f1: 0.4805414551607445\n",
      "200-gini-8-6-balanced_subsample\n",
      "accuracy: 0.8002636783124588\n",
      "f1: 0.4838160136286201\n",
      "200-gini-8-8-None\n",
      "accuracy: 0.8167435728411339\n",
      "f1: 0.041379310344827586\n",
      "200-gini-8-8-balanced\n",
      "accuracy: 0.8029004614370469\n",
      "f1: 0.4923599320882852\n",
      "200-gini-8-8-balanced_subsample\n",
      "accuracy: 0.8029004614370469\n",
      "f1: 0.494077834179357\n",
      "200-gini-11-2-None\n",
      "accuracy: 0.8193803559657218\n",
      "f1: 0.09271523178807946\n",
      "200-gini-11-2-balanced\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.3667481662591687\n",
      "200-gini-11-2-balanced_subsample\n",
      "accuracy: 0.8319050758075148\n",
      "f1: 0.36408977556109723\n",
      "200-gini-11-4-None\n",
      "accuracy: 0.8206987475280159\n",
      "f1: 0.09333333333333332\n",
      "200-gini-11-4-balanced\n",
      "accuracy: 0.8345418589321029\n",
      "f1: 0.3922518159806296\n",
      "200-gini-11-4-balanced_subsample\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.3759036144578313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200-gini-11-6-None\n",
      "accuracy: 0.8180619644034278\n",
      "f1: 0.0738255033557047\n",
      "200-gini-11-6-balanced\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.3788968824940048\n",
      "200-gini-11-6-balanced_subsample\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.40375586854460094\n",
      "200-gini-11-8-None\n",
      "accuracy: 0.8180619644034278\n",
      "f1: 0.0738255033557047\n",
      "200-gini-11-8-balanced\n",
      "accuracy: 0.8253131179960448\n",
      "f1: 0.4097995545657016\n",
      "200-gini-11-8-balanced_subsample\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.40362811791383224\n",
      "200-gini-16-2-None\n",
      "accuracy: 0.8206987475280159\n",
      "f1: 0.09333333333333332\n",
      "200-gini-16-2-balanced\n",
      "accuracy: 0.8272907053394858\n",
      "f1: 0.19135802469135801\n",
      "200-gini-16-2-balanced_subsample\n",
      "accuracy: 0.8286090969017799\n",
      "f1: 0.20245398773006137\n",
      "200-gini-16-4-None\n",
      "accuracy: 0.8180619644034278\n",
      "f1: 0.09803921568627451\n",
      "200-gini-16-4-balanced\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.2359882005899705\n",
      "200-gini-16-4-balanced_subsample\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.23738872403560832\n",
      "200-gini-16-6-None\n",
      "accuracy: 0.8193803559657218\n",
      "f1: 0.09271523178807946\n",
      "200-gini-16-6-balanced\n",
      "accuracy: 0.8338826631509558\n",
      "f1: 0.28409090909090906\n",
      "200-gini-16-6-balanced_subsample\n",
      "accuracy: 0.8352010547132498\n",
      "f1: 0.28160919540229884\n",
      "200-gini-16-8-None\n",
      "accuracy: 0.8180619644034278\n",
      "f1: 0.09210526315789473\n",
      "200-gini-16-8-balanced\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.30601092896174864\n",
      "200-gini-16-8-balanced_subsample\n",
      "accuracy: 0.8312458800263678\n",
      "f1: 0.3081081081081081\n",
      "200-gini-20-2-None\n",
      "accuracy: 0.8200395517468688\n",
      "f1: 0.09302325581395347\n",
      "200-gini-20-2-balanced\n",
      "accuracy: 0.8220171390903098\n",
      "f1: 0.11764705882352941\n",
      "200-gini-20-2-balanced_subsample\n",
      "accuracy: 0.8200395517468688\n",
      "f1: 0.11650485436893204\n",
      "200-gini-20-4-None\n",
      "accuracy: 0.8160843770599868\n",
      "f1: 0.07920792079207921\n",
      "200-gini-20-4-balanced\n",
      "accuracy: 0.8286090969017799\n",
      "f1: 0.19753086419753088\n",
      "200-gini-20-4-balanced_subsample\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.20923076923076922\n",
      "200-gini-20-6-None\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.10561056105610561\n",
      "200-gini-20-6-balanced\n",
      "accuracy: 0.8312458800263678\n",
      "f1: 0.23353293413173654\n",
      "200-gini-20-6-balanced_subsample\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.22222222222222224\n",
      "200-gini-20-8-None\n",
      "accuracy: 0.8187211601845749\n",
      "f1: 0.0983606557377049\n",
      "200-gini-20-8-balanced\n",
      "accuracy: 0.8279499011206328\n",
      "f1: 0.23460410557184752\n",
      "200-gini-20-8-balanced_subsample\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.27840909090909094\n",
      "200-entropy-8-2-None\n",
      "accuracy: 0.8174027686222808\n",
      "f1: 0.06734006734006735\n",
      "200-entropy-8-2-balanced\n",
      "accuracy: 0.8055372445616348\n",
      "f1: 0.5008460236886633\n",
      "200-entropy-8-2-balanced_subsample\n",
      "accuracy: 0.8055372445616348\n",
      "f1: 0.499151103565365\n",
      "200-entropy-8-4-None\n",
      "accuracy: 0.8167435728411339\n",
      "f1: 0.054421768707483\n",
      "200-entropy-8-4-balanced\n",
      "accuracy: 0.8055372445616348\n",
      "f1: 0.4722719141323792\n",
      "200-entropy-8-4-balanced_subsample\n",
      "accuracy: 0.7989452867501649\n",
      "f1: 0.47140381282495664\n",
      "200-entropy-8-6-None\n",
      "accuracy: 0.8154251812788398\n",
      "f1: 0.0410958904109589\n",
      "200-entropy-8-6-balanced\n",
      "accuracy: 0.8048780487804879\n",
      "f1: 0.4931506849315068\n",
      "200-entropy-8-6-balanced_subsample\n",
      "accuracy: 0.7989452867501649\n",
      "f1: 0.48392554991539766\n",
      "200-entropy-8-8-None\n",
      "accuracy: 0.8187211601845749\n",
      "f1: 0.07407407407407408\n",
      "200-entropy-8-8-balanced\n",
      "accuracy: 0.7976268951878708\n",
      "f1: 0.48747913188647746\n",
      "200-entropy-8-8-balanced_subsample\n",
      "accuracy: 0.7989452867501649\n",
      "f1: 0.49081803005008345\n",
      "200-entropy-11-2-None\n",
      "accuracy: 0.8206987475280159\n",
      "f1: 0.09933774834437085\n",
      "200-entropy-11-2-balanced\n",
      "accuracy: 0.8319050758075148\n",
      "f1: 0.35443037974683544\n",
      "200-entropy-11-2-balanced_subsample\n",
      "accuracy: 0.8272907053394858\n",
      "f1: 0.3417085427135678\n",
      "200-entropy-11-4-None\n",
      "accuracy: 0.8206987475280159\n",
      "f1: 0.10526315789473684\n",
      "200-entropy-11-4-balanced\n",
      "accuracy: 0.8279499011206328\n",
      "f1: 0.3523573200992556\n",
      "200-entropy-11-4-balanced_subsample\n",
      "accuracy: 0.8286090969017799\n",
      "f1: 0.3564356435643564\n",
      "200-entropy-11-6-None\n",
      "accuracy: 0.8193803559657218\n",
      "f1: 0.09271523178807946\n",
      "200-entropy-11-6-balanced\n",
      "accuracy: 0.8332234673698088\n",
      "f1: 0.40189125295508277\n",
      "200-entropy-11-6-balanced_subsample\n",
      "accuracy: 0.8319050758075148\n",
      "f1: 0.3971631205673759\n",
      "200-entropy-11-8-None\n",
      "accuracy: 0.8193803559657218\n",
      "f1: 0.09271523178807946\n",
      "200-entropy-11-8-balanced\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.423162583518931\n",
      "200-entropy-11-8-balanced_subsample\n",
      "accuracy: 0.8239947264337508\n",
      "f1: 0.40268456375838924\n",
      "200-entropy-16-2-None\n",
      "accuracy: 0.8206987475280159\n",
      "f1: 0.10526315789473684\n",
      "200-entropy-16-2-balanced\n",
      "accuracy: 0.8220171390903098\n",
      "f1: 0.12903225806451613\n",
      "200-entropy-16-2-balanced_subsample\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.134185303514377\n",
      "200-entropy-16-4-None\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.11726384364820847\n",
      "200-entropy-16-4-balanced\n",
      "accuracy: 0.8233355306526038\n",
      "f1: 0.1625\n",
      "200-entropy-16-4-balanced_subsample\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.1557632398753894\n",
      "200-entropy-16-6-None\n",
      "accuracy: 0.8200395517468688\n",
      "f1: 0.09302325581395347\n",
      "200-entropy-16-6-balanced\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.23738872403560832\n",
      "200-entropy-16-6-balanced_subsample\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.2573099415204678\n",
      "200-entropy-16-8-None\n",
      "accuracy: 0.8187211601845749\n",
      "f1: 0.08637873754152824\n",
      "200-entropy-16-8-balanced\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.28729281767955805\n",
      "200-entropy-16-8-balanced_subsample\n",
      "accuracy: 0.8312458800263678\n",
      "f1: 0.2888888888888889\n",
      "200-entropy-20-2-None\n",
      "accuracy: 0.8226763348714569\n",
      "f1: 0.12377850162866448\n",
      "200-entropy-20-2-balanced\n",
      "accuracy: 0.8154251812788398\n",
      "f1: 0.06666666666666668\n",
      "200-entropy-20-2-balanced_subsample\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.09364548494983277\n",
      "200-entropy-20-4-None\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.11726384364820847\n",
      "200-entropy-20-4-balanced\n",
      "accuracy: 0.8246539222148979\n",
      "f1: 0.14743589743589744\n",
      "200-entropy-20-4-balanced_subsample\n",
      "accuracy: 0.8220171390903098\n",
      "f1: 0.14012738853503184\n",
      "200-entropy-20-6-None\n",
      "accuracy: 0.8187211601845749\n",
      "f1: 0.09240924092409239\n",
      "200-entropy-20-6-balanced\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.2054380664652568\n",
      "200-entropy-20-6-balanced_subsample\n",
      "accuracy: 0.8259723137771918\n",
      "f1: 0.19512195121951223\n",
      "200-entropy-20-8-None\n",
      "accuracy: 0.8193803559657218\n",
      "f1: 0.08666666666666666\n",
      "200-entropy-20-8-balanced\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.276056338028169\n",
      "200-entropy-20-8-balanced_subsample\n",
      "accuracy: 0.8365194462755439\n",
      "f1: 0.2994350282485876\n",
      "300-gini-8-2-None\n",
      "accuracy: 0.8167435728411339\n",
      "f1: 0.04794520547945205\n",
      "300-gini-8-2-balanced\n",
      "accuracy: 0.8015820698747528\n",
      "f1: 0.48547008547008547\n",
      "300-gini-8-2-balanced_subsample\n",
      "accuracy: 0.8015820698747528\n",
      "f1: 0.47652173913043483\n",
      "300-gini-8-4-None\n",
      "accuracy: 0.8174027686222808\n",
      "f1: 0.054607508532423216\n",
      "300-gini-8-4-balanced\n",
      "accuracy: 0.8042188529993408\n",
      "f1: 0.49230769230769234\n",
      "300-gini-8-4-balanced_subsample\n",
      "accuracy: 0.7982860909690178\n",
      "f1: 0.4831081081081081\n",
      "300-gini-8-6-None\n",
      "accuracy: 0.8167435728411339\n",
      "f1: 0.041379310344827586\n",
      "300-gini-8-6-balanced\n",
      "accuracy: 0.7963085036255768\n",
      "f1: 0.47715736040609136\n",
      "300-gini-8-6-balanced_subsample\n",
      "accuracy: 0.8015820698747528\n",
      "f1: 0.4819277108433735\n",
      "300-gini-8-8-None\n",
      "accuracy: 0.8167435728411339\n",
      "f1: 0.041379310344827586\n",
      "300-gini-8-8-balanced\n",
      "accuracy: 0.8035596572181938\n",
      "f1: 0.48972602739726023\n",
      "300-gini-8-8-balanced_subsample\n",
      "accuracy: 0.8009228740936059\n",
      "f1: 0.484641638225256\n",
      "300-gini-11-2-None\n",
      "accuracy: 0.8193803559657218\n",
      "f1: 0.08666666666666666\n",
      "300-gini-11-2-balanced\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.37378640776699035\n",
      "300-gini-11-2-balanced_subsample\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.3712871287128713\n",
      "300-gini-11-4-None\n",
      "accuracy: 0.8187211601845749\n",
      "f1: 0.07407407407407408\n",
      "300-gini-11-4-balanced\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.38349514563106796\n",
      "300-gini-11-4-balanced_subsample\n",
      "accuracy: 0.8279499011206328\n",
      "f1: 0.3555555555555555\n",
      "300-gini-11-6-None\n",
      "accuracy: 0.8180619644034278\n",
      "f1: 0.0738255033557047\n",
      "300-gini-11-6-balanced\n",
      "accuracy: 0.8272907053394858\n",
      "f1: 0.3732057416267943\n",
      "300-gini-11-6-balanced_subsample\n",
      "accuracy: 0.8352010547132498\n",
      "f1: 0.4131455399061033\n",
      "300-gini-11-8-None\n",
      "accuracy: 0.8180619644034278\n",
      "f1: 0.0738255033557047\n",
      "300-gini-11-8-balanced\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.4073226544622426\n",
      "300-gini-11-8-balanced_subsample\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.41363636363636364\n",
      "300-gini-16-2-None\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.09966777408637874\n",
      "300-gini-16-2-balanced\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.20795107033639146\n",
      "300-gini-16-2-balanced_subsample\n",
      "accuracy: 0.8279499011206328\n",
      "f1: 0.2066869300911854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300-gini-16-4-None\n",
      "accuracy: 0.8200395517468688\n",
      "f1: 0.099009900990099\n",
      "300-gini-16-4-balanced\n",
      "accuracy: 0.8272907053394858\n",
      "f1: 0.22485207100591711\n",
      "300-gini-16-4-balanced_subsample\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.2314540059347181\n",
      "300-gini-16-6-None\n",
      "accuracy: 0.8206987475280159\n",
      "f1: 0.09933774834437085\n",
      "300-gini-16-6-balanced\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.26589595375722547\n",
      "300-gini-16-6-balanced_subsample\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.2543352601156069\n",
      "300-gini-16-8-None\n",
      "accuracy: 0.8187211601845749\n",
      "f1: 0.08637873754152824\n",
      "300-gini-16-8-balanced\n",
      "accuracy: 0.8319050758075148\n",
      "f1: 0.3013698630136986\n",
      "300-gini-16-8-balanced_subsample\n",
      "accuracy: 0.8332234673698088\n",
      "f1: 0.29916897506925205\n",
      "300-gini-20-2-None\n",
      "accuracy: 0.8193803559657218\n",
      "f1: 0.09271523178807946\n",
      "300-gini-20-2-balanced\n",
      "accuracy: 0.8233355306526038\n",
      "f1: 0.12987012987012989\n",
      "300-gini-20-2-balanced_subsample\n",
      "accuracy: 0.8206987475280159\n",
      "f1: 0.1111111111111111\n",
      "300-gini-20-4-None\n",
      "accuracy: 0.8167435728411339\n",
      "f1: 0.07947019867549668\n",
      "300-gini-20-4-balanced\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.2030769230769231\n",
      "300-gini-20-4-balanced_subsample\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.20370370370370372\n",
      "300-gini-20-6-None\n",
      "accuracy: 0.8180619644034278\n",
      "f1: 0.08\n",
      "300-gini-20-6-balanced\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.20060790273556234\n",
      "300-gini-20-6-balanced_subsample\n",
      "accuracy: 0.8286090969017799\n",
      "f1: 0.22155688622754494\n",
      "300-gini-20-8-None\n",
      "accuracy: 0.8206987475280159\n",
      "f1: 0.10526315789473684\n",
      "300-gini-20-8-balanced\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.24999999999999997\n",
      "300-gini-20-8-balanced_subsample\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.27011494252873564\n",
      "300-entropy-8-2-None\n",
      "accuracy: 0.8160843770599868\n",
      "f1: 0.054237288135593226\n",
      "300-entropy-8-2-balanced\n",
      "accuracy: 0.8029004614370469\n",
      "f1: 0.4991624790619766\n",
      "300-entropy-8-2-balanced_subsample\n",
      "accuracy: 0.8042188529993408\n",
      "f1: 0.49230769230769234\n",
      "300-entropy-8-4-None\n",
      "accuracy: 0.8180619644034278\n",
      "f1: 0.061224489795918366\n",
      "300-entropy-8-4-balanced\n",
      "accuracy: 0.8042188529993408\n",
      "f1: 0.48347826086956525\n",
      "300-entropy-8-4-balanced_subsample\n",
      "accuracy: 0.7976268951878708\n",
      "f1: 0.47700170357751276\n",
      "300-entropy-8-6-None\n",
      "accuracy: 0.8154251812788398\n",
      "f1: 0.0410958904109589\n",
      "300-entropy-8-6-balanced\n",
      "accuracy: 0.8015820698747528\n",
      "f1: 0.4906937394247039\n",
      "300-entropy-8-6-balanced_subsample\n",
      "accuracy: 0.7969676994067239\n",
      "f1: 0.48148148148148145\n",
      "300-entropy-8-8-None\n",
      "accuracy: 0.8174027686222808\n",
      "f1: 0.061016949152542375\n",
      "300-entropy-8-8-balanced\n",
      "accuracy: 0.7969676994067239\n",
      "f1: 0.48837209302325585\n",
      "300-entropy-8-8-balanced_subsample\n",
      "accuracy: 0.7930125247198417\n",
      "f1: 0.47491638795986624\n",
      "300-entropy-11-2-None\n",
      "accuracy: 0.8220171390903098\n",
      "f1: 0.11184210526315788\n",
      "300-entropy-11-2-balanced\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.34848484848484845\n",
      "300-entropy-11-2-balanced_subsample\n",
      "accuracy: 0.8272907053394858\n",
      "f1: 0.3383838383838384\n",
      "300-entropy-11-4-None\n",
      "accuracy: 0.8193803559657218\n",
      "f1: 0.09271523178807946\n",
      "300-entropy-11-4-balanced\n",
      "accuracy: 0.8226763348714569\n",
      "f1: 0.3325062034739454\n",
      "300-entropy-11-4-balanced_subsample\n",
      "accuracy: 0.8253131179960448\n",
      "f1: 0.3424317617866005\n",
      "300-entropy-11-6-None\n",
      "accuracy: 0.8200395517468688\n",
      "f1: 0.08695652173913043\n",
      "300-entropy-11-6-balanced\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.3952941176470588\n",
      "300-entropy-11-6-balanced_subsample\n",
      "accuracy: 0.8312458800263678\n",
      "f1: 0.39906103286384975\n",
      "300-entropy-11-8-None\n",
      "accuracy: 0.8200395517468688\n",
      "f1: 0.099009900990099\n",
      "300-entropy-11-8-balanced\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.4037122969837587\n",
      "300-entropy-11-8-balanced_subsample\n",
      "accuracy: 0.8279499011206328\n",
      "f1: 0.39722863741339487\n",
      "300-entropy-16-2-None\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.11147540983606558\n",
      "300-entropy-16-2-balanced\n",
      "accuracy: 0.8206987475280159\n",
      "f1: 0.11688311688311688\n",
      "300-entropy-16-2-balanced_subsample\n",
      "accuracy: 0.8206987475280159\n",
      "f1: 0.1111111111111111\n",
      "300-entropy-16-4-None\n",
      "accuracy: 0.8220171390903098\n",
      "f1: 0.12337662337662336\n",
      "300-entropy-16-4-balanced\n",
      "accuracy: 0.8246539222148979\n",
      "f1: 0.17391304347826084\n",
      "300-entropy-16-4-balanced_subsample\n",
      "accuracy: 0.8259723137771918\n",
      "f1: 0.18012422360248448\n",
      "300-entropy-16-6-None\n",
      "accuracy: 0.8187211601845749\n",
      "f1: 0.09240924092409239\n",
      "300-entropy-16-6-balanced\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.23738872403560832\n",
      "300-entropy-16-6-balanced_subsample\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.2573099415204678\n",
      "300-entropy-16-8-None\n",
      "accuracy: 0.8200395517468688\n",
      "f1: 0.099009900990099\n",
      "300-entropy-16-8-balanced\n",
      "accuracy: 0.8332234673698088\n",
      "f1: 0.29916897506925205\n",
      "300-entropy-16-8-balanced_subsample\n",
      "accuracy: 0.8312458800263678\n",
      "f1: 0.2768361581920904\n",
      "300-entropy-20-2-None\n",
      "accuracy: 0.8233355306526038\n",
      "f1: 0.13548387096774195\n",
      "300-entropy-20-2-balanced\n",
      "accuracy: 0.8167435728411339\n",
      "f1: 0.06711409395973156\n",
      "300-entropy-20-2-balanced_subsample\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.09966777408637874\n",
      "300-entropy-20-4-None\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.11147540983606558\n",
      "300-entropy-20-4-balanced\n",
      "accuracy: 0.8233355306526038\n",
      "f1: 0.14102564102564102\n",
      "300-entropy-20-4-balanced_subsample\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.12297734627831713\n",
      "300-entropy-20-6-None\n",
      "accuracy: 0.8220171390903098\n",
      "f1: 0.10596026490066225\n",
      "300-entropy-20-6-balanced\n",
      "accuracy: 0.8246539222148979\n",
      "f1: 0.18902439024390244\n",
      "300-entropy-20-6-balanced_subsample\n",
      "accuracy: 0.8272907053394858\n",
      "f1: 0.20606060606060606\n",
      "300-entropy-20-8-None\n",
      "accuracy: 0.8193803559657218\n",
      "f1: 0.09868421052631579\n",
      "300-entropy-20-8-balanced\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.26285714285714284\n",
      "300-entropy-20-8-balanced_subsample\n",
      "accuracy: 0.8358602504943968\n",
      "f1: 0.2824207492795389\n",
      "400-gini-8-2-None\n",
      "accuracy: 0.8167435728411339\n",
      "f1: 0.041379310344827586\n",
      "400-gini-8-2-balanced\n",
      "accuracy: 0.8009228740936059\n",
      "f1: 0.47750865051903113\n",
      "400-gini-8-2-balanced_subsample\n",
      "accuracy: 0.8035596572181938\n",
      "f1: 0.4844290657439447\n",
      "400-gini-8-4-None\n",
      "accuracy: 0.8167435728411339\n",
      "f1: 0.04794520547945205\n",
      "400-gini-8-4-balanced\n",
      "accuracy: 0.8068556361239289\n",
      "f1: 0.495697074010327\n",
      "400-gini-8-4-balanced_subsample\n",
      "accuracy: 0.8042188529993408\n",
      "f1: 0.4852686308492201\n",
      "400-gini-8-6-None\n",
      "accuracy: 0.8160843770599868\n",
      "f1: 0.03460207612456747\n",
      "400-gini-8-6-balanced\n",
      "accuracy: 0.8015820698747528\n",
      "f1: 0.48547008547008547\n",
      "400-gini-8-6-balanced_subsample\n",
      "accuracy: 0.8042188529993408\n",
      "f1: 0.48347826086956525\n",
      "400-gini-8-8-None\n",
      "accuracy: 0.8160843770599868\n",
      "f1: 0.03460207612456747\n",
      "400-gini-8-8-balanced\n",
      "accuracy: 0.8048780487804879\n",
      "f1: 0.4896551724137931\n",
      "400-gini-8-8-balanced_subsample\n",
      "accuracy: 0.8009228740936059\n",
      "f1: 0.4828767123287671\n",
      "400-gini-11-2-None\n",
      "accuracy: 0.8187211601845749\n",
      "f1: 0.08026755852842811\n",
      "400-gini-11-2-balanced\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.37073170731707317\n",
      "400-gini-11-2-balanced_subsample\n",
      "accuracy: 0.8312458800263678\n",
      "f1: 0.36318407960199\n",
      "400-gini-11-4-None\n",
      "accuracy: 0.8193803559657218\n",
      "f1: 0.07432432432432433\n",
      "400-gini-11-4-balanced\n",
      "accuracy: 0.8312458800263678\n",
      "f1: 0.3816425120772947\n",
      "400-gini-11-4-balanced_subsample\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.38186157517899755\n",
      "400-gini-11-6-None\n",
      "accuracy: 0.8200395517468688\n",
      "f1: 0.09302325581395347\n",
      "400-gini-11-6-balanced\n",
      "accuracy: 0.8272907053394858\n",
      "f1: 0.3791469194312797\n",
      "400-gini-11-6-balanced_subsample\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.39812646370023425\n",
      "400-gini-11-8-None\n",
      "accuracy: 0.8187211601845749\n",
      "f1: 0.07407407407407408\n",
      "400-gini-11-8-balanced\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.4109589041095891\n",
      "400-gini-11-8-balanced_subsample\n",
      "accuracy: 0.8286090969017799\n",
      "f1: 0.40092165898617504\n",
      "400-gini-16-2-None\n",
      "accuracy: 0.8206987475280159\n",
      "f1: 0.09933774834437085\n",
      "400-gini-16-2-balanced\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.2030769230769231\n",
      "400-gini-16-2-balanced_subsample\n",
      "accuracy: 0.8286090969017799\n",
      "f1: 0.20731707317073172\n",
      "400-gini-16-4-None\n",
      "accuracy: 0.8193803559657218\n",
      "f1: 0.09271523178807946\n",
      "400-gini-16-4-balanced\n",
      "accuracy: 0.8286090969017799\n",
      "f1: 0.23529411764705882\n",
      "400-gini-16-4-balanced_subsample\n",
      "accuracy: 0.8286090969017799\n",
      "f1: 0.2261904761904762\n",
      "400-gini-16-6-None\n",
      "accuracy: 0.8187211601845749\n",
      "f1: 0.08637873754152824\n",
      "400-gini-16-6-balanced\n",
      "accuracy: 0.8332234673698088\n",
      "f1: 0.26666666666666666\n",
      "400-gini-16-6-balanced_subsample\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.25936599423631124\n",
      "400-gini-16-8-None\n",
      "accuracy: 0.8200395517468688\n",
      "f1: 0.099009900990099\n",
      "400-gini-16-8-balanced\n",
      "accuracy: 0.8312458800263678\n",
      "f1: 0.2928176795580111\n",
      "400-gini-16-8-balanced_subsample\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.2905027932960894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400-gini-20-2-None\n",
      "accuracy: 0.8200395517468688\n",
      "f1: 0.09302325581395347\n",
      "400-gini-20-2-balanced\n",
      "accuracy: 0.8220171390903098\n",
      "f1: 0.11764705882352941\n",
      "400-gini-20-2-balanced_subsample\n",
      "accuracy: 0.8193803559657218\n",
      "f1: 0.10457516339869281\n",
      "400-gini-20-4-None\n",
      "accuracy: 0.8180619644034278\n",
      "f1: 0.08\n",
      "400-gini-20-4-balanced\n",
      "accuracy: 0.8286090969017799\n",
      "f1: 0.18750000000000003\n",
      "400-gini-20-4-balanced_subsample\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.1987577639751553\n",
      "400-gini-20-6-None\n",
      "accuracy: 0.8193803559657218\n",
      "f1: 0.09868421052631579\n",
      "400-gini-20-6-balanced\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.2127659574468085\n",
      "400-gini-20-6-balanced_subsample\n",
      "accuracy: 0.8279499011206328\n",
      "f1: 0.21148036253776434\n",
      "400-gini-20-8-None\n",
      "accuracy: 0.8180619644034278\n",
      "f1: 0.08\n",
      "400-gini-20-8-balanced\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.2543352601156069\n",
      "400-gini-20-8-balanced_subsample\n",
      "accuracy: 0.8332234673698088\n",
      "f1: 0.27507163323782235\n",
      "400-entropy-8-2-None\n",
      "accuracy: 0.8160843770599868\n",
      "f1: 0.054237288135593226\n",
      "400-entropy-8-2-balanced\n",
      "accuracy: 0.8029004614370469\n",
      "f1: 0.48888888888888893\n",
      "400-entropy-8-2-balanced_subsample\n",
      "accuracy: 0.8048780487804879\n",
      "f1: 0.4948805460750853\n",
      "400-entropy-8-4-None\n",
      "accuracy: 0.8180619644034278\n",
      "f1: 0.061224489795918366\n",
      "400-entropy-8-4-balanced\n",
      "accuracy: 0.8022412656558998\n",
      "f1: 0.4809688581314879\n",
      "400-entropy-8-4-balanced_subsample\n",
      "accuracy: 0.7982860909690178\n",
      "f1: 0.476027397260274\n",
      "400-entropy-8-6-None\n",
      "accuracy: 0.8154251812788398\n",
      "f1: 0.03448275862068966\n",
      "400-entropy-8-6-balanced\n",
      "accuracy: 0.8015820698747528\n",
      "f1: 0.4889643463497453\n",
      "400-entropy-8-6-balanced_subsample\n",
      "accuracy: 0.7969676994067239\n",
      "f1: 0.4761904761904762\n",
      "400-entropy-8-8-None\n",
      "accuracy: 0.8160843770599868\n",
      "f1: 0.0477815699658703\n",
      "400-entropy-8-8-balanced\n",
      "accuracy: 0.7969676994067239\n",
      "f1: 0.48148148148148145\n",
      "400-entropy-8-8-balanced_subsample\n",
      "accuracy: 0.7930125247198417\n",
      "f1: 0.47315436241610737\n",
      "400-entropy-11-2-None\n",
      "accuracy: 0.8220171390903098\n",
      "f1: 0.10596026490066225\n",
      "400-entropy-11-2-balanced\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.3493670886075949\n",
      "400-entropy-11-2-balanced_subsample\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.344139650872818\n",
      "400-entropy-11-4-None\n",
      "accuracy: 0.8193803559657218\n",
      "f1: 0.09271523178807946\n",
      "400-entropy-11-4-balanced\n",
      "accuracy: 0.8253131179960448\n",
      "f1: 0.345679012345679\n",
      "400-entropy-11-4-balanced_subsample\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.35380835380835385\n",
      "400-entropy-11-6-None\n",
      "accuracy: 0.8187211601845749\n",
      "f1: 0.07407407407407408\n",
      "400-entropy-11-6-balanced\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.38479809976247037\n",
      "400-entropy-11-6-balanced_subsample\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.39627039627039623\n",
      "400-entropy-11-8-None\n",
      "accuracy: 0.8193803559657218\n",
      "f1: 0.09271523178807946\n",
      "400-entropy-11-8-balanced\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.4147465437788018\n",
      "400-entropy-11-8-balanced_subsample\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.39907192575406025\n",
      "400-entropy-16-2-None\n",
      "accuracy: 0.8200395517468688\n",
      "f1: 0.099009900990099\n",
      "400-entropy-16-2-balanced\n",
      "accuracy: 0.8220171390903098\n",
      "f1: 0.12337662337662336\n",
      "400-entropy-16-2-balanced_subsample\n",
      "accuracy: 0.8220171390903098\n",
      "f1: 0.12337662337662336\n",
      "400-entropy-16-4-None\n",
      "accuracy: 0.8220171390903098\n",
      "f1: 0.11764705882352941\n",
      "400-entropy-16-4-balanced\n",
      "accuracy: 0.8239947264337508\n",
      "f1: 0.1523809523809524\n",
      "400-entropy-16-4-balanced_subsample\n",
      "accuracy: 0.8246539222148979\n",
      "f1: 0.16875\n",
      "400-entropy-16-6-None\n",
      "accuracy: 0.8193803559657218\n",
      "f1: 0.09271523178807946\n",
      "400-entropy-16-6-balanced\n",
      "accuracy: 0.8279499011206328\n",
      "f1: 0.21621621621621623\n",
      "400-entropy-16-6-balanced_subsample\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.23214285714285712\n",
      "400-entropy-16-8-None\n",
      "accuracy: 0.8200395517468688\n",
      "f1: 0.099009900990099\n",
      "400-entropy-16-8-balanced\n",
      "accuracy: 0.8319050758075148\n",
      "f1: 0.28969359331476324\n",
      "400-entropy-16-8-balanced_subsample\n",
      "accuracy: 0.8312458800263678\n",
      "f1: 0.28491620111731847\n",
      "400-entropy-20-2-None\n",
      "accuracy: 0.8233355306526038\n",
      "f1: 0.13548387096774195\n",
      "400-entropy-20-2-balanced\n",
      "accuracy: 0.8174027686222808\n",
      "f1: 0.07973421926910298\n",
      "400-entropy-20-2-balanced_subsample\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.09966777408637874\n",
      "400-entropy-20-4-None\n",
      "accuracy: 0.8206987475280159\n",
      "f1: 0.1111111111111111\n",
      "400-entropy-20-4-balanced\n",
      "accuracy: 0.8239947264337508\n",
      "f1: 0.14147909967845657\n",
      "400-entropy-20-4-balanced_subsample\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.12861736334405144\n",
      "400-entropy-20-6-None\n",
      "accuracy: 0.8180619644034278\n",
      "f1: 0.08\n",
      "400-entropy-20-6-balanced\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.2127659574468085\n",
      "400-entropy-20-6-balanced_subsample\n",
      "accuracy: 0.8272907053394858\n",
      "f1: 0.19631901840490798\n",
      "400-entropy-20-8-None\n",
      "accuracy: 0.8180619644034278\n",
      "f1: 0.09210526315789473\n",
      "400-entropy-20-8-balanced\n",
      "accuracy: 0.8319050758075148\n",
      "f1: 0.27350427350427353\n",
      "400-entropy-20-8-balanced_subsample\n",
      "accuracy: 0.8345418589321029\n",
      "f1: 0.28080229226361025\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "# RF\n",
    "estimators = [100, 150, 200, 300, 400]\n",
    "criterions = [\"gini\", \"entropy\"]\n",
    "depths = [8, 11, 16, 20]\n",
    "splits = [2, 4, 6, 8]\n",
    "weights = [None, \"balanced\", \"balanced_subsample\"]\n",
    "para_list = [estimators, criterions, depths, splits, weights]\n",
    "paras = list(itertools.product(*para_list))\n",
    "\n",
    "for para in paras:\n",
    "    rf = RandomForestClassifier(n_estimators=para[0], \n",
    "                                    criterion=para[1], \n",
    "                                    max_depth=para[2],\n",
    "                                    min_samples_split = para[3],\n",
    "                                    class_weight=para[4],\n",
    "                                    random_state=73514)\n",
    "    rf.fit(X_train, y_train)\n",
    "    para_string = \"-\".join([str(p) for p in para])\n",
    "    #dev set\n",
    "    y_dev_pred = rf.predict(X_dev)\n",
    "    y_dev_prob = rf.predict_proba(X_dev)\n",
    "    dev_path = \"../myclassify/test_res/RF-dev/RF-\" + para_string + \".txt\"\n",
    "    predict_for_test(y_dev, y_dev_pred, y_dev_prob, dev_path)\n",
    "\n",
    "    #test set\n",
    "    y_pred = rf.predict(X_test)\n",
    "    y_prob = rf.predict_proba(X_test)\n",
    "    test_path = \"../myclassify/test_res/RF-test/RF-\" + para_string + \".txt\"\n",
    "    predict_for_test(y_test, y_pred, y_prob, test_path)\n",
    "\n",
    "    #test result\n",
    "    print(para_string)\n",
    "    print(\"accuracy: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "    print(\"f1: {}\".format(f1_score(y_test, y_pred)))\n",
    "#     print(confusion_matrix(y_test, y_pred))\n",
    "    # predict_for_test(y_test, y_pred, rf.predict_proba(X_test), \"rf.txt\")\n",
    "    \n",
    "#best MAP/MRR for dev when 150-entropy-16-8-balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "penalty: l1; C: 0.01\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.20858895705521474\n",
      "penalty: l1; C: 0.1\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.27011494252873564\n",
      "penalty: l1; C: 1\n",
      "accuracy: 0.8286090969017799\n",
      "f1: 0.24418604651162787\n",
      "penalty: l1; C: 10\n",
      "accuracy: 0.8286090969017799\n",
      "f1: 0.24418604651162787\n",
      "penalty: l1; C: 100\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.24489795918367346\n",
      "penalty: l1; C: 1000\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.24489795918367346\n",
      "penalty: l2; C: 0.01\n",
      "accuracy: 0.8378378378378378\n",
      "f1: 0.28488372093023256\n",
      "penalty: l2; C: 0.1\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.2636103151862464\n",
      "penalty: l2; C: 1\n",
      "accuracy: 0.8279499011206328\n",
      "f1: 0.2434782608695652\n",
      "penalty: l2; C: 10\n",
      "accuracy: 0.8279499011206328\n",
      "f1: 0.239067055393586\n",
      "penalty: l2; C: 100\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.23768115942028983\n",
      "penalty: l2; C: 1000\n",
      "accuracy: 0.8279499011206328\n",
      "f1: 0.239067055393586\n"
     ]
    }
   ],
   "source": [
    "# LR\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# lr = LogisticRegression(C=3, class_weight=\"balanced\")\n",
    "# lr = LogisticRegression(C=0.01)\n",
    "penalties = [\"l1\", \"l2\"]\n",
    "cs = [0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "for para1 in penalties:\n",
    "    for para2 in cs:\n",
    "        lr = LogisticRegression(penalty = para1, C=para2, max_iter=1e8)\n",
    "        lr.fit(X_train, y_train)\n",
    "    \n",
    "        #dev set\n",
    "        y_dev_pred = lr.predict(X_dev)\n",
    "        y_dev_prob = lr.predict_proba(X_dev)\n",
    "        dev_path = \"../myclassify/test_res/LG-dev/LG-\" + str(para1) + \"-\" + str(para2) + \".txt\"\n",
    "        predict_for_test(y_dev, y_dev_pred, y_dev_prob, dev_path)\n",
    "\n",
    "        #test set\n",
    "        y_pred = lr.predict(X_test)\n",
    "        y_prob = lr.predict_proba(X_test)\n",
    "        test_path = \"../myclassify/test_res/LG-test/LG-\" + str(para1) + \"-\" + str(para2) + \".txt\"\n",
    "        predict_for_test(y_test, y_pred, y_prob, test_path)\n",
    "        \n",
    "        #test result\n",
    "        print(\"penalty: \" + str(para1) + \"; C: \" + str(para2))\n",
    "        print(\"accuracy: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "        print(\"f1: {}\".format(f1_score(y_test, y_pred)))\n",
    "#         print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "#best MAP/MRR for dev when l1-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with SIM features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_sim_train, y_sim_train = load_similarity_features(\"../data/features/glove_embedding_sentence_similarities_train_300.txt\")\n",
    "X_sim_dev, y_sim_dev = load_similarity_features(\"../data/features/glove_embedding_sentence_similarities_dev_300.txt\")\n",
    "X_sim_test, y_sim_test = load_similarity_features(\"../data/features/glove_embedding_sentence_similarities_test_300.txt\")\n",
    "\n",
    "# Only normalize the similarity scores\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(X_sim_train)\n",
    "X_sim_train = scaler.transform(X_sim_train)\n",
    "X_sim_dev = scaler.transform(X_sim_dev)\n",
    "X_sim_test = scaler.transform(X_sim_test)\n",
    "X_comb_scaledsim_train = np.hstack((X_train, X_sim_train))\n",
    "X_comb_scaledsim_dev = np.hstack((X_dev, X_sim_dev))\n",
    "X_comb_scaledsim_test = np.hstack((X_test, X_sim_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "penalty: l1; C: 0.01\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.23493975903614459\n",
      "penalty: l1; C: 0.1\n",
      "accuracy: 0.8411338167435728\n",
      "f1: 0.3573333333333333\n",
      "penalty: l1; C: 1\n",
      "accuracy: 0.8404746209624259\n",
      "f1: 0.35638297872340424\n",
      "penalty: l1; C: 10\n",
      "accuracy: 0.8417930125247198\n",
      "f1: 0.3782383419689119\n",
      "penalty: l1; C: 100\n",
      "accuracy: 0.8411338167435728\n",
      "f1: 0.370757180156658\n",
      "penalty: l1; C: 1000\n",
      "accuracy: 0.8411338167435728\n",
      "f1: 0.370757180156658\n",
      "penalty: l2; C: 0.01\n",
      "accuracy: 0.8437705998681608\n",
      "f1: 0.33983286908078\n",
      "penalty: l2; C: 0.1\n",
      "accuracy: 0.8411338167435728\n",
      "f1: 0.370757180156658\n",
      "penalty: l2; C: 1\n",
      "accuracy: 0.8398154251812788\n",
      "f1: 0.3622047244094488\n",
      "penalty: l2; C: 10\n",
      "accuracy: 0.8404746209624259\n",
      "f1: 0.36649214659685864\n",
      "penalty: l2; C: 100\n",
      "accuracy: 0.8404746209624259\n",
      "f1: 0.3697916666666667\n",
      "penalty: l2; C: 1000\n",
      "accuracy: 0.8398154251812788\n",
      "f1: 0.36553524804177545\n"
     ]
    }
   ],
   "source": [
    "penalties = [\"l1\", \"l2\"]\n",
    "cs = [0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "for para1 in penalties:\n",
    "    for para2 in cs:\n",
    "        lr = LogisticRegression(penalty = para1, C=para2, max_iter=1e8)\n",
    "        lr.fit(X_comb_scaledsim_train, y_train)\n",
    "    \n",
    "        #dev set\n",
    "        y_dev_pred = lr.predict(X_comb_scaledsim_dev)\n",
    "        y_dev_prob = lr.predict_proba(X_comb_scaledsim_dev)\n",
    "        dev_path = \"../myclassify/test_res/LGSIM-dev/LGSIM-\" + str(para1) + \"-\" + str(para2) + \".txt\"\n",
    "        predict_for_test(y_dev, y_dev_pred, y_dev_prob, dev_path)\n",
    "\n",
    "        #test set\n",
    "        y_pred = lr.predict(X_comb_scaledsim_test)\n",
    "        y_prob = lr.predict_proba(X_comb_scaledsim_test)\n",
    "        test_path = \"../myclassify/test_res/LGSIM-test/LGSIM-\" + str(para1) + \"-\" + str(para2) + \".txt\"\n",
    "        predict_for_test(y_test, y_pred, y_prob, test_path)\n",
    "        \n",
    "        #test result\n",
    "        print(\"penalty: \" + str(para1) + \"; C: \" + str(para2))\n",
    "        print(\"accuracy: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "        print(\"f1: {}\".format(f1_score(y_test, y_pred)))\n",
    "#         print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "#best for dev: l2-0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100-gini-8-2-None\n",
      "accuracy: 0.8220171390903098\n",
      "f1: 0.10596026490066225\n",
      "100-gini-8-2-balanced\n",
      "accuracy: 0.8141067897165458\n",
      "f1: 0.49462365591397855\n",
      "100-gini-8-2-balanced_subsample\n",
      "accuracy: 0.8174027686222808\n",
      "f1: 0.5097345132743364\n",
      "100-gini-8-4-None\n",
      "accuracy: 0.8220171390903098\n",
      "f1: 0.10596026490066225\n",
      "100-gini-8-4-balanced\n",
      "accuracy: 0.8127883981542519\n",
      "f1: 0.5069444444444444\n",
      "100-gini-8-4-balanced_subsample\n",
      "accuracy: 0.8187211601845749\n",
      "f1: 0.5166959578207382\n",
      "100-gini-8-6-None\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.11726384364820847\n",
      "100-gini-8-6-balanced\n",
      "accuracy: 0.8200395517468688\n",
      "f1: 0.521891418563923\n",
      "100-gini-8-6-balanced_subsample\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.5361552028218696\n",
      "100-gini-8-8-None\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.09966777408637874\n",
      "100-gini-8-8-balanced\n",
      "accuracy: 0.8206987475280159\n",
      "f1: 0.5211267605633803\n",
      "100-gini-8-8-balanced_subsample\n",
      "accuracy: 0.8239947264337508\n",
      "f1: 0.5257548845470693\n",
      "100-gini-11-2-None\n",
      "accuracy: 0.8246539222148979\n",
      "f1: 0.17901234567901236\n",
      "100-gini-11-2-balanced\n",
      "accuracy: 0.8272907053394858\n",
      "f1: 0.3761904761904762\n",
      "100-gini-11-2-balanced_subsample\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.392434988179669\n",
      "100-gini-11-4-None\n",
      "accuracy: 0.8239947264337508\n",
      "f1: 0.16822429906542058\n",
      "100-gini-11-4-balanced\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.4120370370370371\n",
      "100-gini-11-4-balanced_subsample\n",
      "accuracy: 0.8332234673698088\n",
      "f1: 0.4102564102564103\n",
      "100-gini-11-6-None\n",
      "accuracy: 0.8239947264337508\n",
      "f1: 0.17337461300309598\n",
      "100-gini-11-6-balanced\n",
      "accuracy: 0.8358602504943968\n",
      "f1: 0.4328018223234624\n",
      "100-gini-11-6-balanced_subsample\n",
      "accuracy: 0.8319050758075148\n",
      "f1: 0.4217687074829932\n",
      "100-gini-11-8-None\n",
      "accuracy: 0.8220171390903098\n",
      "f1: 0.12337662337662336\n",
      "100-gini-11-8-balanced\n",
      "accuracy: 0.8286090969017799\n",
      "f1: 0.43478260869565216\n",
      "100-gini-11-8-balanced_subsample\n",
      "accuracy: 0.8352010547132498\n",
      "f1: 0.44933920704845814\n",
      "100-gini-16-2-None\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.19076923076923077\n",
      "100-gini-16-2-balanced\n",
      "accuracy: 0.8259723137771918\n",
      "f1: 0.2413793103448276\n",
      "100-gini-16-2-balanced_subsample\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.2543352601156069\n",
      "100-gini-16-4-None\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.2134146341463415\n",
      "100-gini-16-4-balanced\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.3097826086956522\n",
      "100-gini-16-4-balanced_subsample\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.2905027932960894\n",
      "100-gini-16-6-None\n",
      "accuracy: 0.8272907053394858\n",
      "f1: 0.19135802469135801\n",
      "100-gini-16-6-balanced\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.3350785340314136\n",
      "100-gini-16-6-balanced_subsample\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.3109919571045576\n",
      "100-gini-16-8-None\n",
      "accuracy: 0.8253131179960448\n",
      "f1: 0.18461538461538463\n",
      "100-gini-16-8-balanced\n",
      "accuracy: 0.8358602504943968\n",
      "f1: 0.38213399503722084\n",
      "100-gini-16-8-balanced_subsample\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.34196891191709844\n",
      "100-gini-20-2-None\n",
      "accuracy: 0.8272907053394858\n",
      "f1: 0.19631901840490798\n",
      "100-gini-20-2-balanced\n",
      "accuracy: 0.8279499011206328\n",
      "f1: 0.19195046439628483\n",
      "100-gini-20-2-balanced_subsample\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.2127659574468085\n",
      "100-gini-20-4-None\n",
      "accuracy: 0.8319050758075148\n",
      "f1: 0.2433234421364985\n",
      "100-gini-20-4-balanced\n",
      "accuracy: 0.8312458800263678\n",
      "f1: 0.25581395348837205\n",
      "100-gini-20-4-balanced_subsample\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.25936599423631124\n",
      "100-gini-20-6-None\n",
      "accuracy: 0.8286090969017799\n",
      "f1: 0.18750000000000003\n",
      "100-gini-20-6-balanced\n",
      "accuracy: 0.8365194462755439\n",
      "f1: 0.31868131868131866\n",
      "100-gini-20-6-balanced_subsample\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.2752808988764045\n",
      "100-gini-20-8-None\n",
      "accuracy: 0.8253131179960448\n",
      "f1: 0.18461538461538463\n",
      "100-gini-20-8-balanced\n",
      "accuracy: 0.8345418589321029\n",
      "f1: 0.33066666666666666\n",
      "100-gini-20-8-balanced_subsample\n",
      "accuracy: 0.8358602504943968\n",
      "f1: 0.336\n",
      "100-entropy-8-2-None\n",
      "accuracy: 0.8226763348714569\n",
      "f1: 0.14603174603174604\n",
      "100-entropy-8-2-balanced\n",
      "accuracy: 0.8141067897165458\n",
      "f1: 0.5\n",
      "100-entropy-8-2-balanced_subsample\n",
      "accuracy: 0.8187211601845749\n",
      "f1: 0.5166959578207382\n",
      "100-entropy-8-4-None\n",
      "accuracy: 0.8200395517468688\n",
      "f1: 0.10491803278688525\n",
      "100-entropy-8-4-balanced\n",
      "accuracy: 0.8114700065919578\n",
      "f1: 0.5\n",
      "100-entropy-8-4-balanced_subsample\n",
      "accuracy: 0.8088332234673699\n",
      "f1: 0.49652777777777785\n",
      "100-entropy-8-6-None\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.11726384364820847\n",
      "100-entropy-8-6-balanced\n",
      "accuracy: 0.8147659854976929\n",
      "f1: 0.5061511423550088\n",
      "100-entropy-8-6-balanced_subsample\n",
      "accuracy: 0.8141067897165458\n",
      "f1: 0.49642857142857144\n",
      "100-entropy-8-8-None\n",
      "accuracy: 0.8200395517468688\n",
      "f1: 0.11074918566775244\n",
      "100-entropy-8-8-balanced\n",
      "accuracy: 0.8101516150296638\n",
      "f1: 0.4947368421052632\n",
      "100-entropy-8-8-balanced_subsample\n",
      "accuracy: 0.8108108108108109\n",
      "f1: 0.4938271604938272\n",
      "100-entropy-11-2-None\n",
      "accuracy: 0.8253131179960448\n",
      "f1: 0.17956656346749228\n",
      "100-entropy-11-2-balanced\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.37288135593220345\n",
      "100-entropy-11-2-balanced_subsample\n",
      "accuracy: 0.8259723137771918\n",
      "f1: 0.35922330097087374\n",
      "100-entropy-11-4-None\n",
      "accuracy: 0.8259723137771918\n",
      "f1: 0.169811320754717\n",
      "100-entropy-11-4-balanced\n",
      "accuracy: 0.8338826631509558\n",
      "f1: 0.3883495145631068\n",
      "100-entropy-11-4-balanced_subsample\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.3798076923076923\n",
      "100-entropy-11-6-None\n",
      "accuracy: 0.8233355306526038\n",
      "f1: 0.1728395061728395\n",
      "100-entropy-11-6-balanced\n",
      "accuracy: 0.8332234673698088\n",
      "f1: 0.42630385487528344\n",
      "100-entropy-11-6-balanced_subsample\n",
      "accuracy: 0.8286090969017799\n",
      "f1: 0.3953488372093023\n",
      "100-entropy-11-8-None\n",
      "accuracy: 0.8180619644034278\n",
      "f1: 0.12101910828025476\n",
      "100-entropy-11-8-balanced\n",
      "accuracy: 0.8246539222148979\n",
      "f1: 0.41409691629955947\n",
      "100-entropy-11-8-balanced_subsample\n",
      "accuracy: 0.8286090969017799\n",
      "f1: 0.4273127753303964\n",
      "100-entropy-16-2-None\n",
      "accuracy: 0.8226763348714569\n",
      "f1: 0.15141955835962145\n",
      "100-entropy-16-2-balanced\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.22686567164179103\n",
      "100-entropy-16-2-balanced_subsample\n",
      "accuracy: 0.8319050758075148\n",
      "f1: 0.23423423423423426\n",
      "100-entropy-16-4-None\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.20858895705521474\n",
      "100-entropy-16-4-balanced\n",
      "accuracy: 0.8279499011206328\n",
      "f1: 0.2521489971346705\n",
      "100-entropy-16-4-balanced_subsample\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.276056338028169\n",
      "100-entropy-16-6-None\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.21021021021021022\n",
      "100-entropy-16-6-balanced\n",
      "accuracy: 0.8338826631509558\n",
      "f1: 0.31521739130434784\n",
      "100-entropy-16-6-balanced_subsample\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.2880886426592798\n",
      "100-entropy-16-8-None\n",
      "accuracy: 0.8253131179960448\n",
      "f1: 0.18461538461538463\n",
      "100-entropy-16-8-balanced\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.3359173126614987\n",
      "100-entropy-16-8-balanced_subsample\n",
      "accuracy: 0.8319050758075148\n",
      "f1: 0.34782608695652173\n",
      "100-entropy-20-2-None\n",
      "accuracy: 0.8246539222148979\n",
      "f1: 0.17901234567901236\n",
      "100-entropy-20-2-balanced\n",
      "accuracy: 0.8239947264337508\n",
      "f1: 0.16300940438871472\n",
      "100-entropy-20-2-balanced_subsample\n",
      "accuracy: 0.8272907053394858\n",
      "f1: 0.19631901840490798\n",
      "100-entropy-20-4-None\n",
      "accuracy: 0.8286090969017799\n",
      "f1: 0.21686746987951805\n",
      "100-entropy-20-4-balanced\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.22418879056047195\n",
      "100-entropy-20-4-balanced_subsample\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.2054380664652568\n",
      "100-entropy-20-6-None\n",
      "accuracy: 0.8239947264337508\n",
      "f1: 0.18348623853211007\n",
      "100-entropy-20-6-balanced\n",
      "accuracy: 0.8391562294001318\n",
      "f1: 0.2988505747126437\n",
      "100-entropy-20-6-balanced_subsample\n",
      "accuracy: 0.8378378378378378\n",
      "f1: 0.3278688524590164\n",
      "100-entropy-20-8-None\n",
      "accuracy: 0.8272907053394858\n",
      "f1: 0.19135802469135801\n",
      "100-entropy-20-8-balanced\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.3202099737532808\n",
      "100-entropy-20-8-balanced_subsample\n",
      "accuracy: 0.8312458800263678\n",
      "f1: 0.3333333333333333\n",
      "150-gini-8-2-None\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.10561056105610561\n",
      "150-gini-8-2-balanced\n",
      "accuracy: 0.8206987475280159\n",
      "f1: 0.5054545454545455\n",
      "150-gini-8-2-balanced_subsample\n",
      "accuracy: 0.8220171390903098\n",
      "f1: 0.5126353790613718\n",
      "150-gini-8-4-None\n",
      "accuracy: 0.8220171390903098\n",
      "f1: 0.11184210526315788\n",
      "150-gini-8-4-balanced\n",
      "accuracy: 0.8193803559657218\n",
      "f1: 0.5107142857142858\n",
      "150-gini-8-4-balanced_subsample\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.5117117117117117\n",
      "150-gini-8-6-None\n",
      "accuracy: 0.8226763348714569\n",
      "f1: 0.12377850162866448\n",
      "150-gini-8-6-balanced\n",
      "accuracy: 0.8246539222148979\n",
      "f1: 0.5232974910394265\n",
      "150-gini-8-6-balanced_subsample\n",
      "accuracy: 0.8239947264337508\n",
      "f1: 0.5189189189189188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150-gini-8-8-None\n",
      "accuracy: 0.8239947264337508\n",
      "f1: 0.1188118811881188\n",
      "150-gini-8-8-balanced\n",
      "accuracy: 0.8174027686222808\n",
      "f1: 0.5097345132743364\n",
      "150-gini-8-8-balanced_subsample\n",
      "accuracy: 0.8233355306526038\n",
      "f1: 0.516245487364621\n",
      "150-gini-11-2-None\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.19076923076923077\n",
      "150-gini-11-2-balanced\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.3693045563549161\n",
      "150-gini-11-2-balanced_subsample\n",
      "accuracy: 0.8352010547132498\n",
      "f1: 0.3932038834951457\n",
      "150-gini-11-4-None\n",
      "accuracy: 0.8259723137771918\n",
      "f1: 0.1901840490797546\n",
      "150-gini-11-4-balanced\n",
      "accuracy: 0.8332234673698088\n",
      "f1: 0.4074941451990632\n",
      "150-gini-11-4-balanced_subsample\n",
      "accuracy: 0.8332234673698088\n",
      "f1: 0.4129930394431555\n",
      "150-gini-11-6-None\n",
      "accuracy: 0.8239947264337508\n",
      "f1: 0.16822429906542058\n",
      "150-gini-11-6-balanced\n",
      "accuracy: 0.8319050758075148\n",
      "f1: 0.42437923250564336\n",
      "150-gini-11-6-balanced_subsample\n",
      "accuracy: 0.8332234673698088\n",
      "f1: 0.42630385487528344\n",
      "150-gini-11-8-None\n",
      "accuracy: 0.8259723137771918\n",
      "f1: 0.1592356687898089\n",
      "150-gini-11-8-balanced\n",
      "accuracy: 0.8345418589321029\n",
      "f1: 0.45788336933045354\n",
      "150-gini-11-8-balanced_subsample\n",
      "accuracy: 0.8319050758075148\n",
      "f1: 0.4320712694877506\n",
      "150-gini-16-2-None\n",
      "accuracy: 0.8239947264337508\n",
      "f1: 0.17846153846153848\n",
      "150-gini-16-2-balanced\n",
      "accuracy: 0.8338826631509558\n",
      "f1: 0.26315789473684215\n",
      "150-gini-16-2-balanced_subsample\n",
      "accuracy: 0.8312458800263678\n",
      "f1: 0.2601156069364162\n",
      "150-gini-16-4-None\n",
      "accuracy: 0.8272907053394858\n",
      "f1: 0.20606060606060606\n",
      "150-gini-16-4-balanced\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.2905027932960894\n",
      "150-gini-16-4-balanced_subsample\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.29444444444444445\n",
      "150-gini-16-6-None\n",
      "accuracy: 0.8279499011206328\n",
      "f1: 0.2018348623853211\n",
      "150-gini-16-6-balanced\n",
      "accuracy: 0.8312458800263678\n",
      "f1: 0.32631578947368417\n",
      "150-gini-16-6-balanced_subsample\n",
      "accuracy: 0.8312458800263678\n",
      "f1: 0.31550802139037437\n",
      "150-gini-16-8-None\n",
      "accuracy: 0.8259723137771918\n",
      "f1: 0.19512195121951223\n",
      "150-gini-16-8-balanced\n",
      "accuracy: 0.8371786420566908\n",
      "f1: 0.38095238095238093\n",
      "150-gini-16-8-balanced_subsample\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.345360824742268\n",
      "150-gini-20-2-None\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.19076923076923077\n",
      "150-gini-20-2-balanced\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.20858895705521474\n",
      "150-gini-20-2-balanced_subsample\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.21406727828746178\n",
      "150-gini-20-4-None\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.2175226586102719\n",
      "150-gini-20-4-balanced\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.25936599423631124\n",
      "150-gini-20-4-balanced_subsample\n",
      "accuracy: 0.8319050758075148\n",
      "f1: 0.26512968299711814\n",
      "150-gini-20-6-None\n",
      "accuracy: 0.8259723137771918\n",
      "f1: 0.175\n",
      "150-gini-20-6-balanced\n",
      "accuracy: 0.8338826631509558\n",
      "f1: 0.3076923076923077\n",
      "150-gini-20-6-balanced_subsample\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.2678062678062678\n",
      "150-gini-20-8-None\n",
      "accuracy: 0.8253131179960448\n",
      "f1: 0.18960244648318042\n",
      "150-gini-20-8-balanced\n",
      "accuracy: 0.8352010547132498\n",
      "f1: 0.3243243243243243\n",
      "150-gini-20-8-balanced_subsample\n",
      "accuracy: 0.8345418589321029\n",
      "f1: 0.3412073490813648\n",
      "150-entropy-8-2-None\n",
      "accuracy: 0.8246539222148979\n",
      "f1: 0.14743589743589744\n",
      "150-entropy-8-2-balanced\n",
      "accuracy: 0.8187211601845749\n",
      "f1: 0.5080500894454383\n",
      "150-entropy-8-2-balanced_subsample\n",
      "accuracy: 0.8174027686222808\n",
      "f1: 0.5044722719141324\n",
      "150-entropy-8-4-None\n",
      "accuracy: 0.8187211601845749\n",
      "f1: 0.09240924092409239\n",
      "150-entropy-8-4-balanced\n",
      "accuracy: 0.8160843770599868\n",
      "f1: 0.5044404973357015\n",
      "150-entropy-8-4-balanced_subsample\n",
      "accuracy: 0.8154251812788398\n",
      "f1: 0.5035460992907801\n",
      "150-entropy-8-6-None\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.11726384364820847\n",
      "150-entropy-8-6-balanced\n",
      "accuracy: 0.8193803559657218\n",
      "f1: 0.5107142857142858\n",
      "150-entropy-8-6-balanced_subsample\n",
      "accuracy: 0.8180619644034278\n",
      "f1: 0.5071428571428571\n",
      "150-entropy-8-8-None\n",
      "accuracy: 0.8220171390903098\n",
      "f1: 0.12337662337662336\n",
      "150-entropy-8-8-balanced\n",
      "accuracy: 0.8147659854976929\n",
      "f1: 0.5095986038394414\n",
      "150-entropy-8-8-balanced_subsample\n",
      "accuracy: 0.8187211601845749\n",
      "f1: 0.5115452930728241\n",
      "150-entropy-11-2-None\n",
      "accuracy: 0.8233355306526038\n",
      "f1: 0.17791411042944785\n",
      "150-entropy-11-2-balanced\n",
      "accuracy: 0.8345418589321029\n",
      "f1: 0.3863080684596577\n",
      "150-entropy-11-2-balanced_subsample\n",
      "accuracy: 0.8338826631509558\n",
      "f1: 0.3823529411764706\n",
      "150-entropy-11-4-None\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.1755485893416928\n",
      "150-entropy-11-4-balanced\n",
      "accuracy: 0.8319050758075148\n",
      "f1: 0.3795620437956204\n",
      "150-entropy-11-4-balanced_subsample\n",
      "accuracy: 0.8272907053394858\n",
      "f1: 0.3761904761904762\n",
      "150-entropy-11-6-None\n",
      "accuracy: 0.8246539222148979\n",
      "f1: 0.17901234567901236\n",
      "150-entropy-11-6-balanced\n",
      "accuracy: 0.8358602504943968\n",
      "f1: 0.43792325056433407\n",
      "150-entropy-11-6-balanced_subsample\n",
      "accuracy: 0.8319050758075148\n",
      "f1: 0.408352668213457\n",
      "150-entropy-11-8-None\n",
      "accuracy: 0.8226763348714569\n",
      "f1: 0.15141955835962145\n",
      "150-entropy-11-8-balanced\n",
      "accuracy: 0.8332234673698088\n",
      "f1: 0.44395604395604404\n",
      "150-entropy-11-8-balanced_subsample\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.43076923076923074\n",
      "150-entropy-16-2-None\n",
      "accuracy: 0.8259723137771918\n",
      "f1: 0.175\n",
      "150-entropy-16-2-balanced\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.24404761904761904\n",
      "150-entropy-16-2-balanced_subsample\n",
      "accuracy: 0.8332234673698088\n",
      "f1: 0.24477611940298505\n",
      "150-entropy-16-4-None\n",
      "accuracy: 0.8253131179960448\n",
      "f1: 0.18461538461538463\n",
      "150-entropy-16-4-balanced\n",
      "accuracy: 0.8312458800263678\n",
      "f1: 0.27272727272727276\n",
      "150-entropy-16-4-balanced_subsample\n",
      "accuracy: 0.8312458800263678\n",
      "f1: 0.26857142857142857\n",
      "150-entropy-16-6-None\n",
      "accuracy: 0.8286090969017799\n",
      "f1: 0.21212121212121215\n",
      "150-entropy-16-6-balanced\n",
      "accuracy: 0.8352010547132498\n",
      "f1: 0.3093922651933702\n",
      "150-entropy-16-6-balanced_subsample\n",
      "accuracy: 0.8312458800263678\n",
      "f1: 0.28491620111731847\n",
      "150-entropy-16-8-None\n",
      "accuracy: 0.8233355306526038\n",
      "f1: 0.1625\n",
      "150-entropy-16-8-balanced\n",
      "accuracy: 0.8332234673698088\n",
      "f1: 0.3359580052493438\n",
      "150-entropy-16-8-balanced_subsample\n",
      "accuracy: 0.8352010547132498\n",
      "f1: 0.34554973821989526\n",
      "150-entropy-20-2-None\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.19076923076923077\n",
      "150-entropy-20-2-balanced\n",
      "accuracy: 0.8246539222148979\n",
      "f1: 0.1582278481012658\n",
      "150-entropy-20-2-balanced_subsample\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.2030769230769231\n",
      "150-entropy-20-4-None\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.18575851393188855\n",
      "150-entropy-20-4-balanced\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.2359882005899705\n",
      "150-entropy-20-4-balanced_subsample\n",
      "accuracy: 0.8312458800263678\n",
      "f1: 0.25581395348837205\n",
      "150-entropy-20-6-None\n",
      "accuracy: 0.8233355306526038\n",
      "f1: 0.1829268292682927\n",
      "150-entropy-20-6-balanced\n",
      "accuracy: 0.8358602504943968\n",
      "f1: 0.2985915492957747\n",
      "150-entropy-20-6-balanced_subsample\n",
      "accuracy: 0.8384970336189849\n",
      "f1: 0.32506887052341593\n",
      "150-entropy-20-8-None\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.18068535825545173\n",
      "150-entropy-20-8-balanced\n",
      "accuracy: 0.8319050758075148\n",
      "f1: 0.32360742705570295\n",
      "150-entropy-20-8-balanced_subsample\n",
      "accuracy: 0.8338826631509558\n",
      "f1: 0.3403141361256544\n",
      "200-gini-8-2-None\n",
      "accuracy: 0.8220171390903098\n",
      "f1: 0.11764705882352941\n",
      "200-gini-8-2-balanced\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.5027522935779817\n",
      "200-gini-8-2-balanced_subsample\n",
      "accuracy: 0.8200395517468688\n",
      "f1: 0.5098743267504489\n",
      "200-gini-8-4-None\n",
      "accuracy: 0.8220171390903098\n",
      "f1: 0.11184210526315788\n",
      "200-gini-8-4-balanced\n",
      "accuracy: 0.8147659854976929\n",
      "f1: 0.49910873440285203\n",
      "200-gini-8-4-balanced_subsample\n",
      "accuracy: 0.8226763348714569\n",
      "f1: 0.5100182149362477\n",
      "200-gini-8-6-None\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.11147540983606558\n",
      "200-gini-8-6-balanced\n",
      "accuracy: 0.8239947264337508\n",
      "f1: 0.5206463195691203\n",
      "200-gini-8-6-balanced_subsample\n",
      "accuracy: 0.8259723137771918\n",
      "f1: 0.525179856115108\n",
      "200-gini-8-8-None\n",
      "accuracy: 0.8226763348714569\n",
      "f1: 0.11803278688524589\n",
      "200-gini-8-8-balanced\n",
      "accuracy: 0.8187211601845749\n",
      "f1: 0.5132743362831859\n",
      "200-gini-8-8-balanced_subsample\n",
      "accuracy: 0.8200395517468688\n",
      "f1: 0.5150976909413855\n",
      "200-gini-11-2-None\n",
      "accuracy: 0.8259723137771918\n",
      "f1: 0.1851851851851852\n",
      "200-gini-11-2-balanced\n",
      "accuracy: 0.8279499011206328\n",
      "f1: 0.38004750593824227\n",
      "200-gini-11-2-balanced_subsample\n",
      "accuracy: 0.8352010547132498\n",
      "f1: 0.3932038834951457\n",
      "200-gini-11-4-None\n",
      "accuracy: 0.8259723137771918\n",
      "f1: 0.1901840490797546\n",
      "200-gini-11-4-balanced\n",
      "accuracy: 0.8332234673698088\n",
      "f1: 0.4074941451990632\n",
      "200-gini-11-4-balanced_subsample\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.40094339622641506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200-gini-11-6-None\n",
      "accuracy: 0.8246539222148979\n",
      "f1: 0.17901234567901236\n",
      "200-gini-11-6-balanced\n",
      "accuracy: 0.8365194462755439\n",
      "f1: 0.44144144144144143\n",
      "200-gini-11-6-balanced_subsample\n",
      "accuracy: 0.8319050758075148\n",
      "f1: 0.41913439635535304\n",
      "200-gini-11-8-None\n",
      "accuracy: 0.8272907053394858\n",
      "f1: 0.18125000000000002\n",
      "200-gini-11-8-balanced\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.4351648351648352\n",
      "200-gini-11-8-balanced_subsample\n",
      "accuracy: 0.8358602504943968\n",
      "f1: 0.44789356984478934\n",
      "200-gini-16-2-None\n",
      "accuracy: 0.8239947264337508\n",
      "f1: 0.18348623853211007\n",
      "200-gini-16-2-balanced\n",
      "accuracy: 0.8319050758075148\n",
      "f1: 0.247787610619469\n",
      "200-gini-16-2-balanced_subsample\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.2573099415204678\n",
      "200-gini-16-4-None\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.20060790273556234\n",
      "200-gini-16-4-balanced\n",
      "accuracy: 0.8332234673698088\n",
      "f1: 0.29526462395543174\n",
      "200-gini-16-4-balanced_subsample\n",
      "accuracy: 0.8345418589321029\n",
      "f1: 0.2929577464788733\n",
      "200-gini-16-6-None\n",
      "accuracy: 0.8272907053394858\n",
      "f1: 0.19631901840490798\n",
      "200-gini-16-6-balanced\n",
      "accuracy: 0.8345418589321029\n",
      "f1: 0.33773087071240104\n",
      "200-gini-16-6-balanced_subsample\n",
      "accuracy: 0.8338826631509558\n",
      "f1: 0.31147540983606553\n",
      "200-gini-16-8-None\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.2054380664652568\n",
      "200-gini-16-8-balanced\n",
      "accuracy: 0.8378378378378378\n",
      "f1: 0.3756345177664975\n",
      "200-gini-16-8-balanced_subsample\n",
      "accuracy: 0.8338826631509558\n",
      "f1: 0.3471502590673575\n",
      "200-gini-20-2-None\n",
      "accuracy: 0.8279499011206328\n",
      "f1: 0.2066869300911854\n",
      "200-gini-20-2-balanced\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.19314641744548286\n",
      "200-gini-20-2-balanced_subsample\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.2134146341463415\n",
      "200-gini-20-4-None\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.22222222222222224\n",
      "200-gini-20-4-balanced\n",
      "accuracy: 0.8319050758075148\n",
      "f1: 0.2693409742120344\n",
      "200-gini-20-4-balanced_subsample\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.24561403508771928\n",
      "200-gini-20-6-None\n",
      "accuracy: 0.8279499011206328\n",
      "f1: 0.19692307692307692\n",
      "200-gini-20-6-balanced\n",
      "accuracy: 0.8365194462755439\n",
      "f1: 0.31491712707182323\n",
      "200-gini-20-6-balanced_subsample\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.26285714285714284\n",
      "200-gini-20-8-None\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.19571865443425077\n",
      "200-gini-20-8-balanced\n",
      "accuracy: 0.8345418589321029\n",
      "f1: 0.3234501347708895\n",
      "200-gini-20-8-balanced_subsample\n",
      "accuracy: 0.8332234673698088\n",
      "f1: 0.3359580052493438\n",
      "200-entropy-8-2-None\n",
      "accuracy: 0.8246539222148979\n",
      "f1: 0.14743589743589744\n",
      "200-entropy-8-2-balanced\n",
      "accuracy: 0.8206987475280159\n",
      "f1: 0.5090252707581228\n",
      "200-entropy-8-2-balanced_subsample\n",
      "accuracy: 0.8226763348714569\n",
      "f1: 0.5153153153153154\n",
      "200-entropy-8-4-None\n",
      "accuracy: 0.8220171390903098\n",
      "f1: 0.11764705882352941\n",
      "200-entropy-8-4-balanced\n",
      "accuracy: 0.8193803559657218\n",
      "f1: 0.5054151624548737\n",
      "200-entropy-8-4-balanced_subsample\n",
      "accuracy: 0.8180619644034278\n",
      "f1: 0.5053763440860215\n",
      "200-entropy-8-6-None\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.12297734627831713\n",
      "200-entropy-8-6-balanced\n",
      "accuracy: 0.8226763348714569\n",
      "f1: 0.5135623869801085\n",
      "200-entropy-8-6-balanced_subsample\n",
      "accuracy: 0.8193803559657218\n",
      "f1: 0.5089605734767025\n",
      "200-entropy-8-8-None\n",
      "accuracy: 0.8220171390903098\n",
      "f1: 0.11764705882352941\n",
      "200-entropy-8-8-balanced\n",
      "accuracy: 0.8187211601845749\n",
      "f1: 0.5080500894454383\n",
      "200-entropy-8-8-balanced_subsample\n",
      "accuracy: 0.8206987475280159\n",
      "f1: 0.5125448028673835\n",
      "200-entropy-11-2-None\n",
      "accuracy: 0.8239947264337508\n",
      "f1: 0.16300940438871472\n",
      "200-entropy-11-2-balanced\n",
      "accuracy: 0.8358602504943968\n",
      "f1: 0.39119804400978\n",
      "200-entropy-11-2-balanced_subsample\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.3622828784119107\n",
      "200-entropy-11-4-None\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.17034700315457413\n",
      "200-entropy-11-4-balanced\n",
      "accuracy: 0.8345418589321029\n",
      "f1: 0.3922518159806296\n",
      "200-entropy-11-4-balanced_subsample\n",
      "accuracy: 0.8312458800263678\n",
      "f1: 0.3786407766990291\n",
      "200-entropy-11-6-None\n",
      "accuracy: 0.8253131179960448\n",
      "f1: 0.17956656346749228\n",
      "200-entropy-11-6-balanced\n",
      "accuracy: 0.8365194462755439\n",
      "f1: 0.43891402714932126\n",
      "200-entropy-11-6-balanced_subsample\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.4147465437788018\n",
      "200-entropy-11-8-None\n",
      "accuracy: 0.8239947264337508\n",
      "f1: 0.1523809523809524\n",
      "200-entropy-11-8-balanced\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.43555555555555553\n",
      "200-entropy-11-8-balanced_subsample\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.43555555555555553\n",
      "200-entropy-16-2-None\n",
      "accuracy: 0.8253131179960448\n",
      "f1: 0.17956656346749228\n",
      "200-entropy-16-2-balanced\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.2328358208955224\n",
      "200-entropy-16-2-balanced_subsample\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.23493975903614459\n",
      "200-entropy-16-4-None\n",
      "accuracy: 0.8272907053394858\n",
      "f1: 0.20606060606060606\n",
      "200-entropy-16-4-balanced\n",
      "accuracy: 0.8345418589321029\n",
      "f1: 0.2969187675070028\n",
      "200-entropy-16-4-balanced_subsample\n",
      "accuracy: 0.8312458800263678\n",
      "f1: 0.2768361581920904\n",
      "200-entropy-16-6-None\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.19571865443425077\n",
      "200-entropy-16-6-balanced\n",
      "accuracy: 0.8365194462755439\n",
      "f1: 0.31868131868131866\n",
      "200-entropy-16-6-balanced_subsample\n",
      "accuracy: 0.8352010547132498\n",
      "f1: 0.32065217391304346\n",
      "200-entropy-16-8-None\n",
      "accuracy: 0.8259723137771918\n",
      "f1: 0.18012422360248448\n",
      "200-entropy-16-8-balanced\n",
      "accuracy: 0.8279499011206328\n",
      "f1: 0.31496062992125984\n",
      "200-entropy-16-8-balanced_subsample\n",
      "accuracy: 0.8352010547132498\n",
      "f1: 0.34554973821989526\n",
      "200-entropy-20-2-None\n",
      "accuracy: 0.8279499011206328\n",
      "f1: 0.2018348623853211\n",
      "200-entropy-20-2-balanced\n",
      "accuracy: 0.8239947264337508\n",
      "f1: 0.15772870662460567\n",
      "200-entropy-20-2-balanced_subsample\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.21406727828746178\n",
      "200-entropy-20-4-None\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.19076923076923077\n",
      "200-entropy-20-4-balanced\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.2328358208955224\n",
      "200-entropy-20-4-balanced_subsample\n",
      "accuracy: 0.8332234673698088\n",
      "f1: 0.26666666666666666\n",
      "200-entropy-20-6-None\n",
      "accuracy: 0.8279499011206328\n",
      "f1: 0.2066869300911854\n",
      "200-entropy-20-6-balanced\n",
      "accuracy: 0.8391562294001318\n",
      "f1: 0.3222222222222222\n",
      "200-entropy-20-6-balanced_subsample\n",
      "accuracy: 0.8391562294001318\n",
      "f1: 0.3296703296703297\n",
      "200-entropy-20-8-None\n",
      "accuracy: 0.8279499011206328\n",
      "f1: 0.19195046439628483\n",
      "200-entropy-20-8-balanced\n",
      "accuracy: 0.8319050758075148\n",
      "f1: 0.32360742705570295\n",
      "200-entropy-20-8-balanced_subsample\n",
      "accuracy: 0.8352010547132498\n",
      "f1: 0.33862433862433866\n",
      "300-gini-8-2-None\n",
      "accuracy: 0.8233355306526038\n",
      "f1: 0.12987012987012989\n",
      "300-gini-8-2-balanced\n",
      "accuracy: 0.8246539222148979\n",
      "f1: 0.511029411764706\n",
      "300-gini-8-2-balanced_subsample\n",
      "accuracy: 0.8259723137771918\n",
      "f1: 0.5164835164835164\n",
      "300-gini-8-4-None\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.10561056105610561\n",
      "300-gini-8-4-balanced\n",
      "accuracy: 0.8187211601845749\n",
      "f1: 0.5045045045045046\n",
      "300-gini-8-4-balanced_subsample\n",
      "accuracy: 0.8253131179960448\n",
      "f1: 0.5173041894353371\n",
      "300-gini-8-6-None\n",
      "accuracy: 0.8220171390903098\n",
      "f1: 0.11764705882352941\n",
      "300-gini-8-6-balanced\n",
      "accuracy: 0.8246539222148979\n",
      "f1: 0.51985559566787\n",
      "300-gini-8-6-balanced_subsample\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.5134649910233393\n",
      "300-gini-8-8-None\n",
      "accuracy: 0.8233355306526038\n",
      "f1: 0.1241830065359477\n",
      "300-gini-8-8-balanced\n",
      "accuracy: 0.8167435728411339\n",
      "f1: 0.5035714285714286\n",
      "300-gini-8-8-balanced_subsample\n",
      "accuracy: 0.8259723137771918\n",
      "f1: 0.52\n",
      "300-gini-11-2-None\n",
      "accuracy: 0.8246539222148979\n",
      "f1: 0.17391304347826084\n",
      "300-gini-11-2-balanced\n",
      "accuracy: 0.8312458800263678\n",
      "f1: 0.39336492890995267\n",
      "300-gini-11-2-balanced_subsample\n",
      "accuracy: 0.8352010547132498\n",
      "f1: 0.3990384615384615\n",
      "300-gini-11-4-None\n",
      "accuracy: 0.8233355306526038\n",
      "f1: 0.1728395061728395\n",
      "300-gini-11-4-balanced\n",
      "accuracy: 0.8345418589321029\n",
      "f1: 0.40661938534278963\n",
      "300-gini-11-4-balanced_subsample\n",
      "accuracy: 0.8345418589321029\n",
      "f1: 0.4094117647058823\n",
      "300-gini-11-6-None\n",
      "accuracy: 0.8239947264337508\n",
      "f1: 0.17337461300309598\n",
      "300-gini-11-6-balanced\n",
      "accuracy: 0.8338826631509558\n",
      "f1: 0.42727272727272725\n",
      "300-gini-11-6-balanced_subsample\n",
      "accuracy: 0.8312458800263678\n",
      "f1: 0.40740740740740744\n",
      "300-gini-11-8-None\n",
      "accuracy: 0.8246539222148979\n",
      "f1: 0.17391304347826084\n",
      "300-gini-11-8-balanced\n",
      "accuracy: 0.8332234673698088\n",
      "f1: 0.4365256124721604\n",
      "300-gini-11-8-balanced_subsample\n",
      "accuracy: 0.8338826631509558\n",
      "f1: 0.4375\n",
      "300-gini-16-2-None\n",
      "accuracy: 0.8253131179960448\n",
      "f1: 0.19452887537993924\n",
      "300-gini-16-2-balanced\n",
      "accuracy: 0.8332234673698088\n",
      "f1: 0.25368731563421826\n",
      "300-gini-16-2-balanced_subsample\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.24404761904761904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300-gini-16-4-None\n",
      "accuracy: 0.8253131179960448\n",
      "f1: 0.19452887537993924\n",
      "300-gini-16-4-balanced\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.276056338028169\n",
      "300-gini-16-4-balanced_subsample\n",
      "accuracy: 0.8358602504943968\n",
      "f1: 0.2985915492957747\n",
      "300-gini-16-6-None\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.19076923076923077\n",
      "300-gini-16-6-balanced\n",
      "accuracy: 0.8345418589321029\n",
      "f1: 0.3197831978319783\n",
      "300-gini-16-6-balanced_subsample\n",
      "accuracy: 0.8332234673698088\n",
      "f1: 0.3068493150684931\n",
      "300-gini-16-8-None\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.19571865443425077\n",
      "300-gini-16-8-balanced\n",
      "accuracy: 0.8371786420566908\n",
      "f1: 0.36175710594315247\n",
      "300-gini-16-8-balanced_subsample\n",
      "accuracy: 0.8338826631509558\n",
      "f1: 0.3333333333333333\n",
      "300-gini-20-2-None\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.2054380664652568\n",
      "300-gini-20-2-balanced\n",
      "accuracy: 0.8332234673698088\n",
      "f1: 0.22629969418960244\n",
      "300-gini-20-2-balanced_subsample\n",
      "accuracy: 0.8319050758075148\n",
      "f1: 0.22018348623853212\n",
      "300-gini-20-4-None\n",
      "accuracy: 0.8239947264337508\n",
      "f1: 0.18348623853211007\n",
      "300-gini-20-4-balanced\n",
      "accuracy: 0.8319050758075148\n",
      "f1: 0.25655976676384834\n",
      "300-gini-20-4-balanced_subsample\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.24633431085043986\n",
      "300-gini-20-6-None\n",
      "accuracy: 0.8259723137771918\n",
      "f1: 0.1851851851851852\n",
      "300-gini-20-6-balanced\n",
      "accuracy: 0.8384970336189849\n",
      "f1: 0.3213296398891967\n",
      "300-gini-20-6-balanced_subsample\n",
      "accuracy: 0.8312458800263678\n",
      "f1: 0.27272727272727276\n",
      "300-gini-20-8-None\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.19571865443425077\n",
      "300-gini-20-8-balanced\n",
      "accuracy: 0.8345418589321029\n",
      "f1: 0.3197831978319783\n",
      "300-gini-20-8-balanced_subsample\n",
      "accuracy: 0.8332234673698088\n",
      "f1: 0.3253333333333333\n",
      "300-entropy-8-2-None\n",
      "accuracy: 0.8239947264337508\n",
      "f1: 0.14696485623003194\n",
      "300-entropy-8-2-balanced\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.5226860254083485\n",
      "300-entropy-8-2-balanced_subsample\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.5209471766848816\n",
      "300-entropy-8-4-None\n",
      "accuracy: 0.8233355306526038\n",
      "f1: 0.12987012987012989\n",
      "300-entropy-8-4-balanced\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.5099457504520796\n",
      "300-entropy-8-4-balanced_subsample\n",
      "accuracy: 0.8180619644034278\n",
      "f1: 0.5035971223021583\n",
      "300-entropy-8-6-None\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.12297734627831713\n",
      "300-entropy-8-6-balanced\n",
      "accuracy: 0.8220171390903098\n",
      "f1: 0.5126353790613718\n",
      "300-entropy-8-6-balanced_subsample\n",
      "accuracy: 0.8206987475280159\n",
      "f1: 0.5054545454545455\n",
      "300-entropy-8-8-None\n",
      "accuracy: 0.8246539222148979\n",
      "f1: 0.14193548387096774\n",
      "300-entropy-8-8-balanced\n",
      "accuracy: 0.8226763348714569\n",
      "f1: 0.5170556552962297\n",
      "300-entropy-8-8-balanced_subsample\n",
      "accuracy: 0.8206987475280159\n",
      "f1: 0.5125448028673835\n",
      "300-entropy-11-2-None\n",
      "accuracy: 0.8233355306526038\n",
      "f1: 0.15723270440251572\n",
      "300-entropy-11-2-balanced\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.37745098039215685\n",
      "300-entropy-11-2-balanced_subsample\n",
      "accuracy: 0.8279499011206328\n",
      "f1: 0.3523573200992556\n",
      "300-entropy-11-4-None\n",
      "accuracy: 0.8259723137771918\n",
      "f1: 0.169811320754717\n",
      "300-entropy-11-4-balanced\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.37772397094430993\n",
      "300-entropy-11-4-balanced_subsample\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.37288135593220345\n",
      "300-entropy-11-6-None\n",
      "accuracy: 0.8259723137771918\n",
      "f1: 0.18012422360248448\n",
      "300-entropy-11-6-balanced\n",
      "accuracy: 0.8352010547132498\n",
      "f1: 0.4292237442922374\n",
      "300-entropy-11-6-balanced_subsample\n",
      "accuracy: 0.8352010547132498\n",
      "f1: 0.42660550458715596\n",
      "300-entropy-11-8-None\n",
      "accuracy: 0.8246539222148979\n",
      "f1: 0.16352201257861634\n",
      "300-entropy-11-8-balanced\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.42410714285714285\n",
      "300-entropy-11-8-balanced_subsample\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.4330357142857143\n",
      "300-entropy-16-2-None\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.19571865443425077\n",
      "300-entropy-16-2-balanced\n",
      "accuracy: 0.8286090969017799\n",
      "f1: 0.2261904761904762\n",
      "300-entropy-16-2-balanced_subsample\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.2328358208955224\n",
      "300-entropy-16-4-None\n",
      "accuracy: 0.8272907053394858\n",
      "f1: 0.19631901840490798\n",
      "300-entropy-16-4-balanced\n",
      "accuracy: 0.8352010547132498\n",
      "f1: 0.2857142857142857\n",
      "300-entropy-16-4-balanced_subsample\n",
      "accuracy: 0.8352010547132498\n",
      "f1: 0.2857142857142857\n",
      "300-entropy-16-6-None\n",
      "accuracy: 0.8259723137771918\n",
      "f1: 0.2\n",
      "300-entropy-16-6-balanced\n",
      "accuracy: 0.8352010547132498\n",
      "f1: 0.31318681318681324\n",
      "300-entropy-16-6-balanced_subsample\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.2983425414364641\n",
      "300-entropy-16-8-None\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.19076923076923077\n",
      "300-entropy-16-8-balanced\n",
      "accuracy: 0.8312458800263678\n",
      "f1: 0.3333333333333333\n",
      "300-entropy-16-8-balanced_subsample\n",
      "accuracy: 0.8345418589321029\n",
      "f1: 0.3412073490813648\n",
      "300-entropy-20-2-None\n",
      "accuracy: 0.8286090969017799\n",
      "f1: 0.21212121212121215\n",
      "300-entropy-20-2-balanced\n",
      "accuracy: 0.8272907053394858\n",
      "f1: 0.1863354037267081\n",
      "300-entropy-20-2-balanced_subsample\n",
      "accuracy: 0.8279499011206328\n",
      "f1: 0.19692307692307692\n",
      "300-entropy-20-4-None\n",
      "accuracy: 0.8286090969017799\n",
      "f1: 0.20731707317073172\n",
      "300-entropy-20-4-balanced\n",
      "accuracy: 0.8319050758075148\n",
      "f1: 0.247787610619469\n",
      "300-entropy-20-4-balanced_subsample\n",
      "accuracy: 0.8332234673698088\n",
      "f1: 0.25368731563421826\n",
      "300-entropy-20-6-None\n",
      "accuracy: 0.8246539222148979\n",
      "f1: 0.18902439024390244\n",
      "300-entropy-20-6-balanced\n",
      "accuracy: 0.8371786420566908\n",
      "f1: 0.31197771587743733\n",
      "300-entropy-20-6-balanced_subsample\n",
      "accuracy: 0.8365194462755439\n",
      "f1: 0.30726256983240224\n",
      "300-entropy-20-8-None\n",
      "accuracy: 0.8253131179960448\n",
      "f1: 0.17445482866043613\n",
      "300-entropy-20-8-balanced\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.320855614973262\n",
      "300-entropy-20-8-balanced_subsample\n",
      "accuracy: 0.8352010547132498\n",
      "f1: 0.3351063829787234\n",
      "400-gini-8-2-None\n",
      "accuracy: 0.8246539222148979\n",
      "f1: 0.14193548387096774\n",
      "400-gini-8-2-balanced\n",
      "accuracy: 0.8233355306526038\n",
      "f1: 0.5091575091575091\n",
      "400-gini-8-2-balanced_subsample\n",
      "accuracy: 0.8226763348714569\n",
      "f1: 0.5082266910420474\n",
      "400-gini-8-4-None\n",
      "accuracy: 0.8246539222148979\n",
      "f1: 0.13636363636363635\n",
      "400-gini-8-4-balanced\n",
      "accuracy: 0.8200395517468688\n",
      "f1: 0.508108108108108\n",
      "400-gini-8-4-balanced_subsample\n",
      "accuracy: 0.8259723137771918\n",
      "f1: 0.525179856115108\n",
      "400-gini-8-6-None\n",
      "accuracy: 0.8246539222148979\n",
      "f1: 0.13636363636363635\n",
      "400-gini-8-6-balanced\n",
      "accuracy: 0.8279499011206328\n",
      "f1: 0.5245901639344261\n",
      "400-gini-8-6-balanced_subsample\n",
      "accuracy: 0.8246539222148979\n",
      "f1: 0.5181159420289856\n",
      "400-gini-8-8-None\n",
      "accuracy: 0.8239947264337508\n",
      "f1: 0.12459016393442622\n",
      "400-gini-8-8-balanced\n",
      "accuracy: 0.8200395517468688\n",
      "f1: 0.5098743267504489\n",
      "400-gini-8-8-balanced_subsample\n",
      "accuracy: 0.8259723137771918\n",
      "f1: 0.5217391304347826\n",
      "400-gini-11-2-None\n",
      "accuracy: 0.8226763348714569\n",
      "f1: 0.1567398119122257\n",
      "400-gini-11-2-balanced\n",
      "accuracy: 0.8319050758075148\n",
      "f1: 0.3971631205673759\n",
      "400-gini-11-2-balanced_subsample\n",
      "accuracy: 0.8345418589321029\n",
      "f1: 0.40095465393794744\n",
      "400-gini-11-4-None\n",
      "accuracy: 0.8239947264337508\n",
      "f1: 0.16822429906542058\n",
      "400-gini-11-4-balanced\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.3915094339622641\n",
      "400-gini-11-4-balanced_subsample\n",
      "accuracy: 0.8332234673698088\n",
      "f1: 0.4074941451990632\n",
      "400-gini-11-6-None\n",
      "accuracy: 0.8246539222148979\n",
      "f1: 0.17391304347826084\n",
      "400-gini-11-6-balanced\n",
      "accuracy: 0.8332234673698088\n",
      "f1: 0.42630385487528344\n",
      "400-gini-11-6-balanced_subsample\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.4120370370370371\n",
      "400-gini-11-8-None\n",
      "accuracy: 0.8226763348714569\n",
      "f1: 0.1567398119122257\n",
      "400-gini-11-8-balanced\n",
      "accuracy: 0.8352010547132498\n",
      "f1: 0.43946188340807174\n",
      "400-gini-11-8-balanced_subsample\n",
      "accuracy: 0.8371786420566908\n",
      "f1: 0.4498886414253897\n",
      "400-gini-16-2-None\n",
      "accuracy: 0.8246539222148979\n",
      "f1: 0.18902439024390244\n",
      "400-gini-16-2-balanced\n",
      "accuracy: 0.8319050758075148\n",
      "f1: 0.25655976676384834\n",
      "400-gini-16-2-balanced_subsample\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.23668639053254437\n",
      "400-gini-16-4-None\n",
      "accuracy: 0.8279499011206328\n",
      "f1: 0.21148036253776434\n",
      "400-gini-16-4-balanced\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.2719546742209632\n",
      "400-gini-16-4-balanced_subsample\n",
      "accuracy: 0.8332234673698088\n",
      "f1: 0.28328611898017\n",
      "400-gini-16-6-None\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.19076923076923077\n",
      "400-gini-16-6-balanced\n",
      "accuracy: 0.8352010547132498\n",
      "f1: 0.31693989071038253\n",
      "400-gini-16-6-balanced_subsample\n",
      "accuracy: 0.8358602504943968\n",
      "f1: 0.3215258855585831\n",
      "400-gini-16-8-None\n",
      "accuracy: 0.8272907053394858\n",
      "f1: 0.19631901840490798\n",
      "400-gini-16-8-balanced\n",
      "accuracy: 0.8384970336189849\n",
      "f1: 0.37017994858611825\n",
      "400-gini-16-8-balanced_subsample\n",
      "accuracy: 0.8332234673698088\n",
      "f1: 0.3324538258575198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400-gini-20-2-None\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.20060790273556234\n",
      "400-gini-20-2-balanced\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.22560975609756095\n",
      "400-gini-20-2-balanced_subsample\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.22085889570552147\n",
      "400-gini-20-4-None\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.20060790273556234\n",
      "400-gini-20-4-balanced\n",
      "accuracy: 0.8312458800263678\n",
      "f1: 0.25581395348837205\n",
      "400-gini-20-4-balanced_subsample\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.2529411764705882\n",
      "400-gini-20-6-None\n",
      "accuracy: 0.8266315095583389\n",
      "f1: 0.19076923076923077\n",
      "400-gini-20-6-balanced\n",
      "accuracy: 0.8358602504943968\n",
      "f1: 0.2985915492957747\n",
      "400-gini-20-6-balanced_subsample\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.2678062678062678\n",
      "400-gini-20-8-None\n",
      "accuracy: 0.8253131179960448\n",
      "f1: 0.18461538461538463\n",
      "400-gini-20-8-balanced\n",
      "accuracy: 0.8338826631509558\n",
      "f1: 0.31521739130434784\n",
      "400-gini-20-8-balanced_subsample\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.3135135135135135\n",
      "400-entropy-8-2-None\n",
      "accuracy: 0.8226763348714569\n",
      "f1: 0.135048231511254\n",
      "400-entropy-8-2-balanced\n",
      "accuracy: 0.8259723137771918\n",
      "f1: 0.525179856115108\n",
      "400-entropy-8-2-balanced_subsample\n",
      "accuracy: 0.8259723137771918\n",
      "f1: 0.5234657039711191\n",
      "400-entropy-8-4-None\n",
      "accuracy: 0.8226763348714569\n",
      "f1: 0.12944983818770228\n",
      "400-entropy-8-4-balanced\n",
      "accuracy: 0.8206987475280159\n",
      "f1: 0.5125448028673835\n",
      "400-entropy-8-4-balanced_subsample\n",
      "accuracy: 0.8174027686222808\n",
      "f1: 0.5026929982046678\n",
      "400-entropy-8-6-None\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.12297734627831713\n",
      "400-entropy-8-6-balanced\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.5117117117117117\n",
      "400-entropy-8-6-balanced_subsample\n",
      "accuracy: 0.8213579433091628\n",
      "f1: 0.5099457504520796\n",
      "400-entropy-8-8-None\n",
      "accuracy: 0.8233355306526038\n",
      "f1: 0.1241830065359477\n",
      "400-entropy-8-8-balanced\n",
      "accuracy: 0.8187211601845749\n",
      "f1: 0.5115452930728241\n",
      "400-entropy-8-8-balanced_subsample\n",
      "accuracy: 0.8147659854976929\n",
      "f1: 0.5026548672566372\n",
      "400-entropy-11-2-None\n",
      "accuracy: 0.8233355306526038\n",
      "f1: 0.15723270440251572\n",
      "400-entropy-11-2-balanced\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.3716381418092909\n",
      "400-entropy-11-2-balanced_subsample\n",
      "accuracy: 0.8272907053394858\n",
      "f1: 0.35467980295566504\n",
      "400-entropy-11-4-None\n",
      "accuracy: 0.8259723137771918\n",
      "f1: 0.18012422360248448\n",
      "400-entropy-11-4-balanced\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.37772397094430993\n",
      "400-entropy-11-4-balanced_subsample\n",
      "accuracy: 0.8279499011206328\n",
      "f1: 0.3680387409200968\n",
      "400-entropy-11-6-None\n",
      "accuracy: 0.8259723137771918\n",
      "f1: 0.18012422360248448\n",
      "400-entropy-11-6-balanced\n",
      "accuracy: 0.8338826631509558\n",
      "f1: 0.4298642533936652\n",
      "400-entropy-11-6-balanced_subsample\n",
      "accuracy: 0.8371786420566908\n",
      "f1: 0.43478260869565216\n",
      "400-entropy-11-8-None\n",
      "accuracy: 0.8233355306526038\n",
      "f1: 0.1518987341772152\n",
      "400-entropy-11-8-balanced\n",
      "accuracy: 0.8312458800263678\n",
      "f1: 0.4260089686098655\n",
      "400-entropy-11-8-balanced_subsample\n",
      "accuracy: 0.8305866842452209\n",
      "f1: 0.42247191011235957\n",
      "400-entropy-16-2-None\n",
      "accuracy: 0.8272907053394858\n",
      "f1: 0.20121951219512196\n",
      "400-entropy-16-2-balanced\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.22754491017964068\n",
      "400-entropy-16-2-balanced_subsample\n",
      "accuracy: 0.8332234673698088\n",
      "f1: 0.24925816023738873\n",
      "400-entropy-16-4-None\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.2030769230769231\n",
      "400-entropy-16-4-balanced\n",
      "accuracy: 0.8378378378378378\n",
      "f1: 0.30113636363636365\n",
      "400-entropy-16-4-balanced_subsample\n",
      "accuracy: 0.8378378378378378\n",
      "f1: 0.29714285714285715\n",
      "400-entropy-16-6-None\n",
      "accuracy: 0.8253131179960448\n",
      "f1: 0.19452887537993924\n",
      "400-entropy-16-6-balanced\n",
      "accuracy: 0.8345418589321029\n",
      "f1: 0.3085399449035813\n",
      "400-entropy-16-6-balanced_subsample\n",
      "accuracy: 0.8332234673698088\n",
      "f1: 0.29916897506925205\n",
      "400-entropy-16-8-None\n",
      "accuracy: 0.8272907053394858\n",
      "f1: 0.19135802469135801\n",
      "400-entropy-16-8-balanced\n",
      "accuracy: 0.8299274884640738\n",
      "f1: 0.3316062176165803\n",
      "400-entropy-16-8-balanced_subsample\n",
      "accuracy: 0.8332234673698088\n",
      "f1: 0.3359580052493438\n",
      "400-entropy-20-2-None\n",
      "accuracy: 0.8272907053394858\n",
      "f1: 0.20121951219512196\n",
      "400-entropy-20-2-balanced\n",
      "accuracy: 0.8259723137771918\n",
      "f1: 0.175\n",
      "400-entropy-20-2-balanced_subsample\n",
      "accuracy: 0.8292682926829268\n",
      "f1: 0.20795107033639146\n",
      "400-entropy-20-4-None\n",
      "accuracy: 0.8279499011206328\n",
      "f1: 0.2018348623853211\n",
      "400-entropy-20-4-balanced\n",
      "accuracy: 0.8325642715886619\n",
      "f1: 0.2573099415204678\n",
      "400-entropy-20-4-balanced_subsample\n",
      "accuracy: 0.8345418589321029\n",
      "f1: 0.2551928783382789\n",
      "400-entropy-20-6-None\n",
      "accuracy: 0.8253131179960448\n",
      "f1: 0.19452887537993924\n",
      "400-entropy-20-6-balanced\n",
      "accuracy: 0.8345418589321029\n",
      "f1: 0.3008356545961003\n",
      "400-entropy-20-6-balanced_subsample\n",
      "accuracy: 0.8352010547132498\n",
      "f1: 0.3016759776536313\n",
      "400-entropy-20-8-None\n",
      "accuracy: 0.8239947264337508\n",
      "f1: 0.16822429906542058\n",
      "400-entropy-20-8-balanced\n",
      "accuracy: 0.8332234673698088\n",
      "f1: 0.3359580052493438\n",
      "400-entropy-20-8-balanced_subsample\n",
      "accuracy: 0.8358602504943968\n",
      "f1: 0.3395225464190981\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "# RF\n",
    "estimators = [100, 150, 200, 300, 400]\n",
    "criterions = [\"gini\", \"entropy\"]\n",
    "depths = [8, 11, 16, 20]\n",
    "splits = [2, 4, 6, 8]\n",
    "weights = [None, \"balanced\", \"balanced_subsample\"]\n",
    "para_list = [estimators, criterions, depths, splits, weights]\n",
    "paras = list(itertools.product(*para_list))\n",
    "\n",
    "for para in paras:\n",
    "    rf = RandomForestClassifier(n_estimators=para[0], \n",
    "                                    criterion=para[1], \n",
    "                                    max_depth=para[2],\n",
    "                                    min_samples_split = para[3],\n",
    "                                    class_weight=para[4],\n",
    "                                    random_state=73514)\n",
    "    rf.fit(X_comb_scaledsim_train, y_train)\n",
    "    para_string = \"-\".join([str(p) for p in para])\n",
    "    #dev set\n",
    "    y_dev_pred = rf.predict(X_comb_scaledsim_dev)\n",
    "    y_dev_prob = rf.predict_proba(X_comb_scaledsim_dev)\n",
    "    dev_path = \"../myclassify/test_res/RFSIM-dev/RFSIM-\" + para_string + \".txt\"\n",
    "    predict_for_test(y_dev, y_dev_pred, y_dev_prob, dev_path)\n",
    "\n",
    "    #test set\n",
    "    y_pred = rf.predict(X_comb_scaledsim_test)\n",
    "    y_prob = rf.predict_proba(X_comb_scaledsim_test)\n",
    "    test_path = \"../myclassify/test_res/RFSIM-test/RFSIM-\" + para_string + \".txt\"\n",
    "    predict_for_test(y_test, y_pred, y_prob, test_path)\n",
    "\n",
    "    #test result\n",
    "    print(para_string)\n",
    "    print(\"accuracy: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "    print(\"f1: {}\".format(f1_score(y_test, y_pred)))\n",
    "#     print(confusion_matrix(y_test, y_pred))\n",
    "    # predict_for_test(y_test, y_pred, rf.predict_proba(X_test), \"rf.txt\")\n",
    "    \n",
    "#best MAP/MRR for dev when 300-entropy-16-8-balanced_subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 50; max_depth: 2\n",
      "accuracy: 0.8391562294001318\n",
      "f1: 0.37113402061855666\n",
      "n_estimators: 50; max_depth: 3\n",
      "accuracy: 0.8384970336189849\n",
      "f1: 0.4067796610169491\n",
      "n_estimators: 50; max_depth: 6\n",
      "accuracy: 0.8035596572181938\n",
      "f1: 0.3659574468085106\n",
      "n_estimators: 50; max_depth: 12\n",
      "accuracy: 0.8029004614370469\n",
      "f1: 0.380952380952381\n",
      "n_estimators: 50; max_depth: 24\n",
      "accuracy: 0.7870797626895187\n",
      "f1: 0.3962616822429907\n",
      "n_estimators: 100; max_depth: 2\n",
      "accuracy: 0.8391562294001318\n",
      "f1: 0.3838383838383838\n",
      "n_estimators: 100; max_depth: 3\n",
      "accuracy: 0.8404746209624259\n",
      "f1: 0.4182692307692307\n",
      "n_estimators: 100; max_depth: 6\n",
      "accuracy: 0.8101516150296638\n",
      "f1: 0.3924050632911392\n",
      "n_estimators: 100; max_depth: 12\n",
      "accuracy: 0.8134475939353988\n",
      "f1: 0.38876889848812096\n",
      "n_estimators: 100; max_depth: 24\n",
      "accuracy: 0.7923533289386948\n",
      "f1: 0.411214953271028\n",
      "n_estimators: 400; max_depth: 2\n",
      "accuracy: 0.8371786420566908\n",
      "f1: 0.3990267639902676\n",
      "n_estimators: 400; max_depth: 3\n",
      "accuracy: 0.8319050758075148\n",
      "f1: 0.41108545034642036\n",
      "n_estimators: 400; max_depth: 6\n",
      "accuracy: 0.8180619644034278\n",
      "f1: 0.37837837837837845\n",
      "n_estimators: 400; max_depth: 12\n",
      "accuracy: 0.8134475939353988\n",
      "f1: 0.38876889848812096\n",
      "n_estimators: 400; max_depth: 24\n",
      "accuracy: 0.7923533289386948\n",
      "f1: 0.411214953271028\n",
      "n_estimators: 800; max_depth: 2\n",
      "accuracy: 0.8365194462755439\n",
      "f1: 0.40669856459330145\n",
      "n_estimators: 800; max_depth: 3\n",
      "accuracy: 0.8286090969017799\n",
      "f1: 0.3981481481481482\n",
      "n_estimators: 800; max_depth: 6\n",
      "accuracy: 0.8239947264337508\n",
      "f1: 0.3747072599531617\n",
      "n_estimators: 800; max_depth: 12\n",
      "accuracy: 0.8134475939353988\n",
      "f1: 0.38876889848812096\n",
      "n_estimators: 800; max_depth: 24\n",
      "accuracy: 0.7923533289386948\n",
      "f1: 0.411214953271028\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Probably don't try this.\n",
    "# GBM\n",
    "paras1 = [50, 100, 400, 800]\n",
    "paras2 = [2, 3, 6, 12, 24]\n",
    "for para1 in paras1:\n",
    "    for para2 in paras2:    \n",
    "        gbm = GradientBoostingClassifier(n_estimators=para1, max_depth=para2, random_state=47156)\n",
    "        gbm.fit(X_comb_scaledsim_train, y_train)\n",
    "        \n",
    "        #dev set\n",
    "        y_dev_pred = gbm.predict(X_comb_scaledsim_dev)\n",
    "        y_dev_prob = gbm.predict_proba(X_comb_scaledsim_dev)\n",
    "        dev_path = \"../myclassify/test_res/GBSIM-dev/GBSIM-\" + str(para1) + \"-\" + str(para2) + \".txt\"\n",
    "        predict_for_test(y_dev, y_dev_pred, y_dev_prob, dev_path)\n",
    "\n",
    "        #test set\n",
    "        y_pred = gbm.predict(X_comb_scaledsim_test)\n",
    "        y_prob = gbm.predict_proba(X_comb_scaledsim_test)\n",
    "        test_path = \"../myclassify/test_res/GBSIM-test/GBSIM-\" + str(para1) + \"-\" + str(para2) + \".txt\"\n",
    "        predict_for_test(y_test, y_pred, y_prob, test_path)\n",
    "        \n",
    "        #test result\n",
    "        print(\"n_estimators: \" + str(para1) + \"; max_depth: \" + str(para2))\n",
    "        print(\"accuracy: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "        print(\"f1: {}\".format(f1_score(y_test, y_pred)))\n",
    "#         print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "#best MAP/MRR for dev when para1 = 50, para2 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.01\n",
      "accuracy: 0.7514831905075807\n",
      "f1: 0.3747927031509121\n",
      "alpha: 0.1\n",
      "accuracy: 0.7514831905075807\n",
      "f1: 0.3747927031509121\n",
      "alpha: 1\n",
      "accuracy: 0.7547791694133158\n",
      "f1: 0.37583892617449666\n",
      "alpha: 2\n",
      "accuracy: 0.7508239947264338\n",
      "f1: 0.36148648648648646\n",
      "alpha: 10\n",
      "accuracy: 0.7765326301911668\n",
      "f1: 0.3468208092485549\n",
      "alpha: 50\n",
      "accuracy: 0.8068556361239289\n",
      "f1: 0.16997167138810196\n",
      "alpha: 100\n",
      "accuracy: 0.8114700065919578\n",
      "f1: 0.08333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "\n",
    "# nb = GaussianNB()\n",
    "paras = [0.01, 0.1, 1, 2, 10, 50, 100]\n",
    "for para in paras:\n",
    "    nb = BernoulliNB(alpha=para)\n",
    "    nb.fit(X_comb_scaledsim_train, y_train)\n",
    "\n",
    "    #dev set\n",
    "    y_dev_pred = nb.predict(X_comb_scaledsim_dev)\n",
    "    y_dev_prob = nb.predict_proba(X_comb_scaledsim_dev)\n",
    "    dev_path = \"../myclassify/test_res/NBSIM-dev/NBSIM-\" + str(para) + \".txt\"\n",
    "    predict_for_test(y_dev, y_dev_pred, y_dev_prob, dev_path)\n",
    "\n",
    "    #test set\n",
    "    y_pred = nb.predict(X_comb_scaledsim_test)\n",
    "    y_prob = nb.predict_proba(X_comb_scaledsim_test)\n",
    "    test_path = \"../myclassify/test_res/NBSIM-test/NBSIM-\" + str(para) + \".txt\"\n",
    "    predict_for_test(y_test, y_pred, y_prob, test_path)\n",
    "\n",
    "    #test result\n",
    "    print(\"alpha: \" + str(para))\n",
    "    print(\"accuracy: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "    print(\"f1: {}\".format(f1_score(y_test, y_pred)))\n",
    "#     print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "#best MAP/MRR for dev when para = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Rank Propagation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train classifiers using best parameters obtained above, Jacana features only\n",
    "\n",
    "classifiers = {}\n",
    "\n",
    "nb = BernoulliNB(alpha=2)\n",
    "nb.fit(X_train, y_train)\n",
    "classifiers[\"NB\"] = nb\n",
    "\n",
    "gbm = GradientBoostingClassifier(n_estimators=100, max_depth=2, random_state=47156)\n",
    "gbm.fit(X_train, y_train)\n",
    "classifiers[\"GB\"] = gbm\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=150, \n",
    "                                criterion=\"entropy\", \n",
    "                                max_depth=16,\n",
    "                                min_samples_split = 8,\n",
    "                                class_weight=\"balanced\",\n",
    "                                random_state=73514)\n",
    "rf.fit(X_train, y_train)\n",
    "classifiers[\"RF\"] = rf\n",
    "\n",
    "lr = LogisticRegression(penalty = \"l1\", C=10, max_iter=1e8)\n",
    "lr.fit(X_train, y_train)\n",
    "classifiers[\"LG\"] = lr\n",
    "\n",
    "#train classifiers using best parameters obtained above, Jacana features with normalize the similarity scores\n",
    "\n",
    "nbsim = BernoulliNB(alpha=1)\n",
    "nbsim.fit(X_comb_scaledsim_train, y_train)\n",
    "classifiers[\"NBSIM\"] = nbsim\n",
    "\n",
    "gbmsim = GradientBoostingClassifier(n_estimators=50, max_depth=2, random_state=47156)\n",
    "gbmsim.fit(X_comb_scaledsim_train, y_train)\n",
    "classifiers[\"GBSIM\"] = gbmsim\n",
    "\n",
    "rfsim = RandomForestClassifier(n_estimators=300, \n",
    "                                criterion=\"entropy\", \n",
    "                                max_depth=16,\n",
    "                                min_samples_split = 8,\n",
    "                                class_weight=\"balanced_subsample\",\n",
    "                                random_state=73514)\n",
    "rfsim.fit(X_comb_scaledsim_train, y_train)\n",
    "classifiers[\"RFSIM\"] = rfsim\n",
    "\n",
    "lrsim = LogisticRegression(penalty = \"l2\", C=0.1, max_iter=1e8)\n",
    "lrsim.fit(X_comb_scaledsim_train, y_train)\n",
    "\n",
    "classifiers[\"LGSIM\"] = lrsim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.5-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "1.3980779643e-12\n",
      "1.44692234026e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongwei/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:103: DeprecationWarning: elementwise != comparison failed; this will raise an error in the future.\n",
      "/Users/hongwei/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:104: DeprecationWarning: elementwise != comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "1.29042389473e-12\n",
      "3.51773153613e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.5-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "9.82456106118e-11\n",
      "9.5397110168e-08\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "3.53272755466e-10\n",
      "3.09343692539e-07\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.5-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "4.20797882765e-12\n",
      "7.03111528627e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "3.73903202979e-12\n",
      "3.97145799008e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.5-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7116724738675958\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3366733466933868\n",
      "Original f1: 0.2694300518134715\n",
      "0.0954324533976\n",
      "0.997283541176\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 119\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8416    0.7916    0.8158       926\n",
      "          1     0.3032    0.3784    0.3367       222\n",
      "\n",
      "avg / total     0.7375    0.7117    0.7231      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7099538562953197\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3837535014005602\n",
      "Original f1: 0.3050259965337955\n",
      "0.0914636819643\n",
      "0.999999687241\n",
      "440\n",
      "0.290046143705\n",
      "Number of disagreement: 143\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8648    0.7624    0.8103      1233\n",
      "          1     0.3186    0.4824    0.3838       284\n",
      "\n",
      "avg / total     0.7625    0.7100    0.7305      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.5-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "5.73504301526e-12\n",
      "9.70918810628e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "8.23389843527e-12\n",
      "1.76174624889e-09\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.5-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.705574912891986\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3449612403100775\n",
      "Original f1: 0.2694300518134715\n",
      "0.111949685245\n",
      "0.99728354118\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 138\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8443    0.7786    0.8101       926\n",
      "          1     0.3027    0.4009    0.3450       222\n",
      "\n",
      "avg / total     0.7395    0.7056    0.7202      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7053394858272907\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38683127572016457\n",
      "Original f1: 0.3050259965337955\n",
      "0.10153586142\n",
      "0.999999687311\n",
      "447\n",
      "0.294660514173\n",
      "Number of disagreement: 160\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8666    0.7534    0.8061      1233\n",
      "          1     0.3169    0.4965    0.3868       284\n",
      "\n",
      "avg / total     0.7637    0.7053    0.7276      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.5-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "1.4637516196e-05\n",
      "0.0168038468189\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7409360580092288\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.33049403747870526\n",
      "Original f1: 0.3050259965337955\n",
      "0.00525833500181\n",
      "0.979195606876\n",
      "393\n",
      "0.259063941991\n",
      "Number of disagreement: 10\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8460    0.8329    0.8394      1233\n",
      "          1     0.3201    0.3415    0.3305       284\n",
      "\n",
      "avg / total     0.7475    0.7409    0.7441      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.5-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7047038327526133\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.35428571428571426\n",
      "Original f1: 0.2694300518134715\n",
      "0.119543385883\n",
      "0.997283541228\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 147\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8473    0.7732    0.8086       926\n",
      "          1     0.3069    0.4189    0.3543       222\n",
      "\n",
      "avg / total     0.7428    0.7047    0.7207      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7013843111404087\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3870094722598105\n",
      "Original f1: 0.3050259965337955\n",
      "0.107884576037\n",
      "0.999999687175\n",
      "453\n",
      "0.29861568886\n",
      "Number of disagreement: 170\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8672    0.7470    0.8026      1233\n",
      "          1     0.3143    0.5035    0.3870       284\n",
      "\n",
      "avg / total     0.7637    0.7014    0.7248      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.5-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3316831683168317\n",
      "Original f1: 0.2694300518134715\n",
      "0.0146664329088\n",
      "0.993667652546\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 18\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8395    0.8758    0.8573       926\n",
      "          1     0.3681    0.3018    0.3317       222\n",
      "\n",
      "avg / total     0.7484    0.7648    0.7557      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7455504284772577\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3911671924290221\n",
      "Original f1: 0.3050259965337955\n",
      "0.0325559873061\n",
      "0.98853726961\n",
      "386\n",
      "0.254449571523\n",
      "Number of disagreement: 57\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8629    0.8167    0.8392      1233\n",
      "          1     0.3543    0.4366    0.3912       284\n",
      "\n",
      "avg / total     0.7677    0.7456    0.7553      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.5-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7064459930313589\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3629489603024575\n",
      "Original f1: 0.2694300518134715\n",
      "0.123342142041\n",
      "0.999999896685\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 151\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8502    0.7721    0.8093       926\n",
      "          1     0.3127    0.4324    0.3629       222\n",
      "\n",
      "avg / total     0.7462    0.7064    0.7230      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6994067237969677\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38873994638069703\n",
      "Original f1: 0.3050259965337955\n",
      "0.112967299306\n",
      "0.999999687267\n",
      "456\n",
      "0.300593276203\n",
      "Number of disagreement: 177\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8682    0.7429    0.8007      1233\n",
      "          1     0.3139    0.5106    0.3887       284\n",
      "\n",
      "avg / total     0.7645    0.6994    0.7236      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.5-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7656794425087108\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.40879120879120884\n",
      "Original f1: 0.2694300518134715\n",
      "0.0514741166264\n",
      "0.993667658017\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 69\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8590    0.8488    0.8539       926\n",
      "          1     0.3991    0.4189    0.4088       222\n",
      "\n",
      "avg / total     0.7701    0.7657    0.7678      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7336849044166117\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.40762463343108507\n",
      "Original f1: 0.3050259965337955\n",
      "0.0638874901915\n",
      "0.999999681458\n",
      "404\n",
      "0.266315095583\n",
      "Number of disagreement: 105\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8704    0.7899    0.8282      1233\n",
      "          1     0.3492    0.4894    0.4076       284\n",
      "\n",
      "avg / total     0.7729    0.7337    0.7495      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.5-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7029616724738676\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3626168224299065\n",
      "Original f1: 0.2694300518134715\n",
      "0.128098451192\n",
      "0.999999896343\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 157\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8503    0.7667    0.8064       926\n",
      "          1     0.3099    0.4369    0.3626       222\n",
      "\n",
      "avg / total     0.7458    0.7030    0.7205      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6987475280158207\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38821954484605087\n",
      "Original f1: 0.3050259965337955\n",
      "0.113846373141\n",
      "0.999999687373\n",
      "457\n",
      "0.301252471984\n",
      "Number of disagreement: 178\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8681    0.7421    0.8002      1233\n",
      "          1     0.3132    0.5106    0.3882       284\n",
      "\n",
      "avg / total     0.7642    0.6987    0.7231      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.5-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7360627177700348\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3878787878787879\n",
      "Original f1: 0.2694300518134715\n",
      "0.0832425619442\n",
      "0.997283538786\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 109\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8560    0.8089    0.8318       926\n",
      "          1     0.3516    0.4324    0.3879       222\n",
      "\n",
      "avg / total     0.7585    0.7361    0.7459      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7152274225444957\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4016620498614959\n",
      "Original f1: 0.3050259965337955\n",
      "0.0878483495369\n",
      "0.999999686762\n",
      "432\n",
      "0.284772577456\n",
      "Number of disagreement: 145\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8712    0.7624    0.8131      1233\n",
      "          1     0.3311    0.5106    0.4017       284\n",
      "\n",
      "avg / total     0.7701    0.7152    0.7361      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.5-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7029616724738676\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3626168224299065\n",
      "Original f1: 0.2694300518134715\n",
      "0.129655539489\n",
      "0.999999896782\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 157\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8503    0.7667    0.8064       926\n",
      "          1     0.3099    0.4369    0.3626       222\n",
      "\n",
      "avg / total     0.7458    0.7030    0.7205      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6987475280158207\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3898531375166889\n",
      "Original f1: 0.3050259965337955\n",
      "0.115287235498\n",
      "0.999999687277\n",
      "457\n",
      "0.301252471984\n",
      "Number of disagreement: 180\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8688    0.7413    0.8000      1233\n",
      "          1     0.3140    0.5141    0.3899       284\n",
      "\n",
      "avg / total     0.7649    0.6987    0.7232      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.5-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "1.55524775226e-12\n",
      "1.44982716026e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "1.67430198277e-12\n",
      "9.2547371567e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.5-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "9.88643265834e-11\n",
      "9.53989156824e-08\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "3.54371821154e-10\n",
      "3.0942672809e-07\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.5-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "4.31791458995e-12\n",
      "6.97947835089e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "3.86622794196e-12\n",
      "9.2547371567e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.5-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7116724738675958\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3366733466933868\n",
      "Original f1: 0.2694300518134715\n",
      "0.0954764396194\n",
      "0.99728354122\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 119\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8416    0.7916    0.8158       926\n",
      "          1     0.3032    0.3784    0.3367       222\n",
      "\n",
      "avg / total     0.7375    0.7117    0.7231      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7099538562953197\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3837535014005602\n",
      "Original f1: 0.3050259965337955\n",
      "0.0916159348864\n",
      "0.999999687349\n",
      "440\n",
      "0.290046143705\n",
      "Number of disagreement: 143\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8648    0.7624    0.8103      1233\n",
      "          1     0.3186    0.4824    0.3838       284\n",
      "\n",
      "avg / total     0.7625    0.7100    0.7305      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.5-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "6.24909487393e-12\n",
      "9.70918810628e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "7.72323212814e-12\n",
      "1.76174624889e-09\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.5-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7038327526132404\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.34362934362934366\n",
      "Original f1: 0.2694300518134715\n",
      "0.112047137743\n",
      "0.997283541044\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 138\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8439    0.7765    0.8088       926\n",
      "          1     0.3007    0.4009    0.3436       222\n",
      "\n",
      "avg / total     0.7388    0.7038    0.7188      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7053394858272907\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38683127572016457\n",
      "Original f1: 0.3050259965337955\n",
      "0.101623339326\n",
      "0.999999687325\n",
      "447\n",
      "0.294660514173\n",
      "Number of disagreement: 160\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8666    0.7534    0.8061      1233\n",
      "          1     0.3169    0.4965    0.3868       284\n",
      "\n",
      "avg / total     0.7637    0.7053    0.7276      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.5-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "1.85053750441e-05\n",
      "0.0212441425111\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7409360580092288\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.33049403747870526\n",
      "Original f1: 0.3050259965337955\n",
      "0.00522104256924\n",
      "0.979195606288\n",
      "393\n",
      "0.259063941991\n",
      "Number of disagreement: 10\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8460    0.8329    0.8394      1233\n",
      "          1     0.3201    0.3415    0.3305       284\n",
      "\n",
      "avg / total     0.7475    0.7409    0.7441      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.5-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7038327526132404\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3536121673003802\n",
      "Original f1: 0.2694300518134715\n",
      "0.119681476844\n",
      "0.997283541223\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 148\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8472    0.7721    0.8079       926\n",
      "          1     0.3059    0.4189    0.3536       222\n",
      "\n",
      "avg / total     0.7425    0.7038    0.7201      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7013843111404087\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3870094722598105\n",
      "Original f1: 0.3050259965337955\n",
      "0.108004524443\n",
      "0.999999687333\n",
      "453\n",
      "0.29861568886\n",
      "Number of disagreement: 170\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8672    0.7470    0.8026      1233\n",
      "          1     0.3143    0.5035    0.3870       284\n",
      "\n",
      "avg / total     0.7637    0.7014    0.7248      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.5-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3316831683168317\n",
      "Original f1: 0.2694300518134715\n",
      "0.0145919250447\n",
      "0.993667654145\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 18\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8395    0.8758    0.8573       926\n",
      "          1     0.3681    0.3018    0.3317       222\n",
      "\n",
      "avg / total     0.7484    0.7648    0.7557      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7462096242584048\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.39178515007898895\n",
      "Original f1: 0.3050259965337955\n",
      "0.0325603807102\n",
      "0.988537270624\n",
      "385\n",
      "0.253790375742\n",
      "Number of disagreement: 56\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8630    0.8175    0.8397      1233\n",
      "          1     0.3553    0.4366    0.3918       284\n",
      "\n",
      "avg / total     0.7680    0.7462    0.7558      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.5-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7064459930313589\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3629489603024575\n",
      "Original f1: 0.2694300518134715\n",
      "0.123483306093\n",
      "0.999999896685\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 151\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8502    0.7721    0.8093       926\n",
      "          1     0.3127    0.4324    0.3629       222\n",
      "\n",
      "avg / total     0.7462    0.7064    0.7230      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6994067237969677\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38873994638069703\n",
      "Original f1: 0.3050259965337955\n",
      "0.113085426365\n",
      "0.999999687228\n",
      "456\n",
      "0.300593276203\n",
      "Number of disagreement: 177\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8682    0.7429    0.8007      1233\n",
      "          1     0.3139    0.5106    0.3887       284\n",
      "\n",
      "avg / total     0.7645    0.6994    0.7236      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.5-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7656794425087108\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.40879120879120884\n",
      "Original f1: 0.2694300518134715\n",
      "0.0515217719258\n",
      "0.993667658111\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 69\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8590    0.8488    0.8539       926\n",
      "          1     0.3991    0.4189    0.4088       222\n",
      "\n",
      "avg / total     0.7701    0.7657    0.7678      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7336849044166117\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.40762463343108507\n",
      "Original f1: 0.3050259965337955\n",
      "0.0639065705271\n",
      "0.999999686433\n",
      "404\n",
      "0.266315095583\n",
      "Number of disagreement: 105\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8704    0.7899    0.8282      1233\n",
      "          1     0.3492    0.4894    0.4076       284\n",
      "\n",
      "avg / total     0.7729    0.7337    0.7495      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.5-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7029616724738676\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3626168224299065\n",
      "Original f1: 0.2694300518134715\n",
      "0.128198747253\n",
      "0.999999896346\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 157\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8503    0.7667    0.8064       926\n",
      "          1     0.3099    0.4369    0.3626       222\n",
      "\n",
      "avg / total     0.7458    0.7030    0.7205      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.6987475280158207\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38821954484605087\n",
      "Original f1: 0.3050259965337955\n",
      "0.113958668648\n",
      "0.999999687374\n",
      "457\n",
      "0.301252471984\n",
      "Number of disagreement: 178\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8681    0.7421    0.8002      1233\n",
      "          1     0.3132    0.5106    0.3882       284\n",
      "\n",
      "avg / total     0.7642    0.6987    0.7231      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.5-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7360627177700348\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3878787878787879\n",
      "Original f1: 0.2694300518134715\n",
      "0.0835006399411\n",
      "0.997283539956\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 109\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8560    0.8089    0.8318       926\n",
      "          1     0.3516    0.4324    0.3879       222\n",
      "\n",
      "avg / total     0.7585    0.7361    0.7459      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7152274225444957\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4016620498614959\n",
      "Original f1: 0.3050259965337955\n",
      "0.0878010232822\n",
      "0.999999686809\n",
      "432\n",
      "0.284772577456\n",
      "Number of disagreement: 145\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8712    0.7624    0.8131      1233\n",
      "          1     0.3311    0.5106    0.4017       284\n",
      "\n",
      "avg / total     0.7701    0.7152    0.7361      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.5-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7029616724738676\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3626168224299065\n",
      "Original f1: 0.2694300518134715\n",
      "0.129776498327\n",
      "0.999999896782\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 157\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8503    0.7667    0.8064       926\n",
      "          1     0.3099    0.4369    0.3626       222\n",
      "\n",
      "avg / total     0.7458    0.7030    0.7205      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6987475280158207\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3898531375166889\n",
      "Original f1: 0.3050259965337955\n",
      "0.115400942892\n",
      "0.999999687298\n",
      "457\n",
      "0.301252471984\n",
      "Number of disagreement: 180\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8688    0.7413    0.8000      1233\n",
      "          1     0.3140    0.5141    0.3899       284\n",
      "\n",
      "avg / total     0.7649    0.6987    0.7232      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.75-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "1.41536021625e-12\n",
      "1.74101929299e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "1.36795418506e-12\n",
      "5.3707503652e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.75-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "9.86409110512e-11\n",
      "9.63275944906e-08\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "3.54285741485e-10\n",
      "3.09021192405e-07\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.75-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "3.88327289013e-12\n",
      "9.90445415173e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "3.97810651238e-12\n",
      "5.3707503652e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.75-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7090592334494773\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.33466135458167334\n",
      "Original f1: 0.2694300518134715\n",
      "0.0975016954118\n",
      "0.997283541137\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 120\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8410    0.7883    0.8138       926\n",
      "          1     0.3000    0.3784    0.3347       222\n",
      "\n",
      "avg / total     0.7364    0.7091    0.7212      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7079762689518787\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3838664812239222\n",
      "Original f1: 0.3050259965337955\n",
      "0.092868089059\n",
      "0.999999686939\n",
      "443\n",
      "0.292023731048\n",
      "Number of disagreement: 144\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8651    0.7591    0.8086      1233\n",
      "          1     0.3172    0.4859    0.3839       284\n",
      "\n",
      "avg / total     0.7625    0.7080    0.7291      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.75-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "8.80051578688e-12\n",
      "1.85561505833e-09\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "7.78398127716e-12\n",
      "1.70934966182e-09\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.75-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7029616724738676\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3429672447013488\n",
      "Original f1: 0.2694300518134715\n",
      "0.112965798406\n",
      "0.997283541213\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 137\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8437    0.7754    0.8081       926\n",
      "          1     0.2997    0.4009    0.3430       222\n",
      "\n",
      "avg / total     0.7385    0.7030    0.7182      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7033618984838497\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38692098092643046\n",
      "Original f1: 0.3050259965337955\n",
      "0.102224350488\n",
      "0.99999968724\n",
      "450\n",
      "0.296638101516\n",
      "Number of disagreement: 159\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8669    0.7502    0.8043      1233\n",
      "          1     0.3156    0.5000    0.3869       284\n",
      "\n",
      "avg / total     0.7637    0.7034    0.7262      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.75-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "3.83552441797e-05\n",
      "0.0440317581538\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7409360580092288\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.33049403747870526\n",
      "Original f1: 0.3050259965337955\n",
      "0.00567732576329\n",
      "0.988537262862\n",
      "393\n",
      "0.259063941991\n",
      "Number of disagreement: 10\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8460    0.8329    0.8394      1233\n",
      "          1     0.3201    0.3415    0.3305       284\n",
      "\n",
      "avg / total     0.7475    0.7409    0.7441      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.75-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7012195121951219\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.35160680529300564\n",
      "Original f1: 0.2694300518134715\n",
      "0.120413736123\n",
      "0.997283541157\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 147\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8466    0.7689    0.8059       926\n",
      "          1     0.3029    0.4189    0.3516       222\n",
      "\n",
      "avg / total     0.7415    0.7012    0.7180      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.6987475280158207\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3865771812080537\n",
      "Original f1: 0.3050259965337955\n",
      "0.108697826681\n",
      "0.999999687227\n",
      "457\n",
      "0.301252471984\n",
      "Number of disagreement: 170\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8674    0.7429    0.8003      1233\n",
      "          1     0.3124    0.5070    0.3866       284\n",
      "\n",
      "avg / total     0.7635    0.6987    0.7229      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.75-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3316831683168317\n",
      "Original f1: 0.2694300518134715\n",
      "0.014796128984\n",
      "0.993667568999\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 18\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8395    0.8758    0.8573       926\n",
      "          1     0.3681    0.3018    0.3317       222\n",
      "\n",
      "avg / total     0.7484    0.7648    0.7557      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7475280158206987\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3987441130298274\n",
      "Original f1: 0.3050259965337955\n",
      "0.0336058188411\n",
      "0.988537270083\n",
      "383\n",
      "0.252471984179\n",
      "Number of disagreement: 60\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8651    0.8167    0.8402      1233\n",
      "          1     0.3598    0.4472    0.3987       284\n",
      "\n",
      "avg / total     0.7705    0.7475    0.7576      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.75-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7038327526132404\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3609022556390978\n",
      "Original f1: 0.2694300518134715\n",
      "0.124171660066\n",
      "0.999999895836\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 150\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8496    0.7689    0.8073       926\n",
      "          1     0.3097    0.4324    0.3609       222\n",
      "\n",
      "avg / total     0.7452    0.7038    0.7209      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6967699406723797\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3882978723404255\n",
      "Original f1: 0.3050259965337955\n",
      "0.113886132408\n",
      "0.999999687417\n",
      "460\n",
      "0.303230059328\n",
      "Number of disagreement: 177\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8684    0.7388    0.7984      1233\n",
      "          1     0.3120    0.5141    0.3883       284\n",
      "\n",
      "avg / total     0.7643    0.6968    0.7216      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.75-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.40789473684210525\n",
      "Original f1: 0.2694300518134715\n",
      "0.0522195898392\n",
      "0.993667658026\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 70\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8589    0.8477    0.8533       926\n",
      "          1     0.3974    0.4189    0.4079       222\n",
      "\n",
      "avg / total     0.7696    0.7648    0.7671      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7330257086354647\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.40875912408759124\n",
      "Original f1: 0.3050259965337955\n",
      "0.0656703811852\n",
      "0.999999685425\n",
      "405\n",
      "0.266974291365\n",
      "Number of disagreement: 108\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8710    0.7883    0.8276      1233\n",
      "          1     0.3491    0.4930    0.4088       284\n",
      "\n",
      "avg / total     0.7733    0.7330    0.7492      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.75-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7012195121951219\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36126629422718803\n",
      "Original f1: 0.2694300518134715\n",
      "0.128393247058\n",
      "0.999999896792\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 155\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8499    0.7646    0.8050       926\n",
      "          1     0.3079    0.4369    0.3613       222\n",
      "\n",
      "avg / total     0.7451    0.7012    0.7192      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6967699406723797\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3882978723404255\n",
      "Original f1: 0.3050259965337955\n",
      "0.114529837123\n",
      "0.999999687413\n",
      "460\n",
      "0.303230059328\n",
      "Number of disagreement: 177\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8684    0.7388    0.7984      1233\n",
      "          1     0.3120    0.5141    0.3883       284\n",
      "\n",
      "avg / total     0.7643    0.6968    0.7216      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.75-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7343205574912892\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.386317907444668\n",
      "Original f1: 0.2694300518134715\n",
      "0.0849554283782\n",
      "0.999999893678\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 111\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8557    0.8067    0.8305       926\n",
      "          1     0.3491    0.4324    0.3863       222\n",
      "\n",
      "avg / total     0.7577    0.7343    0.7446      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7152274225444957\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4016620498614959\n",
      "Original f1: 0.3050259965337955\n",
      "0.088858591422\n",
      "0.999999684683\n",
      "432\n",
      "0.284772577456\n",
      "Number of disagreement: 145\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8712    0.7624    0.8131      1233\n",
      "          1     0.3311    0.5106    0.4017       284\n",
      "\n",
      "avg / total     0.7701    0.7152    0.7361      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.75-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7003484320557491\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36059479553903345\n",
      "Original f1: 0.2694300518134715\n",
      "0.130605342036\n",
      "0.99999989681\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 156\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8498    0.7635    0.8043       926\n",
      "          1     0.3070    0.4369    0.3606       222\n",
      "\n",
      "avg / total     0.7448    0.7003    0.7185      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6967699406723797\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38992042440318303\n",
      "Original f1: 0.3050259965337955\n",
      "0.116002530643\n",
      "0.999999687378\n",
      "460\n",
      "0.303230059328\n",
      "Number of disagreement: 179\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8691    0.7380    0.7982      1233\n",
      "          1     0.3128    0.5176    0.3899       284\n",
      "\n",
      "avg / total     0.7650    0.6968    0.7218      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.75-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "1.51714202459e-12\n",
      "1.8173499454e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "1.16215580703e-12\n",
      "2.33049336075e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.75-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "9.62207178156e-11\n",
      "9.6433386575e-08\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "3.539753803e-10\n",
      "3.08973701373e-07\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.75-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "4.0782736212e-12\n",
      "9.74031675748e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "3.73428841111e-12\n",
      "5.29014543739e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.75-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7099303135888502\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.33532934131736525\n",
      "Original f1: 0.2694300518134715\n",
      "0.0976811803737\n",
      "0.99728354121\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 121\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8412    0.7894    0.8145       926\n",
      "          1     0.3011    0.3784    0.3353       222\n",
      "\n",
      "avg / total     0.7367    0.7099    0.7218      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7086354647330257\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38440111420612816\n",
      "Original f1: 0.3050259965337955\n",
      "0.0932976300441\n",
      "0.999999687178\n",
      "442\n",
      "0.291364535267\n",
      "Number of disagreement: 145\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8652    0.7599    0.8092      1233\n",
      "          1     0.3180    0.4859    0.3844       284\n",
      "\n",
      "avg / total     0.7627    0.7086    0.7296      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.75-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "9.03379183119e-12\n",
      "1.77290859771e-09\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "9.85952589801e-12\n",
      "1.70934966182e-09\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.75-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7038327526132404\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.34362934362934366\n",
      "Original f1: 0.2694300518134715\n",
      "0.113180866603\n",
      "0.997283541197\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 138\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8439    0.7765    0.8088       926\n",
      "          1     0.3007    0.4009    0.3436       222\n",
      "\n",
      "avg / total     0.7388    0.7038    0.7188      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7040210942649967\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38744884038199184\n",
      "Original f1: 0.3050259965337955\n",
      "0.102578406691\n",
      "0.9999996874\n",
      "449\n",
      "0.295978905735\n",
      "Number of disagreement: 160\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8670    0.7510    0.8049      1233\n",
      "          1     0.3163    0.5000    0.3874       284\n",
      "\n",
      "avg / total     0.7639    0.7040    0.7267      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.75-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "8.10541329091e-05\n",
      "0.0930501107873\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7409360580092288\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.33049403747870526\n",
      "Original f1: 0.3050259965337955\n",
      "0.00558313732602\n",
      "0.988537225242\n",
      "393\n",
      "0.259063941991\n",
      "Number of disagreement: 10\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8460    0.8329    0.8394      1233\n",
      "          1     0.3201    0.3415    0.3305       284\n",
      "\n",
      "avg / total     0.7475    0.7409    0.7441      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.75-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7020905923344948\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.35227272727272724\n",
      "Original f1: 0.2694300518134715\n",
      "0.120671176985\n",
      "0.997283541187\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 148\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8468    0.7700    0.8066       926\n",
      "          1     0.3039    0.4189    0.3523       222\n",
      "\n",
      "avg / total     0.7418    0.7021    0.7187      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6994067237969677\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3870967741935485\n",
      "Original f1: 0.3050259965337955\n",
      "0.109108901109\n",
      "0.999999687242\n",
      "456\n",
      "0.300593276203\n",
      "Number of disagreement: 171\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8675    0.7437    0.8009      1233\n",
      "          1     0.3130    0.5070    0.3871       284\n",
      "\n",
      "avg / total     0.7637    0.6994    0.7234      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.75-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3316831683168317\n",
      "Original f1: 0.2694300518134715\n",
      "0.0147565355207\n",
      "0.993667656615\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 18\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8395    0.8758    0.8573       926\n",
      "          1     0.3681    0.3018    0.3317       222\n",
      "\n",
      "avg / total     0.7484    0.7648    0.7557      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7475280158206987\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3987441130298274\n",
      "Original f1: 0.3050259965337955\n",
      "0.0333704812024\n",
      "0.988537270482\n",
      "383\n",
      "0.252471984179\n",
      "Number of disagreement: 60\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8651    0.8167    0.8402      1233\n",
      "          1     0.3598    0.4472    0.3987       284\n",
      "\n",
      "avg / total     0.7705    0.7475    0.7576      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.75-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7047038327526133\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3615819209039548\n",
      "Original f1: 0.2694300518134715\n",
      "0.124487700534\n",
      "0.999999895916\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 151\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8498    0.7700    0.8079       926\n",
      "          1     0.3107    0.4324    0.3616       222\n",
      "\n",
      "avg / total     0.7456    0.7047    0.7216      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6974291364535267\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.388814913448735\n",
      "Original f1: 0.3050259965337955\n",
      "0.114284526235\n",
      "0.999999687397\n",
      "459\n",
      "0.302570863546\n",
      "Number of disagreement: 178\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8686    0.7397    0.7989      1233\n",
      "          1     0.3126    0.5141    0.3888       284\n",
      "\n",
      "avg / total     0.7645    0.6974    0.7222      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.75-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.40789473684210525\n",
      "Original f1: 0.2694300518134715\n",
      "0.0522687163293\n",
      "0.993667658794\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 70\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8589    0.8477    0.8533       926\n",
      "          1     0.3974    0.4189    0.4079       222\n",
      "\n",
      "avg / total     0.7696    0.7648    0.7671      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7336849044166117\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4093567251461988\n",
      "Original f1: 0.3050259965337955\n",
      "0.0656163821143\n",
      "0.999999681144\n",
      "404\n",
      "0.266315095583\n",
      "Number of disagreement: 107\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8711    0.7891    0.8281      1233\n",
      "          1     0.3500    0.4930    0.4094       284\n",
      "\n",
      "avg / total     0.7735    0.7337    0.7497      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.75-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7029616724738676\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3626168224299065\n",
      "Original f1: 0.2694300518134715\n",
      "0.128612409951\n",
      "0.999999896785\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 155\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8503    0.7667    0.8064       926\n",
      "          1     0.3099    0.4369    0.3626       222\n",
      "\n",
      "avg / total     0.7458    0.7030    0.7205      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6974291364535267\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.388814913448735\n",
      "Original f1: 0.3050259965337955\n",
      "0.114916881534\n",
      "0.99999968742\n",
      "459\n",
      "0.302570863546\n",
      "Number of disagreement: 178\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8686    0.7397    0.7989      1233\n",
      "          1     0.3126    0.5141    0.3888       284\n",
      "\n",
      "avg / total     0.7645    0.6974    0.7222      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.75-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7325783972125436\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3847695390781563\n",
      "Original f1: 0.2694300518134715\n",
      "0.0855077307424\n",
      "0.999999874815\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 113\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8553    0.8045    0.8292       926\n",
      "          1     0.3466    0.4324    0.3848       222\n",
      "\n",
      "avg / total     0.7570    0.7326    0.7432      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7152274225444957\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4016620498614959\n",
      "Original f1: 0.3050259965337955\n",
      "0.0889396877956\n",
      "0.999999687111\n",
      "432\n",
      "0.284772577456\n",
      "Number of disagreement: 145\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8712    0.7624    0.8131      1233\n",
      "          1     0.3311    0.5106    0.4017       284\n",
      "\n",
      "avg / total     0.7701    0.7152    0.7361      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-0.75-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7012195121951219\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36126629422718803\n",
      "Original f1: 0.2694300518134715\n",
      "0.130873454428\n",
      "0.999999896811\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 157\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8499    0.7646    0.8050       926\n",
      "          1     0.3079    0.4369    0.3613       222\n",
      "\n",
      "avg / total     0.7451    0.7012    0.7192      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.6974291364535267\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.39043824701195223\n",
      "Original f1: 0.3050259965337955\n",
      "0.116405228383\n",
      "0.999999687414\n",
      "459\n",
      "0.302570863546\n",
      "Number of disagreement: 180\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8693    0.7388    0.7988      1233\n",
      "          1     0.3134    0.5176    0.3904       284\n",
      "\n",
      "avg / total     0.7652    0.6974    0.7223      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.0-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "1.49785816861e-12\n",
      "2.04177315963e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "1.22395675502e-12\n",
      "2.90303205536e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.0-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "9.86955303028e-11\n",
      "9.68099070554e-08\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "3.56107041708e-10\n",
      "3.09178738863e-07\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.0-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "3.48687561278e-12\n",
      "8.12513186453e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "4.44427255491e-12\n",
      "5.23651836007e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.0-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7090592334494773\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.33992094861660077\n",
      "Original f1: 0.2694300518134715\n",
      "0.0989808255163\n",
      "0.997283541023\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 124\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8426    0.7862    0.8134       926\n",
      "          1     0.3028    0.3874    0.3399       222\n",
      "\n",
      "avg / total     0.7382    0.7091    0.7218      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7079762689518787\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3855755894590846\n",
      "Original f1: 0.3050259965337955\n",
      "0.0933487008382\n",
      "0.999999687407\n",
      "443\n",
      "0.292023731048\n",
      "Number of disagreement: 146\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8657    0.7583    0.8085      1233\n",
      "          1     0.3181    0.4894    0.3856       284\n",
      "\n",
      "avg / total     0.7632    0.7080    0.7293      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.0-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "8.27962111852e-12\n",
      "1.58024424804e-09\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "7.76560002758e-12\n",
      "1.3966766077e-09\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.0-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7038327526132404\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3461538461538462\n",
      "Original f1: 0.2694300518134715\n",
      "0.113504644445\n",
      "0.997283541207\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 138\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8447    0.7754    0.8086       926\n",
      "          1     0.3020    0.4054    0.3462       222\n",
      "\n",
      "avg / total     0.7398    0.7038    0.7191      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7033618984838497\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38692098092643046\n",
      "Original f1: 0.3050259965337955\n",
      "0.10270092924\n",
      "0.999999687402\n",
      "450\n",
      "0.296638101516\n",
      "Number of disagreement: 159\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8669    0.7502    0.8043      1233\n",
      "          1     0.3156    0.5000    0.3869       284\n",
      "\n",
      "avg / total     0.7637    0.7034    0.7262      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.0-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.000107508513494\n",
      "0.0608946384432\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7409360580092288\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.33049403747870526\n",
      "Original f1: 0.3050259965337955\n",
      "0.00568689151266\n",
      "0.988537264804\n",
      "393\n",
      "0.259063941991\n",
      "Number of disagreement: 10\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8460    0.8329    0.8394      1233\n",
      "          1     0.3201    0.3415    0.3305       284\n",
      "\n",
      "avg / total     0.7475    0.7409    0.7441      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.0-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7012195121951219\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3540489642184557\n",
      "Original f1: 0.2694300518134715\n",
      "0.12100924762\n",
      "0.99728354122\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 149\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8474    0.7678    0.8057       926\n",
      "          1     0.3042    0.4234    0.3540       222\n",
      "\n",
      "avg / total     0.7424    0.7012    0.7183      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6987475280158207\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3865771812080537\n",
      "Original f1: 0.3050259965337955\n",
      "0.109171381935\n",
      "0.999999687399\n",
      "457\n",
      "0.301252471984\n",
      "Number of disagreement: 170\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8674    0.7429    0.8003      1233\n",
      "          1     0.3124    0.5070    0.3866       284\n",
      "\n",
      "avg / total     0.7635    0.6987    0.7229      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.0-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7639372822299652\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3275434243176179\n",
      "Original f1: 0.2694300518134715\n",
      "0.0146440060626\n",
      "0.993264875122\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 17\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8387    0.8758    0.8568       926\n",
      "          1     0.3646    0.2973    0.3275       222\n",
      "\n",
      "avg / total     0.7470    0.7639    0.7545      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7468688200395518\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3981191222570533\n",
      "Original f1: 0.3050259965337955\n",
      "0.0334759073829\n",
      "0.988537270495\n",
      "384\n",
      "0.25313117996\n",
      "Number of disagreement: 61\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8650    0.8159    0.8397      1233\n",
      "          1     0.3588    0.4472    0.3981       284\n",
      "\n",
      "avg / total     0.7702    0.7469    0.7571      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.0-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7038327526132404\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3632958801498127\n",
      "Original f1: 0.2694300518134715\n",
      "0.124849565327\n",
      "0.999999896336\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 152\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8505    0.7678    0.8070       926\n",
      "          1     0.3109    0.4369    0.3633       222\n",
      "\n",
      "avg / total     0.7461    0.7038    0.7212      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.6967699406723797\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3882978723404255\n",
      "Original f1: 0.3050259965337955\n",
      "0.114344326029\n",
      "0.999999687332\n",
      "460\n",
      "0.303230059328\n",
      "Number of disagreement: 177\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8684    0.7388    0.7984      1233\n",
      "          1     0.3120    0.5141    0.3883       284\n",
      "\n",
      "avg / total     0.7643    0.6968    0.7216      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.0-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.40789473684210525\n",
      "Original f1: 0.2694300518134715\n",
      "0.0525800124312\n",
      "0.993667657004\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 70\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8589    0.8477    0.8533       926\n",
      "          1     0.3974    0.4189    0.4079       222\n",
      "\n",
      "avg / total     0.7696    0.7648    0.7671      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7323665128543178\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4081632653061225\n",
      "Original f1: 0.3050259965337955\n",
      "0.0666431552639\n",
      "0.999999685223\n",
      "406\n",
      "0.267633487146\n",
      "Number of disagreement: 109\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8709    0.7875    0.8271      1233\n",
      "          1     0.3483    0.4930    0.4082       284\n",
      "\n",
      "avg / total     0.7730    0.7324    0.7487      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.0-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7020905923344948\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3643122676579925\n",
      "Original f1: 0.2694300518134715\n",
      "0.128945328008\n",
      "0.999999896774\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 156\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8510    0.7646    0.8055       926\n",
      "          1     0.3101    0.4414    0.3643       222\n",
      "\n",
      "avg / total     0.7464    0.7021    0.7202      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6967699406723797\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3882978723404255\n",
      "Original f1: 0.3050259965337955\n",
      "0.114947441065\n",
      "0.999999687419\n",
      "460\n",
      "0.303230059328\n",
      "Number of disagreement: 177\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8684    0.7388    0.7984      1233\n",
      "          1     0.3120    0.5141    0.3883       284\n",
      "\n",
      "avg / total     0.7643    0.6968    0.7216      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.0-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7325783972125436\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3847695390781563\n",
      "Original f1: 0.2694300518134715\n",
      "0.0857701882731\n",
      "0.999999892149\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 113\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8553    0.8045    0.8292       926\n",
      "          1     0.3466    0.4324    0.3848       222\n",
      "\n",
      "avg / total     0.7570    0.7326    0.7432      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7145682267633487\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4011065006915629\n",
      "Original f1: 0.3050259965337955\n",
      "0.089414431542\n",
      "0.999999685627\n",
      "433\n",
      "0.285431773237\n",
      "Number of disagreement: 146\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8711    0.7616    0.8126      1233\n",
      "          1     0.3303    0.5106    0.4011       284\n",
      "\n",
      "avg / total     0.7698    0.7146    0.7356      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.0-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7003484320557491\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36296296296296293\n",
      "Original f1: 0.2694300518134715\n",
      "0.13133455327\n",
      "0.999999896817\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 158\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8506    0.7624    0.8041       926\n",
      "          1     0.3082    0.4414    0.3630       222\n",
      "\n",
      "avg / total     0.7457    0.7003    0.7188      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6961107448912327\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3894039735099337\n",
      "Original f1: 0.3050259965337955\n",
      "0.116457657308\n",
      "0.999999687412\n",
      "461\n",
      "0.303889255109\n",
      "Number of disagreement: 180\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8690    0.7372    0.7977      1233\n",
      "          1     0.3121    0.5176    0.3894       284\n",
      "\n",
      "avg / total     0.7648    0.6961    0.7213      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.0-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "1.28690390842e-12\n",
      "2.08741155001e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "1.42760545573e-12\n",
      "7.70606766945e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.0-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "1.04705913129e-10\n",
      "9.70243774947e-08\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "3.5459616039e-10\n",
      "3.09072777111e-07\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.0-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "3.36147166749e-12\n",
      "9.04682211704e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "3.70101253444e-12\n",
      "7.70606766945e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.0-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.710801393728223\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3412698412698413\n",
      "Original f1: 0.2694300518134715\n",
      "0.0990689961243\n",
      "0.997283541055\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 122\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8430    0.7883    0.8147       926\n",
      "          1     0.3050    0.3874    0.3413       222\n",
      "\n",
      "avg / total     0.7389    0.7108    0.7232      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7079762689518787\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3855755894590846\n",
      "Original f1: 0.3050259965337955\n",
      "0.0939690960336\n",
      "0.999999687141\n",
      "443\n",
      "0.292023731048\n",
      "Number of disagreement: 146\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8657    0.7583    0.8085      1233\n",
      "          1     0.3181    0.4894    0.3856       284\n",
      "\n",
      "avg / total     0.7632    0.7080    0.7293      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.0-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "8.01176801408e-12\n",
      "1.96670434671e-09\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "5.9193234187e-12\n",
      "1.3966766077e-09\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.0-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7047038327526133\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.34682080924855496\n",
      "Original f1: 0.2694300518134715\n",
      "0.113929965241\n",
      "0.997283541182\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 139\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8449    0.7765    0.8092       926\n",
      "          1     0.3030    0.4054    0.3468       222\n",
      "\n",
      "avg / total     0.7401    0.7047    0.7198      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7033618984838497\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38692098092643046\n",
      "Original f1: 0.3050259965337955\n",
      "0.103280996355\n",
      "0.999999687416\n",
      "450\n",
      "0.296638101516\n",
      "Number of disagreement: 159\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8669    0.7502    0.8043      1233\n",
      "          1     0.3156    0.5000    0.3869       284\n",
      "\n",
      "avg / total     0.7637    0.7034    0.7262      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.0-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.000191768903008\n",
      "0.159256023969\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7409360580092288\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.33049403747870526\n",
      "Original f1: 0.3050259965337955\n",
      "0.00559544972084\n",
      "0.988537268765\n",
      "393\n",
      "0.259063941991\n",
      "Number of disagreement: 10\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8460    0.8329    0.8394      1233\n",
      "          1     0.3201    0.3415    0.3305       284\n",
      "\n",
      "avg / total     0.7475    0.7409    0.7441      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.0-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7029616724738676\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3553875236294896\n",
      "Original f1: 0.2694300518134715\n",
      "0.121363319143\n",
      "0.997283541193\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 149\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8478    0.7700    0.8070       926\n",
      "          1     0.3062    0.4234    0.3554       222\n",
      "\n",
      "avg / total     0.7431    0.7030    0.7197      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6987475280158207\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3865771812080537\n",
      "Original f1: 0.3050259965337955\n",
      "0.109758011629\n",
      "0.999999687235\n",
      "457\n",
      "0.301252471984\n",
      "Number of disagreement: 170\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8674    0.7429    0.8003      1233\n",
      "          1     0.3124    0.5070    0.3866       284\n",
      "\n",
      "avg / total     0.7635    0.6987    0.7229      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.0-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7639372822299652\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3275434243176179\n",
      "Original f1: 0.2694300518134715\n",
      "0.0147117760274\n",
      "0.993667657524\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 17\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8387    0.8758    0.8568       926\n",
      "          1     0.3646    0.2973    0.3275       222\n",
      "\n",
      "avg / total     0.7470    0.7639    0.7545      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7468688200395518\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3962264150943396\n",
      "Original f1: 0.3050259965337955\n",
      "0.0328328743181\n",
      "0.988537270358\n",
      "384\n",
      "0.25313117996\n",
      "Number of disagreement: 59\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8644    0.8167    0.8399      1233\n",
      "          1     0.3580    0.4437    0.3962       284\n",
      "\n",
      "avg / total     0.7696    0.7469    0.7568      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.0-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.705574912891986\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36466165413533835\n",
      "Original f1: 0.2694300518134715\n",
      "0.125236548199\n",
      "0.999999896438\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 152\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8508    0.7700    0.8084       926\n",
      "          1     0.3129    0.4369    0.3647       222\n",
      "\n",
      "avg / total     0.7468    0.7056    0.7226      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6967699406723797\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3882978723404255\n",
      "Original f1: 0.3050259965337955\n",
      "0.114893080214\n",
      "0.999999687407\n",
      "460\n",
      "0.303230059328\n",
      "Number of disagreement: 177\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8684    0.7388    0.7984      1233\n",
      "          1     0.3120    0.5141    0.3883       284\n",
      "\n",
      "avg / total     0.7643    0.6968    0.7216      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.0-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.40789473684210525\n",
      "Original f1: 0.2694300518134715\n",
      "0.0526145229889\n",
      "0.993667659014\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 70\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8589    0.8477    0.8533       926\n",
      "          1     0.3974    0.4189    0.4079       222\n",
      "\n",
      "avg / total     0.7696    0.7648    0.7671      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7317073170731707\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4058394160583942\n",
      "Original f1: 0.3050259965337955\n",
      "0.0665949257809\n",
      "0.999999684352\n",
      "407\n",
      "0.268292682927\n",
      "Number of disagreement: 108\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8701    0.7875    0.8267      1233\n",
      "          1     0.3466    0.4894    0.4058       284\n",
      "\n",
      "avg / total     0.7721    0.7317    0.7479      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.0-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7038327526132404\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3656716417910448\n",
      "Original f1: 0.2694300518134715\n",
      "0.1292476408\n",
      "0.999999896755\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 156\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8513    0.7667    0.8068       926\n",
      "          1     0.3121    0.4414    0.3657       222\n",
      "\n",
      "avg / total     0.7470    0.7038    0.7215      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6967699406723797\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3882978723404255\n",
      "Original f1: 0.3050259965337955\n",
      "0.115490955438\n",
      "0.999999687365\n",
      "460\n",
      "0.303230059328\n",
      "Number of disagreement: 177\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8684    0.7388    0.7984      1233\n",
      "          1     0.3120    0.5141    0.3883       284\n",
      "\n",
      "avg / total     0.7643    0.6968    0.7216      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.0-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7325783972125436\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3847695390781563\n",
      "Original f1: 0.2694300518134715\n",
      "0.086279367262\n",
      "0.999999893915\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 113\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8553    0.8045    0.8292       926\n",
      "          1     0.3466    0.4324    0.3848       222\n",
      "\n",
      "avg / total     0.7570    0.7326    0.7432      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7145682267633487\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4011065006915629\n",
      "Original f1: 0.3050259965337955\n",
      "0.0895520862556\n",
      "0.999999686961\n",
      "433\n",
      "0.285431773237\n",
      "Number of disagreement: 146\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8711    0.7616    0.8126      1233\n",
      "          1     0.3303    0.5106    0.4011       284\n",
      "\n",
      "avg / total     0.7698    0.7146    0.7356      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.0-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7020905923344948\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3643122676579925\n",
      "Original f1: 0.2694300518134715\n",
      "0.131665351285\n",
      "0.99999989682\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 158\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8510    0.7646    0.8055       926\n",
      "          1     0.3101    0.4414    0.3643       222\n",
      "\n",
      "avg / total     0.7464    0.7021    0.7202      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6961107448912327\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3894039735099337\n",
      "Original f1: 0.3050259965337955\n",
      "0.117028947777\n",
      "0.999999687415\n",
      "461\n",
      "0.303889255109\n",
      "Number of disagreement: 180\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8690    0.7372    0.7977      1233\n",
      "          1     0.3121    0.5176    0.3894       284\n",
      "\n",
      "avg / total     0.7648    0.6961    0.7213      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.5-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "1.81813068584e-12\n",
      "2.09333214389e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "1.3778577564e-12\n",
      "3.38214466935e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.5-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "1.01162836513e-10\n",
      "9.69449963259e-08\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "3.54785729063e-10\n",
      "3.09140081079e-07\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.5-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "5.0187039679e-12\n",
      "8.87172405866e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "3.20753881159e-12\n",
      "5.71708228543e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.5-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7090592334494773\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.33992094861660077\n",
      "Original f1: 0.2694300518134715\n",
      "0.0999233844976\n",
      "0.997283541177\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 122\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8426    0.7862    0.8134       926\n",
      "          1     0.3028    0.3874    0.3399       222\n",
      "\n",
      "avg / total     0.7382    0.7091    0.7218      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7073170731707317\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3850415512465374\n",
      "Original f1: 0.3050259965337955\n",
      "0.0938666026853\n",
      "0.999999686992\n",
      "444\n",
      "0.292682926829\n",
      "Number of disagreement: 145\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8656    0.7575    0.8080      1233\n",
      "          1     0.3174    0.4894    0.3850       284\n",
      "\n",
      "avg / total     0.7630    0.7073    0.7288      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.5-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "9.47847951888e-12\n",
      "2.54187014467e-09\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "6.83497690901e-12\n",
      "6.49842180067e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.5-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7038327526132404\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3461538461538462\n",
      "Original f1: 0.2694300518134715\n",
      "0.114233799682\n",
      "0.997283541227\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 136\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8447    0.7754    0.8086       926\n",
      "          1     0.3020    0.4054    0.3462       222\n",
      "\n",
      "avg / total     0.7398    0.7038    0.7191      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7027027027027027\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38639455782312926\n",
      "Original f1: 0.3050259965337955\n",
      "0.103364459684\n",
      "0.999999687389\n",
      "451\n",
      "0.297297297297\n",
      "Number of disagreement: 158\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8668    0.7494    0.8038      1233\n",
      "          1     0.3149    0.5000    0.3864       284\n",
      "\n",
      "avg / total     0.7635    0.7027    0.7257      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.5-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.000227433890082\n",
      "0.182403554889\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7409360580092288\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.33049403747870526\n",
      "Original f1: 0.3050259965337955\n",
      "0.00574794244721\n",
      "0.988537267291\n",
      "393\n",
      "0.259063941991\n",
      "Number of disagreement: 10\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8460    0.8329    0.8394      1233\n",
      "          1     0.3201    0.3415    0.3305       284\n",
      "\n",
      "avg / total     0.7475    0.7409    0.7441      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.5-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7012195121951219\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3540489642184557\n",
      "Original f1: 0.2694300518134715\n",
      "0.12180930227\n",
      "0.997283541227\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 147\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8474    0.7678    0.8057       926\n",
      "          1     0.3042    0.4234    0.3540       222\n",
      "\n",
      "avg / total     0.7424    0.7012    0.7183      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6980883322346737\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.386058981233244\n",
      "Original f1: 0.3050259965337955\n",
      "0.109628194726\n",
      "0.999999687389\n",
      "458\n",
      "0.301911667765\n",
      "Number of disagreement: 169\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8673    0.7421    0.7998      1233\n",
      "          1     0.3117    0.5070    0.3861       284\n",
      "\n",
      "avg / total     0.7633    0.6981    0.7224      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.5-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7639372822299652\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3275434243176179\n",
      "Original f1: 0.2694300518134715\n",
      "0.0143593347796\n",
      "0.993264876573\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 17\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8387    0.8758    0.8568       926\n",
      "          1     0.3646    0.2973    0.3275       222\n",
      "\n",
      "avg / total     0.7470    0.7639    0.7545      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7455504284772577\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3949843260188088\n",
      "Original f1: 0.3050259965337955\n",
      "0.0331709673571\n",
      "0.988537270536\n",
      "386\n",
      "0.254449571523\n",
      "Number of disagreement: 61\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8641    0.8151    0.8389      1233\n",
      "          1     0.3559    0.4437    0.3950       284\n",
      "\n",
      "avg / total     0.7690    0.7456    0.7558      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.5-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7038327526132404\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3632958801498127\n",
      "Original f1: 0.2694300518134715\n",
      "0.125729233188\n",
      "0.999999896382\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 150\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8505    0.7678    0.8070       926\n",
      "          1     0.3109    0.4369    0.3633       222\n",
      "\n",
      "avg / total     0.7461    0.7038    0.7212      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6961107448912327\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3877822045152722\n",
      "Original f1: 0.3050259965337955\n",
      "0.114786913367\n",
      "0.999999687262\n",
      "461\n",
      "0.303889255109\n",
      "Number of disagreement: 176\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8683    0.7380    0.7979      1233\n",
      "          1     0.3113    0.5141    0.3878       284\n",
      "\n",
      "avg / total     0.7640    0.6961    0.7211      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.5-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.40789473684210525\n",
      "Original f1: 0.2694300518134715\n",
      "0.0527553873938\n",
      "0.993667659032\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 70\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8589    0.8477    0.8533       926\n",
      "          1     0.3974    0.4189    0.4079       222\n",
      "\n",
      "avg / total     0.7696    0.7648    0.7671      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7323665128543178\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4081632653061225\n",
      "Original f1: 0.3050259965337955\n",
      "0.0674495362649\n",
      "0.999999684469\n",
      "406\n",
      "0.267633487146\n",
      "Number of disagreement: 109\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8709    0.7875    0.8271      1233\n",
      "          1     0.3483    0.4930    0.4082       284\n",
      "\n",
      "avg / total     0.7730    0.7324    0.7487      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.5-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7020905923344948\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3643122676579925\n",
      "Original f1: 0.2694300518134715\n",
      "0.129715828214\n",
      "0.999999896717\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 154\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8510    0.7646    0.8055       926\n",
      "          1     0.3101    0.4414    0.3643       222\n",
      "\n",
      "avg / total     0.7464    0.7021    0.7202      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.6961107448912327\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3877822045152722\n",
      "Original f1: 0.3050259965337955\n",
      "0.115392451347\n",
      "0.999999687407\n",
      "461\n",
      "0.303889255109\n",
      "Number of disagreement: 176\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8683    0.7380    0.7979      1233\n",
      "          1     0.3113    0.5141    0.3878       284\n",
      "\n",
      "avg / total     0.7640    0.6961    0.7211      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.5-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7317073170731707\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.384\n",
      "Original f1: 0.2694300518134715\n",
      "0.0864867652509\n",
      "0.999999896187\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 114\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8552    0.8035    0.8285       926\n",
      "          1     0.3453    0.4324    0.3840       222\n",
      "\n",
      "avg / total     0.7566    0.7317    0.7425      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7145682267633487\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4011065006915629\n",
      "Original f1: 0.3050259965337955\n",
      "0.089431151609\n",
      "0.999999687171\n",
      "433\n",
      "0.285431773237\n",
      "Number of disagreement: 146\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8711    0.7616    0.8126      1233\n",
      "          1     0.3303    0.5106    0.4011       284\n",
      "\n",
      "avg / total     0.7698    0.7146    0.7356      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.5-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7003484320557491\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36296296296296293\n",
      "Original f1: 0.2694300518134715\n",
      "0.132207749294\n",
      "0.999999896822\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 156\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8506    0.7624    0.8041       926\n",
      "          1     0.3082    0.4414    0.3630       222\n",
      "\n",
      "avg / total     0.7457    0.7003    0.7188      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6954515491100857\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38888888888888884\n",
      "Original f1: 0.3050259965337955\n",
      "0.116947615742\n",
      "0.999999687421\n",
      "462\n",
      "0.30454845089\n",
      "Number of disagreement: 179\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8689    0.7364    0.7972      1233\n",
      "          1     0.3114    0.5176    0.3889       284\n",
      "\n",
      "avg / total     0.7645    0.6955    0.7208      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.5-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "5.4928126605e-12\n",
      "4.47265823847e-09\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "1.80515195326e-12\n",
      "1.15637963116e-09\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.5-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "9.97368761429e-11\n",
      "9.74363693358e-08\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "3.56095462967e-10\n",
      "3.09016393904e-07\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.5-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "4.59246309459e-12\n",
      "8.01778038018e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "4.62790989889e-12\n",
      "1.15637963116e-09\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.5-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7099303135888502\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.34059405940594056\n",
      "Original f1: 0.2694300518134715\n",
      "0.099963453386\n",
      "0.99728354116\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 123\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8428    0.7873    0.8141       926\n",
      "          1     0.3039    0.3874    0.3406       222\n",
      "\n",
      "avg / total     0.7386    0.7099    0.7225      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7073170731707317\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3850415512465374\n",
      "Original f1: 0.3050259965337955\n",
      "0.0946572417211\n",
      "0.999999687249\n",
      "444\n",
      "0.292682926829\n",
      "Number of disagreement: 145\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8656    0.7575    0.8080      1233\n",
      "          1     0.3174    0.4894    0.3850       284\n",
      "\n",
      "avg / total     0.7630    0.7073    0.7288      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.5-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "7.86321615079e-12\n",
      "1.56632694415e-09\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "7.25720191192e-12\n",
      "1.15637963116e-09\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.5-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7038327526132404\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3461538461538462\n",
      "Original f1: 0.2694300518134715\n",
      "0.114751277948\n",
      "0.997283541142\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 138\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8447    0.7754    0.8086       926\n",
      "          1     0.3020    0.4054    0.3462       222\n",
      "\n",
      "avg / total     0.7398    0.7038    0.7191      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7027027027027027\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38639455782312926\n",
      "Original f1: 0.3050259965337955\n",
      "0.104170182734\n",
      "0.99999968714\n",
      "451\n",
      "0.297297297297\n",
      "Number of disagreement: 158\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8668    0.7494    0.8038      1233\n",
      "          1     0.3149    0.5000    0.3864       284\n",
      "\n",
      "avg / total     0.7635    0.7027    0.7257      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.5-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.00035230092603\n",
      "0.222037876054\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7409360580092288\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.33049403747870526\n",
      "Original f1: 0.3050259965337955\n",
      "0.00561454231033\n",
      "0.988537240249\n",
      "393\n",
      "0.259063941991\n",
      "Number of disagreement: 10\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8460    0.8329    0.8394      1233\n",
      "          1     0.3201    0.3415    0.3305       284\n",
      "\n",
      "avg / total     0.7475    0.7409    0.7441      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.5-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7020905923344948\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3547169811320755\n",
      "Original f1: 0.2694300518134715\n",
      "0.122146847227\n",
      "0.99728354119\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 148\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8476    0.7689    0.8063       926\n",
      "          1     0.3052    0.4234    0.3547       222\n",
      "\n",
      "avg / total     0.7427    0.7021    0.7190      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.6980883322346737\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.386058981233244\n",
      "Original f1: 0.3050259965337955\n",
      "0.110340178349\n",
      "0.999999687189\n",
      "458\n",
      "0.301911667765\n",
      "Number of disagreement: 169\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8673    0.7421    0.7998      1233\n",
      "          1     0.3117    0.5070    0.3861       284\n",
      "\n",
      "avg / total     0.7633    0.6981    0.7224      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.5-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7639372822299652\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3275434243176179\n",
      "Original f1: 0.2694300518134715\n",
      "0.0145372957721\n",
      "0.993264863917\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 17\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8387    0.8758    0.8568       926\n",
      "          1     0.3646    0.2973    0.3275       222\n",
      "\n",
      "avg / total     0.7470    0.7639    0.7545      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7455504284772577\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3911671924290221\n",
      "Original f1: 0.3050259965337955\n",
      "0.0323272602582\n",
      "0.988537269926\n",
      "386\n",
      "0.254449571523\n",
      "Number of disagreement: 57\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8629    0.8167    0.8392      1233\n",
      "          1     0.3543    0.4366    0.3912       284\n",
      "\n",
      "avg / total     0.7677    0.7456    0.7553      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.5-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7047038327526133\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36397748592870544\n",
      "Original f1: 0.2694300518134715\n",
      "0.126052079722\n",
      "0.999999896396\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 151\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8507    0.7689    0.8077       926\n",
      "          1     0.3119    0.4369    0.3640       222\n",
      "\n",
      "avg / total     0.7465    0.7047    0.7219      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6961107448912327\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3877822045152722\n",
      "Original f1: 0.3050259965337955\n",
      "0.115414135558\n",
      "0.999999687379\n",
      "461\n",
      "0.303889255109\n",
      "Number of disagreement: 176\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8683    0.7380    0.7979      1233\n",
      "          1     0.3113    0.5141    0.3878       284\n",
      "\n",
      "avg / total     0.7640    0.6961    0.7211      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.5-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7665505226480837\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.40969162995594716\n",
      "Original f1: 0.2694300518134715\n",
      "0.0527428430463\n",
      "0.993667658818\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 68\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8592    0.8499    0.8545       926\n",
      "          1     0.4009    0.4189    0.4097       222\n",
      "\n",
      "avg / total     0.7705    0.7666    0.7685      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7310481212920237\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4052478134110787\n",
      "Original f1: 0.3050259965337955\n",
      "0.0674118054251\n",
      "0.999999684781\n",
      "408\n",
      "0.268951878708\n",
      "Number of disagreement: 109\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8700    0.7867    0.8262      1233\n",
      "          1     0.3458    0.4894    0.4052       284\n",
      "\n",
      "avg / total     0.7718    0.7310    0.7474      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.5-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7029616724738676\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3649906890130354\n",
      "Original f1: 0.2694300518134715\n",
      "0.130003797936\n",
      "0.999999896485\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 155\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8511    0.7657    0.8061       926\n",
      "          1     0.3111    0.4414    0.3650       222\n",
      "\n",
      "avg / total     0.7467    0.7030    0.7208      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6961107448912327\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3877822045152722\n",
      "Original f1: 0.3050259965337955\n",
      "0.116032884718\n",
      "0.999999687402\n",
      "461\n",
      "0.303889255109\n",
      "Number of disagreement: 176\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8683    0.7380    0.7979      1233\n",
      "          1     0.3113    0.5141    0.3878       284\n",
      "\n",
      "avg / total     0.7640    0.6961    0.7211      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.5-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7317073170731707\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.384\n",
      "Original f1: 0.2694300518134715\n",
      "0.0869091711732\n",
      "0.999999896639\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 114\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8552    0.8035    0.8285       926\n",
      "          1     0.3453    0.4324    0.3840       222\n",
      "\n",
      "avg / total     0.7566    0.7317    0.7425      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7145682267633487\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4011065006915629\n",
      "Original f1: 0.3050259965337955\n",
      "0.0897036645076\n",
      "0.999999687344\n",
      "433\n",
      "0.285431773237\n",
      "Number of disagreement: 146\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8711    0.7616    0.8126      1233\n",
      "          1     0.3303    0.5106    0.4011       284\n",
      "\n",
      "avg / total     0.7698    0.7146    0.7356      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-1.5-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7012195121951219\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3636363636363636\n",
      "Original f1: 0.2694300518134715\n",
      "0.132445120853\n",
      "0.999999896772\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 157\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8508    0.7635    0.8048       926\n",
      "          1     0.3091    0.4414    0.3636       222\n",
      "\n",
      "avg / total     0.7460    0.7012    0.7195      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6954515491100857\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38888888888888884\n",
      "Original f1: 0.3050259965337955\n",
      "0.11763142707\n",
      "0.999999687406\n",
      "462\n",
      "0.30454845089\n",
      "Number of disagreement: 179\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8689    0.7364    0.7972      1233\n",
      "          1     0.3114    0.5176    0.3889       284\n",
      "\n",
      "avg / total     0.7645    0.6955    0.7208      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-2.0-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "1.95658378018e-12\n",
      "3.04059344352e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "1.61007722014e-12\n",
      "5.97573164622e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-2.0-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "1.00490073749e-10\n",
      "9.68408364966e-08\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "3.53695579169e-10\n",
      "3.09171082135e-07\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-2.0-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "4.06518614855e-12\n",
      "9.05707903799e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "3.50835469219e-12\n",
      "5.97573164622e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-2.0-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7090592334494773\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.33992094861660077\n",
      "Original f1: 0.2694300518134715\n",
      "0.1003356308\n",
      "0.997283541169\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 122\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8426    0.7862    0.8134       926\n",
      "          1     0.3028    0.3874    0.3399       222\n",
      "\n",
      "avg / total     0.7382    0.7091    0.7218      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7079762689518787\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3855755894590846\n",
      "Original f1: 0.3050259965337955\n",
      "0.0941038451522\n",
      "0.999999687115\n",
      "443\n",
      "0.292023731048\n",
      "Number of disagreement: 146\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8657    0.7583    0.8085      1233\n",
      "          1     0.3181    0.4894    0.3856       284\n",
      "\n",
      "avg / total     0.7632    0.7080    0.7293      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-2.0-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "1.18162978433e-11\n",
      "2.83962199267e-09\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "7.08250042366e-12\n",
      "5.97573164622e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-2.0-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7038327526132404\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3461538461538462\n",
      "Original f1: 0.2694300518134715\n",
      "0.114543338155\n",
      "0.997283541182\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 136\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8447    0.7754    0.8086       926\n",
      "          1     0.3020    0.4054    0.3462       222\n",
      "\n",
      "avg / total     0.7398    0.7038    0.7191      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7033618984838497\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38692098092643046\n",
      "Original f1: 0.3050259965337955\n",
      "0.103725823776\n",
      "0.999999687403\n",
      "450\n",
      "0.296638101516\n",
      "Number of disagreement: 159\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8669    0.7502    0.8043      1233\n",
      "          1     0.3156    0.5000    0.3869       284\n",
      "\n",
      "avg / total     0.7637    0.7034    0.7262      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-2.0-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.000244784434675\n",
      "0.197396476122\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7409360580092288\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.33049403747870526\n",
      "Original f1: 0.3050259965337955\n",
      "0.00576325434869\n",
      "0.988537262007\n",
      "393\n",
      "0.259063941991\n",
      "Number of disagreement: 10\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8460    0.8329    0.8394      1233\n",
      "          1     0.3201    0.3415    0.3305       284\n",
      "\n",
      "avg / total     0.7475    0.7409    0.7441      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-2.0-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7012195121951219\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3540489642184557\n",
      "Original f1: 0.2694300518134715\n",
      "0.122188830959\n",
      "0.997283541155\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 147\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8474    0.7678    0.8057       926\n",
      "          1     0.3042    0.4234    0.3540       222\n",
      "\n",
      "avg / total     0.7424    0.7012    0.7183      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6987475280158207\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3865771812080537\n",
      "Original f1: 0.3050259965337955\n",
      "0.109814012272\n",
      "0.999999687418\n",
      "457\n",
      "0.301252471984\n",
      "Number of disagreement: 170\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8674    0.7429    0.8003      1233\n",
      "          1     0.3124    0.5070    0.3866       284\n",
      "\n",
      "avg / total     0.7635    0.6987    0.7229      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-2.0-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7639372822299652\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3275434243176179\n",
      "Original f1: 0.2694300518134715\n",
      "0.0142300415549\n",
      "0.993264871072\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 17\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8387    0.8758    0.8568       926\n",
      "          1     0.3646    0.2973    0.3275       222\n",
      "\n",
      "avg / total     0.7470    0.7639    0.7545      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7455504284772577\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3949843260188088\n",
      "Original f1: 0.3050259965337955\n",
      "0.0330399671952\n",
      "0.988537270484\n",
      "386\n",
      "0.254449571523\n",
      "Number of disagreement: 61\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8641    0.8151    0.8389      1233\n",
      "          1     0.3559    0.4437    0.3950       284\n",
      "\n",
      "avg / total     0.7690    0.7456    0.7558      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-2.0-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7038327526132404\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3632958801498127\n",
      "Original f1: 0.2694300518134715\n",
      "0.126141677577\n",
      "0.999999896314\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 150\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8505    0.7678    0.8070       926\n",
      "          1     0.3109    0.4369    0.3633       222\n",
      "\n",
      "avg / total     0.7461    0.7038    0.7212      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6967699406723797\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3882978723404255\n",
      "Original f1: 0.3050259965337955\n",
      "0.114960102316\n",
      "0.999999687274\n",
      "460\n",
      "0.303230059328\n",
      "Number of disagreement: 177\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8684    0.7388    0.7984      1233\n",
      "          1     0.3120    0.5141    0.3883       284\n",
      "\n",
      "avg / total     0.7643    0.6968    0.7216      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-2.0-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7656794425087108\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.40879120879120884\n",
      "Original f1: 0.2694300518134715\n",
      "0.0527017567037\n",
      "0.993667657472\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 69\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8590    0.8488    0.8539       926\n",
      "          1     0.3991    0.4189    0.4088       222\n",
      "\n",
      "avg / total     0.7701    0.7657    0.7678      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7323665128543178\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4081632653061225\n",
      "Original f1: 0.3050259965337955\n",
      "0.0676947272956\n",
      "0.99999968522\n",
      "406\n",
      "0.267633487146\n",
      "Number of disagreement: 109\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8709    0.7875    0.8271      1233\n",
      "          1     0.3483    0.4930    0.4082       284\n",
      "\n",
      "avg / total     0.7730    0.7324    0.7487      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-2.0-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7029616724738676\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3649906890130354\n",
      "Original f1: 0.2694300518134715\n",
      "0.129942086385\n",
      "0.999999896696\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 153\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8511    0.7657    0.8061       926\n",
      "          1     0.3111    0.4414    0.3650       222\n",
      "\n",
      "avg / total     0.7467    0.7030    0.7208      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6967699406723797\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3882978723404255\n",
      "Original f1: 0.3050259965337955\n",
      "0.115569785411\n",
      "0.999999687395\n",
      "460\n",
      "0.303230059328\n",
      "Number of disagreement: 177\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8684    0.7388    0.7984      1233\n",
      "          1     0.3120    0.5141    0.3883       284\n",
      "\n",
      "avg / total     0.7643    0.6968    0.7216      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-2.0-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.730836236933798\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3832335329341318\n",
      "Original f1: 0.2694300518134715\n",
      "0.0867548831681\n",
      "0.999999896372\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 115\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8550    0.8024    0.8279       926\n",
      "          1     0.3441    0.4324    0.3832       222\n",
      "\n",
      "avg / total     0.7562    0.7308    0.7419      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7145682267633487\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4011065006915629\n",
      "Original f1: 0.3050259965337955\n",
      "0.0895316644956\n",
      "0.999999687279\n",
      "433\n",
      "0.285431773237\n",
      "Number of disagreement: 146\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8711    0.7616    0.8126      1233\n",
      "          1     0.3303    0.5106    0.4011       284\n",
      "\n",
      "avg / total     0.7698    0.7146    0.7356      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-2.0-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7003484320557491\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36296296296296293\n",
      "Original f1: 0.2694300518134715\n",
      "0.132597316202\n",
      "0.999999896819\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 156\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8506    0.7624    0.8041       926\n",
      "          1     0.3082    0.4414    0.3630       222\n",
      "\n",
      "avg / total     0.7457    0.7003    0.7188      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.6961107448912327\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3894039735099337\n",
      "Original f1: 0.3050259965337955\n",
      "0.117150953754\n",
      "0.999999687312\n",
      "461\n",
      "0.303889255109\n",
      "Number of disagreement: 180\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8690    0.7372    0.7977      1233\n",
      "          1     0.3121    0.5176    0.3894       284\n",
      "\n",
      "avg / total     0.7648    0.6961    0.7213      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-2.0-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "4.6112199007e-12\n",
      "3.43298073816e-09\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "1.64964215521e-12\n",
      "8.63952164587e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-2.0-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "1.0090228008e-10\n",
      "9.73341573303e-08\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "3.55706265789e-10\n",
      "3.09065294311e-07\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-2.0-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "3.90301351495e-12\n",
      "7.65710397492e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "6.00765212708e-12\n",
      "8.63952164587e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-2.0-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7099303135888502\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.34059405940594056\n",
      "Original f1: 0.2694300518134715\n",
      "0.100360886158\n",
      "0.997283541025\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 123\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8428    0.7873    0.8141       926\n",
      "          1     0.3039    0.3874    0.3406       222\n",
      "\n",
      "avg / total     0.7386    0.7099    0.7225      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7073170731707317\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3850415512465374\n",
      "Original f1: 0.3050259965337955\n",
      "0.0949439082561\n",
      "0.999999687077\n",
      "444\n",
      "0.292682926829\n",
      "Number of disagreement: 145\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8656    0.7575    0.8080      1233\n",
      "          1     0.3174    0.4894    0.3850       284\n",
      "\n",
      "avg / total     0.7630    0.7073    0.7288      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-2.0-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "8.55563151826e-12\n",
      "1.52342137032e-09\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "8.27830428923e-12\n",
      "8.63952164587e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-2.0-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7029616724738676\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.345489443378119\n",
      "Original f1: 0.2694300518134715\n",
      "0.115147911681\n",
      "0.997283541227\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 139\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8445    0.7743    0.8079       926\n",
      "          1     0.3010    0.4054    0.3455       222\n",
      "\n",
      "avg / total     0.7394    0.7030    0.7185      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7027027027027027\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38639455782312926\n",
      "Original f1: 0.3050259965337955\n",
      "0.104596018256\n",
      "0.999999687141\n",
      "451\n",
      "0.297297297297\n",
      "Number of disagreement: 158\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8668    0.7494    0.8038      1233\n",
      "          1     0.3149    0.5000    0.3864       284\n",
      "\n",
      "avg / total     0.7635    0.7027    0.7257      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-2.0-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.000385486976183\n",
      "0.245142535376\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7409360580092288\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.33049403747870526\n",
      "Original f1: 0.3050259965337955\n",
      "0.00561487828168\n",
      "0.988537265818\n",
      "393\n",
      "0.259063941991\n",
      "Number of disagreement: 10\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8460    0.8329    0.8394      1233\n",
      "          1     0.3201    0.3415    0.3305       284\n",
      "\n",
      "avg / total     0.7475    0.7409    0.7441      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-2.0-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7020905923344948\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3547169811320755\n",
      "Original f1: 0.2694300518134715\n",
      "0.122536741357\n",
      "0.99728354122\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 148\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8476    0.7689    0.8063       926\n",
      "          1     0.3052    0.4234    0.3547       222\n",
      "\n",
      "avg / total     0.7427    0.7021    0.7190      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6980883322346737\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.386058981233244\n",
      "Original f1: 0.3050259965337955\n",
      "0.110542787992\n",
      "0.999999687403\n",
      "458\n",
      "0.301911667765\n",
      "Number of disagreement: 171\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8673    0.7421    0.7998      1233\n",
      "          1     0.3117    0.5070    0.3861       284\n",
      "\n",
      "avg / total     0.7633    0.6981    0.7224      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-2.0-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7639372822299652\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3275434243176179\n",
      "Original f1: 0.2694300518134715\n",
      "0.0144352257726\n",
      "0.993264827456\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 17\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8387    0.8758    0.8568       926\n",
      "          1     0.3646    0.2973    0.3275       222\n",
      "\n",
      "avg / total     0.7470    0.7639    0.7545      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7455504284772577\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3911671924290221\n",
      "Original f1: 0.3050259965337955\n",
      "0.0321400181674\n",
      "0.988537270483\n",
      "386\n",
      "0.254449571523\n",
      "Number of disagreement: 57\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8629    0.8167    0.8392      1233\n",
      "          1     0.3543    0.4366    0.3912       284\n",
      "\n",
      "avg / total     0.7677    0.7456    0.7553      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-2.0-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7047038327526133\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36397748592870544\n",
      "Original f1: 0.2694300518134715\n",
      "0.126472612851\n",
      "0.999999896494\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 151\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8507    0.7689    0.8077       926\n",
      "          1     0.3119    0.4369    0.3640       222\n",
      "\n",
      "avg / total     0.7465    0.7047    0.7219      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.6967699406723797\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3882978723404255\n",
      "Original f1: 0.3050259965337955\n",
      "0.115582664128\n",
      "0.999999687394\n",
      "460\n",
      "0.303230059328\n",
      "Number of disagreement: 177\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8684    0.7388    0.7984      1233\n",
      "          1     0.3120    0.5141    0.3883       284\n",
      "\n",
      "avg / total     0.7643    0.6968    0.7216      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-2.0-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7674216027874564\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.41059602649006627\n",
      "Original f1: 0.2694300518134715\n",
      "0.0527206603975\n",
      "0.993667658237\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 67\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8593    0.8510    0.8551       926\n",
      "          1     0.4026    0.4189    0.4106       222\n",
      "\n",
      "avg / total     0.7710    0.7674    0.7692      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7310481212920237\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4052478134110787\n",
      "Original f1: 0.3050259965337955\n",
      "0.0675597394335\n",
      "0.999999686782\n",
      "408\n",
      "0.268951878708\n",
      "Number of disagreement: 109\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8700    0.7867    0.8262      1233\n",
      "          1     0.3458    0.4894    0.4052       284\n",
      "\n",
      "avg / total     0.7718    0.7310    0.7474      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-2.0-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7029616724738676\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3649906890130354\n",
      "Original f1: 0.2694300518134715\n",
      "0.130268025037\n",
      "0.999999896331\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 155\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8511    0.7657    0.8061       926\n",
      "          1     0.3111    0.4414    0.3650       222\n",
      "\n",
      "avg / total     0.7467    0.7030    0.7208      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6967699406723797\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3882978723404255\n",
      "Original f1: 0.3050259965337955\n",
      "0.116220868264\n",
      "0.999999687354\n",
      "460\n",
      "0.303230059328\n",
      "Number of disagreement: 177\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8684    0.7388    0.7984      1233\n",
      "          1     0.3120    0.5141    0.3883       284\n",
      "\n",
      "avg / total     0.7643    0.6968    0.7216      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-2.0-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7317073170731707\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.384\n",
      "Original f1: 0.2694300518134715\n",
      "0.0871473068469\n",
      "0.999999896744\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 114\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8552    0.8035    0.8285       926\n",
      "          1     0.3453    0.4324    0.3840       222\n",
      "\n",
      "avg / total     0.7566    0.7317    0.7425      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7152274225444957\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.40331491712707185\n",
      "Original f1: 0.3050259965337955\n",
      "0.0898710533837\n",
      "0.999999687097\n",
      "432\n",
      "0.284772577456\n",
      "Number of disagreement: 147\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8719    0.7616    0.8130      1233\n",
      "          1     0.3318    0.5141    0.4033       284\n",
      "\n",
      "avg / total     0.7708    0.7152    0.7363      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.05-2.0-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7012195121951219\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3636363636363636\n",
      "Original f1: 0.2694300518134715\n",
      "0.132834443401\n",
      "0.999999896668\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 157\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8508    0.7635    0.8048       926\n",
      "          1     0.3091    0.4414    0.3636       222\n",
      "\n",
      "avg / total     0.7460    0.7012    0.7195      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6961107448912327\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3894039735099337\n",
      "Original f1: 0.3050259965337955\n",
      "0.117845626881\n",
      "0.999999687329\n",
      "461\n",
      "0.303889255109\n",
      "Number of disagreement: 180\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8690    0.7372    0.7977      1233\n",
      "          1     0.3121    0.5176    0.3894       284\n",
      "\n",
      "avg / total     0.7648    0.6961    0.7213      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.5-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "1.44350685074e-12\n",
      "1.38299804961e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "1.21778117093e-12\n",
      "4.71328465854e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.5-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "1.10846162362e-10\n",
      "9.79834641591e-08\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "3.62431537166e-10\n",
      "3.09317976858e-07\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.5-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "5.17169075872e-12\n",
      "2.46642744984e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "4.17665004339e-12\n",
      "2.36219849237e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.5-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7177700348432056\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.34146341463414637\n",
      "Original f1: 0.2694300518134715\n",
      "0.0964829722072\n",
      "0.997283540938\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 120\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8428    0.7991    0.8204       926\n",
      "          1     0.3111    0.3784    0.3415       222\n",
      "\n",
      "avg / total     0.7400    0.7178    0.7278      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7099538562953197\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38202247191011235\n",
      "Original f1: 0.3050259965337955\n",
      "0.09258440439\n",
      "0.999999687245\n",
      "440\n",
      "0.290046143705\n",
      "Number of disagreement: 153\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8641    0.7632    0.8105      1233\n",
      "          1     0.3178    0.4789    0.3820       284\n",
      "\n",
      "avg / total     0.7618    0.7100    0.7303      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.5-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "7.07913661885e-12\n",
      "3.08767733603e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "5.64837823067e-12\n",
      "6.73548883334e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.5-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.710801393728223\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.35156250000000006\n",
      "Original f1: 0.2694300518134715\n",
      "0.114649813936\n",
      "0.997283541023\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 144\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8462    0.7840    0.8139       926\n",
      "          1     0.3103    0.4054    0.3516       222\n",
      "\n",
      "avg / total     0.7425    0.7108    0.7245      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7059986816084377\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3856749311294766\n",
      "Original f1: 0.3050259965337955\n",
      "0.102670191462\n",
      "0.999999687403\n",
      "446\n",
      "0.294001318392\n",
      "Number of disagreement: 167\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8660    0.7551    0.8068      1233\n",
      "          1     0.3167    0.4930    0.3857       284\n",
      "\n",
      "avg / total     0.7632    0.7060    0.7279      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.5-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "3.27983356148e-05\n",
      "0.0376524610646\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7396176664469347\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.32478632478632474\n",
      "Original f1: 0.3050259965337955\n",
      "0.00417114038327\n",
      "0.97919560566\n",
      "395\n",
      "0.260382333553\n",
      "Number of disagreement: 8\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8446    0.8329    0.8387      1233\n",
      "          1     0.3156    0.3345    0.3248       284\n",
      "\n",
      "avg / total     0.7455    0.7396    0.7425      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.5-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7081881533101045\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.35946462715105165\n",
      "Original f1: 0.2694300518134715\n",
      "0.12532918622\n",
      "0.997283541151\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 155\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8489    0.7765    0.8111       926\n",
      "          1     0.3123    0.4234    0.3595       222\n",
      "\n",
      "avg / total     0.7451    0.7082    0.7237      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7027027027027027\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3880597014925374\n",
      "Original f1: 0.3050259965337955\n",
      "0.111450365118\n",
      "0.999999687376\n",
      "451\n",
      "0.297297297297\n",
      "Number of disagreement: 182\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8675    0.7486    0.8037      1233\n",
      "          1     0.3157    0.5035    0.3881       284\n",
      "\n",
      "avg / total     0.7642    0.7027    0.7259      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.5-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3316831683168317\n",
      "Original f1: 0.2694300518134715\n",
      "0.0135099354592\n",
      "0.99366764875\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 18\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8395    0.8758    0.8573       926\n",
      "          1     0.3681    0.3018    0.3317       222\n",
      "\n",
      "avg / total     0.7484    0.7648    0.7557      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7468688200395518\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3904761904761905\n",
      "Original f1: 0.3050259965337955\n",
      "0.0303275531176\n",
      "0.988537270606\n",
      "384\n",
      "0.25313117996\n",
      "Number of disagreement: 53\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8625    0.8191    0.8403      1233\n",
      "          1     0.3555    0.4331    0.3905       284\n",
      "\n",
      "avg / total     0.7676    0.7469    0.7561      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.5-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7090592334494773\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3650190114068441\n",
      "Original f1: 0.2694300518134715\n",
      "0.128937659264\n",
      "0.997283541149\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 158\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8507    0.7754    0.8113       926\n",
      "          1     0.3158    0.4324    0.3650       222\n",
      "\n",
      "avg / total     0.7473    0.7091    0.7250      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7000659195781147\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3892617449664429\n",
      "Original f1: 0.3050259965337955\n",
      "0.116998531525\n",
      "0.999999687093\n",
      "455\n",
      "0.299934080422\n",
      "Number of disagreement: 190\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8684    0.7437    0.8012      1233\n",
      "          1     0.3145    0.5106    0.3893       284\n",
      "\n",
      "avg / total     0.7647    0.7001    0.7241      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.5-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.40265486725663713\n",
      "Original f1: 0.2694300518134715\n",
      "0.0475466586548\n",
      "0.993667658307\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 66\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8573    0.8499    0.8536       926\n",
      "          1     0.3957    0.4099    0.4027       222\n",
      "\n",
      "avg / total     0.7680    0.7648    0.7664      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7369808833223468\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4123711340206186\n",
      "Original f1: 0.3050259965337955\n",
      "0.0604974007209\n",
      "0.999999681885\n",
      "399\n",
      "0.263019116678\n",
      "Number of disagreement: 102\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8717    0.7932    0.8306      1233\n",
      "          1     0.3544    0.4930    0.4124       284\n",
      "\n",
      "avg / total     0.7748    0.7370    0.7523      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.5-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7081881533101045\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3691148775894539\n",
      "Original f1: 0.2694300518134715\n",
      "0.134019966523\n",
      "0.999999896331\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 163\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8522    0.7721    0.8102       926\n",
      "          1     0.3172    0.4414    0.3691       222\n",
      "\n",
      "avg / total     0.7487    0.7082    0.7249      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6987475280158207\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38821954484605087\n",
      "Original f1: 0.3050259965337955\n",
      "0.118636723008\n",
      "0.999999687297\n",
      "457\n",
      "0.301252471984\n",
      "Number of disagreement: 192\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8681    0.7421    0.8002      1233\n",
      "          1     0.3132    0.5106    0.3882       284\n",
      "\n",
      "avg / total     0.7642    0.6987    0.7231      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.5-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7412891986062717\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3901437371663244\n",
      "Original f1: 0.2694300518134715\n",
      "0.0769675499591\n",
      "0.996963293\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 101\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8562    0.8164    0.8358       926\n",
      "          1     0.3585    0.4279    0.3901       222\n",
      "\n",
      "avg / total     0.7599    0.7413    0.7496      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7185234014502307\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.40446304044630405\n",
      "Original f1: 0.3050259965337955\n",
      "0.08443973175\n",
      "0.999999686562\n",
      "427\n",
      "0.28147659855\n",
      "Number of disagreement: 140\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8718    0.7664    0.8157      1233\n",
      "          1     0.3349    0.5106    0.4045       284\n",
      "\n",
      "avg / total     0.7713    0.7185    0.7387      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.5-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7064459930313589\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36772983114446534\n",
      "Original f1: 0.2694300518134715\n",
      "0.136201666394\n",
      "0.999999896391\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 165\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8519    0.7700    0.8088       926\n",
      "          1     0.3151    0.4414    0.3677       222\n",
      "\n",
      "avg / total     0.7481    0.7064    0.7235      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6987475280158207\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3898531375166889\n",
      "Original f1: 0.3050259965337955\n",
      "0.12016490829\n",
      "0.999999687356\n",
      "457\n",
      "0.301252471984\n",
      "Number of disagreement: 194\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8688    0.7413    0.8000      1233\n",
      "          1     0.3140    0.5141    0.3899       284\n",
      "\n",
      "avg / total     0.7649    0.6987    0.7232      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.5-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "1.37365077509e-12\n",
      "1.38352846072e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "1.20000732194e-12\n",
      "4.56840499023e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.5-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "1.01225092511e-10\n",
      "9.79819485034e-08\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "3.65526392137e-10\n",
      "3.09411266273e-07\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.5-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "4.36611361091e-12\n",
      "2.462862851e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "3.99834262215e-12\n",
      "2.70568425209e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.5-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7177700348432056\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.34146341463414637\n",
      "Original f1: 0.2694300518134715\n",
      "0.0966559693643\n",
      "0.997283541068\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 120\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8428    0.7991    0.8204       926\n",
      "          1     0.3111    0.3784    0.3415       222\n",
      "\n",
      "avg / total     0.7400    0.7178    0.7278      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7092946605141727\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3814866760168303\n",
      "Original f1: 0.3050259965337955\n",
      "0.0928021363974\n",
      "0.999999687211\n",
      "441\n",
      "0.290705339486\n",
      "Number of disagreement: 154\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8640    0.7624    0.8100      1233\n",
      "          1     0.3170    0.4789    0.3815       284\n",
      "\n",
      "avg / total     0.7616    0.7093    0.7298      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.5-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "7.00625972946e-12\n",
      "3.09373332508e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "4.02858114995e-12\n",
      "6.73548883334e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.5-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7099303135888502\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3508771929824561\n",
      "Original f1: 0.2694300518134715\n",
      "0.114844794251\n",
      "0.997283541219\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 145\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8460    0.7829    0.8132       926\n",
      "          1     0.3093    0.4054    0.3509       222\n",
      "\n",
      "avg / total     0.7422    0.7099    0.7238      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7059986816084377\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3856749311294766\n",
      "Original f1: 0.3050259965337955\n",
      "0.10285216687\n",
      "0.999999687409\n",
      "446\n",
      "0.294001318392\n",
      "Number of disagreement: 167\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8660    0.7551    0.8068      1233\n",
      "          1     0.3167    0.4930    0.3857       284\n",
      "\n",
      "avg / total     0.7632    0.7060    0.7279      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.5-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "3.27983372828e-05\n",
      "0.0376524610646\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7389584706657878\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3219178082191781\n",
      "Original f1: 0.3050259965337955\n",
      "0.00408562183026\n",
      "0.979195607115\n",
      "396\n",
      "0.261041529334\n",
      "Number of disagreement: 7\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8439    0.8329    0.8384      1233\n",
      "          1     0.3133    0.3310    0.3219       284\n",
      "\n",
      "avg / total     0.7446    0.7390    0.7417      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.5-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7081881533101045\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.35946462715105165\n",
      "Original f1: 0.2694300518134715\n",
      "0.125611523251\n",
      "0.997283541101\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 155\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8489    0.7765    0.8111       926\n",
      "          1     0.3123    0.4234    0.3595       222\n",
      "\n",
      "avg / total     0.7451    0.7082    0.7237      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7027027027027027\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3880597014925374\n",
      "Original f1: 0.3050259965337955\n",
      "0.111662042923\n",
      "0.999999687379\n",
      "451\n",
      "0.297297297297\n",
      "Number of disagreement: 182\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8675    0.7486    0.8037      1233\n",
      "          1     0.3157    0.5035    0.3881       284\n",
      "\n",
      "avg / total     0.7642    0.7027    0.7259      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.5-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7639372822299652\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3275434243176179\n",
      "Original f1: 0.2694300518134715\n",
      "0.0134044294625\n",
      "0.993667648607\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 17\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8387    0.8758    0.8568       926\n",
      "          1     0.3646    0.2973    0.3275       222\n",
      "\n",
      "avg / total     0.7470    0.7639    0.7545      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7475280158206987\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.393026941362916\n",
      "Original f1: 0.3050259965337955\n",
      "0.0306800036568\n",
      "0.988537270408\n",
      "383\n",
      "0.252471984179\n",
      "Number of disagreement: 54\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8632    0.8191    0.8406      1233\n",
      "          1     0.3573    0.4366    0.3930       284\n",
      "\n",
      "avg / total     0.7685    0.7475    0.7568      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.5-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7090592334494773\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3650190114068441\n",
      "Original f1: 0.2694300518134715\n",
      "0.129216062312\n",
      "0.997283541139\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 158\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8507    0.7754    0.8113       926\n",
      "          1     0.3158    0.4324    0.3650       222\n",
      "\n",
      "avg / total     0.7473    0.7091    0.7250      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7000659195781147\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3892617449664429\n",
      "Original f1: 0.3050259965337955\n",
      "0.117206085712\n",
      "0.999999687409\n",
      "455\n",
      "0.299934080422\n",
      "Number of disagreement: 190\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8684    0.7437    0.8012      1233\n",
      "          1     0.3145    0.5106    0.3893       284\n",
      "\n",
      "avg / total     0.7647    0.7001    0.7241      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.5-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.40265486725663713\n",
      "Original f1: 0.2694300518134715\n",
      "0.0474162126967\n",
      "0.993667658284\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 66\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8573    0.8499    0.8536       926\n",
      "          1     0.3957    0.4099    0.4027       222\n",
      "\n",
      "avg / total     0.7680    0.7648    0.7664      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7363216875411998\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4117647058823529\n",
      "Original f1: 0.3050259965337955\n",
      "0.0603838940248\n",
      "0.999999685129\n",
      "400\n",
      "0.263678312459\n",
      "Number of disagreement: 103\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8715    0.7924    0.8301      1233\n",
      "          1     0.3535    0.4930    0.4118       284\n",
      "\n",
      "avg / total     0.7746    0.7363    0.7518      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.5-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7081881533101045\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3691148775894539\n",
      "Original f1: 0.2694300518134715\n",
      "0.134252063838\n",
      "0.999999896324\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 163\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8522    0.7721    0.8102       926\n",
      "          1     0.3172    0.4414    0.3691       222\n",
      "\n",
      "avg / total     0.7487    0.7082    0.7249      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.6987475280158207\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38821954484605087\n",
      "Original f1: 0.3050259965337955\n",
      "0.118836522767\n",
      "0.999999687312\n",
      "457\n",
      "0.301252471984\n",
      "Number of disagreement: 192\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8681    0.7421    0.8002      1233\n",
      "          1     0.3132    0.5106    0.3882       284\n",
      "\n",
      "avg / total     0.7642    0.6987    0.7231      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.5-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.740418118466899\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.38934426229508196\n",
      "Original f1: 0.2694300518134715\n",
      "0.0773481758303\n",
      "0.996963292997\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 102\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8560    0.8153    0.8352       926\n",
      "          1     0.3571    0.4279    0.3893       222\n",
      "\n",
      "avg / total     0.7595    0.7404    0.7490      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7198417930125247\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4055944055944055\n",
      "Original f1: 0.3050259965337955\n",
      "0.0844107946887\n",
      "0.999999686133\n",
      "425\n",
      "0.280158206987\n",
      "Number of disagreement: 138\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8720    0.7680    0.8167      1233\n",
      "          1     0.3364    0.5106    0.4056       284\n",
      "\n",
      "avg / total     0.7717    0.7198    0.7398      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.5-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7064459930313589\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36772983114446534\n",
      "Original f1: 0.2694300518134715\n",
      "0.136435398689\n",
      "0.999999896278\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 165\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8519    0.7700    0.8088       926\n",
      "          1     0.3151    0.4414    0.3677       222\n",
      "\n",
      "avg / total     0.7481    0.7064    0.7235      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6987475280158207\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3898531375166889\n",
      "Original f1: 0.3050259965337955\n",
      "0.120358515508\n",
      "0.999999687274\n",
      "457\n",
      "0.301252471984\n",
      "Number of disagreement: 194\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8688    0.7413    0.8000      1233\n",
      "          1     0.3140    0.5141    0.3899       284\n",
      "\n",
      "avg / total     0.7649    0.6987    0.7232      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.75-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "1.29069199182e-12\n",
      "1.43316249012e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "1.0257484894e-12\n",
      "4.42756843732e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.75-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "1.02113126599e-10\n",
      "9.78868642147e-08\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "3.63568697562e-10\n",
      "3.09426177083e-07\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.75-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "4.34972710758e-12\n",
      "1.50741197302e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "4.18044547855e-12\n",
      "2.23170204539e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.75-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7151567944250871\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3420523138832998\n",
      "Original f1: 0.2694300518134715\n",
      "0.0997490572838\n",
      "0.997283540947\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 125\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8431    0.7948    0.8182       926\n",
      "          1     0.3091    0.3829    0.3421       222\n",
      "\n",
      "avg / total     0.7398    0.7152    0.7261      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7086354647330257\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38440111420612816\n",
      "Original f1: 0.3050259965337955\n",
      "0.0956408424464\n",
      "0.999999687335\n",
      "442\n",
      "0.291364535267\n",
      "Number of disagreement: 151\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8652    0.7599    0.8092      1233\n",
      "          1     0.3180    0.4859    0.3844       284\n",
      "\n",
      "avg / total     0.7627    0.7086    0.7296      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.75-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "9.60677241693e-12\n",
      "2.13745869689e-09\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "4.85891331887e-12\n",
      "7.87784004697e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.75-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7064459930313589\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3481624758220503\n",
      "Original f1: 0.2694300518134715\n",
      "0.11709113487\n",
      "0.997283541207\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 145\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8453    0.7786    0.8106       926\n",
      "          1     0.3051    0.4054    0.3482       222\n",
      "\n",
      "avg / total     0.7408    0.7064    0.7211      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7046802900461437\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3863013698630137\n",
      "Original f1: 0.3050259965337955\n",
      "0.104367355408\n",
      "0.999999687112\n",
      "448\n",
      "0.295319709954\n",
      "Number of disagreement: 163\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8665    0.7526    0.8056      1233\n",
      "          1     0.3161    0.4965    0.3863       284\n",
      "\n",
      "avg / total     0.7635    0.7047    0.7271      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.75-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.000107632831405\n",
      "0.0859099839621\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7409360580092288\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.33049403747870526\n",
      "Original f1: 0.3050259965337955\n",
      "0.00467086502492\n",
      "0.977680805642\n",
      "393\n",
      "0.259063941991\n",
      "Number of disagreement: 10\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8460    0.8329    0.8394      1233\n",
      "          1     0.3201    0.3415    0.3305       284\n",
      "\n",
      "avg / total     0.7475    0.7409    0.7441      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.75-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7038327526132404\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3584905660377358\n",
      "Original f1: 0.2694300518134715\n",
      "0.126884216055\n",
      "0.997283541205\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 158\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8488    0.7700    0.8075       926\n",
      "          1     0.3084    0.4279    0.3585       222\n",
      "\n",
      "avg / total     0.7443    0.7038    0.7207      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7000659195781147\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3876177658142665\n",
      "Original f1: 0.3050259965337955\n",
      "0.113436738027\n",
      "0.999999687334\n",
      "455\n",
      "0.299934080422\n",
      "Number of disagreement: 180\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8677    0.7445    0.8014      1233\n",
      "          1     0.3137    0.5070    0.3876       284\n",
      "\n",
      "avg / total     0.7640    0.7001    0.7239      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.75-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7656794425087108\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3325062034739454\n",
      "Original f1: 0.2694300518134715\n",
      "0.0139897310865\n",
      "0.993264876143\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 17\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8397    0.8769    0.8579       926\n",
      "          1     0.3702    0.3018    0.3325       222\n",
      "\n",
      "avg / total     0.7489    0.7657    0.7563      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7455504284772577\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3930817610062893\n",
      "Original f1: 0.3050259965337955\n",
      "0.0325007782018\n",
      "0.988537269753\n",
      "386\n",
      "0.254449571523\n",
      "Number of disagreement: 59\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8635    0.8159    0.8390      1233\n",
      "          1     0.3551    0.4401    0.3931       284\n",
      "\n",
      "avg / total     0.7683    0.7456    0.7555      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.75-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.705574912891986\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36466165413533835\n",
      "Original f1: 0.2694300518134715\n",
      "0.130713541077\n",
      "0.999999895325\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 160\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8508    0.7700    0.8084       926\n",
      "          1     0.3129    0.4369    0.3647       222\n",
      "\n",
      "avg / total     0.7468    0.7056    0.7226      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6974291364535267\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.388814913448735\n",
      "Original f1: 0.3050259965337955\n",
      "0.11874480006\n",
      "0.999999687197\n",
      "459\n",
      "0.302570863546\n",
      "Number of disagreement: 188\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8686    0.7397    0.7989      1233\n",
      "          1     0.3126    0.5141    0.3888       284\n",
      "\n",
      "avg / total     0.7645    0.6974    0.7222      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.75-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.40789473684210525\n",
      "Original f1: 0.2694300518134715\n",
      "0.0489492662595\n",
      "0.993667658819\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 70\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8589    0.8477    0.8533       926\n",
      "          1     0.3974    0.4189    0.4079       222\n",
      "\n",
      "avg / total     0.7696    0.7648    0.7671      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7343441001977588\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.40995607613469986\n",
      "Original f1: 0.3050259965337955\n",
      "0.0629934231103\n",
      "0.9999996845\n",
      "403\n",
      "0.265655899802\n",
      "Number of disagreement: 106\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8712    0.7899    0.8286      1233\n",
      "          1     0.3509    0.4930    0.4100       284\n",
      "\n",
      "avg / total     0.7738    0.7343    0.7502      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.75-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.705574912891986\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3694029850746269\n",
      "Original f1: 0.2694300518134715\n",
      "0.135235481004\n",
      "0.99999989632\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 164\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8525    0.7678    0.8080       926\n",
      "          1     0.3153    0.4459    0.3694       222\n",
      "\n",
      "avg / total     0.7486    0.7056    0.7231      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6967699406723797\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3882978723404255\n",
      "Original f1: 0.3050259965337955\n",
      "0.120052472864\n",
      "0.999999687343\n",
      "460\n",
      "0.303230059328\n",
      "Number of disagreement: 189\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8684    0.7388    0.7984      1233\n",
      "          1     0.3120    0.5141    0.3883       284\n",
      "\n",
      "avg / total     0.7643    0.6968    0.7216      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.75-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7386759581881533\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3902439024390244\n",
      "Original f1: 0.2694300518134715\n",
      "0.080038711956\n",
      "0.997283524381\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 106\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8565    0.8121    0.8337       926\n",
      "          1     0.3556    0.4324    0.3902       222\n",
      "\n",
      "avg / total     0.7596    0.7387    0.7479      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7172050098879367\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4033379694019471\n",
      "Original f1: 0.3050259965337955\n",
      "0.0865029970014\n",
      "0.999999686808\n",
      "429\n",
      "0.282794990112\n",
      "Number of disagreement: 142\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8715    0.7648    0.8147      1233\n",
      "          1     0.3333    0.5106    0.4033       284\n",
      "\n",
      "avg / total     0.7708    0.7172    0.7377      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.75-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7029616724738676\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3673469387755102\n",
      "Original f1: 0.2694300518134715\n",
      "0.137984273236\n",
      "0.99999989573\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 167\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8520    0.7646    0.8059       926\n",
      "          1     0.3123    0.4459    0.3673       222\n",
      "\n",
      "avg / total     0.7476    0.7030    0.7211      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6967699406723797\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38992042440318303\n",
      "Original f1: 0.3050259965337955\n",
      "0.121521410947\n",
      "0.999999687242\n",
      "460\n",
      "0.303230059328\n",
      "Number of disagreement: 191\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8691    0.7380    0.7982      1233\n",
      "          1     0.3128    0.5176    0.3899       284\n",
      "\n",
      "avg / total     0.7650    0.6968    0.7218      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.75-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "1.27791672297e-12\n",
      "1.55420625002e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "1.55734872047e-12\n",
      "6.86145800559e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.75-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "1.04974503239e-10\n",
      "9.79403611321e-08\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "3.61227071034e-10\n",
      "3.09364305417e-07\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.75-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "4.04369054333e-12\n",
      "2.70957379797e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "2.75686363498e-12\n",
      "6.86145800559e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.75-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7134146341463414\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.34068136272545085\n",
      "Original f1: 0.2694300518134715\n",
      "0.100104903932\n",
      "0.99728354118\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 125\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8427    0.7927    0.8169       926\n",
      "          1     0.3069    0.3829    0.3407       222\n",
      "\n",
      "avg / total     0.7391    0.7134    0.7248      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7079762689518787\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3838664812239222\n",
      "Original f1: 0.3050259965337955\n",
      "0.0964368657974\n",
      "0.999999687315\n",
      "443\n",
      "0.292023731048\n",
      "Number of disagreement: 150\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8651    0.7591    0.8086      1233\n",
      "          1     0.3172    0.4859    0.3839       284\n",
      "\n",
      "avg / total     0.7625    0.7080    0.7291      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.75-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "9.4373208676e-12\n",
      "1.22646276004e-09\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "9.53688360911e-12\n",
      "7.87784004697e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.75-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.705574912891986\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3474903474903475\n",
      "Original f1: 0.2694300518134715\n",
      "0.117680161375\n",
      "0.99728354115\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 146\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8451    0.7775    0.8099       926\n",
      "          1     0.3041    0.4054    0.3475       222\n",
      "\n",
      "avg / total     0.7404    0.7056    0.7205      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7046802900461437\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3863013698630137\n",
      "Original f1: 0.3050259965337955\n",
      "0.105012246918\n",
      "0.999999687096\n",
      "448\n",
      "0.295319709954\n",
      "Number of disagreement: 163\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8665    0.7526    0.8056      1233\n",
      "          1     0.3161    0.4965    0.3863       284\n",
      "\n",
      "avg / total     0.7635    0.7047    0.7271      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.75-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.000140980933691\n",
      "0.0773080856464\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7409360580092288\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.33049403747870526\n",
      "Original f1: 0.3050259965337955\n",
      "0.00414584086828\n",
      "0.819294027981\n",
      "393\n",
      "0.259063941991\n",
      "Number of disagreement: 10\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8460    0.8329    0.8394      1233\n",
      "          1     0.3201    0.3415    0.3305       284\n",
      "\n",
      "avg / total     0.7475    0.7409    0.7441      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.75-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7038327526132404\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3584905660377358\n",
      "Original f1: 0.2694300518134715\n",
      "0.127412342011\n",
      "0.997283541201\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 158\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8488    0.7700    0.8075       926\n",
      "          1     0.3084    0.4279    0.3585       222\n",
      "\n",
      "avg / total     0.7443    0.7038    0.7207      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7000659195781147\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3876177658142665\n",
      "Original f1: 0.3050259965337955\n",
      "0.114151904959\n",
      "0.999999687332\n",
      "455\n",
      "0.299934080422\n",
      "Number of disagreement: 178\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8677    0.7445    0.8014      1233\n",
      "          1     0.3137    0.5070    0.3876       284\n",
      "\n",
      "avg / total     0.7640    0.7001    0.7239      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.75-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7656794425087108\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3325062034739454\n",
      "Original f1: 0.2694300518134715\n",
      "0.0138585460287\n",
      "0.993667623127\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 17\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8397    0.8769    0.8579       926\n",
      "          1     0.3702    0.3018    0.3325       222\n",
      "\n",
      "avg / total     0.7489    0.7657    0.7563      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7462096242584048\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3937007874015748\n",
      "Original f1: 0.3050259965337955\n",
      "0.0328480856454\n",
      "0.9885372699\n",
      "385\n",
      "0.253790375742\n",
      "Number of disagreement: 58\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8636    0.8167    0.8395      1233\n",
      "          1     0.3561    0.4401    0.3937       284\n",
      "\n",
      "avg / total     0.7686    0.7462    0.7561      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.75-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.705574912891986\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36466165413533835\n",
      "Original f1: 0.2694300518134715\n",
      "0.131322342112\n",
      "0.999999886901\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 160\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8508    0.7700    0.8084       926\n",
      "          1     0.3129    0.4369    0.3647       222\n",
      "\n",
      "avg / total     0.7468    0.7056    0.7226      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6974291364535267\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.388814913448735\n",
      "Original f1: 0.3050259965337955\n",
      "0.119508063973\n",
      "0.999999687271\n",
      "459\n",
      "0.302570863546\n",
      "Number of disagreement: 186\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8686    0.7397    0.7989      1233\n",
      "          1     0.3126    0.5141    0.3888       284\n",
      "\n",
      "avg / total     0.7645    0.6974    0.7222      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.75-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7656794425087108\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.40879120879120884\n",
      "Original f1: 0.2694300518134715\n",
      "0.0489938344518\n",
      "0.993667658602\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 69\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8590    0.8488    0.8539       926\n",
      "          1     0.3991    0.4189    0.4088       222\n",
      "\n",
      "avg / total     0.7701    0.7657    0.7678      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7336849044166117\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.40762463343108507\n",
      "Original f1: 0.3050259965337955\n",
      "0.0629434535848\n",
      "0.999999681364\n",
      "404\n",
      "0.266315095583\n",
      "Number of disagreement: 105\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8704    0.7899    0.8282      1233\n",
      "          1     0.3492    0.4894    0.4076       284\n",
      "\n",
      "avg / total     0.7729    0.7337    0.7495      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.75-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.705574912891986\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3694029850746269\n",
      "Original f1: 0.2694300518134715\n",
      "0.135729751861\n",
      "0.999999896505\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 164\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8525    0.7678    0.8080       926\n",
      "          1     0.3153    0.4459    0.3694       222\n",
      "\n",
      "avg / total     0.7486    0.7056    0.7231      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6974291364535267\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.388814913448735\n",
      "Original f1: 0.3050259965337955\n",
      "0.120795833585\n",
      "0.999999687279\n",
      "459\n",
      "0.302570863546\n",
      "Number of disagreement: 186\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8686    0.7397    0.7989      1233\n",
      "          1     0.3126    0.5141    0.3888       284\n",
      "\n",
      "avg / total     0.7645    0.6974    0.7222      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.75-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7369337979094077\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.38866396761133604\n",
      "Original f1: 0.2694300518134715\n",
      "0.0808382349488\n",
      "0.997283532824\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 108\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8562    0.8099    0.8324       926\n",
      "          1     0.3529    0.4324    0.3887       222\n",
      "\n",
      "avg / total     0.7589    0.7369    0.7466      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7172050098879367\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4033379694019471\n",
      "Original f1: 0.3050259965337955\n",
      "0.0865285104707\n",
      "0.999999686815\n",
      "429\n",
      "0.282794990112\n",
      "Number of disagreement: 142\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8715    0.7648    0.8147      1233\n",
      "          1     0.3333    0.5106    0.4033       284\n",
      "\n",
      "avg / total     0.7708    0.7172    0.7377      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-0.75-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7029616724738676\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3673469387755102\n",
      "Original f1: 0.2694300518134715\n",
      "0.138455182226\n",
      "0.999999895894\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 167\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8520    0.7646    0.8059       926\n",
      "          1     0.3123    0.4459    0.3673       222\n",
      "\n",
      "avg / total     0.7476    0.7030    0.7211      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.6974291364535267\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.39043824701195223\n",
      "Original f1: 0.3050259965337955\n",
      "0.122267354151\n",
      "0.999999687234\n",
      "459\n",
      "0.302570863546\n",
      "Number of disagreement: 188\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8693    0.7388    0.7988      1233\n",
      "          1     0.3134    0.5176    0.3904       284\n",
      "\n",
      "avg / total     0.7652    0.6974    0.7223      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.0-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "2.47149387124e-12\n",
      "1.50661307635e-09\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "1.53579059563e-12\n",
      "7.21374391865e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.0-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "1.15979394575e-10\n",
      "9.83038383188e-08\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "3.65149522539e-10\n",
      "3.09685159118e-07\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.0-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "4.076689749e-12\n",
      "2.08931003574e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "2.57721825261e-12\n",
      "7.21374391865e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.0-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7099303135888502\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.33797216699801197\n",
      "Original f1: 0.2694300518134715\n",
      "0.101849128923\n",
      "0.997283541148\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 129\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8420    0.7883    0.8143       926\n",
      "          1     0.3025    0.3829    0.3380       222\n",
      "\n",
      "avg / total     0.7377    0.7099    0.7222      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7086354647330257\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38611111111111107\n",
      "Original f1: 0.3050259965337955\n",
      "0.0967987741163\n",
      "0.999999686831\n",
      "442\n",
      "0.291364535267\n",
      "Number of disagreement: 149\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8659    0.7591    0.8090      1233\n",
      "          1     0.3188    0.4894    0.3861       284\n",
      "\n",
      "avg / total     0.7634    0.7086    0.7298      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.0-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "5.8321306949e-12\n",
      "6.76123713276e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "1.00802789252e-11\n",
      "8.32761026803e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.0-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.705574912891986\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3474903474903475\n",
      "Original f1: 0.2694300518134715\n",
      "0.118527483606\n",
      "0.997283541152\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 144\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8451    0.7775    0.8099       926\n",
      "          1     0.3041    0.4054    0.3475       222\n",
      "\n",
      "avg / total     0.7404    0.7056    0.7205      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7040210942649967\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38577291381668943\n",
      "Original f1: 0.3050259965337955\n",
      "0.105461346403\n",
      "0.999999687398\n",
      "449\n",
      "0.295978905735\n",
      "Number of disagreement: 160\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8664    0.7518    0.8050      1233\n",
      "          1     0.3154    0.4965    0.3858       284\n",
      "\n",
      "avg / total     0.7632    0.7040    0.7265      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.0-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.000145553985891\n",
      "0.118675084319\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7409360580092288\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.33049403747870526\n",
      "Original f1: 0.3050259965337955\n",
      "0.00480119236729\n",
      "0.915979916075\n",
      "393\n",
      "0.259063941991\n",
      "Number of disagreement: 10\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8460    0.8329    0.8394      1233\n",
      "          1     0.3201    0.3415    0.3305       284\n",
      "\n",
      "avg / total     0.7475    0.7409    0.7441      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.0-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7029616724738676\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.35781544256120523\n",
      "Original f1: 0.2694300518134715\n",
      "0.127564478815\n",
      "0.997283541165\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 157\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8486    0.7689    0.8068       926\n",
      "          1     0.3074    0.4279    0.3578       222\n",
      "\n",
      "avg / total     0.7440    0.7030    0.7200      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7000659195781147\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3892617449664429\n",
      "Original f1: 0.3050259965337955\n",
      "0.114353138009\n",
      "0.999999687344\n",
      "455\n",
      "0.299934080422\n",
      "Number of disagreement: 178\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8684    0.7437    0.8012      1233\n",
      "          1     0.3145    0.5106    0.3893       284\n",
      "\n",
      "avg / total     0.7647    0.7001    0.7241      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.0-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7630662020905923\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.32000000000000006\n",
      "Original f1: 0.2694300518134715\n",
      "0.0137454998598\n",
      "0.993264876266\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 14\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8371    0.8769    0.8565       926\n",
      "          1     0.3596    0.2883    0.3200       222\n",
      "\n",
      "avg / total     0.7448    0.7631    0.7528      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7468688200395518\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3981191222570533\n",
      "Original f1: 0.3050259965337955\n",
      "0.0321672154209\n",
      "0.988537270553\n",
      "384\n",
      "0.25313117996\n",
      "Number of disagreement: 61\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8650    0.8159    0.8397      1233\n",
      "          1     0.3588    0.4472    0.3981       284\n",
      "\n",
      "avg / total     0.7702    0.7469    0.7571      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.0-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7047038327526133\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36397748592870544\n",
      "Original f1: 0.2694300518134715\n",
      "0.131976129205\n",
      "0.999999896298\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 159\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8507    0.7689    0.8077       926\n",
      "          1     0.3119    0.4369    0.3640       222\n",
      "\n",
      "avg / total     0.7465    0.7047    0.7219      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.6967699406723797\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3882978723404255\n",
      "Original f1: 0.3050259965337955\n",
      "0.119787469673\n",
      "0.999999687345\n",
      "460\n",
      "0.303230059328\n",
      "Number of disagreement: 185\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8684    0.7388    0.7984      1233\n",
      "          1     0.3120    0.5141    0.3883       284\n",
      "\n",
      "avg / total     0.7643    0.6968    0.7216      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.0-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.40789473684210525\n",
      "Original f1: 0.2694300518134715\n",
      "0.0497178611349\n",
      "0.993667658692\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 70\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8589    0.8477    0.8533       926\n",
      "          1     0.3974    0.4189    0.4079       222\n",
      "\n",
      "avg / total     0.7696    0.7648    0.7671      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7310481212920237\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4052478134110787\n",
      "Original f1: 0.3050259965337955\n",
      "0.0647833218428\n",
      "0.999999683335\n",
      "408\n",
      "0.268951878708\n",
      "Number of disagreement: 109\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8700    0.7867    0.8262      1233\n",
      "          1     0.3458    0.4894    0.4052       284\n",
      "\n",
      "avg / total     0.7718    0.7310    0.7474      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.0-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7047038327526133\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3687150837988827\n",
      "Original f1: 0.2694300518134715\n",
      "0.135886806765\n",
      "0.999999896682\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 163\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8523    0.7667    0.8073       926\n",
      "          1     0.3143    0.4459    0.3687       222\n",
      "\n",
      "avg / total     0.7483    0.7047    0.7225      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6967699406723797\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3882978723404255\n",
      "Original f1: 0.3050259965337955\n",
      "0.120865482764\n",
      "0.999999687267\n",
      "460\n",
      "0.303230059328\n",
      "Number of disagreement: 185\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8684    0.7388    0.7984      1233\n",
      "          1     0.3120    0.5141    0.3883       284\n",
      "\n",
      "avg / total     0.7643    0.6968    0.7216      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.0-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7386759581881533\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3902439024390244\n",
      "Original f1: 0.2694300518134715\n",
      "0.0815461636793\n",
      "0.997283538541\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 106\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8565    0.8121    0.8337       926\n",
      "          1     0.3556    0.4324    0.3902       222\n",
      "\n",
      "avg / total     0.7596    0.7387    0.7479      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7158866183256427\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4022191400832177\n",
      "Original f1: 0.3050259965337955\n",
      "0.0867888737762\n",
      "0.999999686668\n",
      "431\n",
      "0.284113381674\n",
      "Number of disagreement: 144\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8713    0.7632    0.8137      1233\n",
      "          1     0.3318    0.5106    0.4022       284\n",
      "\n",
      "avg / total     0.7703    0.7159    0.7366      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.0-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7020905923344948\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36666666666666664\n",
      "Original f1: 0.2694300518134715\n",
      "0.139212031909\n",
      "0.999999896309\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 166\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8518    0.7635    0.8052       926\n",
      "          1     0.3113    0.4459    0.3667       222\n",
      "\n",
      "avg / total     0.7473    0.7021    0.7204      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6967699406723797\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38992042440318303\n",
      "Original f1: 0.3050259965337955\n",
      "0.122343853568\n",
      "0.999999687382\n",
      "460\n",
      "0.303230059328\n",
      "Number of disagreement: 187\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8691    0.7380    0.7982      1233\n",
      "          1     0.3128    0.5176    0.3899       284\n",
      "\n",
      "avg / total     0.7650    0.6968    0.7218      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.0-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "1.32679190128e-12\n",
      "1.16857888874e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "1.42293939037e-12\n",
      "4.47658405231e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.0-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "1.11373482002e-10\n",
      "9.58789657092e-08\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "3.87260896081e-10\n",
      "3.09631540499e-07\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.0-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "3.30792436443e-12\n",
      "1.46939571621e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "3.86234808019e-12\n",
      "3.00889183232e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.0-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7090592334494773\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.33466135458167334\n",
      "Original f1: 0.2694300518134715\n",
      "0.102169201239\n",
      "0.997283541208\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 126\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8410    0.7883    0.8138       926\n",
      "          1     0.3000    0.3784    0.3347       222\n",
      "\n",
      "avg / total     0.7364    0.7091    0.7212      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7059986816084377\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38397790055248615\n",
      "Original f1: 0.3050259965337955\n",
      "0.0979319778107\n",
      "0.999999687169\n",
      "446\n",
      "0.294001318392\n",
      "Number of disagreement: 149\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8654    0.7559    0.8069      1233\n",
      "          1     0.3159    0.4894    0.3840       284\n",
      "\n",
      "avg / total     0.7625    0.7060    0.7277      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.0-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "4.11470504892e-12\n",
      "2.33812323925e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "7.09360803495e-12\n",
      "8.32761026803e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.0-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7047038327526133\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.34682080924855496\n",
      "Original f1: 0.2694300518134715\n",
      "0.119190335609\n",
      "0.997283541068\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 145\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8449    0.7765    0.8092       926\n",
      "          1     0.3030    0.4054    0.3468       222\n",
      "\n",
      "avg / total     0.7401    0.7047    0.7198      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7020435069215557\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38419618528610355\n",
      "Original f1: 0.3050259965337955\n",
      "0.10648180709\n",
      "0.999999687393\n",
      "452\n",
      "0.297956493078\n",
      "Number of disagreement: 161\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8660    0.7494    0.8035      1233\n",
      "          1     0.3133    0.4965    0.3842       284\n",
      "\n",
      "avg / total     0.7625    0.7020    0.7250      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.0-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.000210996152957\n",
      "0.110363421365\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7409360580092288\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.33049403747870526\n",
      "Original f1: 0.3050259965337955\n",
      "0.00415976802053\n",
      "0.759052839526\n",
      "393\n",
      "0.259063941991\n",
      "Number of disagreement: 10\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8460    0.8329    0.8394      1233\n",
      "          1     0.3201    0.3415    0.3305       284\n",
      "\n",
      "avg / total     0.7475    0.7409    0.7441      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.0-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7029616724738676\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.35781544256120523\n",
      "Original f1: 0.2694300518134715\n",
      "0.128318539123\n",
      "0.997283541184\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 157\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8486    0.7689    0.8068       926\n",
      "          1     0.3074    0.4279    0.3578       222\n",
      "\n",
      "avg / total     0.7440    0.7030    0.7200      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6974291364535267\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3871829105473965\n",
      "Original f1: 0.3050259965337955\n",
      "0.115394095853\n",
      "0.999999687222\n",
      "459\n",
      "0.302570863546\n",
      "Number of disagreement: 178\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8679    0.7405    0.7991      1233\n",
      "          1     0.3118    0.5106    0.3872       284\n",
      "\n",
      "avg / total     0.7638    0.6974    0.7220      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.0-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7639372822299652\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.32418952618453867\n",
      "Original f1: 0.2694300518134715\n",
      "0.0137161984536\n",
      "0.993264868577\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 15\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8380    0.8769    0.8570       926\n",
      "          1     0.3631    0.2928    0.3242       222\n",
      "\n",
      "avg / total     0.7462    0.7639    0.7540      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7462096242584048\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.39560439560439564\n",
      "Original f1: 0.3050259965337955\n",
      "0.0320069840936\n",
      "0.988537270535\n",
      "385\n",
      "0.253790375742\n",
      "Number of disagreement: 60\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8643    0.8159    0.8394      1233\n",
      "          1     0.3569    0.4437    0.3956       284\n",
      "\n",
      "avg / total     0.7693    0.7462    0.7563      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.0-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7047038327526133\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36397748592870544\n",
      "Original f1: 0.2694300518134715\n",
      "0.132721502585\n",
      "0.999999896607\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 159\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8507    0.7689    0.8077       926\n",
      "          1     0.3119    0.4369    0.3640       222\n",
      "\n",
      "avg / total     0.7465    0.7047    0.7219      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6947923533289387\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3867549668874172\n",
      "Original f1: 0.3050259965337955\n",
      "0.120851638785\n",
      "0.999999687353\n",
      "463\n",
      "0.305207646671\n",
      "Number of disagreement: 184\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8681    0.7364    0.7968      1233\n",
      "          1     0.3100    0.5141    0.3868       284\n",
      "\n",
      "avg / total     0.7636    0.6948    0.7201      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.0-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7639372822299652\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.40700218818380746\n",
      "Original f1: 0.2694300518134715\n",
      "0.0498820513545\n",
      "0.993667658274\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 71\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8587    0.8467    0.8526       926\n",
      "          1     0.3957    0.4189    0.4070       222\n",
      "\n",
      "avg / total     0.7692    0.7639    0.7665      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7303889255108768\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4029197080291971\n",
      "Original f1: 0.3050259965337955\n",
      "0.0650168380976\n",
      "0.999999684243\n",
      "409\n",
      "0.269611074489\n",
      "Number of disagreement: 108\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8692    0.7867    0.8259      1233\n",
      "          1     0.3441    0.4859    0.4029       284\n",
      "\n",
      "avg / total     0.7709    0.7304    0.7467      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.0-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7047038327526133\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3687150837988827\n",
      "Original f1: 0.2694300518134715\n",
      "0.136513032177\n",
      "0.999999896689\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 163\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8523    0.7667    0.8073       926\n",
      "          1     0.3143    0.4459    0.3687       222\n",
      "\n",
      "avg / total     0.7483    0.7047    0.7225      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6947923533289387\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3867549668874172\n",
      "Original f1: 0.3050259965337955\n",
      "0.121847757936\n",
      "0.99999968725\n",
      "463\n",
      "0.305207646671\n",
      "Number of disagreement: 184\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8681    0.7364    0.7968      1233\n",
      "          1     0.3100    0.5141    0.3868       284\n",
      "\n",
      "avg / total     0.7636    0.6948    0.7201      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.0-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7360627177700348\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3878787878787879\n",
      "Original f1: 0.2694300518134715\n",
      "0.0823916041885\n",
      "0.999999893338\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 109\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8560    0.8089    0.8318       926\n",
      "          1     0.3516    0.4324    0.3879       222\n",
      "\n",
      "avg / total     0.7585    0.7361    0.7459      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7165458141067897\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.40277777777777773\n",
      "Original f1: 0.3050259965337955\n",
      "0.0868917285825\n",
      "0.999999686328\n",
      "430\n",
      "0.283454185893\n",
      "Number of disagreement: 143\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8714    0.7640    0.8142      1233\n",
      "          1     0.3326    0.5106    0.4028       284\n",
      "\n",
      "avg / total     0.7705    0.7165    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.0-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7020905923344948\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36666666666666664\n",
      "Original f1: 0.2694300518134715\n",
      "0.139780019819\n",
      "0.99999989682\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 166\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8518    0.7635    0.8052       926\n",
      "          1     0.3113    0.4459    0.3667       222\n",
      "\n",
      "avg / total     0.7473    0.7021    0.7204      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6947923533289387\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38837516512549536\n",
      "Original f1: 0.3050259965337955\n",
      "0.123367952717\n",
      "0.999999687345\n",
      "463\n",
      "0.305207646671\n",
      "Number of disagreement: 186\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8688    0.7356    0.7967      1233\n",
      "          1     0.3108    0.5176    0.3884       284\n",
      "\n",
      "avg / total     0.7643    0.6948    0.7202      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.5-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "3.97523292221e-12\n",
      "3.3610364023e-09\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "1.72541188136e-12\n",
      "9.68382552192e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.5-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "1.03125515079e-10\n",
      "9.74567165839e-08\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "3.76214260539e-10\n",
      "3.09616382352e-07\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.5-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "3.47868185903e-12\n",
      "1.76428801256e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "2.54616209043e-12\n",
      "9.68382552192e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.5-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7099303135888502\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.33797216699801197\n",
      "Original f1: 0.2694300518134715\n",
      "0.103919927329\n",
      "0.997283541203\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 127\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8420    0.7883    0.8143       926\n",
      "          1     0.3025    0.3829    0.3380       222\n",
      "\n",
      "avg / total     0.7377    0.7099    0.7222      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7079762689518787\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3855755894590846\n",
      "Original f1: 0.3050259965337955\n",
      "0.09782966042\n",
      "0.999999687243\n",
      "443\n",
      "0.292023731048\n",
      "Number of disagreement: 148\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8657    0.7583    0.8085      1233\n",
      "          1     0.3181    0.4894    0.3856       284\n",
      "\n",
      "avg / total     0.7632    0.7080    0.7293      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.5-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "8.09019958829e-12\n",
      "2.9431346249e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "1.06334281438e-11\n",
      "1.12469994429e-09\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.5-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7064459930313589\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3481624758220503\n",
      "Original f1: 0.2694300518134715\n",
      "0.119951143184\n",
      "0.99728354119\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 143\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8453    0.7786    0.8106       926\n",
      "          1     0.3051    0.4054    0.3482       222\n",
      "\n",
      "avg / total     0.7408    0.7064    0.7211      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7040210942649967\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38577291381668943\n",
      "Original f1: 0.3050259965337955\n",
      "0.106627028408\n",
      "0.999999687408\n",
      "449\n",
      "0.295978905735\n",
      "Number of disagreement: 160\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8664    0.7518    0.8050      1233\n",
      "          1     0.3154    0.4965    0.3858       284\n",
      "\n",
      "avg / total     0.7632    0.7040    0.7265      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.5-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.000210565351593\n",
      "0.132691512739\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7409360580092288\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.33049403747870526\n",
      "Original f1: 0.3050259965337955\n",
      "0.00492320289013\n",
      "0.881812943119\n",
      "393\n",
      "0.259063941991\n",
      "Number of disagreement: 10\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8460    0.8329    0.8394      1233\n",
      "          1     0.3201    0.3415    0.3305       284\n",
      "\n",
      "avg / total     0.7475    0.7409    0.7441      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.5-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7038327526132404\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3584905660377358\n",
      "Original f1: 0.2694300518134715\n",
      "0.12868474486\n",
      "0.997283541171\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 156\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8488    0.7700    0.8075       926\n",
      "          1     0.3084    0.4279    0.3585       222\n",
      "\n",
      "avg / total     0.7443    0.7038    0.7207      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6980883322346737\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3877005347593583\n",
      "Original f1: 0.3050259965337955\n",
      "0.115276990515\n",
      "0.999999687324\n",
      "458\n",
      "0.301911667765\n",
      "Number of disagreement: 177\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8680    0.7413    0.7997      1233\n",
      "          1     0.3125    0.5106    0.3877       284\n",
      "\n",
      "avg / total     0.7640    0.6981    0.7225      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.5-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7630662020905923\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.32000000000000006\n",
      "Original f1: 0.2694300518134715\n",
      "0.0133834179416\n",
      "0.9932648749\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 14\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8371    0.8769    0.8565       926\n",
      "          1     0.3596    0.2883    0.3200       222\n",
      "\n",
      "avg / total     0.7448    0.7631    0.7528      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7455504284772577\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3930817610062893\n",
      "Original f1: 0.3050259965337955\n",
      "0.0321252730923\n",
      "0.988537270522\n",
      "386\n",
      "0.254449571523\n",
      "Number of disagreement: 59\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8635    0.8159    0.8390      1233\n",
      "          1     0.3551    0.4401    0.3931       284\n",
      "\n",
      "avg / total     0.7683    0.7456    0.7555      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.5-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.705574912891986\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36466165413533835\n",
      "Original f1: 0.2694300518134715\n",
      "0.133594811212\n",
      "0.999999896481\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 158\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8508    0.7700    0.8084       926\n",
      "          1     0.3129    0.4369    0.3647       222\n",
      "\n",
      "avg / total     0.7468    0.7056    0.7226      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6961107448912327\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3877822045152722\n",
      "Original f1: 0.3050259965337955\n",
      "0.120685558417\n",
      "0.999999687219\n",
      "461\n",
      "0.303889255109\n",
      "Number of disagreement: 182\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8683    0.7380    0.7979      1233\n",
      "          1     0.3113    0.5141    0.3878       284\n",
      "\n",
      "avg / total     0.7640    0.6961    0.7211      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.5-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.40789473684210525\n",
      "Original f1: 0.2694300518134715\n",
      "0.0499117375464\n",
      "0.993667658805\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 70\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8589    0.8477    0.8533       926\n",
      "          1     0.3974    0.4189    0.4079       222\n",
      "\n",
      "avg / total     0.7696    0.7648    0.7671      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7290705339485827\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.40174672489082974\n",
      "Original f1: 0.3050259965337955\n",
      "0.0663064253428\n",
      "0.999999680649\n",
      "411\n",
      "0.270929466051\n",
      "Number of disagreement: 110\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8689    0.7851    0.8249      1233\n",
      "          1     0.3424    0.4859    0.4017       284\n",
      "\n",
      "avg / total     0.7704    0.7291    0.7457      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.5-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7064459930313589\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3700934579439252\n",
      "Original f1: 0.2694300518134715\n",
      "0.137123602516\n",
      "0.999999896717\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 161\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8527    0.7689    0.8086       926\n",
      "          1     0.3163    0.4459    0.3701       222\n",
      "\n",
      "avg / total     0.7490    0.7064    0.7238      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.6961107448912327\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3877822045152722\n",
      "Original f1: 0.3050259965337955\n",
      "0.121666399953\n",
      "0.999999687238\n",
      "461\n",
      "0.303889255109\n",
      "Number of disagreement: 182\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8683    0.7380    0.7979      1233\n",
      "          1     0.3113    0.5141    0.3878       284\n",
      "\n",
      "avg / total     0.7640    0.6961    0.7211      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.5-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.735191637630662\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3870967741935484\n",
      "Original f1: 0.2694300518134715\n",
      "0.0831777550233\n",
      "0.999999888106\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 110\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8558    0.8078    0.8311       926\n",
      "          1     0.3504    0.4324    0.3871       222\n",
      "\n",
      "avg / total     0.7581    0.7352    0.7452      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7152274225444957\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4016620498614959\n",
      "Original f1: 0.3050259965337955\n",
      "0.0874900460583\n",
      "0.999999686132\n",
      "432\n",
      "0.284772577456\n",
      "Number of disagreement: 145\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8712    0.7624    0.8131      1233\n",
      "          1     0.3311    0.5106    0.4017       284\n",
      "\n",
      "avg / total     0.7701    0.7152    0.7361      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.5-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7029616724738676\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3673469387755102\n",
      "Original f1: 0.2694300518134715\n",
      "0.140731786094\n",
      "0.999999896132\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 165\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8520    0.7646    0.8059       926\n",
      "          1     0.3123    0.4459    0.3673       222\n",
      "\n",
      "avg / total     0.7476    0.7030    0.7211      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6961107448912327\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3894039735099337\n",
      "Original f1: 0.3050259965337955\n",
      "0.123179897698\n",
      "0.999999687409\n",
      "461\n",
      "0.303889255109\n",
      "Number of disagreement: 184\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8690    0.7372    0.7977      1233\n",
      "          1     0.3121    0.5176    0.3894       284\n",
      "\n",
      "avg / total     0.7648    0.6961    0.7213      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.5-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "1.45598390286e-12\n",
      "2.62068391909e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "1.8559446966e-12\n",
      "8.31203224788e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.5-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "1.12983200721e-10\n",
      "9.76105520405e-08\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "3.69991604444e-10\n",
      "3.09540999281e-07\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.5-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "2.70966720385e-12\n",
      "1.62420743521e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "3.99726551462e-12\n",
      "8.31203224788e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.5-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7081881533101045\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.33925049309664695\n",
      "Original f1: 0.2694300518134715\n",
      "0.105161160723\n",
      "0.997283541122\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 127\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8424    0.7851    0.8127       926\n",
      "          1     0.3018    0.3874    0.3393       222\n",
      "\n",
      "avg / total     0.7379    0.7082    0.7212      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7059986816084377\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38397790055248615\n",
      "Original f1: 0.3050259965337955\n",
      "0.0993954576241\n",
      "0.999999687399\n",
      "446\n",
      "0.294001318392\n",
      "Number of disagreement: 149\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8654    0.7559    0.8069      1233\n",
      "          1     0.3159    0.4894    0.3840       284\n",
      "\n",
      "avg / total     0.7625    0.7060    0.7277      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.5-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "4.92709324097e-12\n",
      "4.18171287635e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "6.91968281969e-12\n",
      "1.12469994429e-09\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.5-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7029616724738676\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.345489443378119\n",
      "Original f1: 0.2694300518134715\n",
      "0.120647342025\n",
      "0.997283541093\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 143\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8445    0.7743    0.8079       926\n",
      "          1     0.3010    0.4054    0.3455       222\n",
      "\n",
      "avg / total     0.7394    0.7030    0.7185      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7027027027027027\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3847203274215552\n",
      "Original f1: 0.3050259965337955\n",
      "0.108005107044\n",
      "0.999999687278\n",
      "451\n",
      "0.297297297297\n",
      "Number of disagreement: 160\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8661    0.7502    0.8040      1233\n",
      "          1     0.3140    0.4965    0.3847       284\n",
      "\n",
      "avg / total     0.7628    0.7027    0.7255      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.5-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.000299995519745\n",
      "0.173122614041\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7402768622280818\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3299319727891156\n",
      "Original f1: 0.3050259965337955\n",
      "0.0041359976241\n",
      "0.744694323728\n",
      "394\n",
      "0.259723137772\n",
      "Number of disagreement: 11\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8458    0.8321    0.8389      1233\n",
      "          1     0.3191    0.3415    0.3299       284\n",
      "\n",
      "avg / total     0.7472    0.7403    0.7436      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.5-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7003484320557491\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3533834586466165\n",
      "Original f1: 0.2694300518134715\n",
      "0.129401675078\n",
      "0.997283541212\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 154\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8473    0.7667    0.8050       926\n",
      "          1     0.3032    0.4234    0.3534       222\n",
      "\n",
      "avg / total     0.7421    0.7003    0.7177      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.6974291364535267\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3871829105473965\n",
      "Original f1: 0.3050259965337955\n",
      "0.116586570926\n",
      "0.999999687131\n",
      "459\n",
      "0.302570863546\n",
      "Number of disagreement: 176\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8679    0.7405    0.7991      1233\n",
      "          1     0.3118    0.5106    0.3872       284\n",
      "\n",
      "avg / total     0.7638    0.6974    0.7220      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.5-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7630662020905923\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.32000000000000006\n",
      "Original f1: 0.2694300518134715\n",
      "0.0134126864938\n",
      "0.966456082403\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 14\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8371    0.8769    0.8565       926\n",
      "          1     0.3596    0.2883    0.3200       222\n",
      "\n",
      "avg / total     0.7448    0.7631    0.7528      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7442320369149638\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38801261829652994\n",
      "Original f1: 0.3050259965337955\n",
      "0.0312000621362\n",
      "0.988537270221\n",
      "388\n",
      "0.255767963085\n",
      "Number of disagreement: 57\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8620    0.8159    0.8383      1233\n",
      "          1     0.3514    0.4331    0.3880       284\n",
      "\n",
      "avg / total     0.7664    0.7442    0.7540      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.5-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7020905923344948\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3595505617977528\n",
      "Original f1: 0.2694300518134715\n",
      "0.134271632949\n",
      "0.999999896028\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 156\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8493    0.7667    0.8059       926\n",
      "          1     0.3077    0.4324    0.3596       222\n",
      "\n",
      "avg / total     0.7445    0.7021    0.7196      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6947923533289387\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3867549668874172\n",
      "Original f1: 0.3050259965337955\n",
      "0.121931606671\n",
      "0.999999687391\n",
      "463\n",
      "0.305207646671\n",
      "Number of disagreement: 182\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8681    0.7364    0.7968      1233\n",
      "          1     0.3100    0.5141    0.3868       284\n",
      "\n",
      "avg / total     0.7636    0.6948    0.7201      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.5-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.40789473684210525\n",
      "Original f1: 0.2694300518134715\n",
      "0.0501849400701\n",
      "0.993667658422\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 70\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8589    0.8477    0.8533       926\n",
      "          1     0.3974    0.4189    0.4079       222\n",
      "\n",
      "avg / total     0.7696    0.7648    0.7671      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7290705339485827\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.40174672489082974\n",
      "Original f1: 0.3050259965337955\n",
      "0.0666277336539\n",
      "0.999999683147\n",
      "411\n",
      "0.270929466051\n",
      "Number of disagreement: 110\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8689    0.7851    0.8249      1233\n",
      "          1     0.3424    0.4859    0.4017       284\n",
      "\n",
      "avg / total     0.7704    0.7291    0.7457      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.5-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7029616724738676\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3649906890130354\n",
      "Original f1: 0.2694300518134715\n",
      "0.137701331862\n",
      "0.999999896739\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 159\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8511    0.7657    0.8061       926\n",
      "          1     0.3111    0.4414    0.3650       222\n",
      "\n",
      "avg / total     0.7467    0.7030    0.7208      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6947923533289387\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3867549668874172\n",
      "Original f1: 0.3050259965337955\n",
      "0.122845433117\n",
      "0.999999687229\n",
      "463\n",
      "0.305207646671\n",
      "Number of disagreement: 182\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8681    0.7364    0.7968      1233\n",
      "          1     0.3100    0.5141    0.3868       284\n",
      "\n",
      "avg / total     0.7636    0.6948    0.7201      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.5-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7317073170731707\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.38152610441767065\n",
      "Original f1: 0.2694300518134715\n",
      "0.0836517496097\n",
      "0.999999892196\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 112\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8544    0.8045    0.8287       926\n",
      "          1     0.3442    0.4279    0.3815       222\n",
      "\n",
      "avg / total     0.7557    0.7317    0.7422      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7158866183256427\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4022191400832177\n",
      "Original f1: 0.3050259965337955\n",
      "0.0877877444302\n",
      "0.999999686561\n",
      "431\n",
      "0.284113381674\n",
      "Number of disagreement: 144\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8713    0.7632    0.8137      1233\n",
      "          1     0.3318    0.5106    0.4022       284\n",
      "\n",
      "avg / total     0.7703    0.7159    0.7366      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-1.5-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6994773519163763\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36229205175600737\n",
      "Original f1: 0.2694300518134715\n",
      "0.1411017557\n",
      "0.999999896821\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 163\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8504    0.7613    0.8034       926\n",
      "          1     0.3072    0.4414    0.3623       222\n",
      "\n",
      "avg / total     0.7454    0.6995    0.7181      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6947923533289387\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38837516512549536\n",
      "Original f1: 0.3050259965337955\n",
      "0.12442677188\n",
      "0.999999687314\n",
      "463\n",
      "0.305207646671\n",
      "Number of disagreement: 184\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8688    0.7356    0.7967      1233\n",
      "          1     0.3108    0.5176    0.3884       284\n",
      "\n",
      "avg / total     0.7643    0.6948    0.7202      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-2.0-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "4.5333692005e-12\n",
      "3.0310750946e-09\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "1.77446752636e-12\n",
      "9.74829677192e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-2.0-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "1.04724886109e-10\n",
      "9.74256094256e-08\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "3.75725145766e-10\n",
      "3.09655770861e-07\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-2.0-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "2.73119036886e-12\n",
      "1.69840919106e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "2.66241443449e-12\n",
      "9.74829677192e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-2.0-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7090592334494773\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.33466135458167334\n",
      "Original f1: 0.2694300518134715\n",
      "0.104742149573\n",
      "0.997283541161\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 126\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8410    0.7883    0.8138       926\n",
      "          1     0.3000    0.3784    0.3347       222\n",
      "\n",
      "avg / total     0.7364    0.7091    0.7212      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7079762689518787\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3855755894590846\n",
      "Original f1: 0.3050259965337955\n",
      "0.098248526915\n",
      "0.999999687335\n",
      "443\n",
      "0.292023731048\n",
      "Number of disagreement: 148\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8657    0.7583    0.8085      1233\n",
      "          1     0.3181    0.4894    0.3856       284\n",
      "\n",
      "avg / total     0.7632    0.7080    0.7293      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-2.0-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "4.18935482961e-12\n",
      "2.01589908637e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "7.89703076726e-12\n",
      "2.0636383713e-09\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-2.0-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7047038327526133\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.344294003868472\n",
      "Original f1: 0.2694300518134715\n",
      "0.120594187389\n",
      "0.997283541161\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 141\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8441    0.7775    0.8094       926\n",
      "          1     0.3017    0.4009    0.3443       222\n",
      "\n",
      "avg / total     0.7392    0.7047    0.7195      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7053394858272907\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38850889192886456\n",
      "Original f1: 0.3050259965337955\n",
      "0.107115156419\n",
      "0.999999687302\n",
      "447\n",
      "0.294660514173\n",
      "Number of disagreement: 160\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8673    0.7526    0.8059      1233\n",
      "          1     0.3177    0.5000    0.3885       284\n",
      "\n",
      "avg / total     0.7644    0.7053    0.7278      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-2.0-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.000252272088566\n",
      "0.134978523238\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7409360580092288\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.33049403747870526\n",
      "Original f1: 0.3050259965337955\n",
      "0.00496687938529\n",
      "0.871070076303\n",
      "393\n",
      "0.259063941991\n",
      "Number of disagreement: 10\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8460    0.8329    0.8394      1233\n",
      "          1     0.3201    0.3415    0.3305       284\n",
      "\n",
      "avg / total     0.7475    0.7409    0.7441      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-2.0-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7029616724738676\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3553875236294896\n",
      "Original f1: 0.2694300518134715\n",
      "0.129237336483\n",
      "0.997283541213\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 153\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8478    0.7700    0.8070       926\n",
      "          1     0.3062    0.4234    0.3554       222\n",
      "\n",
      "avg / total     0.7431    0.7030    0.7197      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6987475280158207\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38821954484605087\n",
      "Original f1: 0.3050259965337955\n",
      "0.115621720254\n",
      "0.999999687348\n",
      "457\n",
      "0.301252471984\n",
      "Number of disagreement: 176\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8681    0.7421    0.8002      1233\n",
      "          1     0.3132    0.5106    0.3882       284\n",
      "\n",
      "avg / total     0.7642    0.6987    0.7231      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-2.0-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7630662020905923\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.32000000000000006\n",
      "Original f1: 0.2694300518134715\n",
      "0.0132114200625\n",
      "0.993264874158\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 14\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8371    0.8769    0.8565       926\n",
      "          1     0.3596    0.2883    0.3200       222\n",
      "\n",
      "avg / total     0.7448    0.7631    0.7528      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7442320369149638\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38801261829652994\n",
      "Original f1: 0.3050259965337955\n",
      "0.031920779656\n",
      "0.988537270269\n",
      "388\n",
      "0.255767963085\n",
      "Number of disagreement: 57\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8620    0.8159    0.8383      1233\n",
      "          1     0.3514    0.4331    0.3880       284\n",
      "\n",
      "avg / total     0.7664    0.7442    0.7540      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-2.0-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7038327526132404\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3609022556390978\n",
      "Original f1: 0.2694300518134715\n",
      "0.134292401903\n",
      "0.999999896274\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 156\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8496    0.7689    0.8073       926\n",
      "          1     0.3097    0.4324    0.3609       222\n",
      "\n",
      "avg / total     0.7452    0.7038    0.7209      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6967699406723797\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3882978723404255\n",
      "Original f1: 0.3050259965337955\n",
      "0.121006877606\n",
      "0.999999687354\n",
      "460\n",
      "0.303230059328\n",
      "Number of disagreement: 181\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8684    0.7388    0.7984      1233\n",
      "          1     0.3120    0.5141    0.3883       284\n",
      "\n",
      "avg / total     0.7643    0.6968    0.7216      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-2.0-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7639372822299652\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.40700218818380746\n",
      "Original f1: 0.2694300518134715\n",
      "0.0498083085616\n",
      "0.993667658735\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 71\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8587    0.8467    0.8526       926\n",
      "          1     0.3957    0.4189    0.4070       222\n",
      "\n",
      "avg / total     0.7692    0.7639    0.7665      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7284113381674358\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4011627906976744\n",
      "Original f1: 0.3050259965337955\n",
      "0.0668860869395\n",
      "0.999999673847\n",
      "412\n",
      "0.271588661833\n",
      "Number of disagreement: 111\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8688    0.7843    0.8244      1233\n",
      "          1     0.3416    0.4859    0.4012       284\n",
      "\n",
      "avg / total     0.7701    0.7284    0.7452      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-2.0-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7038327526132404\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3632958801498127\n",
      "Original f1: 0.2694300518134715\n",
      "0.137718063239\n",
      "0.999999896731\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 158\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8505    0.7678    0.8070       926\n",
      "          1     0.3109    0.4369    0.3633       222\n",
      "\n",
      "avg / total     0.7461    0.7038    0.7212      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6967699406723797\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3882978723404255\n",
      "Original f1: 0.3050259965337955\n",
      "0.121968350151\n",
      "0.999999687373\n",
      "460\n",
      "0.303230059328\n",
      "Number of disagreement: 181\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8684    0.7388    0.7984      1233\n",
      "          1     0.3120    0.5141    0.3883       284\n",
      "\n",
      "avg / total     0.7643    0.6968    0.7216      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-2.0-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.735191637630662\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3870967741935484\n",
      "Original f1: 0.2694300518134715\n",
      "0.0836461311298\n",
      "0.999999896701\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 110\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8558    0.8078    0.8311       926\n",
      "          1     0.3504    0.4324    0.3871       222\n",
      "\n",
      "avg / total     0.7581    0.7352    0.7452      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7152274225444957\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4016620498614959\n",
      "Original f1: 0.3050259965337955\n",
      "0.0877697018599\n",
      "0.999999687263\n",
      "432\n",
      "0.284772577456\n",
      "Number of disagreement: 145\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8712    0.7624    0.8131      1233\n",
      "          1     0.3311    0.5106    0.4017       284\n",
      "\n",
      "avg / total     0.7701    0.7152    0.7361      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-2.0-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7012195121951219\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3636363636363636\n",
      "Original f1: 0.2694300518134715\n",
      "0.141392873643\n",
      "0.999999896021\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 163\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8508    0.7635    0.8048       926\n",
      "          1     0.3091    0.4414    0.3636       222\n",
      "\n",
      "avg / total     0.7460    0.7012    0.7195      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.6961107448912327\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3894039735099337\n",
      "Original f1: 0.3050259965337955\n",
      "0.123497585443\n",
      "0.999999687299\n",
      "461\n",
      "0.303889255109\n",
      "Number of disagreement: 184\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8690    0.7372    0.7977      1233\n",
      "          1     0.3121    0.5176    0.3894       284\n",
      "\n",
      "avg / total     0.7648    0.6961    0.7213      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-2.0-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "1.2869926974e-12\n",
      "2.28337241982e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "1.8618196094e-12\n",
      "8.19735151074e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-2.0-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "1.01620529844e-10\n",
      "9.78747529285e-08\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "3.6522137307e-10\n",
      "3.09623348681e-07\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-2.0-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "2.78114287984e-12\n",
      "1.69840919106e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "4.61396369595e-12\n",
      "8.19735151074e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-2.0-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7090592334494773\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.33992094861660077\n",
      "Original f1: 0.2694300518134715\n",
      "0.106010381778\n",
      "0.997283541121\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 126\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8426    0.7862    0.8134       926\n",
      "          1     0.3028    0.3874    0.3399       222\n",
      "\n",
      "avg / total     0.7382    0.7091    0.7218      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7053394858272907\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.383448275862069\n",
      "Original f1: 0.3050259965337955\n",
      "0.0999282099937\n",
      "0.999999687272\n",
      "447\n",
      "0.294660514173\n",
      "Number of disagreement: 148\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8652    0.7551    0.8064      1233\n",
      "          1     0.3152    0.4894    0.3834       284\n",
      "\n",
      "avg / total     0.7623    0.7053    0.7272      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-2.0-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "2.72903230478e-12\n",
      "4.49774780183e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "7.44898314313e-12\n",
      "2.0636383713e-09\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-2.0-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7029616724738676\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.345489443378119\n",
      "Original f1: 0.2694300518134715\n",
      "0.121365475414\n",
      "0.99728354115\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 141\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8445    0.7743    0.8079       926\n",
      "          1     0.3010    0.4054    0.3455       222\n",
      "\n",
      "avg / total     0.7394    0.7030    0.7185      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7020435069215557\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3858695652173913\n",
      "Original f1: 0.3050259965337955\n",
      "0.108592181043\n",
      "0.999999687309\n",
      "452\n",
      "0.297956493078\n",
      "Number of disagreement: 161\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8667    0.7486    0.8033      1233\n",
      "          1     0.3142    0.5000    0.3859       284\n",
      "\n",
      "avg / total     0.7632    0.7020    0.7252      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-2.0-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.000348362072441\n",
      "0.19623854619\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7402768622280818\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3299319727891156\n",
      "Original f1: 0.3050259965337955\n",
      "0.00409961945614\n",
      "0.744694324611\n",
      "394\n",
      "0.259723137772\n",
      "Number of disagreement: 11\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8458    0.8321    0.8389      1233\n",
      "          1     0.3191    0.3415    0.3299       284\n",
      "\n",
      "avg / total     0.7472    0.7403    0.7436      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-2.0-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7003484320557491\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3533834586466165\n",
      "Original f1: 0.2694300518134715\n",
      "0.129987655081\n",
      "0.997283541198\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 152\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8473    0.7667    0.8050       926\n",
      "          1     0.3032    0.4234    0.3534       222\n",
      "\n",
      "avg / total     0.7421    0.7003    0.7177      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6967699406723797\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38666666666666666\n",
      "Original f1: 0.3050259965337955\n",
      "0.116993145517\n",
      "0.999999687341\n",
      "460\n",
      "0.303230059328\n",
      "Number of disagreement: 175\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8677    0.7397    0.7986      1233\n",
      "          1     0.3112    0.5106    0.3867       284\n",
      "\n",
      "avg / total     0.7635    0.6968    0.7215      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-2.0-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7630662020905923\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.32000000000000006\n",
      "Original f1: 0.2694300518134715\n",
      "0.0131610054106\n",
      "0.966456082403\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 14\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8371    0.8769    0.8565       926\n",
      "          1     0.3596    0.2883    0.3200       222\n",
      "\n",
      "avg / total     0.7448    0.7631    0.7528      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7462096242584048\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3898573692551505\n",
      "Original f1: 0.3050259965337955\n",
      "0.0306756371794\n",
      "0.988537270527\n",
      "385\n",
      "0.253790375742\n",
      "Number of disagreement: 54\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8624    0.8183    0.8398      1233\n",
      "          1     0.3545    0.4331    0.3899       284\n",
      "\n",
      "avg / total     0.7673    0.7462    0.7556      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-2.0-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7029616724738676\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3602251407129456\n",
      "Original f1: 0.2694300518134715\n",
      "0.135007921525\n",
      "0.999999894285\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 155\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8495    0.7678    0.8066       926\n",
      "          1     0.3087    0.4324    0.3602       222\n",
      "\n",
      "avg / total     0.7449    0.7030    0.7203      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.6941331575477917\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3862433862433862\n",
      "Original f1: 0.3050259965337955\n",
      "0.122241744177\n",
      "0.999999687402\n",
      "464\n",
      "0.305866842452\n",
      "Number of disagreement: 181\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8679    0.7356    0.7963      1233\n",
      "          1     0.3093    0.5141    0.3862       284\n",
      "\n",
      "avg / total     0.7634    0.6941    0.7195      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-2.0-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.40789473684210525\n",
      "Original f1: 0.2694300518134715\n",
      "0.0500377525797\n",
      "0.993667657494\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 70\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8589    0.8477    0.8533       926\n",
      "          1     0.3974    0.4189    0.4079       222\n",
      "\n",
      "avg / total     0.7696    0.7648    0.7671      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7290705339485827\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.40174672489082974\n",
      "Original f1: 0.3050259965337955\n",
      "0.0671575641518\n",
      "0.999999686449\n",
      "411\n",
      "0.270929466051\n",
      "Number of disagreement: 110\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8689    0.7851    0.8249      1233\n",
      "          1     0.3424    0.4859    0.4017       284\n",
      "\n",
      "avg / total     0.7704    0.7291    0.7457      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-2.0-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7029616724738676\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3626168224299065\n",
      "Original f1: 0.2694300518134715\n",
      "0.138362472269\n",
      "0.999999896769\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 157\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8503    0.7667    0.8064       926\n",
      "          1     0.3099    0.4369    0.3626       222\n",
      "\n",
      "avg / total     0.7458    0.7030    0.7205      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6941331575477917\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3862433862433862\n",
      "Original f1: 0.3050259965337955\n",
      "0.123183641285\n",
      "0.999999687359\n",
      "464\n",
      "0.305866842452\n",
      "Number of disagreement: 181\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8679    0.7356    0.7963      1233\n",
      "          1     0.3093    0.5141    0.3862       284\n",
      "\n",
      "avg / total     0.7634    0.6941    0.7195      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-2.0-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7317073170731707\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.38152610441767065\n",
      "Original f1: 0.2694300518134715\n",
      "0.0840733417713\n",
      "0.999999892403\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 112\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8544    0.8045    0.8287       926\n",
      "          1     0.3442    0.4279    0.3815       222\n",
      "\n",
      "avg / total     0.7557    0.7317    0.7422      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7158866183256427\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4038727524204702\n",
      "Original f1: 0.3050259965337955\n",
      "0.0881498633678\n",
      "0.999999686122\n",
      "431\n",
      "0.284113381674\n",
      "Number of disagreement: 146\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8720    0.7624    0.8135      1233\n",
      "          1     0.3326    0.5141    0.4039       284\n",
      "\n",
      "avg / total     0.7710    0.7159    0.7368      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.1-2.0-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7003484320557491\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36296296296296293\n",
      "Original f1: 0.2694300518134715\n",
      "0.141775567317\n",
      "0.999999896816\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 162\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8506    0.7624    0.8041       926\n",
      "          1     0.3082    0.4414    0.3630       222\n",
      "\n",
      "avg / total     0.7457    0.7003    0.7188      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6934739617666447\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3873517786561265\n",
      "Original f1: 0.3050259965337955\n",
      "0.124790179453\n",
      "0.999999687363\n",
      "465\n",
      "0.306526038233\n",
      "Number of disagreement: 184\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8685    0.7340    0.7956      1233\n",
      "          1     0.3095    0.5176    0.3874       284\n",
      "\n",
      "avg / total     0.7639    0.6935    0.7192      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.5-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "3.19616969359e-12\n",
      "1.64320987373e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "6.08575050574e-12\n",
      "1.81278581035e-09\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.5-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7813588850174216\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2808022922636103\n",
      "Original f1: 0.2694300518134715\n",
      "0.0362939919633\n",
      "0.429980352635\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 39\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8306    0.9158    0.8711       926\n",
      "          1     0.3858    0.2207    0.2808       222\n",
      "\n",
      "avg / total     0.7446    0.7814    0.7569      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7778510217534608\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3051546391752577\n",
      "Original f1: 0.3050259965337955\n",
      "0.0525213167283\n",
      "0.574967923809\n",
      "337\n",
      "0.222148978247\n",
      "Number of disagreement: 110\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8404    0.8970    0.8678      1233\n",
      "          1     0.3682    0.2606    0.3052       284\n",
      "\n",
      "avg / total     0.7520    0.7779    0.7625      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.5-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.000173155837757\n",
      "0.141164765299\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "0.000643707728787\n",
      "0.234918055718\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.5-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7508710801393729\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3587443946188341\n",
      "Original f1: 0.2694300518134715\n",
      "0.1134369127\n",
      "0.99326487616\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 138\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8463    0.8445    0.8454       926\n",
      "          1     0.3571    0.3604    0.3587       222\n",
      "\n",
      "avg / total     0.7517    0.7509    0.7513      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7462096242584048\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38202247191011235\n",
      "Original f1: 0.3050259965337955\n",
      "0.117190272269\n",
      "0.998004585319\n",
      "385\n",
      "0.253790375742\n",
      "Number of disagreement: 220\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8599    0.8216    0.8403      1233\n",
      "          1     0.3510    0.4190    0.3820       284\n",
      "\n",
      "avg / total     0.7647    0.7462    0.7545      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.5-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.000784478673094\n",
      "0.261768569022\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7363216875411998\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3079584775086506\n",
      "Original f1: 0.3050259965337955\n",
      "0.0020164775529\n",
      "0.378815270489\n",
      "400\n",
      "0.263678312459\n",
      "Number of disagreement: 1\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8406    0.8337    0.8371      1233\n",
      "          1     0.3027    0.3134    0.3080       284\n",
      "\n",
      "avg / total     0.7399    0.7363    0.7381      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.5-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7412891986062717\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.37209302325581395\n",
      "Original f1: 0.2694300518134715\n",
      "0.129914056928\n",
      "0.993667656758\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 165\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8506    0.8240    0.8371       926\n",
      "          1     0.3506    0.3964    0.3721       222\n",
      "\n",
      "avg / total     0.7539    0.7413    0.7472      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7350032959789057\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38532110091743127\n",
      "Original f1: 0.3050259965337955\n",
      "0.132888950544\n",
      "0.999999685122\n",
      "402\n",
      "0.264996704021\n",
      "Number of disagreement: 253\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8622    0.8021    0.8311      1233\n",
      "          1     0.3405    0.4437    0.3853       284\n",
      "\n",
      "avg / total     0.7646    0.7350    0.7476      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.5-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.27319587628865977\n",
      "Original f1: 0.2694300518134715\n",
      "0.00271000292435\n",
      "0.412528272798\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 2\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8279    0.8780    0.8522       926\n",
      "          1     0.3193    0.2387    0.2732       222\n",
      "\n",
      "avg / total     0.7295    0.7544    0.7402      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7376400791034937\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3254237288135593\n",
      "Original f1: 0.3050259965337955\n",
      "0.00847430595544\n",
      "0.744694325393\n",
      "398\n",
      "0.262359920897\n",
      "Number of disagreement: 13\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8448    0.8297    0.8372      1233\n",
      "          1     0.3137    0.3380    0.3254       284\n",
      "\n",
      "avg / total     0.7453    0.7376    0.7414      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.5-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7290940766550522\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.376753507014028\n",
      "Original f1: 0.2694300518134715\n",
      "0.148573500974\n",
      "0.997283540248\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 191\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8530    0.8024    0.8269       926\n",
      "          1     0.3394    0.4234    0.3768       222\n",
      "\n",
      "avg / total     0.7537    0.7291    0.7399      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7284113381674358\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38690476190476186\n",
      "Original f1: 0.3050259965337955\n",
      "0.145687125414\n",
      "0.999999686995\n",
      "412\n",
      "0.271588661833\n",
      "Number of disagreement: 271\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8636    0.7908    0.8256      1233\n",
      "          1     0.3351    0.4577    0.3869       284\n",
      "\n",
      "avg / total     0.7646    0.7284    0.7434      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.5-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7656794425087108\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3358024691358025\n",
      "Original f1: 0.2694300518134715\n",
      "0.0124862112009\n",
      "0.993264876466\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 19\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8404    0.8758    0.8577       926\n",
      "          1     0.3716    0.3063    0.3358       222\n",
      "\n",
      "avg / total     0.7498    0.7657    0.7568      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7376400791034937\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3559870550161812\n",
      "Original f1: 0.3050259965337955\n",
      "0.0251628523217\n",
      "0.979195606969\n",
      "398\n",
      "0.262359920897\n",
      "Number of disagreement: 41\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8529    0.8183    0.8353      1233\n",
      "          1     0.3293    0.3873    0.3560       284\n",
      "\n",
      "avg / total     0.7549    0.7376    0.7455      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.5-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7177700348432056\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.37451737451737455\n",
      "Original f1: 0.2694300518134715\n",
      "0.159924179942\n",
      "0.997283540718\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 210\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8533    0.7851    0.8178       926\n",
      "          1     0.3277    0.4369    0.3745       222\n",
      "\n",
      "avg / total     0.7516    0.7178    0.7321      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7211601845748187\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3878437047756874\n",
      "Original f1: 0.3050259965337955\n",
      "0.15691033287\n",
      "0.999999687262\n",
      "423\n",
      "0.278839815425\n",
      "Number of disagreement: 292\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8649    0.7786    0.8195      1233\n",
      "          1     0.3292    0.4718    0.3878       284\n",
      "\n",
      "avg / total     0.7646    0.7212    0.7387      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.5-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7656794425087108\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3758700696055685\n",
      "Original f1: 0.2694300518134715\n",
      "0.0347308176302\n",
      "0.993667659029\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 45\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8498    0.8618    0.8558       926\n",
      "          1     0.3876    0.3649    0.3759       222\n",
      "\n",
      "avg / total     0.7604    0.7657    0.7630      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7415952537903757\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.400611620795107\n",
      "Original f1: 0.3050259965337955\n",
      "0.0463793929645\n",
      "0.993179317947\n",
      "392\n",
      "0.25840474621\n",
      "Number of disagreement: 77\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8666    0.8062    0.8353      1233\n",
      "          1     0.3541    0.4613    0.4006       284\n",
      "\n",
      "avg / total     0.7707    0.7416    0.7539      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.5-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7168989547038328\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3809523809523809\n",
      "Original f1: 0.2694300518134715\n",
      "0.169052513855\n",
      "0.997283540893\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 215\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8556    0.7808    0.8165       926\n",
      "          1     0.3300    0.4505    0.3810       222\n",
      "\n",
      "avg / total     0.7540    0.7169    0.7323      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7158866183256427\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3834048640915593\n",
      "Original f1: 0.3050259965337955\n",
      "0.163648438759\n",
      "0.999999687204\n",
      "431\n",
      "0.284113381674\n",
      "Number of disagreement: 300\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8639    0.7721    0.8154      1233\n",
      "          1     0.3229    0.4718    0.3834       284\n",
      "\n",
      "avg / total     0.7626    0.7159    0.7345      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.5-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3869565217391304\n",
      "Original f1: 0.2694300518134715\n",
      "0.0539980544992\n",
      "0.993667659137\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 74\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8538    0.8391    0.8464       926\n",
      "          1     0.3739    0.4009    0.3870       222\n",
      "\n",
      "avg / total     0.7610    0.7544    0.7576      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7336849044166117\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.40762463343108507\n",
      "Original f1: 0.3050259965337955\n",
      "0.0603443123513\n",
      "0.99999968542\n",
      "404\n",
      "0.266315095583\n",
      "Number of disagreement: 105\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8704    0.7899    0.8282      1233\n",
      "          1     0.3492    0.4894    0.4076       284\n",
      "\n",
      "avg / total     0.7729    0.7337    0.7495      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.5-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7142857142857143\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3857677902621723\n",
      "Original f1: 0.2694300518134715\n",
      "0.177103872153\n",
      "0.997283541165\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 224\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8577    0.7743    0.8138       926\n",
      "          1     0.3301    0.4640    0.3858       222\n",
      "\n",
      "avg / total     0.7556    0.7143    0.7311      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7132498352010547\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38297872340425526\n",
      "Original f1: 0.3050259965337955\n",
      "0.168749393875\n",
      "0.999999687322\n",
      "435\n",
      "0.286750164799\n",
      "Number of disagreement: 304\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8641    0.7680    0.8132      1233\n",
      "          1     0.3207    0.4754    0.3830       284\n",
      "\n",
      "avg / total     0.7623    0.7132    0.7327      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.5-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "2.40017415323e-12\n",
      "1.64320987373e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "6.84819349849e-12\n",
      "2.88127643966e-09\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.5-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7796167247386759\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.27920227920227925\n",
      "Original f1: 0.2694300518134715\n",
      "0.0359220409518\n",
      "0.44166182342\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 37\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8302    0.9136    0.8699       926\n",
      "          1     0.3798    0.2207    0.2792       222\n",
      "\n",
      "avg / total     0.7431    0.7796    0.7557      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7771918259723137\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.30452674897119336\n",
      "Original f1: 0.3050259965337955\n",
      "0.0522494879228\n",
      "0.574427000109\n",
      "338\n",
      "0.222808174028\n",
      "Number of disagreement: 109\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8403    0.8962    0.8673      1233\n",
      "          1     0.3663    0.2606    0.3045       284\n",
      "\n",
      "avg / total     0.7516    0.7772    0.7620      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.5-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.000137658001483\n",
      "0.116516556222\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "0.000468901349245\n",
      "0.212797484935\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.5-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7491289198606271\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3571428571428571\n",
      "Original f1: 0.2694300518134715\n",
      "0.113440841794\n",
      "0.993264876255\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 136\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8460    0.8423    0.8442       926\n",
      "          1     0.3540    0.3604    0.3571       222\n",
      "\n",
      "avg / total     0.7508    0.7491    0.7500      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7455504284772577\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38141025641025644\n",
      "Original f1: 0.3050259965337955\n",
      "0.117548720605\n",
      "0.999999678657\n",
      "386\n",
      "0.254449571523\n",
      "Number of disagreement: 217\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8598    0.8208    0.8398      1233\n",
      "          1     0.3500    0.4190    0.3814       284\n",
      "\n",
      "avg / total     0.7644    0.7456    0.7540      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.5-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.000758286589079\n",
      "0.237120739626\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7363216875411998\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3079584775086506\n",
      "Original f1: 0.3050259965337955\n",
      "0.00178402263394\n",
      "0.356681316088\n",
      "400\n",
      "0.263678312459\n",
      "Number of disagreement: 1\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8406    0.8337    0.8371      1233\n",
      "          1     0.3027    0.3134    0.3080       284\n",
      "\n",
      "avg / total     0.7399    0.7363    0.7381      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.5-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7430313588850174\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3763213530655391\n",
      "Original f1: 0.2694300518134715\n",
      "0.13007795774\n",
      "0.997283540635\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 161\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8517    0.8251    0.8382       926\n",
      "          1     0.3546    0.4009    0.3763       222\n",
      "\n",
      "avg / total     0.7556    0.7430    0.7489      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7343441001977588\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38473282442748086\n",
      "Original f1: 0.3050259965337955\n",
      "0.133148276321\n",
      "0.999999685113\n",
      "403\n",
      "0.265655899802\n",
      "Number of disagreement: 252\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8621    0.8013    0.8306      1233\n",
      "          1     0.3396    0.4437    0.3847       284\n",
      "\n",
      "avg / total     0.7643    0.7343    0.7471      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.5-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7552264808362369\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.27763496143958866\n",
      "Original f1: 0.2694300518134715\n",
      "0.00256830574156\n",
      "0.388329559325\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 3\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8287    0.8780    0.8526       926\n",
      "          1     0.3234    0.2432    0.2776       222\n",
      "\n",
      "avg / total     0.7310    0.7552    0.7415      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7369808833223468\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3248730964467005\n",
      "Original f1: 0.3050259965337955\n",
      "0.00807978123081\n",
      "0.744694325393\n",
      "399\n",
      "0.263019116678\n",
      "Number of disagreement: 14\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8446    0.8289    0.8367      1233\n",
      "          1     0.3127    0.3380    0.3249       284\n",
      "\n",
      "avg / total     0.7450    0.7370    0.7409      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.5-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7247386759581882\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3705179282868526\n",
      "Original f1: 0.2694300518134715\n",
      "0.148618193446\n",
      "0.997283541135\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 190\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8514    0.7981    0.8239       926\n",
      "          1     0.3321    0.4189    0.3705       222\n",
      "\n",
      "avg / total     0.7510    0.7247    0.7362      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7290705339485827\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38748137108792846\n",
      "Original f1: 0.3050259965337955\n",
      "0.145925616214\n",
      "0.99999968733\n",
      "411\n",
      "0.270929466051\n",
      "Number of disagreement: 268\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8637    0.7916    0.8261      1233\n",
      "          1     0.3359    0.4577    0.3875       284\n",
      "\n",
      "avg / total     0.7649    0.7291    0.7440      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.5-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7639372822299652\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3275434243176179\n",
      "Original f1: 0.2694300518134715\n",
      "0.0113756238599\n",
      "0.993264876278\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 17\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8387    0.8758    0.8568       926\n",
      "          1     0.3646    0.2973    0.3275       222\n",
      "\n",
      "avg / total     0.7470    0.7639    0.7545      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7382992748846408\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3586429725363489\n",
      "Original f1: 0.3050259965337955\n",
      "0.0252221592307\n",
      "0.979195607154\n",
      "397\n",
      "0.261700725115\n",
      "Number of disagreement: 42\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8536    0.8183    0.8356      1233\n",
      "          1     0.3313    0.3908    0.3586       284\n",
      "\n",
      "avg / total     0.7559    0.7383    0.7463      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.5-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7195121951219512\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3831417624521073\n",
      "Original f1: 0.2694300518134715\n",
      "0.160739947206\n",
      "0.997283540969\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 210\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8561    0.7840    0.8185       926\n",
      "          1     0.3333    0.4505    0.3831       222\n",
      "\n",
      "avg / total     0.7550    0.7195    0.7343      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7205009887936717\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3872832369942197\n",
      "Original f1: 0.3050259965337955\n",
      "0.157370269928\n",
      "0.999999686983\n",
      "424\n",
      "0.279499011206\n",
      "Number of disagreement: 289\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8647    0.7778    0.8190      1233\n",
      "          1     0.3284    0.4718    0.3873       284\n",
      "\n",
      "avg / total     0.7643    0.7205    0.7381      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.5-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7656794425087108\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3758700696055685\n",
      "Original f1: 0.2694300518134715\n",
      "0.0338946859341\n",
      "0.993667658527\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 45\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8498    0.8618    0.8558       926\n",
      "          1     0.3876    0.3649    0.3759       222\n",
      "\n",
      "avg / total     0.7604    0.7657    0.7630      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7422544495715228\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4012251148545176\n",
      "Original f1: 0.3050259965337955\n",
      "0.0466280734241\n",
      "0.992866684182\n",
      "391\n",
      "0.257745550428\n",
      "Number of disagreement: 76\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8667    0.8070    0.8358      1233\n",
      "          1     0.3550    0.4613    0.4012       284\n",
      "\n",
      "avg / total     0.7709    0.7423    0.7544      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.5-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7195121951219512\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.39015151515151514\n",
      "Original f1: 0.2694300518134715\n",
      "0.169879297706\n",
      "0.997283540913\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 214\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8587    0.7808    0.8179       926\n",
      "          1     0.3366    0.4640    0.3902       222\n",
      "\n",
      "avg / total     0.7577    0.7195    0.7352      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7152274225444957\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38285714285714284\n",
      "Original f1: 0.3050259965337955\n",
      "0.164139239348\n",
      "0.99999968737\n",
      "432\n",
      "0.284772577456\n",
      "Number of disagreement: 297\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8638    0.7713    0.8149      1233\n",
      "          1     0.3221    0.4718    0.3829       284\n",
      "\n",
      "avg / total     0.7624    0.7152    0.7340      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.5-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7534843205574913\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.38344226579520696\n",
      "Original f1: 0.2694300518134715\n",
      "0.0540762030295\n",
      "0.993667659163\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 73\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8529    0.8391    0.8459       926\n",
      "          1     0.3713    0.3964    0.3834       222\n",
      "\n",
      "avg / total     0.7598    0.7535    0.7565      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7336849044166117\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4058823529411765\n",
      "Original f1: 0.3050259965337955\n",
      "0.0602444511453\n",
      "0.999999686262\n",
      "404\n",
      "0.266315095583\n",
      "Number of disagreement: 103\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8698    0.7908    0.8284      1233\n",
      "          1     0.3485    0.4859    0.4059       284\n",
      "\n",
      "avg / total     0.7722    0.7337    0.7493      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.5-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7160278745644599\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.39179104477611937\n",
      "Original f1: 0.2694300518134715\n",
      "0.177845355622\n",
      "0.997283541001\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 222\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8597    0.7743    0.8148       926\n",
      "          1     0.3344    0.4730    0.3918       222\n",
      "\n",
      "avg / total     0.7581    0.7160    0.7330      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7106130520764667\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38081805359661497\n",
      "Original f1: 0.3050259965337955\n",
      "0.169247463463\n",
      "0.999999687324\n",
      "439\n",
      "0.289386947924\n",
      "Number of disagreement: 304\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8636    0.7648    0.8112      1233\n",
      "          1     0.3176    0.4754    0.3808       284\n",
      "\n",
      "avg / total     0.7614    0.7106    0.7306      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.75-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "4.85502239247e-12\n",
      "2.39496967629e-09\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "3.61088424139e-12\n",
      "7.36801079687e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.75-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7787456445993032\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2865168539325843\n",
      "Original f1: 0.2694300518134715\n",
      "0.0310448468597\n",
      "0.363718429858\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 32\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8314    0.9104    0.8691       926\n",
      "          1     0.3806    0.2297    0.2865       222\n",
      "\n",
      "avg / total     0.7442    0.7787    0.7564      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7745550428477258\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.32677165354330706\n",
      "Original f1: 0.3050259965337955\n",
      "0.0453745727896\n",
      "0.517579764706\n",
      "342\n",
      "0.225444957152\n",
      "Number of disagreement: 81\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8445    0.8856    0.8646      1233\n",
      "          1     0.3705    0.2923    0.3268       284\n",
      "\n",
      "avg / total     0.7558    0.7746    0.7639      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.75-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "5.10329578831e-05\n",
      "0.0585858288602\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "0.000484075181476\n",
      "0.292291223216\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.75-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7378048780487805\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3636363636363636\n",
      "Original f1: 0.2694300518134715\n",
      "0.122140336518\n",
      "0.997283539835\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 151\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8484    0.8218    0.8349       926\n",
      "          1     0.3426    0.3874    0.3636       222\n",
      "\n",
      "avg / total     0.7506    0.7378    0.7438      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7310481212920237\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3928571428571429\n",
      "Original f1: 0.3050259965337955\n",
      "0.127747124274\n",
      "0.993179321017\n",
      "408\n",
      "0.268951878708\n",
      "Number of disagreement: 223\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8654    0.7924    0.8273      1233\n",
      "          1     0.3402    0.4648    0.3929       284\n",
      "\n",
      "avg / total     0.7671    0.7310    0.7459      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.75-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.000574350918375\n",
      "0.202832394887\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7363216875411998\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3079584775086506\n",
      "Original f1: 0.3050259965337955\n",
      "0.00173605736313\n",
      "0.436185653099\n",
      "400\n",
      "0.263678312459\n",
      "Number of disagreement: 1\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8406    0.8337    0.8371      1233\n",
      "          1     0.3027    0.3134    0.3080       284\n",
      "\n",
      "avg / total     0.7399    0.7363    0.7381      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.75-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7273519163763066\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.37274549098196386\n",
      "Original f1: 0.2694300518134715\n",
      "0.139614978813\n",
      "0.997283541001\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 177\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8519    0.8013    0.8258       926\n",
      "          1     0.3357    0.4189    0.3727       222\n",
      "\n",
      "avg / total     0.7521    0.7274    0.7382      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7224785761371127\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38896952104499277\n",
      "Original f1: 0.3050259965337955\n",
      "0.139288001384\n",
      "0.999999687169\n",
      "421\n",
      "0.277521423863\n",
      "Number of disagreement: 240\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8651    0.7802    0.8205      1233\n",
      "          1     0.3309    0.4718    0.3890       284\n",
      "\n",
      "avg / total     0.7651    0.7225    0.7397      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.75-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.0025586891939\n",
      "0.383138612591\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7389584706657878\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.32653061224489793\n",
      "Original f1: 0.3050259965337955\n",
      "0.00760219944841\n",
      "0.744694330138\n",
      "396\n",
      "0.261041529334\n",
      "Number of disagreement: 11\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8450    0.8313    0.8381      1233\n",
      "          1     0.3158    0.3380    0.3265       284\n",
      "\n",
      "avg / total     0.7459    0.7390    0.7423      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.75-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.710801393728223\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36882129277566544\n",
      "Original f1: 0.2694300518134715\n",
      "0.155007176139\n",
      "0.997283540995\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 204\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8519    0.7765    0.8124       926\n",
      "          1     0.3191    0.4369    0.3688       222\n",
      "\n",
      "avg / total     0.7489    0.7108    0.7266      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7158866183256427\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.39038189533239037\n",
      "Original f1: 0.3050259965337955\n",
      "0.151255030624\n",
      "0.999999687033\n",
      "431\n",
      "0.284113381674\n",
      "Number of disagreement: 258\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8665    0.7689    0.8148      1233\n",
      "          1     0.3262    0.4859    0.3904       284\n",
      "\n",
      "avg / total     0.7654    0.7159    0.7353      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.75-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7639372822299652\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.33415233415233414\n",
      "Original f1: 0.2694300518134715\n",
      "0.0138221726674\n",
      "0.993264876575\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 21\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8401    0.8737    0.8565       926\n",
      "          1     0.3676    0.3063    0.3342       222\n",
      "\n",
      "avg / total     0.7487    0.7639    0.7555      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7415952537903757\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3738019169329074\n",
      "Original f1: 0.3050259965337955\n",
      "0.0297520637732\n",
      "0.979195587761\n",
      "392\n",
      "0.25840474621\n",
      "Number of disagreement: 49\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8579    0.8175    0.8372      1233\n",
      "          1     0.3421    0.4120    0.3738       284\n",
      "\n",
      "avg / total     0.7613    0.7416    0.7505      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.75-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7081881533101045\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.37847866419294995\n",
      "Original f1: 0.2694300518134715\n",
      "0.16665114548\n",
      "0.997283541192\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 217\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8556    0.7678    0.8093       926\n",
      "          1     0.3218    0.4595    0.3785       222\n",
      "\n",
      "avg / total     0.7524    0.7082    0.7260      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7086354647330257\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3911845730027549\n",
      "Original f1: 0.3050259965337955\n",
      "0.161712287298\n",
      "0.999999686892\n",
      "442\n",
      "0.291364535267\n",
      "Number of disagreement: 277\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8679    0.7567    0.8085      1233\n",
      "          1     0.3213    0.5000    0.3912       284\n",
      "\n",
      "avg / total     0.7656    0.7086    0.7304      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.75-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7656794425087108\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3816091954022989\n",
      "Original f1: 0.2694300518134715\n",
      "0.0379666104627\n",
      "0.993667657218\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 49\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8513    0.8596    0.8555       926\n",
      "          1     0.3897    0.3739    0.3816       222\n",
      "\n",
      "avg / total     0.7621    0.7657    0.7638      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7409360580092288\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.41255605381165916\n",
      "Original f1: 0.3050259965337955\n",
      "0.0528235433399\n",
      "0.993179315844\n",
      "393\n",
      "0.259063941991\n",
      "Number of disagreement: 92\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8710    0.7997    0.8338      1233\n",
      "          1     0.3584    0.4859    0.4126       284\n",
      "\n",
      "avg / total     0.7751    0.7409    0.7550      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.75-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7116724738675958\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3904235727440147\n",
      "Original f1: 0.2694300518134715\n",
      "0.173522042578\n",
      "0.997283541183\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 221\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8597    0.7678    0.8112       926\n",
      "          1     0.3302    0.4775    0.3904       222\n",
      "\n",
      "avg / total     0.7573    0.7117    0.7298      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7027027027027027\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38639455782312926\n",
      "Original f1: 0.3050259965337955\n",
      "0.166787998332\n",
      "0.999999687017\n",
      "451\n",
      "0.297297297297\n",
      "Number of disagreement: 284\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8668    0.7494    0.8038      1233\n",
      "          1     0.3149    0.5000    0.3864       284\n",
      "\n",
      "avg / total     0.7635    0.7027    0.7257      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.75-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7508710801393729\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3888888888888889\n",
      "Original f1: 0.2694300518134715\n",
      "0.0602447549845\n",
      "0.993667658705\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 82\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8548    0.8326    0.8435       926\n",
      "          1     0.3699    0.4099    0.3889       222\n",
      "\n",
      "avg / total     0.7610    0.7509    0.7556      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7277521423862887\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4074605451936872\n",
      "Original f1: 0.3050259965337955\n",
      "0.0675886344571\n",
      "0.99999968651\n",
      "413\n",
      "0.272247857614\n",
      "Number of disagreement: 120\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8714    0.7802    0.8233      1233\n",
      "          1     0.3438    0.5000    0.4075       284\n",
      "\n",
      "avg / total     0.7726    0.7278    0.7454      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.75-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7081881533101045\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.39201451905626133\n",
      "Original f1: 0.2694300518134715\n",
      "0.180151063726\n",
      "0.997283541095\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 229\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8608    0.7613    0.8080       926\n",
      "          1     0.3283    0.4865    0.3920       222\n",
      "\n",
      "avg / total     0.7578    0.7082    0.7276      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7013843111404087\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3870094722598105\n",
      "Original f1: 0.3050259965337955\n",
      "0.1708093107\n",
      "0.999999687183\n",
      "453\n",
      "0.29861568886\n",
      "Number of disagreement: 288\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8672    0.7470    0.8026      1233\n",
      "          1     0.3143    0.5035    0.3870       284\n",
      "\n",
      "avg / total     0.7637    0.7014    0.7248      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.75-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "4.47975623505e-12\n",
      "2.6399616415e-09\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "3.24028778516e-12\n",
      "6.5595186006e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.75-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7761324041811847\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.28412256267409475\n",
      "Original f1: 0.2694300518134715\n",
      "0.0301582738028\n",
      "0.386315082677\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 31\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8309    0.9071    0.8673       926\n",
      "          1     0.3723    0.2297    0.2841       222\n",
      "\n",
      "avg / total     0.7422    0.7761    0.7545      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7725774555042848\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3195266272189349\n",
      "Original f1: 0.3050259965337955\n",
      "0.044898061664\n",
      "0.518715588513\n",
      "345\n",
      "0.227422544496\n",
      "Number of disagreement: 78\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8431    0.8848    0.8635      1233\n",
      "          1     0.3632    0.2852    0.3195       284\n",
      "\n",
      "avg / total     0.7533    0.7726    0.7616      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.75-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "6.27358158731e-05\n",
      "0.0720207109198\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "0.00041074738927\n",
      "0.232870905237\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.75-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.735191637630662\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36401673640167365\n",
      "Original f1: 0.2694300518134715\n",
      "0.122429827657\n",
      "0.997283540763\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 152\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8487    0.8175    0.8328       926\n",
      "          1     0.3398    0.3919    0.3640       222\n",
      "\n",
      "avg / total     0.7503    0.7352    0.7421      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7284113381674358\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38872403560830854\n",
      "Original f1: 0.3050259965337955\n",
      "0.129012483676\n",
      "0.999999685607\n",
      "412\n",
      "0.271588661833\n",
      "Number of disagreement: 221\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8642    0.7899    0.8254      1233\n",
      "          1     0.3359    0.4613    0.3887       284\n",
      "\n",
      "avg / total     0.7653    0.7284    0.7437      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.75-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.000496147849003\n",
      "0.216263180318\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "0.00129970793676\n",
      "0.383914997548\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.75-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7203832752613241\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3668639053254438\n",
      "Original f1: 0.2694300518134715\n",
      "0.139886918837\n",
      "0.997283540865\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 181\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8505    0.7927    0.8206       926\n",
      "          1     0.3263    0.4189    0.3669       222\n",
      "\n",
      "avg / total     0.7492    0.7204    0.7328      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7205009887936717\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3872832369942197\n",
      "Original f1: 0.3050259965337955\n",
      "0.140885111425\n",
      "0.999999687029\n",
      "424\n",
      "0.279499011206\n",
      "Number of disagreement: 241\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8647    0.7778    0.8190      1233\n",
      "          1     0.3284    0.4718    0.3873       284\n",
      "\n",
      "avg / total     0.7643    0.7205    0.7381      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.75-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.00251557128833\n",
      "0.396564789161\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7389584706657878\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.32423208191126274\n",
      "Original f1: 0.3050259965337955\n",
      "0.00703971163333\n",
      "0.744694330138\n",
      "396\n",
      "0.261041529334\n",
      "Number of disagreement: 9\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8444    0.8321    0.8382      1233\n",
      "          1     0.3146    0.3345    0.3242       284\n",
      "\n",
      "avg / total     0.7452    0.7390    0.7420      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.75-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.705574912891986\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36466165413533835\n",
      "Original f1: 0.2694300518134715\n",
      "0.155893125426\n",
      "0.997283541202\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 206\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8508    0.7700    0.8084       926\n",
      "          1     0.3129    0.4369    0.3647       222\n",
      "\n",
      "avg / total     0.7468    0.7056    0.7226      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7119314436387607\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38537271448663857\n",
      "Original f1: 0.3050259965337955\n",
      "0.152538749723\n",
      "0.999999687338\n",
      "437\n",
      "0.288068556361\n",
      "Number of disagreement: 262\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8651    0.7648    0.8119      1233\n",
      "          1     0.3208    0.4824    0.3854       284\n",
      "\n",
      "avg / total     0.7632    0.7119    0.7320      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.75-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7621951219512195\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3259259259259259\n",
      "Original f1: 0.2694300518134715\n",
      "0.0127078725776\n",
      "0.993264875985\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 19\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8383    0.8737    0.8556       926\n",
      "          1     0.3607    0.2973    0.3259       222\n",
      "\n",
      "avg / total     0.7460    0.7622    0.7532      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7415952537903757\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3738019169329074\n",
      "Original f1: 0.3050259965337955\n",
      "0.0288102172999\n",
      "0.959584902532\n",
      "392\n",
      "0.25840474621\n",
      "Number of disagreement: 49\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8579    0.8175    0.8372      1233\n",
      "          1     0.3421    0.4120    0.3738       284\n",
      "\n",
      "avg / total     0.7613    0.7416    0.7505      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.75-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7020905923344948\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.37132352941176466\n",
      "Original f1: 0.2694300518134715\n",
      "0.167863883241\n",
      "0.99728354101\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 216\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8535    0.7613    0.8048       926\n",
      "          1     0.3137    0.4550    0.3713       222\n",
      "\n",
      "avg / total     0.7491    0.7021    0.7210      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7033618984838497\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38524590163934425\n",
      "Original f1: 0.3050259965337955\n",
      "0.163054462853\n",
      "0.999999687335\n",
      "450\n",
      "0.296638101516\n",
      "Number of disagreement: 283\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8662    0.7510    0.8045      1233\n",
      "          1     0.3147    0.4965    0.3852       284\n",
      "\n",
      "avg / total     0.7630    0.7034    0.7260      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.75-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7674216027874564\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3862068965517241\n",
      "Original f1: 0.2694300518134715\n",
      "0.0356436115082\n",
      "0.993667658113\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 49\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8524    0.8607    0.8565       926\n",
      "          1     0.3944    0.3784    0.3862       222\n",
      "\n",
      "avg / total     0.7638    0.7674    0.7656      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7409360580092288\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4107946026986507\n",
      "Original f1: 0.3050259965337955\n",
      "0.0527674930485\n",
      "0.992866688689\n",
      "393\n",
      "0.259063941991\n",
      "Number of disagreement: 90\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8704    0.8005    0.8340      1233\n",
      "          1     0.3577    0.4824    0.4108       284\n",
      "\n",
      "avg / total     0.7744    0.7409    0.7547      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.75-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7038327526132404\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3840579710144928\n",
      "Original f1: 0.2694300518134715\n",
      "0.174197238207\n",
      "0.99728354113\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 224\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8582    0.7581    0.8050       926\n",
      "          1     0.3212    0.4775    0.3841       222\n",
      "\n",
      "avg / total     0.7543    0.7038    0.7236      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6994067237969677\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3821138211382114\n",
      "Original f1: 0.3050259965337955\n",
      "0.167943359428\n",
      "0.999999687326\n",
      "456\n",
      "0.300593276203\n",
      "Number of disagreement: 289\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8655    0.7461    0.8014      1233\n",
      "          1     0.3106    0.4965    0.3821       284\n",
      "\n",
      "avg / total     0.7616    0.6994    0.7229      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.75-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.75\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.38805970149253727\n",
      "Original f1: 0.2694300518134715\n",
      "0.060822329051\n",
      "0.993667658751\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 83\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8546    0.8315    0.8429       926\n",
      "          1     0.3684    0.4099    0.3881       222\n",
      "\n",
      "avg / total     0.7606    0.7500    0.7550      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7284113381674358\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4097421203438395\n",
      "Original f1: 0.3050259965337955\n",
      "0.06696811597\n",
      "0.999999686375\n",
      "412\n",
      "0.271588661833\n",
      "Number of disagreement: 121\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8722    0.7802    0.8236      1233\n",
      "          1     0.3454    0.5035    0.4097       284\n",
      "\n",
      "avg / total     0.7736    0.7284    0.7461      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-0.75-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7012195121951219\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3864042933810376\n",
      "Original f1: 0.2694300518134715\n",
      "0.18083175999\n",
      "0.997283541175\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 231\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8594    0.7527    0.8025       926\n",
      "          1     0.3205    0.4865    0.3864       222\n",
      "\n",
      "avg / total     0.7552    0.7012    0.7221      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6967699406723797\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3817204301075269\n",
      "Original f1: 0.3050259965337955\n",
      "0.172240635156\n",
      "0.999999687367\n",
      "460\n",
      "0.303230059328\n",
      "Number of disagreement: 295\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8657    0.7421    0.7991      1233\n",
      "          1     0.3087    0.5000    0.3817       284\n",
      "\n",
      "avg / total     0.7614    0.6968    0.7210      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.0-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "4.42263856528e-12\n",
      "2.56047270113e-09\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "3.13766001701e-12\n",
      "9.66024519656e-10\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.0-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7761324041811847\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.28412256267409475\n",
      "Original f1: 0.2694300518134715\n",
      "0.028991572087\n",
      "0.349555042967\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 29\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8309    0.9071    0.8673       926\n",
      "          1     0.3723    0.2297    0.2841       222\n",
      "\n",
      "avg / total     0.7422    0.7761    0.7545      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7692814765985497\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.31906614785992216\n",
      "Original f1: 0.3050259965337955\n",
      "0.0430375086063\n",
      "0.466204051336\n",
      "350\n",
      "0.230718523401\n",
      "Number of disagreement: 71\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8430    0.8800    0.8611      1233\n",
      "          1     0.3565    0.2887    0.3191       284\n",
      "\n",
      "avg / total     0.7520    0.7693    0.7596      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.0-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "2.69251794687e-05\n",
      "0.0309101001803\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "0.000398667541463\n",
      "0.276889183925\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.0-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7247386759581882\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3603238866396761\n",
      "Original f1: 0.2694300518134715\n",
      "0.128205827022\n",
      "0.997283540985\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 162\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8482    0.8024    0.8246       926\n",
      "          1     0.3272    0.4009    0.3603       222\n",
      "\n",
      "avg / total     0.7474    0.7247    0.7349      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7185234014502307\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3838383838383838\n",
      "Original f1: 0.3050259965337955\n",
      "0.132595920258\n",
      "0.999080084228\n",
      "427\n",
      "0.28147659855\n",
      "Number of disagreement: 220\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8637    0.7762    0.8176      1233\n",
      "          1     0.3252    0.4683    0.3838       284\n",
      "\n",
      "avg / total     0.7629    0.7185    0.7364      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.0-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.000452350894695\n",
      "0.175159071733\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7363216875411998\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3079584775086506\n",
      "Original f1: 0.3050259965337955\n",
      "0.00146475637141\n",
      "0.420784599413\n",
      "400\n",
      "0.263678312459\n",
      "Number of disagreement: 1\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8406    0.8337    0.8371      1233\n",
      "          1     0.3027    0.3134    0.3080       284\n",
      "\n",
      "avg / total     0.7399    0.7363    0.7381      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.0-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7125435540069687\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36293436293436293\n",
      "Original f1: 0.2694300518134715\n",
      "0.145670045638\n",
      "0.997283541128\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 184\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8498    0.7819    0.8144       926\n",
      "          1     0.3176    0.4234    0.3629       222\n",
      "\n",
      "avg / total     0.7468    0.7125    0.7271      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7119314436387607\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.383638928067701\n",
      "Original f1: 0.3050259965337955\n",
      "0.14380040874\n",
      "0.999999686983\n",
      "437\n",
      "0.288068556361\n",
      "Number of disagreement: 238\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8645    0.7656    0.8120      1233\n",
      "          1     0.3200    0.4789    0.3836       284\n",
      "\n",
      "avg / total     0.7625    0.7119    0.7318      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.0-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7552264808362369\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2739018087855297\n",
      "Original f1: 0.2694300518134715\n",
      "0.002437225057\n",
      "0.35546532273\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 1\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8281    0.8790    0.8528       926\n",
      "          1     0.3212    0.2387    0.2739       222\n",
      "\n",
      "avg / total     0.7301    0.7552    0.7409      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7396176664469347\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3293718166383701\n",
      "Original f1: 0.3050259965337955\n",
      "0.00731375122683\n",
      "0.744694326489\n",
      "395\n",
      "0.260382333553\n",
      "Number of disagreement: 12\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8457    0.8313    0.8384      1233\n",
      "          1     0.3180    0.3415    0.3294       284\n",
      "\n",
      "avg / total     0.7469    0.7396    0.7431      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.0-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7020905923344948\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3643122676579925\n",
      "Original f1: 0.2694300518134715\n",
      "0.160260788606\n",
      "0.997283540968\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 204\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8510    0.7646    0.8055       926\n",
      "          1     0.3101    0.4414    0.3643       222\n",
      "\n",
      "avg / total     0.7464    0.7021    0.7202      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7059986816084377\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38397790055248615\n",
      "Original f1: 0.3050259965337955\n",
      "0.154699082756\n",
      "0.999999687034\n",
      "446\n",
      "0.294001318392\n",
      "Number of disagreement: 253\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8654    0.7559    0.8069      1233\n",
      "          1     0.3159    0.4894    0.3840       284\n",
      "\n",
      "avg / total     0.7625    0.7060    0.7277      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.0-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7639372822299652\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3275434243176179\n",
      "Original f1: 0.2694300518134715\n",
      "0.0138498291623\n",
      "0.993264876589\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 17\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8387    0.8758    0.8568       926\n",
      "          1     0.3646    0.2973    0.3275       222\n",
      "\n",
      "avg / total     0.7470    0.7639    0.7545      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7409360580092288\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.37519872813990457\n",
      "Original f1: 0.3050259965337955\n",
      "0.0292400205392\n",
      "0.95323302518\n",
      "393\n",
      "0.259063941991\n",
      "Number of disagreement: 52\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8584    0.8159    0.8366      1233\n",
      "          1     0.3420    0.4155    0.3752       284\n",
      "\n",
      "avg / total     0.7617    0.7409    0.7502      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.0-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6968641114982579\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3695652173913044\n",
      "Original f1: 0.2694300518134715\n",
      "0.171088741704\n",
      "0.997283541028\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 218\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8533    0.7538    0.8005       926\n",
      "          1     0.3091    0.4595    0.3696       222\n",
      "\n",
      "avg / total     0.7481    0.6969    0.7171      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6967699406723797\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3817204301075269\n",
      "Original f1: 0.3050259965337955\n",
      "0.16464457171\n",
      "0.999999687034\n",
      "460\n",
      "0.303230059328\n",
      "Number of disagreement: 273\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8657    0.7421    0.7991      1233\n",
      "          1     0.3087    0.5000    0.3817       284\n",
      "\n",
      "avg / total     0.7614    0.6968    0.7210      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.0-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.38073394495412843\n",
      "Original f1: 0.2694300518134715\n",
      "0.0376339785956\n",
      "0.993667659118\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 50\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8512    0.8585    0.8548       926\n",
      "          1     0.3879    0.3739    0.3807       222\n",
      "\n",
      "avg / total     0.7616    0.7648    0.7632      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7363216875411998\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.41002949852507375\n",
      "Original f1: 0.3050259965337955\n",
      "0.0562113502606\n",
      "0.9928666892\n",
      "400\n",
      "0.263678312459\n",
      "Number of disagreement: 101\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8709    0.7932    0.8302      1233\n",
      "          1     0.3528    0.4894    0.4100       284\n",
      "\n",
      "avg / total     0.7739    0.7363    0.7516      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.0-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7003484320557491\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3857142857142858\n",
      "Original f1: 0.2694300518134715\n",
      "0.176950777024\n",
      "0.997283541187\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 226\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8593    0.7516    0.8018       926\n",
      "          1     0.3195    0.4865    0.3857       222\n",
      "\n",
      "avg / total     0.7549    0.7003    0.7214      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6934739617666447\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3791722296395193\n",
      "Original f1: 0.3050259965337955\n",
      "0.169471698857\n",
      "0.999999686957\n",
      "465\n",
      "0.306526038233\n",
      "Number of disagreement: 278\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8650    0.7380    0.7965      1233\n",
      "          1     0.3054    0.5000    0.3792       284\n",
      "\n",
      "avg / total     0.7602    0.6935    0.7184      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.0-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7491289198606271\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3924050632911393\n",
      "Original f1: 0.2694300518134715\n",
      "0.0627130960829\n",
      "0.993667658189\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 88\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8560    0.8283    0.8419       926\n",
      "          1     0.3690    0.4189    0.3924       222\n",
      "\n",
      "avg / total     0.7619    0.7491    0.7550      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7231377719182597\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.40509915014164305\n",
      "Original f1: 0.3050259965337955\n",
      "0.0713651057933\n",
      "0.999999683352\n",
      "420\n",
      "0.276862228082\n",
      "Number of disagreement: 129\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8712    0.7737    0.8196      1233\n",
      "          1     0.3389    0.5035    0.4051       284\n",
      "\n",
      "avg / total     0.7716    0.7231    0.7420      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.0-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6977351916376306\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3858407079646018\n",
      "Original f1: 0.2694300518134715\n",
      "0.182578531321\n",
      "0.999999886802\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 231\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8596    0.7473    0.7995       926\n",
      "          1     0.3178    0.4910    0.3858       222\n",
      "\n",
      "avg / total     0.7548    0.6977    0.7195      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6908371786420567\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3788079470198675\n",
      "Original f1: 0.3050259965337955\n",
      "0.173124592893\n",
      "0.999999687399\n",
      "469\n",
      "0.309162821358\n",
      "Number of disagreement: 284\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8652    0.7340    0.7942      1233\n",
      "          1     0.3036    0.5035    0.3788       284\n",
      "\n",
      "avg / total     0.7601    0.6908    0.7164      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.0-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "4.86722661265e-12\n",
      "3.27687282207e-09\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "2.66284002528e-12\n",
      "1.06588598616e-09\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.0-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7726480836236934\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2809917355371901\n",
      "Original f1: 0.2694300518134715\n",
      "0.0278756994636\n",
      "0.37569217973\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 25\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8302    0.9028    0.8650       926\n",
      "          1     0.3617    0.2297    0.2810       222\n",
      "\n",
      "avg / total     0.7396    0.7726    0.7520      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7686222808174028\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3157894736842105\n",
      "Original f1: 0.3050259965337955\n",
      "0.0427149776327\n",
      "0.466901371232\n",
      "351\n",
      "0.231377719183\n",
      "Number of disagreement: 70\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8424    0.8800    0.8608      1233\n",
      "          1     0.3537    0.2852    0.3158       284\n",
      "\n",
      "avg / total     0.7509    0.7686    0.7587      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.0-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "5.85083537352e-05\n",
      "0.0671675831886\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "0.000360232320727\n",
      "0.238134719952\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.0-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7168989547038328\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3538767395626243\n",
      "Original f1: 0.2694300518134715\n",
      "0.128553562331\n",
      "0.997283541214\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 163\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8466    0.7927    0.8187       926\n",
      "          1     0.3167    0.4009    0.3539       222\n",
      "\n",
      "avg / total     0.7441    0.7169    0.7288      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7191825972313777\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38439306358381503\n",
      "Original f1: 0.3050259965337955\n",
      "0.134807740167\n",
      "0.999999686808\n",
      "426\n",
      "0.280817402769\n",
      "Number of disagreement: 225\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8638    0.7770    0.8181      1233\n",
      "          1     0.3260    0.4683    0.3844       284\n",
      "\n",
      "avg / total     0.7631    0.7192    0.7369      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.0-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.000417307585148\n",
      "0.211415068077\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "0.00100902181129\n",
      "0.401198453565\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.0-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7047038327526133\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3591682419659736\n",
      "Original f1: 0.2694300518134715\n",
      "0.146179521309\n",
      "0.997283541158\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 187\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8490    0.7711    0.8081       926\n",
      "          1     0.3094    0.4279    0.3592       222\n",
      "\n",
      "avg / total     0.7447    0.7047    0.7213      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7106130520764667\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3825597749648383\n",
      "Original f1: 0.3050259965337955\n",
      "0.146307272901\n",
      "0.999999686954\n",
      "439\n",
      "0.289386947924\n",
      "Number of disagreement: 242\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8642    0.7640    0.8110      1233\n",
      "          1     0.3185    0.4789    0.3826       284\n",
      "\n",
      "avg / total     0.7621    0.7106    0.7308      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.0-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.00259074929435\n",
      "0.391715835934\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7396176664469347\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3270868824531516\n",
      "Original f1: 0.3050259965337955\n",
      "0.00673245859823\n",
      "0.744694326489\n",
      "395\n",
      "0.260382333553\n",
      "Number of disagreement: 10\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8451    0.8321    0.8386      1233\n",
      "          1     0.3168    0.3380    0.3271       284\n",
      "\n",
      "avg / total     0.7462    0.7396    0.7428      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.0-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6916376306620209\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.354014598540146\n",
      "Original f1: 0.2694300518134715\n",
      "0.162296844185\n",
      "0.997283541095\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 206\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8479    0.7527    0.7975       926\n",
      "          1     0.2975    0.4369    0.3540       222\n",
      "\n",
      "avg / total     0.7415    0.6916    0.7117      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7007251153592617\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.37978142076502736\n",
      "Original f1: 0.3050259965337955\n",
      "0.157083446179\n",
      "0.999999686884\n",
      "454\n",
      "0.299274884641\n",
      "Number of disagreement: 263\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8644    0.7494    0.8028      1233\n",
      "          1     0.3103    0.4894    0.3798       284\n",
      "\n",
      "avg / total     0.7606    0.7007    0.7236      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.0-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7604529616724739\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.314214463840399\n",
      "Original f1: 0.2694300518134715\n",
      "0.0127826694919\n",
      "0.993264875922\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 15\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8359    0.8747    0.8549       926\n",
      "          1     0.3520    0.2838    0.3142       222\n",
      "\n",
      "avg / total     0.7423    0.7605    0.7503      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7402768622280818\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.37060702875399365\n",
      "Original f1: 0.3050259965337955\n",
      "0.0288062580769\n",
      "0.9595846149\n",
      "394\n",
      "0.259723137772\n",
      "Number of disagreement: 49\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8570    0.8167    0.8364      1233\n",
      "          1     0.3392    0.4085    0.3706       284\n",
      "\n",
      "avg / total     0.7601    0.7403    0.7492      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.0-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6898954703832753\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36200716845878134\n",
      "Original f1: 0.2694300518134715\n",
      "0.17274506883\n",
      "0.997283541183\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 216\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8510    0.7462    0.7952       926\n",
      "          1     0.3006    0.4550    0.3620       222\n",
      "\n",
      "avg / total     0.7446    0.6899    0.7114      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6947923533289387\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38184245660881183\n",
      "Original f1: 0.3050259965337955\n",
      "0.166649511181\n",
      "0.999999687419\n",
      "463\n",
      "0.305207646671\n",
      "Number of disagreement: 280\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8660    0.7388    0.7974      1233\n",
      "          1     0.3075    0.5035    0.3818       284\n",
      "\n",
      "avg / total     0.7614    0.6948    0.7196      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.0-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.769163763066202\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3879907621247113\n",
      "Original f1: 0.2694300518134715\n",
      "0.035836048629\n",
      "0.993667659016\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 47\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8527    0.8629    0.8578       926\n",
      "          1     0.3981    0.3784    0.3880       222\n",
      "\n",
      "avg / total     0.7648    0.7692    0.7669      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7330257086354647\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.39999999999999997\n",
      "Original f1: 0.3050259965337955\n",
      "0.0557855796503\n",
      "0.996668608092\n",
      "405\n",
      "0.266974291365\n",
      "Number of disagreement: 98\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8677    0.7924    0.8283      1233\n",
      "          1     0.3453    0.4754    0.4000       284\n",
      "\n",
      "avg / total     0.7699    0.7330    0.7481      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.0-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.6951219512195121\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.38162544169611307\n",
      "Original f1: 0.2694300518134715\n",
      "0.177746997092\n",
      "0.997283541222\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 224\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8582    0.7451    0.7977       926\n",
      "          1     0.3140    0.4865    0.3816       222\n",
      "\n",
      "avg / total     0.7530    0.6951    0.7172      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6921555702043507\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.37981407702523245\n",
      "Original f1: 0.3050259965337955\n",
      "0.171100966113\n",
      "0.999999687394\n",
      "467\n",
      "0.307844429796\n",
      "Number of disagreement: 284\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8655    0.7356    0.7953      1233\n",
      "          1     0.3049    0.5035    0.3798       284\n",
      "\n",
      "avg / total     0.7605    0.6922    0.7175      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.0-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7482578397212544\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.391578947368421\n",
      "Original f1: 0.2694300518134715\n",
      "0.0637453928884\n",
      "0.993667658428\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 89\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8559    0.8272    0.8413       926\n",
      "          1     0.3676    0.4189    0.3916       222\n",
      "\n",
      "avg / total     0.7614    0.7483    0.7543      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7244561634805537\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.40625\n",
      "Original f1: 0.3050259965337955\n",
      "0.07025508024\n",
      "0.999999687293\n",
      "418\n",
      "0.275543836519\n",
      "Number of disagreement: 127\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8715    0.7753    0.8206      1233\n",
      "          1     0.3405    0.5035    0.4062       284\n",
      "\n",
      "avg / total     0.7721    0.7245    0.7430      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.0-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6925087108013938\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.38178633975481613\n",
      "Original f1: 0.2694300518134715\n",
      "0.183822935903\n",
      "0.99999989672\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 229\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8586    0.7408    0.7954       926\n",
      "          1     0.3123    0.4910    0.3818       222\n",
      "\n",
      "avg / total     0.7529    0.6925    0.7154      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6895187870797627\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3794466403162056\n",
      "Original f1: 0.3050259965337955\n",
      "0.175138971751\n",
      "0.999999687292\n",
      "471\n",
      "0.31048121292\n",
      "Number of disagreement: 290\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8656    0.7315    0.7930      1233\n",
      "          1     0.3032    0.5070    0.3794       284\n",
      "\n",
      "avg / total     0.7603    0.6895    0.7156      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.5-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "2.3319038795e-12\n",
      "1.68778143608e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "2.77102544854e-12\n",
      "1.31028715594e-09\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.5-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7752613240418118\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2833333333333333\n",
      "Original f1: 0.2694300518134715\n",
      "0.027782295242\n",
      "0.37141448685\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 26\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8307    0.9060    0.8667       926\n",
      "          1     0.3696    0.2297    0.2833       222\n",
      "\n",
      "avg / total     0.7415    0.7753    0.7539      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7679630850362558\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.31782945736434104\n",
      "Original f1: 0.3050259965337955\n",
      "0.0422484446616\n",
      "0.402009571544\n",
      "352\n",
      "0.232036914964\n",
      "Number of disagreement: 65\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8428    0.8783    0.8602      1233\n",
      "          1     0.3534    0.2887    0.3178       284\n",
      "\n",
      "avg / total     0.7512    0.7680    0.7587      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.5-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "5.88624642935e-06\n",
      "0.00675740566728\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "0.000306419956546\n",
      "0.248624103612\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.5-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7081881533101045\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.34951456310679613\n",
      "Original f1: 0.2694300518134715\n",
      "0.134100082191\n",
      "0.99728354101\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 175\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8456    0.7808    0.8119       926\n",
      "          1     0.3072    0.4054    0.3495       222\n",
      "\n",
      "avg / total     0.7415    0.7082    0.7225      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7125906394199077\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38418079096045193\n",
      "Original f1: 0.3050259965337955\n",
      "0.137655878754\n",
      "0.993179320427\n",
      "436\n",
      "0.28740936058\n",
      "Number of disagreement: 227\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8646    0.7664    0.8126      1233\n",
      "          1     0.3208    0.4789    0.3842       284\n",
      "\n",
      "avg / total     0.7628    0.7126    0.7324      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.5-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.000458337520572\n",
      "0.158167101876\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7363216875411998\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3079584775086506\n",
      "Original f1: 0.3050259965337955\n",
      "0.00119681788718\n",
      "0.392523016216\n",
      "400\n",
      "0.263678312459\n",
      "Number of disagreement: 1\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8406    0.8337    0.8371      1233\n",
      "          1     0.3027    0.3134    0.3080       284\n",
      "\n",
      "avg / total     0.7399    0.7363    0.7381      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.5-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7003484320557491\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3582089552238806\n",
      "Original f1: 0.2694300518134715\n",
      "0.152076711836\n",
      "0.997283541181\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 196\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8489    0.7646    0.8045       926\n",
      "          1     0.3057    0.4324    0.3582       222\n",
      "\n",
      "avg / total     0.7439    0.7003    0.7182      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7092946605141727\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38493723849372385\n",
      "Original f1: 0.3050259965337955\n",
      "0.147946171368\n",
      "0.999999685696\n",
      "441\n",
      "0.290705339486\n",
      "Number of disagreement: 240\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8653    0.7607    0.8097      1233\n",
      "          1     0.3187    0.4859    0.3849       284\n",
      "\n",
      "avg / total     0.7630    0.7093    0.7302      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.5-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7552264808362369\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2739018087855297\n",
      "Original f1: 0.2694300518134715\n",
      "0.00237754991063\n",
      "0.347430363151\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 1\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8281    0.8790    0.8528       926\n",
      "          1     0.3212    0.2387    0.2739       222\n",
      "\n",
      "avg / total     0.7301    0.7552    0.7409      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7382992748846408\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.32136752136752134\n",
      "Original f1: 0.3050259965337955\n",
      "0.00718177291935\n",
      "0.715319896723\n",
      "397\n",
      "0.261700725115\n",
      "Number of disagreement: 8\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8438    0.8321    0.8379      1233\n",
      "          1     0.3123    0.3310    0.3214       284\n",
      "\n",
      "avg / total     0.7443    0.7383    0.7412      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.5-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6907665505226481\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3603603603603604\n",
      "Original f1: 0.2694300518134715\n",
      "0.165892713138\n",
      "0.997283541218\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 215\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8503    0.7484    0.7961       926\n",
      "          1     0.3003    0.4505    0.3604       222\n",
      "\n",
      "avg / total     0.7439    0.6908    0.7118      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7000659195781147\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38263229308005425\n",
      "Original f1: 0.3050259965337955\n",
      "0.158371860792\n",
      "0.999999687346\n",
      "455\n",
      "0.299934080422\n",
      "Number of disagreement: 260\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8656    0.7470    0.8019      1233\n",
      "          1     0.3113    0.4965    0.3826       284\n",
      "\n",
      "avg / total     0.7618    0.7001    0.7234      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.5-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7621951219512195\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3192019950124688\n",
      "Original f1: 0.2694300518134715\n",
      "0.0135980029623\n",
      "0.993264873532\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 15\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8369    0.8758    0.8559       926\n",
      "          1     0.3575    0.2883    0.3192       222\n",
      "\n",
      "avg / total     0.7442    0.7622    0.7521      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7415952537903757\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3697749196141479\n",
      "Original f1: 0.3050259965337955\n",
      "0.0273206086545\n",
      "0.941206198496\n",
      "392\n",
      "0.25840474621\n",
      "Number of disagreement: 45\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8567    0.8191    0.8375      1233\n",
      "          1     0.3402    0.4049    0.3698       284\n",
      "\n",
      "avg / total     0.7600    0.7416    0.7499      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.5-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6907665505226481\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3716814159292036\n",
      "Original f1: 0.2694300518134715\n",
      "0.176014723487\n",
      "0.997283541078\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 223\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8547    0.7430    0.7949       926\n",
      "          1     0.3061    0.4730    0.3717       222\n",
      "\n",
      "avg / total     0.7486    0.6908    0.7131      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6921555702043507\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3781624500665779\n",
      "Original f1: 0.3050259965337955\n",
      "0.167350641952\n",
      "0.999999687414\n",
      "467\n",
      "0.307844429796\n",
      "Number of disagreement: 272\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8648    0.7364    0.7954      1233\n",
      "          1     0.3041    0.5000    0.3782       284\n",
      "\n",
      "avg / total     0.7598    0.6922    0.7173      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.5-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7674216027874564\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3862068965517241\n",
      "Original f1: 0.2694300518134715\n",
      "0.0367205628826\n",
      "0.993667649851\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 49\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8524    0.8607    0.8565       926\n",
      "          1     0.3944    0.3784    0.3862       222\n",
      "\n",
      "avg / total     0.7638    0.7674    0.7656      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7303889255108768\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4011713030746705\n",
      "Original f1: 0.3050259965337955\n",
      "0.0586241390283\n",
      "0.992866688512\n",
      "409\n",
      "0.269611074489\n",
      "Number of disagreement: 106\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8685    0.7875    0.8260      1233\n",
      "          1     0.3434    0.4824    0.4012       284\n",
      "\n",
      "avg / total     0.7702    0.7304    0.7465      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.5-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6933797909407665\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3846153846153846\n",
      "Original f1: 0.2694300518134715\n",
      "0.181309964419\n",
      "0.999999886901\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 230\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8596    0.7408    0.7958       926\n",
      "          1     0.3143    0.4955    0.3846       222\n",
      "\n",
      "avg / total     0.7542    0.6934    0.7163      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6855636123928807\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.37483617300131067\n",
      "Original f1: 0.3050259965337955\n",
      "0.172652392326\n",
      "0.999999687378\n",
      "477\n",
      "0.314436387607\n",
      "Number of disagreement: 284\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8642    0.7275    0.7900      1233\n",
      "          1     0.2985    0.5035    0.3748       284\n",
      "\n",
      "avg / total     0.7583    0.6856    0.7122      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.5-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7465156794425087\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.389937106918239\n",
      "Original f1: 0.2694300518134715\n",
      "0.0641855891765\n",
      "0.993667659187\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 91\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8555    0.8251    0.8400       926\n",
      "          1     0.3647    0.4189    0.3899       222\n",
      "\n",
      "avg / total     0.7606    0.7465    0.7530      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7198417930125247\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.40225035161744016\n",
      "Original f1: 0.3050259965337955\n",
      "0.0741412815374\n",
      "0.999999681842\n",
      "425\n",
      "0.280158206987\n",
      "Number of disagreement: 134\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8706    0.7697    0.8170      1233\n",
      "          1     0.3349    0.5035    0.4023       284\n",
      "\n",
      "avg / total     0.7703    0.7198    0.7394      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.5-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6916376306620209\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3875432525951557\n",
      "Original f1: 0.2694300518134715\n",
      "0.186014129218\n",
      "0.999999896776\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 236\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8611    0.7365    0.7939       926\n",
      "          1     0.3146    0.5045    0.3875       222\n",
      "\n",
      "avg / total     0.7554    0.6916    0.7154      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6855636123928807\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.37647058823529417\n",
      "Original f1: 0.3050259965337955\n",
      "0.17591714194\n",
      "0.999999687287\n",
      "477\n",
      "0.314436387607\n",
      "Number of disagreement: 286\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8649    0.7267    0.7898      1233\n",
      "          1     0.2994    0.5070    0.3765       284\n",
      "\n",
      "avg / total     0.7590    0.6856    0.7124      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.5-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "2.09333927838e-12\n",
      "1.64320987373e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "3.68980697451e-12\n",
      "1.94525506609e-09\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.5-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.769163763066202\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2779291553133515\n",
      "Original f1: 0.2694300518134715\n",
      "0.0275904627486\n",
      "0.376019652145\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 21\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8295    0.8985    0.8626       926\n",
      "          1     0.3517    0.2297    0.2779       222\n",
      "\n",
      "avg / total     0.7371    0.7692    0.7496      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7626895187870798\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.31034482758620685\n",
      "Original f1: 0.3050259965337955\n",
      "0.0422076167982\n",
      "0.400572366274\n",
      "360\n",
      "0.237310481213\n",
      "Number of disagreement: 61\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8413    0.8727    0.8567      1233\n",
      "          1     0.3403    0.2852    0.3103       284\n",
      "\n",
      "avg / total     0.7475    0.7627    0.7544      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.5-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "5.10242554464e-05\n",
      "0.0585758380249\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "0.000292546473427\n",
      "0.246667881639\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.5-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7012195121951219\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3441682600382409\n",
      "Original f1: 0.2694300518134715\n",
      "0.136213560763\n",
      "0.997283541208\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 181\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8442    0.7721    0.8065       926\n",
      "          1     0.2990    0.4054    0.3442       222\n",
      "\n",
      "avg / total     0.7387    0.7012    0.7171      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7059986816084377\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3770949720670391\n",
      "Original f1: 0.3050259965337955\n",
      "0.140846567742\n",
      "0.999999686746\n",
      "446\n",
      "0.294001318392\n",
      "Number of disagreement: 223\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8627    0.7591    0.8076      1233\n",
      "          1     0.3125    0.4754    0.3771       284\n",
      "\n",
      "avg / total     0.7597    0.7060    0.7270      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.5-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.000430255371303\n",
      "0.202826190997\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "0.00073283406538\n",
      "0.403361485207\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.5-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6881533101045296\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3443223443223443\n",
      "Original f1: 0.2694300518134715\n",
      "0.154140400323\n",
      "0.99728354117\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 204\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8447    0.7516    0.7954       926\n",
      "          1     0.2901    0.4234    0.3443       222\n",
      "\n",
      "avg / total     0.7374    0.6882    0.7082      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6994067237969677\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.37534246575342467\n",
      "Original f1: 0.3050259965337955\n",
      "0.151791609082\n",
      "0.999999687244\n",
      "456\n",
      "0.300593276203\n",
      "Number of disagreement: 237\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8627    0.7494    0.8021      1233\n",
      "          1     0.3072    0.4824    0.3753       284\n",
      "\n",
      "avg / total     0.7587    0.6994    0.7222      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.5-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7552264808362369\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2739018087855297\n",
      "Original f1: 0.2694300518134715\n",
      "0.00269875334917\n",
      "0.383128921085\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 1\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8281    0.8790    0.8528       926\n",
      "          1     0.3212    0.2387    0.2739       222\n",
      "\n",
      "avg / total     0.7301    0.7552    0.7409      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7382992748846408\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.32136752136752134\n",
      "Original f1: 0.3050259965337955\n",
      "0.0065142791383\n",
      "0.715319896723\n",
      "397\n",
      "0.261700725115\n",
      "Number of disagreement: 8\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8438    0.8321    0.8379      1233\n",
      "          1     0.3123    0.3310    0.3214       284\n",
      "\n",
      "avg / total     0.7443    0.7383    0.7412      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.5-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6785714285714286\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3469026548672566\n",
      "Original f1: 0.2694300518134715\n",
      "0.169478510699\n",
      "0.997283541197\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 221\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8460    0.7354    0.7868       926\n",
      "          1     0.2857    0.4414    0.3469       222\n",
      "\n",
      "avg / total     0.7376    0.6786    0.7018      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6888595912986157\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3740053050397878\n",
      "Original f1: 0.3050259965337955\n",
      "0.161833580261\n",
      "0.999999687403\n",
      "472\n",
      "0.311140408701\n",
      "Number of disagreement: 261\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8634    0.7332    0.7930      1233\n",
      "          1     0.3000    0.4965    0.3740       284\n",
      "\n",
      "avg / total     0.7579    0.6889    0.7145      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.5-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.759581881533101\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3065326633165829\n",
      "Original f1: 0.2694300518134715\n",
      "0.0126098758251\n",
      "0.989572916507\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 12\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8344    0.8758    0.8546       926\n",
      "          1     0.3466    0.2748    0.3065       222\n",
      "\n",
      "avg / total     0.7400    0.7596    0.7486      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7409360580092288\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.36304700162074555\n",
      "Original f1: 0.3050259965337955\n",
      "0.0242600112678\n",
      "0.941206198575\n",
      "393\n",
      "0.259063941991\n",
      "Number of disagreement: 40\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8547    0.8208    0.8374      1233\n",
      "          1     0.3363    0.3944    0.3630       284\n",
      "\n",
      "avg / total     0.7577    0.7409    0.7486      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.5-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.681184668989547\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3601398601398601\n",
      "Original f1: 0.2694300518134715\n",
      "0.178878943077\n",
      "0.997283541181\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 228\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8509    0.7333    0.7877       926\n",
      "          1     0.2943    0.4640    0.3601       222\n",
      "\n",
      "avg / total     0.7432    0.6812    0.7050      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6802900461437047\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3693107932379714\n",
      "Original f1: 0.3050259965337955\n",
      "0.170096672321\n",
      "0.99999968742\n",
      "485\n",
      "0.319709953856\n",
      "Number of disagreement: 276\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8624    0.7218    0.7859      1233\n",
      "          1     0.2928    0.5000    0.3693       284\n",
      "\n",
      "avg / total     0.7558    0.6803    0.7079      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.5-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7709059233449478\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3897911832946636\n",
      "Original f1: 0.2694300518134715\n",
      "0.0357299993261\n",
      "0.993667658471\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 45\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8530    0.8650    0.8590       926\n",
      "          1     0.4019    0.3784    0.3898       222\n",
      "\n",
      "avg / total     0.7658    0.7709    0.7682      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7270929466051417\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3911764705882353\n",
      "Original f1: 0.3050259965337955\n",
      "0.0577171137383\n",
      "0.999999685836\n",
      "414\n",
      "0.272907053395\n",
      "Number of disagreement: 103\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8653    0.7867    0.8241      1233\n",
      "          1     0.3359    0.4683    0.3912       284\n",
      "\n",
      "avg / total     0.7662    0.7271    0.7431      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.5-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6820557491289199\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3717728055077453\n",
      "Original f1: 0.2694300518134715\n",
      "0.183611032397\n",
      "0.999999896042\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 235\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8555    0.7289    0.7872       926\n",
      "          1     0.3008    0.4865    0.3718       222\n",
      "\n",
      "avg / total     0.7482    0.6821    0.7068      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6769940672379697\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.36855670103092786\n",
      "Original f1: 0.3050259965337955\n",
      "0.175390876233\n",
      "0.999999687392\n",
      "490\n",
      "0.323005932762\n",
      "Number of disagreement: 283\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8624    0.7170    0.7830      1233\n",
      "          1     0.2907    0.5035    0.3686       284\n",
      "\n",
      "avg / total     0.7554    0.6770    0.7054      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.5-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7473867595818815\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.39075630252100846\n",
      "Original f1: 0.2694300518134715\n",
      "0.065452418147\n",
      "0.993667659218\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 90\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8557    0.8261    0.8407       926\n",
      "          1     0.3661    0.4189    0.3908       222\n",
      "\n",
      "avg / total     0.7610    0.7474    0.7537      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7224785761371127\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.40452616690240445\n",
      "Original f1: 0.3050259965337955\n",
      "0.0730466586611\n",
      "0.999999686819\n",
      "421\n",
      "0.277521423863\n",
      "Number of disagreement: 130\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8711    0.7729    0.8191      1233\n",
      "          1     0.3381    0.5035    0.4045       284\n",
      "\n",
      "avg / total     0.7713    0.7225    0.7415      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-1.5-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6794425087108014\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3741496598639456\n",
      "Original f1: 0.2694300518134715\n",
      "0.188656086623\n",
      "0.99999989648\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 242\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8568    0.7235    0.7845       926\n",
      "          1     0.3005    0.4955    0.3741       222\n",
      "\n",
      "avg / total     0.7492    0.6794    0.7052      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.6763348714568227\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3697047496790757\n",
      "Original f1: 0.3050259965337955\n",
      "0.178410205521\n",
      "0.999999687372\n",
      "491\n",
      "0.323665128543\n",
      "Number of disagreement: 286\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8630    0.7153    0.7823      1233\n",
      "          1     0.2909    0.5070    0.3697       284\n",
      "\n",
      "avg / total     0.7559    0.6763    0.7050      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-2.0-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "2.72101532088e-12\n",
      "2.44897695585e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "2.79707049677e-12\n",
      "1.31994856643e-09\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-2.0-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7735191637630662\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2817679558011049\n",
      "Original f1: 0.2694300518134715\n",
      "0.0277605268723\n",
      "0.381032606813\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 24\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8304    0.9039    0.8656       926\n",
      "          1     0.3643    0.2297    0.2818       222\n",
      "\n",
      "avg / total     0.7402    0.7735    0.7527      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7646671061305208\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3147792706333973\n",
      "Original f1: 0.3050259965337955\n",
      "0.0422499328079\n",
      "0.393534154687\n",
      "357\n",
      "0.235332893869\n",
      "Number of disagreement: 62\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8422    0.8743    0.8579      1233\n",
      "          1     0.3460    0.2887    0.3148       284\n",
      "\n",
      "avg / total     0.7493    0.7647    0.7563      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-2.0-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "7.87672262971e-06\n",
      "0.00904247153842\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "0.00028665395824\n",
      "0.234984229466\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-2.0-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7012195121951219\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.34914611005692603\n",
      "Original f1: 0.2694300518134715\n",
      "0.136783851111\n",
      "0.99728354116\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 183\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8458    0.7700    0.8061       926\n",
      "          1     0.3016    0.4144    0.3491       222\n",
      "\n",
      "avg / total     0.7406    0.7012    0.7177      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7079762689518787\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3804195804195804\n",
      "Original f1: 0.3050259965337955\n",
      "0.1396020041\n",
      "0.993179320755\n",
      "443\n",
      "0.292023731048\n",
      "Number of disagreement: 220\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8637    0.7607    0.8090      1233\n",
      "          1     0.3155    0.4789    0.3804       284\n",
      "\n",
      "avg / total     0.7611    0.7080    0.7287      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-2.0-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.000468384458335\n",
      "0.160458815085\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7363216875411998\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3079584775086506\n",
      "Original f1: 0.3050259965337955\n",
      "0.00107916375391\n",
      "0.378883254229\n",
      "400\n",
      "0.263678312459\n",
      "Number of disagreement: 1\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8406    0.8337    0.8371      1233\n",
      "          1     0.3027    0.3134    0.3080       284\n",
      "\n",
      "avg / total     0.7399    0.7363    0.7381      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-2.0-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6925087108013938\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.35229357798165134\n",
      "Original f1: 0.2694300518134715\n",
      "0.155249670523\n",
      "0.997283541217\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 201\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8473    0.7549    0.7984       926\n",
      "          1     0.2972    0.4324    0.3523       222\n",
      "\n",
      "avg / total     0.7409    0.6925    0.7121      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7027027027027027\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3796423658872076\n",
      "Original f1: 0.3050259965337955\n",
      "0.149576685959\n",
      "0.99999968616\n",
      "451\n",
      "0.297297297297\n",
      "Number of disagreement: 236\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8641    0.7526    0.8045      1233\n",
      "          1     0.3115    0.4859    0.3796       284\n",
      "\n",
      "avg / total     0.7606    0.7027    0.7250      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-2.0-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7552264808362369\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2739018087855297\n",
      "Original f1: 0.2694300518134715\n",
      "0.00235801826917\n",
      "0.34971831505\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 1\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8281    0.8790    0.8528       926\n",
      "          1     0.3212    0.2387    0.2739       222\n",
      "\n",
      "avg / total     0.7301    0.7552    0.7409      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7376400791034937\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.32081911262798635\n",
      "Original f1: 0.3050259965337955\n",
      "0.00722442285196\n",
      "0.699927943107\n",
      "398\n",
      "0.262359920897\n",
      "Number of disagreement: 9\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8436    0.8313    0.8374      1233\n",
      "          1     0.3113    0.3310    0.3208       284\n",
      "\n",
      "avg / total     0.7440    0.7376    0.7407      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-2.0-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6820557491289199\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.35168738898756663\n",
      "Original f1: 0.2694300518134715\n",
      "0.168437837639\n",
      "0.997283541111\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 217\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8476    0.7387    0.7894       926\n",
      "          1     0.2903    0.4459    0.3517       222\n",
      "\n",
      "avg / total     0.7398    0.6821    0.7047      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6914963744232037\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.37600000000000006\n",
      "Original f1: 0.3050259965337955\n",
      "0.159865124275\n",
      "0.999999687293\n",
      "468\n",
      "0.308503625577\n",
      "Number of disagreement: 259\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8639    0.7364    0.7951      1233\n",
      "          1     0.3026    0.4965    0.3760       284\n",
      "\n",
      "avg / total     0.7588    0.6915    0.7166      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-2.0-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7621951219512195\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3192019950124688\n",
      "Original f1: 0.2694300518134715\n",
      "0.0134703743787\n",
      "0.993264875559\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 15\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8369    0.8758    0.8559       926\n",
      "          1     0.3575    0.2883    0.3192       222\n",
      "\n",
      "avg / total     0.7442    0.7622    0.7521      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7402768622280818\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3685897435897436\n",
      "Original f1: 0.3050259965337955\n",
      "0.0274035019062\n",
      "0.94120619861\n",
      "394\n",
      "0.259723137772\n",
      "Number of disagreement: 47\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8564    0.8175    0.8365      1233\n",
      "          1     0.3382    0.4049    0.3686       284\n",
      "\n",
      "avg / total     0.7594    0.7403    0.7489      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-2.0-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6829268292682927\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36585365853658536\n",
      "Original f1: 0.2694300518134715\n",
      "0.178264465845\n",
      "0.997283541148\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 228\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8530    0.7333    0.7886       926\n",
      "          1     0.2983    0.4730    0.3659       222\n",
      "\n",
      "avg / total     0.7457    0.6829    0.7069      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.6835860250494397\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3717277486910995\n",
      "Original f1: 0.3050259965337955\n",
      "0.1690059638\n",
      "0.999999687179\n",
      "480\n",
      "0.316413974951\n",
      "Number of disagreement: 273\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8631    0.7259    0.7885      1233\n",
      "          1     0.2958    0.5000    0.3717       284\n",
      "\n",
      "avg / total     0.7569    0.6836    0.7105      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-2.0-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.769163763066202\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3879907621247113\n",
      "Original f1: 0.2694300518134715\n",
      "0.036026712802\n",
      "0.99326487658\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 47\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8527    0.8629    0.8578       926\n",
      "          1     0.3981    0.3784    0.3880       222\n",
      "\n",
      "avg / total     0.7648    0.7692    0.7669      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7290705339485827\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4\n",
      "Original f1: 0.3050259965337955\n",
      "0.0593775307053\n",
      "0.992866689055\n",
      "411\n",
      "0.270929466051\n",
      "Number of disagreement: 108\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8683    0.7859    0.8250      1233\n",
      "          1     0.3416    0.4824    0.4000       284\n",
      "\n",
      "avg / total     0.7697    0.7291    0.7455      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-2.0-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6855400696864111\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.37865748709122204\n",
      "Original f1: 0.2694300518134715\n",
      "0.183700618492\n",
      "0.999999894329\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 235\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8580    0.7311    0.7895       926\n",
      "          1     0.3064    0.4955    0.3787       222\n",
      "\n",
      "avg / total     0.7514    0.6855    0.7101      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6789716545814107\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.369987063389392\n",
      "Original f1: 0.3050259965337955\n",
      "0.174046450953\n",
      "0.999999687415\n",
      "487\n",
      "0.321028345419\n",
      "Number of disagreement: 282\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8628    0.7194    0.7846      1233\n",
      "          1     0.2924    0.5035    0.3700       284\n",
      "\n",
      "avg / total     0.7561    0.6790    0.7070      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-2.0-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7456445993031359\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3891213389121339\n",
      "Original f1: 0.2694300518134715\n",
      "0.0645880331353\n",
      "0.993667659055\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 92\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8554    0.8240    0.8394       926\n",
      "          1     0.3633    0.4189    0.3891       222\n",
      "\n",
      "avg / total     0.7602    0.7456    0.7523      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7198417930125247\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.40225035161744016\n",
      "Original f1: 0.3050259965337955\n",
      "0.0750319823773\n",
      "0.999570793939\n",
      "425\n",
      "0.280158206987\n",
      "Number of disagreement: 134\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8706    0.7697    0.8170      1233\n",
      "          1     0.3349    0.5035    0.4023       284\n",
      "\n",
      "avg / total     0.7703    0.7198    0.7394      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-2.0-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.681184668989547\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.37755102040816324\n",
      "Original f1: 0.2694300518134715\n",
      "0.188080949487\n",
      "0.999999895789\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 242\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8581    0.7246    0.7857       926\n",
      "          1     0.3033    0.5000    0.3776       222\n",
      "\n",
      "avg / total     0.7508    0.6812    0.7068      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6783124588002637\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.37113402061855666\n",
      "Original f1: 0.3050259965337955\n",
      "0.176966402389\n",
      "0.999999687306\n",
      "488\n",
      "0.3216875412\n",
      "Number of disagreement: 285\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8634    0.7178    0.7839      1233\n",
      "          1     0.2927    0.5070    0.3711       284\n",
      "\n",
      "avg / total     0.7566    0.6783    0.7066      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-2.0-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "2.28696892042e-12\n",
      "2.92652391916e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "3.70949320916e-12\n",
      "2.03925414428e-09\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-2.0-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7700348432055749\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.27868852459016397\n",
      "Original f1: 0.2694300518134715\n",
      "0.0279133823255\n",
      "0.378116688761\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 22\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8297    0.8996    0.8632       926\n",
      "          1     0.3542    0.2297    0.2787       222\n",
      "\n",
      "avg / total     0.7377    0.7700    0.7502      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7640079103493738\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.31417624521072796\n",
      "Original f1: 0.3050259965337955\n",
      "0.0426869305614\n",
      "0.39147091748\n",
      "358\n",
      "0.235992089651\n",
      "Number of disagreement: 59\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8421    0.8735    0.8575      1233\n",
      "          1     0.3445    0.2887    0.3142       284\n",
      "\n",
      "avg / total     0.7489    0.7640    0.7558      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-2.0-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "4.62566053947e-05\n",
      "0.0531025781334\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "0.000279452765801\n",
      "0.245327852327\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-2.0-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6925087108013938\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3352165725047081\n",
      "Original f1: 0.2694300518134715\n",
      "0.139505307491\n",
      "0.997283541022\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 191\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8415    0.7624    0.8000       926\n",
      "          1     0.2880    0.4009    0.3352       222\n",
      "\n",
      "avg / total     0.7345    0.6925    0.7101      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7013843111404087\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.37517241379310345\n",
      "Original f1: 0.3050259965337955\n",
      "0.143560486784\n",
      "0.999999687352\n",
      "453\n",
      "0.29861568886\n",
      "Number of disagreement: 226\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8625    0.7526    0.8038      1233\n",
      "          1     0.3084    0.4789    0.3752       284\n",
      "\n",
      "avg / total     0.7587    0.7014    0.7236      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-2.0-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.000438331158945\n",
      "0.197352654171\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "0.000643176576155\n",
      "0.400946750308\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-2.0-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6846689895470384\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.34657039711191334\n",
      "Original f1: 0.2694300518134715\n",
      "0.157852090836\n",
      "0.997283541134\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 214\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8456    0.7451    0.7922       926\n",
      "          1     0.2892    0.4324    0.3466       222\n",
      "\n",
      "avg / total     0.7380    0.6847    0.7060      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6974291364535267\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.37551020408163266\n",
      "Original f1: 0.3050259965337955\n",
      "0.154376588421\n",
      "0.999999687238\n",
      "459\n",
      "0.302570863546\n",
      "Number of disagreement: 238\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8630    0.7461    0.8003      1233\n",
      "          1     0.3060    0.4859    0.3755       284\n",
      "\n",
      "avg / total     0.7588    0.6974    0.7208      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-2.0-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7552264808362369\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2739018087855297\n",
      "Original f1: 0.2694300518134715\n",
      "0.00274010895145\n",
      "0.37765431458\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 1\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8281    0.8790    0.8528       926\n",
      "          1     0.3212    0.2387    0.2739       222\n",
      "\n",
      "avg / total     0.7301    0.7552    0.7409      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7376400791034937\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.32081911262798635\n",
      "Original f1: 0.3050259965337955\n",
      "0.00651244364884\n",
      "0.686616594759\n",
      "398\n",
      "0.262359920897\n",
      "Number of disagreement: 9\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8436    0.8313    0.8374      1233\n",
      "          1     0.3113    0.3310    0.3208       284\n",
      "\n",
      "avg / total     0.7440    0.7376    0.7407      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-2.0-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.671602787456446\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3443478260869565\n",
      "Original f1: 0.2694300518134715\n",
      "0.172704731106\n",
      "0.997283541197\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 231\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8453    0.7257    0.7809       926\n",
      "          1     0.2805    0.4459    0.3443       222\n",
      "\n",
      "avg / total     0.7361    0.6716    0.6965      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6888595912986157\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.37566137566137564\n",
      "Original f1: 0.3050259965337955\n",
      "0.163850296908\n",
      "0.999999687399\n",
      "472\n",
      "0.311140408701\n",
      "Number of disagreement: 259\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8641    0.7324    0.7928      1233\n",
      "          1     0.3008    0.5000    0.3757       284\n",
      "\n",
      "avg / total     0.7587    0.6889    0.7147      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-2.0-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.759581881533101\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3065326633165829\n",
      "Original f1: 0.2694300518134715\n",
      "0.0122706298384\n",
      "0.903604032351\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 12\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8344    0.8758    0.8546       926\n",
      "          1     0.3466    0.2748    0.3065       222\n",
      "\n",
      "avg / total     0.7400    0.7596    0.7486      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7409360580092288\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.36304700162074555\n",
      "Original f1: 0.3050259965337955\n",
      "0.0234639168739\n",
      "0.941206198369\n",
      "393\n",
      "0.259063941991\n",
      "Number of disagreement: 40\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8547    0.8208    0.8374      1233\n",
      "          1     0.3363    0.3944    0.3630       284\n",
      "\n",
      "avg / total     0.7577    0.7409    0.7486      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-2.0-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6742160278745645\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.35958904109589046\n",
      "Original f1: 0.2694300518134715\n",
      "0.181569302205\n",
      "0.99999989602\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 240\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8511    0.7225    0.7815       926\n",
      "          1     0.2901    0.4730    0.3596       222\n",
      "\n",
      "avg / total     0.7426    0.6742    0.6999      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6809492419248517\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.37142857142857144\n",
      "Original f1: 0.3050259965337955\n",
      "0.172133495752\n",
      "0.99999968738\n",
      "484\n",
      "0.319050758075\n",
      "Number of disagreement: 273\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8632    0.7218    0.7862      1233\n",
      "          1     0.2942    0.5035    0.3714       284\n",
      "\n",
      "avg / total     0.7567    0.6809    0.7086      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-2.0-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7709059233449478\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3897911832946636\n",
      "Original f1: 0.2694300518134715\n",
      "0.035652093475\n",
      "0.993667656037\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 45\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8530    0.8650    0.8590       926\n",
      "          1     0.4019    0.3784    0.3898       222\n",
      "\n",
      "avg / total     0.7658    0.7709    0.7682      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7270929466051417\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3911764705882353\n",
      "Original f1: 0.3050259965337955\n",
      "0.058372593319\n",
      "0.999999679826\n",
      "414\n",
      "0.272907053395\n",
      "Number of disagreement: 103\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8653    0.7867    0.8241      1233\n",
      "          1     0.3359    0.4683    0.3912       284\n",
      "\n",
      "avg / total     0.7662    0.7271    0.7431      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-2.0-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.6724738675958188\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.367003367003367\n",
      "Original f1: 0.2694300518134715\n",
      "0.186424816785\n",
      "0.999999895112\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 248\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8544    0.7160    0.7791       926\n",
      "          1     0.2930    0.4910    0.3670       222\n",
      "\n",
      "avg / total     0.7458    0.6725    0.6994      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6763348714568227\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3697047496790757\n",
      "Original f1: 0.3050259965337955\n",
      "0.17714468606\n",
      "0.999999687384\n",
      "491\n",
      "0.323665128543\n",
      "Number of disagreement: 282\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8630    0.7153    0.7823      1233\n",
      "          1     0.2909    0.5070    0.3697       284\n",
      "\n",
      "avg / total     0.7559    0.6763    0.7050      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-2.0-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7465156794425087\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.389937106918239\n",
      "Original f1: 0.2694300518134715\n",
      "0.0658799522555\n",
      "0.993667658734\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 91\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8555    0.8251    0.8400       926\n",
      "          1     0.3647    0.4189    0.3899       222\n",
      "\n",
      "avg / total     0.7606    0.7465    0.7530      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7211601845748187\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4033850493653032\n",
      "Original f1: 0.3050259965337955\n",
      "0.0737608719234\n",
      "0.9999996873\n",
      "423\n",
      "0.278839815425\n",
      "Number of disagreement: 132\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8709    0.7713    0.8181      1233\n",
      "          1     0.3365    0.5035    0.4034       284\n",
      "\n",
      "avg / total     0.7708    0.7212    0.7404      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  0.5-2.0-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6698606271777003\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3672787979966611\n",
      "Original f1: 0.2694300518134715\n",
      "0.191168102594\n",
      "0.999999896787\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 253\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8547    0.7117    0.7767       926\n",
      "          1     0.2918    0.4955    0.3673       222\n",
      "\n",
      "avg / total     0.7459    0.6699    0.6975      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6750164798945286\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3703703703703704\n",
      "Original f1: 0.3050259965337955\n",
      "0.179960145351\n",
      "0.99999968736\n",
      "493\n",
      "0.324983520105\n",
      "Number of disagreement: 286\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8635    0.7129    0.7810      1233\n",
      "          1     0.2906    0.5106    0.3704       284\n",
      "\n",
      "avg / total     0.7562    0.6750    0.7041      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.5-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.00947611083556\n",
      "0.396007176941\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7350032959789057\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3044982698961938\n",
      "Original f1: 0.3050259965337955\n",
      "0.0121479637078\n",
      "0.457968358118\n",
      "402\n",
      "0.264996704021\n",
      "Number of disagreement: 1\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8397    0.8329    0.8363      1233\n",
      "          1     0.2993    0.3099    0.3045       284\n",
      "\n",
      "avg / total     0.7386    0.7350    0.7368      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.5-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7909407665505227\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2105263157894737\n",
      "Original f1: 0.2694300518134715\n",
      "0.0813854701295\n",
      "0.629622352966\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 100\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8218    0.9460    0.8795       926\n",
      "          1     0.3902    0.1441    0.2105       222\n",
      "\n",
      "avg / total     0.7383    0.7909    0.7501      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7956493078444298\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.2790697674418604\n",
      "Original f1: 0.3050259965337955\n",
      "0.0974309254987\n",
      "0.757089152558\n",
      "310\n",
      "0.204350692156\n",
      "Number of disagreement: 185\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8366    0.9303    0.8810      1233\n",
      "          1     0.4110    0.2113    0.2791       284\n",
      "\n",
      "avg / total     0.7569    0.7956    0.7683      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.5-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7534843205574913\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2687338501291989\n",
      "Original f1: 0.2694300518134715\n",
      "0.00990121768657\n",
      "0.399957733511\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 1\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8271    0.8780    0.8518       926\n",
      "          1     0.3152    0.2342    0.2687       222\n",
      "\n",
      "avg / total     0.7281    0.7535    0.7390      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7369808833223468\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3156089193825043\n",
      "Original f1: 0.3050259965337955\n",
      "0.0143889419852\n",
      "0.457968358118\n",
      "399\n",
      "0.263019116678\n",
      "Number of disagreement: 6\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8424    0.8321    0.8372      1233\n",
      "          1     0.3077    0.3239    0.3156       284\n",
      "\n",
      "avg / total     0.7423    0.7370    0.7396      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.5-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7709059233449478\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3441396508728179\n",
      "Original f1: 0.2694300518134715\n",
      "0.141380458968\n",
      "0.993264875662\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 179\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8421    0.8812    0.8612       926\n",
      "          1     0.3855    0.3108    0.3441       222\n",
      "\n",
      "avg / total     0.7538    0.7709    0.7612      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7686222808174028\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3765541740674956\n",
      "Original f1: 0.3050259965337955\n",
      "0.143661607956\n",
      "0.993179281688\n",
      "351\n",
      "0.231377719183\n",
      "Number of disagreement: 262\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8562    0.8597    0.8580      1233\n",
      "          1     0.3799    0.3732    0.3766       284\n",
      "\n",
      "avg / total     0.7671    0.7686    0.7678      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.5-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.27692307692307694\n",
      "Original f1: 0.2694300518134715\n",
      "0.0108782913401\n",
      "0.460262973405\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 4\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8286    0.8769    0.8520       926\n",
      "          1     0.3214    0.2432    0.2769       222\n",
      "\n",
      "avg / total     0.7305    0.7544    0.7408      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.31918505942275044\n",
      "Original f1: 0.3050259965337955\n",
      "0.0166012506098\n",
      "0.575498305164\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 12\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8432    0.8289    0.8360      1233\n",
      "          1     0.3082    0.3310    0.3192       284\n",
      "\n",
      "avg / total     0.7431    0.7357    0.7392      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.5-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7621951219512195\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.35460992907801414\n",
      "Original f1: 0.2694300518134715\n",
      "0.155275775485\n",
      "0.993264876391\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 201\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8448    0.8639    0.8542       926\n",
      "          1     0.3731    0.3378    0.3546       222\n",
      "\n",
      "avg / total     0.7536    0.7622    0.7576      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7607119314436388\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.37948717948717947\n",
      "Original f1: 0.3050259965337955\n",
      "0.155613113236\n",
      "0.993179320994\n",
      "363\n",
      "0.239288068556\n",
      "Number of disagreement: 280\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8577    0.8459    0.8518      1233\n",
      "          1     0.3688    0.3908    0.3795       284\n",
      "\n",
      "avg / total     0.7662    0.7607    0.7634      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.5-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7534843205574913\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2762148337595908\n",
      "Original f1: 0.2694300518134715\n",
      "0.0133677247361\n",
      "0.535633534485\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 5\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8284    0.8758    0.8514       926\n",
      "          1     0.3195    0.2432    0.2762       222\n",
      "\n",
      "avg / total     0.7300    0.7535    0.7402      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7323665128543178\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.32333333333333336\n",
      "Original f1: 0.3050259965337955\n",
      "0.0221176686873\n",
      "0.744694329911\n",
      "406\n",
      "0.267633487146\n",
      "Number of disagreement: 23\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8443    0.8224    0.8332      1233\n",
      "          1     0.3070    0.3415    0.3233       284\n",
      "\n",
      "avg / total     0.7437    0.7324    0.7377      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.5-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7560975609756098\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36936936936936937\n",
      "Original f1: 0.2694300518134715\n",
      "0.170334686989\n",
      "0.993667658801\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 220\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8488    0.8488    0.8488       926\n",
      "          1     0.3694    0.3694    0.3694       222\n",
      "\n",
      "avg / total     0.7561    0.7561    0.7561      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7528015820698748\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3842364532019705\n",
      "Original f1: 0.3050259965337955\n",
      "0.166599077026\n",
      "0.999999684684\n",
      "375\n",
      "0.24719841793\n",
      "Number of disagreement: 298\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8599    0.8313    0.8454      1233\n",
      "          1     0.3600    0.4120    0.3842       284\n",
      "\n",
      "avg / total     0.7663    0.7528    0.7590      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.5-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7630662020905923\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3300492610837439\n",
      "Original f1: 0.2694300518134715\n",
      "0.022153586562\n",
      "0.993264876455\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 20\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8392    0.8737    0.8561       926\n",
      "          1     0.3641    0.3018    0.3300       222\n",
      "\n",
      "avg / total     0.7473    0.7631    0.7544      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7363216875411998\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3548387096774194\n",
      "Original f1: 0.3050259965337955\n",
      "0.0362416778312\n",
      "0.959584901063\n",
      "400\n",
      "0.263678312459\n",
      "Number of disagreement: 43\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8527    0.8167    0.8343      1233\n",
      "          1     0.3274    0.3873    0.3548       284\n",
      "\n",
      "avg / total     0.7543    0.7363    0.7445      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.5-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.75\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3827956989247312\n",
      "Original f1: 0.2694300518134715\n",
      "0.181189420299\n",
      "0.99691252575\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 239\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8530    0.8337    0.8433       926\n",
      "          1     0.3663    0.4009    0.3828       222\n",
      "\n",
      "avg / total     0.7589    0.7500    0.7542      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7409360580092288\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38304552590266877\n",
      "Original f1: 0.3050259965337955\n",
      "0.17635160416\n",
      "0.999999685728\n",
      "393\n",
      "0.259063941991\n",
      "Number of disagreement: 322\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8608    0.8127    0.8360      1233\n",
      "          1     0.3456    0.4296    0.3830       284\n",
      "\n",
      "avg / total     0.7644    0.7409    0.7512      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.5-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7613240418118467\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3598130841121495\n",
      "Original f1: 0.2694300518134715\n",
      "0.0384534198173\n",
      "0.993264876601\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 42\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8461    0.8607    0.8533       926\n",
      "          1     0.3738    0.3468    0.3598       222\n",
      "\n",
      "avg / total     0.7547    0.7613    0.7579      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7376400791034937\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3819875776397515\n",
      "Original f1: 0.3050259965337955\n",
      "0.0499877594707\n",
      "0.979195607225\n",
      "398\n",
      "0.262359920897\n",
      "Number of disagreement: 67\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8608    0.8078    0.8335      1233\n",
      "          1     0.3417    0.4331    0.3820       284\n",
      "\n",
      "avg / total     0.7637    0.7376    0.7489      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.5-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7421602787456446\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3858921161825726\n",
      "Original f1: 0.2694300518134715\n",
      "0.1904283831\n",
      "0.997283538396\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 256\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8547    0.8197    0.8368       926\n",
      "          1     0.3577    0.4189    0.3859       222\n",
      "\n",
      "avg / total     0.7586    0.7422    0.7496      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7317073170731707\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3786259541984733\n",
      "Original f1: 0.3050259965337955\n",
      "0.183658923382\n",
      "0.999999687078\n",
      "407\n",
      "0.268292682927\n",
      "Number of disagreement: 338\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8604    0.7997    0.8289      1233\n",
      "          1     0.3342    0.4366    0.3786       284\n",
      "\n",
      "avg / total     0.7619    0.7317    0.7446      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.5-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7569686411149826\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.37303370786516854\n",
      "Original f1: 0.2694300518134715\n",
      "0.0513865339615\n",
      "0.993667657422\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 59\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8497    0.8488    0.8493       926\n",
      "          1     0.3722    0.3739    0.3730       222\n",
      "\n",
      "avg / total     0.7574    0.7570    0.7572      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7369808833223468\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.39819004524886875\n",
      "Original f1: 0.3050259965337955\n",
      "0.0599280065705\n",
      "0.993999072713\n",
      "399\n",
      "0.263019116678\n",
      "Number of disagreement: 86\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8664    0.7997    0.8317      1233\n",
      "          1     0.3483    0.4648    0.3982       284\n",
      "\n",
      "avg / total     0.7694    0.7370    0.7506      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.5-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7360627177700348\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.38539553752535505\n",
      "Original f1: 0.2694300518134715\n",
      "0.20058781717\n",
      "0.99728353998\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 267\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8552    0.8099    0.8319       926\n",
      "          1     0.3506    0.4279    0.3854       222\n",
      "\n",
      "avg / total     0.7576    0.7361    0.7456      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7264337508239948\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.37781109445277367\n",
      "Original f1: 0.3050259965337955\n",
      "0.190140819843\n",
      "0.999999686444\n",
      "415\n",
      "0.273566249176\n",
      "Number of disagreement: 350\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8607    0.7916    0.8247      1233\n",
      "          1     0.3290    0.4437    0.3778       284\n",
      "\n",
      "avg / total     0.7611    0.7264    0.7410      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.5-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.00910122949167\n",
      "0.395363967538\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "0.0117665683127\n",
      "0.457968282665\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 2\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.5-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.794425087108014\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.21333333333333335\n",
      "Original f1: 0.2694300518134715\n",
      "0.0821986726412\n",
      "0.638750936765\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 100\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8224    0.9503    0.8818       926\n",
      "          1     0.4103    0.1441    0.2133       222\n",
      "\n",
      "avg / total     0.7427    0.7944    0.7525      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7976268951878708\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.28103044496487123\n",
      "Original f1: 0.3050259965337955\n",
      "0.0977587706578\n",
      "0.756605182353\n",
      "307\n",
      "0.202373104812\n",
      "Number of disagreement: 186\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8370    0.9327    0.8822      1233\n",
      "          1     0.4196    0.2113    0.2810       284\n",
      "\n",
      "avg / total     0.7588    0.7976    0.7697      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.5-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.00949921620285\n",
      "0.375307928352\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7376400791034937\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.31615120274914094\n",
      "Original f1: 0.3050259965337955\n",
      "0.0139144188222\n",
      "0.457968282665\n",
      "398\n",
      "0.262359920897\n",
      "Number of disagreement: 7\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8425    0.8329    0.8377      1233\n",
      "          1     0.3087    0.3239    0.3162       284\n",
      "\n",
      "avg / total     0.7426    0.7376    0.7400      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.5-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.774390243902439\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3508771929824561\n",
      "Original f1: 0.2694300518134715\n",
      "0.142437986993\n",
      "0.993264876403\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 181\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8435    0.8844    0.8635       926\n",
      "          1     0.3955    0.3153    0.3509       222\n",
      "\n",
      "avg / total     0.7568    0.7744    0.7643      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7699406723796968\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3756708407871199\n",
      "Original f1: 0.3050259965337955\n",
      "0.144736125778\n",
      "0.983029415823\n",
      "349\n",
      "0.23005932762\n",
      "Number of disagreement: 260\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8559    0.8621    0.8590      1233\n",
      "          1     0.3818    0.3697    0.3757       284\n",
      "\n",
      "avg / total     0.7671    0.7699    0.7685      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.5-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.27692307692307694\n",
      "Original f1: 0.2694300518134715\n",
      "0.0103886711155\n",
      "0.436349942272\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 4\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8286    0.8769    0.8520       926\n",
      "          1     0.3214    0.2432    0.2769       222\n",
      "\n",
      "avg / total     0.7305    0.7544    0.7408      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7363216875411998\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3197278911564626\n",
      "Original f1: 0.3050259965337955\n",
      "0.0160203060562\n",
      "0.542822374242\n",
      "400\n",
      "0.263678312459\n",
      "Number of disagreement: 13\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8434    0.8297    0.8365      1233\n",
      "          1     0.3092    0.3310    0.3197       284\n",
      "\n",
      "avg / total     0.7434    0.7363    0.7397      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.5-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7665505226480837\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3619047619047619\n",
      "Original f1: 0.2694300518134715\n",
      "0.156353736565\n",
      "0.993264876375\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 202\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8463    0.8683    0.8571       926\n",
      "          1     0.3838    0.3423    0.3619       222\n",
      "\n",
      "avg / total     0.7569    0.7666    0.7614      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7607119314436388\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.37948717948717947\n",
      "Original f1: 0.3050259965337955\n",
      "0.156446832441\n",
      "0.995267640837\n",
      "363\n",
      "0.239288068556\n",
      "Number of disagreement: 282\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8577    0.8459    0.8518      1233\n",
      "          1     0.3688    0.3908    0.3795       284\n",
      "\n",
      "avg / total     0.7662    0.7607    0.7634      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.5-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7534843205574913\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2762148337595908\n",
      "Original f1: 0.2694300518134715\n",
      "0.0129130455867\n",
      "0.513927624661\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 5\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8284    0.8758    0.8514       926\n",
      "          1     0.3195    0.2432    0.2762       222\n",
      "\n",
      "avg / total     0.7300    0.7535    0.7402      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7343441001977588\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.32495812395309875\n",
      "Original f1: 0.3050259965337955\n",
      "0.0218306984005\n",
      "0.744694329911\n",
      "403\n",
      "0.265655899802\n",
      "Number of disagreement: 22\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8447    0.8248    0.8346      1233\n",
      "          1     0.3099    0.3415    0.3250       284\n",
      "\n",
      "avg / total     0.7446    0.7343    0.7392      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.5-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7578397212543554\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.37104072398190047\n",
      "Original f1: 0.2694300518134715\n",
      "0.171203522822\n",
      "0.993667658804\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 222\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8491    0.8510    0.8501       926\n",
      "          1     0.3727    0.3694    0.3710       222\n",
      "\n",
      "avg / total     0.7570    0.7578    0.7574      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7534607778510217\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3868852459016393\n",
      "Original f1: 0.3050259965337955\n",
      "0.167512427307\n",
      "0.999999685951\n",
      "374\n",
      "0.246539222149\n",
      "Number of disagreement: 297\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8606    0.8313    0.8457      1233\n",
      "          1     0.3620    0.4155    0.3869       284\n",
      "\n",
      "avg / total     0.7673    0.7535    0.7598      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.5-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7613240418118467\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.32178217821782185\n",
      "Original f1: 0.2694300518134715\n",
      "0.0213077460542\n",
      "0.993264876402\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 18\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8375    0.8737    0.8552       926\n",
      "          1     0.3571    0.2928    0.3218       222\n",
      "\n",
      "avg / total     0.7446    0.7613    0.7520      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7376400791034937\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3580645161290323\n",
      "Original f1: 0.3050259965337955\n",
      "0.0355899347867\n",
      "0.959584900228\n",
      "398\n",
      "0.262359920897\n",
      "Number of disagreement: 45\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8535    0.8175    0.8351      1233\n",
      "          1     0.3304    0.3908    0.3581       284\n",
      "\n",
      "avg / total     0.7556    0.7376    0.7458      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.5-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7526132404181185\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3852813852813853\n",
      "Original f1: 0.2694300518134715\n",
      "0.182523265258\n",
      "0.997283539979\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 242\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8535    0.8369    0.8451       926\n",
      "          1     0.3708    0.4009    0.3853       222\n",
      "\n",
      "avg / total     0.7602    0.7526    0.7562      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7396176664469347\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.37990580847723704\n",
      "Original f1: 0.3050259965337955\n",
      "0.177167646097\n",
      "0.999999686719\n",
      "395\n",
      "0.260382333553\n",
      "Number of disagreement: 322\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8600    0.8118    0.8352      1233\n",
      "          1     0.3428    0.4261    0.3799       284\n",
      "\n",
      "avg / total     0.7631    0.7396    0.7500      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.5-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7665505226480837\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36792452830188677\n",
      "Original f1: 0.2694300518134715\n",
      "0.0349928527761\n",
      "0.993264876478\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 38\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8478    0.8661    0.8568       926\n",
      "          1     0.3861    0.3514    0.3679       222\n",
      "\n",
      "avg / total     0.7585    0.7666    0.7623      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7389584706657878\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38509316770186336\n",
      "Original f1: 0.3050259965337955\n",
      "0.0493853263811\n",
      "0.979195603371\n",
      "396\n",
      "0.261041529334\n",
      "Number of disagreement: 69\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8617    0.8086    0.8343      1233\n",
      "          1     0.3444    0.4366    0.3851       284\n",
      "\n",
      "avg / total     0.7649    0.7390    0.7502      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.5-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7447735191637631\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3883089770354906\n",
      "Original f1: 0.2694300518134715\n",
      "0.192047232379\n",
      "0.997283540071\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 257\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8552    0.8229    0.8387       926\n",
      "          1     0.3619    0.4189    0.3883       222\n",
      "\n",
      "avg / total     0.7598    0.7448    0.7516      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7323665128543178\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.37920489296636084\n",
      "Original f1: 0.3050259965337955\n",
      "0.184283228773\n",
      "0.999999686865\n",
      "406\n",
      "0.267633487146\n",
      "Number of disagreement: 337\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8605    0.8005    0.8294      1233\n",
      "          1     0.3351    0.4366    0.3792       284\n",
      "\n",
      "avg / total     0.7622    0.7324    0.7451      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.5-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7587108013937283\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3775280898876404\n",
      "Original f1: 0.2694300518134715\n",
      "0.0506265731745\n",
      "0.993667656743\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 59\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8508    0.8499    0.8504       926\n",
      "          1     0.3767    0.3784    0.3775       222\n",
      "\n",
      "avg / total     0.7591    0.7587    0.7589      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7363216875411998\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3957703927492447\n",
      "Original f1: 0.3050259965337955\n",
      "0.0598034517688\n",
      "0.992866689191\n",
      "400\n",
      "0.263678312459\n",
      "Number of disagreement: 87\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8657    0.7997    0.8314      1233\n",
      "          1     0.3466    0.4613    0.3958       284\n",
      "\n",
      "avg / total     0.7685    0.7363    0.7498      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.5-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7386759581881533\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.38775510204081637\n",
      "Original f1: 0.2694300518134715\n",
      "0.202286379929\n",
      "0.997283540998\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 268\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8557    0.8132    0.8339       926\n",
      "          1     0.3545    0.4279    0.3878       222\n",
      "\n",
      "avg / total     0.7588    0.7387    0.7476      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7270929466051417\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3765060240963856\n",
      "Original f1: 0.3050259965337955\n",
      "0.190852587833\n",
      "0.999999687122\n",
      "414\n",
      "0.272907053395\n",
      "Number of disagreement: 347\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8602    0.7932    0.8253      1233\n",
      "          1     0.3289    0.4401    0.3765       284\n",
      "\n",
      "avg / total     0.7607    0.7271    0.7413      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.75-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.00629148250524\n",
      "0.387470141416\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7350032959789057\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3044982698961938\n",
      "Original f1: 0.3050259965337955\n",
      "0.00781006418644\n",
      "0.457583465777\n",
      "402\n",
      "0.264996704021\n",
      "Number of disagreement: 1\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8397    0.8329    0.8363      1233\n",
      "          1     0.2993    0.3099    0.3045       284\n",
      "\n",
      "avg / total     0.7386    0.7350    0.7368      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.75-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7848432055749129\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.22570532915360503\n",
      "Original f1: 0.2694300518134715\n",
      "0.0741314611837\n",
      "0.549184478716\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 89\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8230    0.9341    0.8751       926\n",
      "          1     0.3711    0.1622    0.2257       222\n",
      "\n",
      "avg / total     0.7356    0.7848    0.7495      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7969676994067239\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.31555555555555553\n",
      "Original f1: 0.3050259965337955\n",
      "0.0899182163671\n",
      "0.708103734245\n",
      "308\n",
      "0.203032300593\n",
      "Number of disagreement: 163\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8423    0.9230    0.8808      1233\n",
      "          1     0.4277    0.2500    0.3156       284\n",
      "\n",
      "avg / total     0.7647    0.7970    0.7750      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.75-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.00668661119971\n",
      "0.270092799022\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.31217838765008576\n",
      "Original f1: 0.3050259965337955\n",
      "0.0101288753425\n",
      "0.500866868067\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 6\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8415    0.8313    0.8364      1233\n",
      "          1     0.3043    0.3204    0.3122       284\n",
      "\n",
      "avg / total     0.7410    0.7357    0.7383      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.75-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7517421602787456\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3566591422121896\n",
      "Original f1: 0.2694300518134715\n",
      "0.151394258292\n",
      "0.993264876624\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 195\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8457    0.8467    0.8462       926\n",
      "          1     0.3575    0.3559    0.3567       222\n",
      "\n",
      "avg / total     0.7513    0.7517    0.7515      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7488464073829928\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3961965134706814\n",
      "Original f1: 0.3050259965337955\n",
      "0.155460293614\n",
      "0.992866689116\n",
      "381\n",
      "0.251153592617\n",
      "Number of disagreement: 280\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8641    0.8200    0.8414      1233\n",
      "          1     0.3602    0.4401    0.3962       284\n",
      "\n",
      "avg / total     0.7698    0.7488    0.7581      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.75-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.00787947993471\n",
      "0.342216287468\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7363216875411998\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3197278911564626\n",
      "Original f1: 0.3050259965337955\n",
      "0.0126221941584\n",
      "0.597534855771\n",
      "400\n",
      "0.263678312459\n",
      "Number of disagreement: 11\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8434    0.8297    0.8365      1233\n",
      "          1     0.3092    0.3310    0.3197       284\n",
      "\n",
      "avg / total     0.7434    0.7363    0.7397      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.75-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7360627177700348\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.35940803382663844\n",
      "Original f1: 0.2694300518134715\n",
      "0.167157825086\n",
      "0.994722396299\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 225\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8473    0.8207    0.8338       926\n",
      "          1     0.3386    0.3829    0.3594       222\n",
      "\n",
      "avg / total     0.7489    0.7361    0.7421      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.39150227617602423\n",
      "Original f1: 0.3050259965337955\n",
      "0.165786226987\n",
      "0.993179320437\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 306\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8643    0.8005    0.8312      1233\n",
      "          1     0.3440    0.4542    0.3915       284\n",
      "\n",
      "avg / total     0.7669    0.7357    0.7488      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.75-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.27692307692307694\n",
      "Original f1: 0.2694300518134715\n",
      "0.0108720630758\n",
      "0.459891560117\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 4\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8286    0.8769    0.8520       926\n",
      "          1     0.3214    0.2432    0.2769       222\n",
      "\n",
      "avg / total     0.7305    0.7544    0.7408      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7343441001977588\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.32495812395309875\n",
      "Original f1: 0.3050259965337955\n",
      "0.0192251196661\n",
      "0.802287252522\n",
      "403\n",
      "0.265655899802\n",
      "Number of disagreement: 20\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8447    0.8248    0.8346      1233\n",
      "          1     0.3099    0.3415    0.3250       284\n",
      "\n",
      "avg / total     0.7446    0.7343    0.7392      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.75-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7247386759581882\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3629032258064516\n",
      "Original f1: 0.2694300518134715\n",
      "0.180292190342\n",
      "0.99728354111\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 244\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8490    0.8013    0.8244       926\n",
      "          1     0.3285    0.4054    0.3629       222\n",
      "\n",
      "avg / total     0.7483    0.7247    0.7352      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7257745550428477\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38823529411764707\n",
      "Original f1: 0.3050259965337955\n",
      "0.176933294915\n",
      "0.999999685552\n",
      "416\n",
      "0.274225444957\n",
      "Number of disagreement: 323\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8644    0.7859    0.8233      1233\n",
      "          1     0.3333    0.4648    0.3882       284\n",
      "\n",
      "avg / total     0.7650    0.7258    0.7418      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.75-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7613240418118467\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.32512315270935965\n",
      "Original f1: 0.2694300518134715\n",
      "0.0205914293601\n",
      "0.993264876568\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 20\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8382    0.8726    0.8550       926\n",
      "          1     0.3587    0.2973    0.3251       222\n",
      "\n",
      "avg / total     0.7455    0.7613    0.7526      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7369808833223468\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.35955056179775285\n",
      "Original f1: 0.3050259965337955\n",
      "0.0357974416792\n",
      "0.962421875945\n",
      "399\n",
      "0.263019116678\n",
      "Number of disagreement: 46\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8540    0.8159    0.8345      1233\n",
      "          1     0.3304    0.3944    0.3596       284\n",
      "\n",
      "avg / total     0.7560    0.7370    0.7456      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.75-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7203832752613241\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.37426900584795325\n",
      "Original f1: 0.2694300518134715\n",
      "0.19094302185\n",
      "0.997283541125\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 261\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8530    0.7894    0.8200       926\n",
      "          1     0.3299    0.4324    0.3743       222\n",
      "\n",
      "avg / total     0.7518    0.7204    0.7338      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7165458141067897\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3839541547277937\n",
      "Original f1: 0.3050259965337955\n",
      "0.187196128904\n",
      "0.99999968549\n",
      "430\n",
      "0.283454185893\n",
      "Number of disagreement: 339\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8640    0.7729    0.8159      1233\n",
      "          1     0.3237    0.4718    0.3840       284\n",
      "\n",
      "avg / total     0.7629    0.7165    0.7351      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.75-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3691588785046729\n",
      "Original f1: 0.2694300518134715\n",
      "0.0363424588847\n",
      "0.993667658551\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 42\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8482    0.8629    0.8555       926\n",
      "          1     0.3835    0.3559    0.3692       222\n",
      "\n",
      "avg / total     0.7583    0.7648    0.7614      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7389584706657878\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4\n",
      "Original f1: 0.3050259965337955\n",
      "0.0534259756968\n",
      "0.992866687647\n",
      "396\n",
      "0.261041529334\n",
      "Number of disagreement: 83\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8668    0.8021    0.8332      1233\n",
      "          1     0.3511    0.4648    0.4000       284\n",
      "\n",
      "avg / total     0.7702    0.7390    0.7521      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.75-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7151567944250871\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.37476099426386233\n",
      "Original f1: 0.2694300518134715\n",
      "0.201320527412\n",
      "0.997283540801\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 271\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8536    0.7808    0.8156       926\n",
      "          1     0.3256    0.4414    0.3748       222\n",
      "\n",
      "avg / total     0.7515    0.7152    0.7303      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7106130520764667\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.379066478076379\n",
      "Original f1: 0.3050259965337955\n",
      "0.194637863617\n",
      "0.999999687251\n",
      "439\n",
      "0.289386947924\n",
      "Number of disagreement: 344\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8629    0.7656    0.8113      1233\n",
      "          1     0.3168    0.4718    0.3791       284\n",
      "\n",
      "avg / total     0.7607    0.7106    0.7304      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.75-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.37885462555066085\n",
      "Original f1: 0.2694300518134715\n",
      "0.0547631807421\n",
      "0.993667658145\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 68\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8515    0.8423    0.8469       926\n",
      "          1     0.3707    0.3874    0.3789       222\n",
      "\n",
      "avg / total     0.7585    0.7544    0.7564      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7343441001977588\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.406480117820324\n",
      "Original f1: 0.3050259965337955\n",
      "0.0638164237021\n",
      "0.993179320317\n",
      "403\n",
      "0.265655899802\n",
      "Number of disagreement: 102\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8699    0.7916    0.8289      1233\n",
      "          1     0.3494    0.4859    0.4065       284\n",
      "\n",
      "avg / total     0.7724    0.7343    0.7498      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.75-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7081881533101045\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3738317757009346\n",
      "Original f1: 0.2694300518134715\n",
      "0.210176192211\n",
      "0.997283541053\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 283\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8539    0.7700    0.8098       926\n",
      "          1     0.3195    0.4505    0.3738       222\n",
      "\n",
      "avg / total     0.7505    0.7082    0.7255      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7079762689518787\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3804195804195804\n",
      "Original f1: 0.3050259965337955\n",
      "0.200908208737\n",
      "0.999999687072\n",
      "443\n",
      "0.292023731048\n",
      "Number of disagreement: 352\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8637    0.7607    0.8090      1233\n",
      "          1     0.3155    0.4789    0.3804       284\n",
      "\n",
      "avg / total     0.7611    0.7080    0.7287      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.75-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.00558731462103\n",
      "0.380799023293\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "0.00724627028081\n",
      "0.457611742639\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.75-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7822299651567944\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.21875\n",
      "Original f1: 0.2694300518134715\n",
      "0.0757089664772\n",
      "0.571587789667\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 86\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8219    0.9320    0.8735       926\n",
      "          1     0.3571    0.1577    0.2188       222\n",
      "\n",
      "avg / total     0.7320    0.7822    0.7469      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7936717205009888\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3150984682713348\n",
      "Original f1: 0.3050259965337955\n",
      "0.0911363912666\n",
      "0.707845026646\n",
      "313\n",
      "0.206328279499\n",
      "Number of disagreement: 158\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8423    0.9181    0.8785      1233\n",
      "          1     0.4162    0.2535    0.3151       284\n",
      "\n",
      "avg / total     0.7625    0.7937    0.7731      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.75-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.00581869696987\n",
      "0.283532629804\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7363216875411998\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3103448275862069\n",
      "Original f1: 0.3050259965337955\n",
      "0.00916189500901\n",
      "0.469882366692\n",
      "400\n",
      "0.263678312459\n",
      "Number of disagreement: 3\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8411    0.8329    0.8370      1233\n",
      "          1     0.3041    0.3169    0.3103       284\n",
      "\n",
      "avg / total     0.7406    0.7363    0.7384      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.75-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7482578397212544\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.35346756152125275\n",
      "Original f1: 0.2694300518134715\n",
      "0.154220630116\n",
      "0.993264876614\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 195\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8451    0.8423    0.8437       926\n",
      "          1     0.3511    0.3559    0.3535       222\n",
      "\n",
      "avg / total     0.7495    0.7483    0.7489      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7442320369149638\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.39375000000000004\n",
      "Original f1: 0.3050259965337955\n",
      "0.159103116127\n",
      "0.99286668905\n",
      "388\n",
      "0.255767963085\n",
      "Number of disagreement: 279\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8639    0.8135    0.8379      1233\n",
      "          1     0.3539    0.4437    0.3938       284\n",
      "\n",
      "avg / total     0.7684    0.7442    0.7548      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.75-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.00701095054566\n",
      "0.361678838669\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7376400791034937\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.32081911262798635\n",
      "Original f1: 0.3050259965337955\n",
      "0.0116862160829\n",
      "0.593105045517\n",
      "398\n",
      "0.262359920897\n",
      "Number of disagreement: 9\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8436    0.8313    0.8374      1233\n",
      "          1     0.3113    0.3310    0.3208       284\n",
      "\n",
      "avg / total     0.7440    0.7376    0.7407      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.75-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7317073170731707\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.35564853556485354\n",
      "Original f1: 0.2694300518134715\n",
      "0.168806662036\n",
      "0.997283540987\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 224\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8464    0.8153    0.8306       926\n",
      "          1     0.3320    0.3829    0.3556       222\n",
      "\n",
      "avg / total     0.7469    0.7317    0.7387      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7363216875411998\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.39209726443768994\n",
      "Original f1: 0.3050259965337955\n",
      "0.168893969897\n",
      "0.999999686487\n",
      "400\n",
      "0.263678312459\n",
      "Number of disagreement: 299\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8644    0.8013    0.8316      1233\n",
      "          1     0.3449    0.4542    0.3921       284\n",
      "\n",
      "avg / total     0.7671    0.7363    0.7494      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.75-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7560975609756098\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2857142857142857\n",
      "Original f1: 0.2694300518134715\n",
      "0.0104206069634\n",
      "0.479194222756\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 6\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8303    0.8769    0.8529       926\n",
      "          1     0.3294    0.2523    0.2857       222\n",
      "\n",
      "avg / total     0.7334    0.7561    0.7433      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7350032959789057\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.32550335570469796\n",
      "Original f1: 0.3050259965337955\n",
      "0.0180988433375\n",
      "0.766262114177\n",
      "402\n",
      "0.264996704021\n",
      "Number of disagreement: 19\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8448    0.8256    0.8351      1233\n",
      "          1     0.3109    0.3415    0.3255       284\n",
      "\n",
      "avg / total     0.7449    0.7350    0.7397      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.75-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7142857142857143\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.35177865612648224\n",
      "Original f1: 0.2694300518134715\n",
      "0.183141105291\n",
      "0.997283541059\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 248\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8461    0.7894    0.8168       926\n",
      "          1     0.3134    0.4009    0.3518       222\n",
      "\n",
      "avg / total     0.7431    0.7143    0.7268      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7231377719182597\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38596491228070173\n",
      "Original f1: 0.3050259965337955\n",
      "0.179576843372\n",
      "0.999999687291\n",
      "420\n",
      "0.276862228082\n",
      "Number of disagreement: 323\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8639    0.7826    0.8213      1233\n",
      "          1     0.3300    0.4648    0.3860       284\n",
      "\n",
      "avg / total     0.7640    0.7231    0.7398      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.75-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7604529616724739\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.32098765432098764\n",
      "Original f1: 0.2694300518134715\n",
      "0.0193404310316\n",
      "0.993264876628\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 19\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8373    0.8726    0.8546       926\n",
      "          1     0.3552    0.2928    0.3210       222\n",
      "\n",
      "avg / total     0.7441    0.7605    0.7514      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7350032959789057\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.35161290322580646\n",
      "Original f1: 0.3050259965337955\n",
      "0.0346499216727\n",
      "0.962421876517\n",
      "402\n",
      "0.264996704021\n",
      "Number of disagreement: 43\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8518    0.8159    0.8335      1233\n",
      "          1     0.3244    0.3838    0.3516       284\n",
      "\n",
      "avg / total     0.7531    0.7350    0.7433      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.75-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7116724738675958\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36952380952380953\n",
      "Original f1: 0.2694300518134715\n",
      "0.194499717082\n",
      "0.997283541143\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 265\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8521    0.7775    0.8131       926\n",
      "          1     0.3201    0.4369    0.3695       222\n",
      "\n",
      "avg / total     0.7492    0.7117    0.7273      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7132498352010547\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38122332859174957\n",
      "Original f1: 0.3050259965337955\n",
      "0.18932147732\n",
      "0.999999687083\n",
      "435\n",
      "0.286750164799\n",
      "Number of disagreement: 336\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8634    0.7689    0.8134      1233\n",
      "          1     0.3198    0.4718    0.3812       284\n",
      "\n",
      "avg / total     0.7616    0.7132    0.7325      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.75-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7656794425087108\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3610451306413302\n",
      "Original f1: 0.2694300518134715\n",
      "0.0348373512048\n",
      "0.99366765867\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 35\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8462    0.8672    0.8565       926\n",
      "          1     0.3819    0.3423    0.3610       222\n",
      "\n",
      "avg / total     0.7564    0.7657    0.7607      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7389584706657878\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4\n",
      "Original f1: 0.3050259965337955\n",
      "0.0523299165522\n",
      "0.992866688266\n",
      "396\n",
      "0.261041529334\n",
      "Number of disagreement: 83\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8668    0.8021    0.8332      1233\n",
      "          1     0.3511    0.4648    0.4000       284\n",
      "\n",
      "avg / total     0.7702    0.7390    0.7521      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.75-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7047038327526133\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3663551401869159\n",
      "Original f1: 0.2694300518134715\n",
      "0.204584274055\n",
      "0.997283541182\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 275\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8515    0.7678    0.8075       926\n",
      "          1     0.3131    0.4414    0.3664       222\n",
      "\n",
      "avg / total     0.7474    0.7047    0.7222      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7092946605141727\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.37799717912552894\n",
      "Original f1: 0.3050259965337955\n",
      "0.196351540765\n",
      "0.999999687171\n",
      "441\n",
      "0.290705339486\n",
      "Number of disagreement: 342\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8626    0.7640    0.8103      1233\n",
      "          1     0.3153    0.4718    0.3780       284\n",
      "\n",
      "avg / total     0.7602    0.7093    0.7294      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.75-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.37885462555066085\n",
      "Original f1: 0.2694300518134715\n",
      "0.0551327219895\n",
      "0.993667659147\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 68\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8515    0.8423    0.8469       926\n",
      "          1     0.3707    0.3874    0.3789       222\n",
      "\n",
      "avg / total     0.7585    0.7544    0.7564      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7363216875411998\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.40828402366863903\n",
      "Original f1: 0.3050259965337955\n",
      "0.0631919554352\n",
      "0.992866689083\n",
      "400\n",
      "0.263678312459\n",
      "Number of disagreement: 99\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8702    0.7940    0.8304      1233\n",
      "          1     0.3520    0.4859    0.4083       284\n",
      "\n",
      "avg / total     0.7732    0.7363    0.7513      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-0.75-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6977351916376306\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3679417122040073\n",
      "Original f1: 0.2694300518134715\n",
      "0.212949139448\n",
      "0.997283541042\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 289\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8526    0.7559    0.8014       926\n",
      "          1     0.3089    0.4550    0.3679       222\n",
      "\n",
      "avg / total     0.7475    0.6977    0.7176      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7053394858272907\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.37830319888734354\n",
      "Original f1: 0.3050259965337955\n",
      "0.202689435641\n",
      "0.999999687304\n",
      "447\n",
      "0.294660514173\n",
      "Number of disagreement: 350\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8632    0.7575    0.8069      1233\n",
      "          1     0.3126    0.4789    0.3783       284\n",
      "\n",
      "avg / total     0.7601    0.7053    0.7267      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.0-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.00526757855003\n",
      "0.38531007394\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "0.0064880467228\n",
      "0.452223820291\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.0-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7831010452961672\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.22910216718266255\n",
      "Original f1: 0.2694300518134715\n",
      "0.0714564255458\n",
      "0.52925068111\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 81\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8233    0.9309    0.8738       926\n",
      "          1     0.3663    0.1667    0.2291       222\n",
      "\n",
      "avg / total     0.7349    0.7831    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7923533289386948\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.32258064516129037\n",
      "Original f1: 0.3050259965337955\n",
      "0.0881224054283\n",
      "0.654195025476\n",
      "315\n",
      "0.207646671061\n",
      "Number of disagreement: 142\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8436    0.9140    0.8774      1233\n",
      "          1     0.4144    0.2641    0.3226       284\n",
      "\n",
      "avg / total     0.7632    0.7924    0.7735      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.0-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.00562726972033\n",
      "0.263633047022\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7363216875411998\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3127147766323024\n",
      "Original f1: 0.3050259965337955\n",
      "0.00862072823557\n",
      "0.489095372297\n",
      "400\n",
      "0.263678312459\n",
      "Number of disagreement: 5\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8417    0.8321    0.8369      1233\n",
      "          1     0.3054    0.3204    0.3127       284\n",
      "\n",
      "avg / total     0.7413    0.7363    0.7387      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.0-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7334494773519163\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.34893617021276596\n",
      "Original f1: 0.2694300518134715\n",
      "0.159000628311\n",
      "0.99728353979\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 202\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8444    0.8207    0.8324       926\n",
      "          1     0.3306    0.3694    0.3489       222\n",
      "\n",
      "avg / total     0.7451    0.7334    0.7389      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7330257086354647\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3909774436090226\n",
      "Original f1: 0.3050259965337955\n",
      "0.162342719785\n",
      "0.992866689091\n",
      "405\n",
      "0.266974291365\n",
      "Number of disagreement: 286\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8644    0.7964    0.8290      1233\n",
      "          1     0.3412    0.4577    0.3910       284\n",
      "\n",
      "avg / total     0.7665    0.7330    0.7470      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.0-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.00671863505313\n",
      "0.314548936924\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7369808833223468\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3156089193825043\n",
      "Original f1: 0.3050259965337955\n",
      "0.0112223967931\n",
      "0.601759183579\n",
      "399\n",
      "0.263019116678\n",
      "Number of disagreement: 6\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8424    0.8321    0.8372      1233\n",
      "          1     0.3077    0.3239    0.3156       284\n",
      "\n",
      "avg / total     0.7423    0.7370    0.7396      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.0-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7177700348432056\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.352\n",
      "Original f1: 0.2694300518134715\n",
      "0.172869103\n",
      "0.997283540811\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 230\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8460    0.7948    0.8196       926\n",
      "          1     0.3165    0.3964    0.3520       222\n",
      "\n",
      "avg / total     0.7436    0.7178    0.7292      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7211601845748187\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.386066763425254\n",
      "Original f1: 0.3050259965337955\n",
      "0.173337516622\n",
      "0.993179319849\n",
      "423\n",
      "0.278839815425\n",
      "Number of disagreement: 302\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8642    0.7794    0.8196      1233\n",
      "          1     0.3284    0.4683    0.3861       284\n",
      "\n",
      "avg / total     0.7639    0.7212    0.7385      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.0-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.27319587628865977\n",
      "Original f1: 0.2694300518134715\n",
      "0.00999614547923\n",
      "0.430843628101\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 2\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8279    0.8780    0.8522       926\n",
      "          1     0.3193    0.2387    0.2732       222\n",
      "\n",
      "avg / total     0.7295    0.7544    0.7402      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7369808833223468\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3294117647058824\n",
      "Original f1: 0.3050259965337955\n",
      "0.0180611708811\n",
      "0.778890125435\n",
      "399\n",
      "0.263019116678\n",
      "Number of disagreement: 18\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8458    0.8273    0.8364      1233\n",
      "          1     0.3151    0.3451    0.3294       284\n",
      "\n",
      "avg / total     0.7464    0.7370    0.7415      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.0-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7064459930313589\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3556405353728489\n",
      "Original f1: 0.2694300518134715\n",
      "0.187679839737\n",
      "0.997283541117\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 251\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8477    0.7754    0.8099       926\n",
      "          1     0.3090    0.4189    0.3556       222\n",
      "\n",
      "avg / total     0.7435    0.7064    0.7221      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7125906394199077\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38243626062322944\n",
      "Original f1: 0.3050259965337955\n",
      "0.184880619631\n",
      "0.999999685166\n",
      "436\n",
      "0.28740936058\n",
      "Number of disagreement: 317\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8639    0.7672    0.8127      1233\n",
      "          1     0.3199    0.4754    0.3824       284\n",
      "\n",
      "avg / total     0.7621    0.7126    0.7322      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.0-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7613240418118467\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.32512315270935965\n",
      "Original f1: 0.2694300518134715\n",
      "0.0200087081862\n",
      "0.993264876554\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 20\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8382    0.8726    0.8550       926\n",
      "          1     0.3587    0.2973    0.3251       222\n",
      "\n",
      "avg / total     0.7455    0.7613    0.7526      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7343441001977588\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3425774877650898\n",
      "Original f1: 0.3050259965337955\n",
      "0.0315161780502\n",
      "0.941206191389\n",
      "403\n",
      "0.265655899802\n",
      "Number of disagreement: 36\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8493    0.8183    0.8335      1233\n",
      "          1     0.3191    0.3697    0.3426       284\n",
      "\n",
      "avg / total     0.7501    0.7343    0.7416      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.0-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6994773519163763\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3669724770642202\n",
      "Original f1: 0.2694300518134715\n",
      "0.198853761332\n",
      "0.997283541182\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 273\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8521    0.7592    0.8030       926\n",
      "          1     0.3096    0.4505    0.3670       222\n",
      "\n",
      "avg / total     0.7472    0.6995    0.7187      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7040210942649967\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.37897648686030433\n",
      "Original f1: 0.3050259965337955\n",
      "0.194484705284\n",
      "0.999999687134\n",
      "449\n",
      "0.295978905735\n",
      "Number of disagreement: 334\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8636    0.7551    0.8057      1233\n",
      "          1     0.3121    0.4824    0.3790       284\n",
      "\n",
      "avg / total     0.7604    0.7040    0.7258      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.0-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7665505226480837\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3738317757009346\n",
      "Original f1: 0.2694300518134715\n",
      "0.0366846369778\n",
      "0.993667594091\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 42\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8493    0.8639    0.8565       926\n",
      "          1     0.3883    0.3604    0.3738       222\n",
      "\n",
      "avg / total     0.7601    0.7666    0.7632      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7396176664469347\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4095665171898356\n",
      "Original f1: 0.3050259965337955\n",
      "0.055564903447\n",
      "0.992866688853\n",
      "395\n",
      "0.260382333553\n",
      "Number of disagreement: 92\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8701    0.7989    0.8330      1233\n",
      "          1     0.3558    0.4824    0.4096       284\n",
      "\n",
      "avg / total     0.7739    0.7396    0.7537      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.0-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6951219512195121\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36823104693140796\n",
      "Original f1: 0.2694300518134715\n",
      "0.208228406114\n",
      "0.99728354116\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 282\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8529    0.7516    0.7991       926\n",
      "          1     0.3072    0.4595    0.3682       222\n",
      "\n",
      "avg / total     0.7474    0.6951    0.7158      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6994067237969677\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.37874659400544963\n",
      "Original f1: 0.3050259965337955\n",
      "0.202537333385\n",
      "0.999999686386\n",
      "456\n",
      "0.300593276203\n",
      "Number of disagreement: 341\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8641    0.7478    0.8017      1233\n",
      "          1     0.3089    0.4894    0.3787       284\n",
      "\n",
      "avg / total     0.7602    0.6994    0.7226      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.0-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7552264808362369\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.38512035010940915\n",
      "Original f1: 0.2694300518134715\n",
      "0.0559050288072\n",
      "0.993667659088\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 71\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8532    0.8413    0.8472       926\n",
      "          1     0.3745    0.3964    0.3851       222\n",
      "\n",
      "avg / total     0.7606    0.7552    0.7578      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7310481212920237\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4052478134110787\n",
      "Original f1: 0.3050259965337955\n",
      "0.0669512597286\n",
      "0.992866688896\n",
      "408\n",
      "0.268951878708\n",
      "Number of disagreement: 109\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8700    0.7867    0.8262      1233\n",
      "          1     0.3458    0.4894    0.4052       284\n",
      "\n",
      "avg / total     0.7718    0.7310    0.7474      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.0-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.6907665505226481\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.369449378330373\n",
      "Original f1: 0.2694300518134715\n",
      "0.214611498765\n",
      "0.997283541204\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 289\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8538    0.7441    0.7952       926\n",
      "          1     0.3050    0.4685    0.3694       222\n",
      "\n",
      "avg / total     0.7477    0.6908    0.7128      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6947923533289387\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3768506056527591\n",
      "Original f1: 0.3050259965337955\n",
      "0.208145977048\n",
      "0.999999687006\n",
      "463\n",
      "0.305207646671\n",
      "Number of disagreement: 350\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8639    0.7413    0.7979      1233\n",
      "          1     0.3050    0.4930    0.3769       284\n",
      "\n",
      "avg / total     0.7593    0.6948    0.7191      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.0-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.00440670176458\n",
      "0.371965874174\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "0.00573658058362\n",
      "0.45269408683\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.0-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7804878048780488\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.21250000000000002\n",
      "Original f1: 0.2694300518134715\n",
      "0.0740264226523\n",
      "0.558515269521\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 86\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8210    0.9309    0.8725       926\n",
      "          1     0.3469    0.1532    0.2125       222\n",
      "\n",
      "avg / total     0.7293    0.7805    0.7448      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7916941331575478\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.31601731601731603\n",
      "Original f1: 0.3050259965337955\n",
      "0.0904390107907\n",
      "0.65564354604\n",
      "316\n",
      "0.208305866842\n",
      "Number of disagreement: 145\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8424    0.9148    0.8771      1233\n",
      "          1     0.4101    0.2570    0.3160       284\n",
      "\n",
      "avg / total     0.7615    0.7917    0.7721      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.0-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.00457457248226\n",
      "0.278676737044\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7363216875411998\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3103448275862069\n",
      "Original f1: 0.3050259965337955\n",
      "0.00737457091912\n",
      "0.477326718799\n",
      "400\n",
      "0.263678312459\n",
      "Number of disagreement: 3\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8411    0.8329    0.8370      1233\n",
      "          1     0.3041    0.3169    0.3103       284\n",
      "\n",
      "avg / total     0.7406    0.7363    0.7384      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.0-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7229965156794426\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.33193277310924363\n",
      "Original f1: 0.2694300518134715\n",
      "0.162873170165\n",
      "0.99728354101\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 218\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8400    0.8110    0.8253       926\n",
      "          1     0.3110    0.3559    0.3319       222\n",
      "\n",
      "avg / total     0.7377    0.7230    0.7299      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7310481212920237\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3892215568862276\n",
      "Original f1: 0.3050259965337955\n",
      "0.167752559017\n",
      "0.999999686862\n",
      "408\n",
      "0.268951878708\n",
      "Number of disagreement: 291\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8641    0.7940    0.8276      1233\n",
      "          1     0.3385    0.4577    0.3892       284\n",
      "\n",
      "avg / total     0.7657    0.7310    0.7455      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.0-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.00577639256779\n",
      "0.356427950185\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7369808833223468\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3156089193825043\n",
      "Original f1: 0.3050259965337955\n",
      "0.0100114018439\n",
      "0.591653834957\n",
      "399\n",
      "0.263019116678\n",
      "Number of disagreement: 6\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8424    0.8321    0.8372      1233\n",
      "          1     0.3077    0.3239    0.3156       284\n",
      "\n",
      "avg / total     0.7423    0.7370    0.7396      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.0-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.710801393728223\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3412698412698413\n",
      "Original f1: 0.2694300518134715\n",
      "0.176190604945\n",
      "0.997283541144\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 240\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8430    0.7883    0.8147       926\n",
      "          1     0.3050    0.3874    0.3413       222\n",
      "\n",
      "avg / total     0.7389    0.7108    0.7232      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7211601845748187\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.386066763425254\n",
      "Original f1: 0.3050259965337955\n",
      "0.178050652817\n",
      "0.9999996859\n",
      "423\n",
      "0.278839815425\n",
      "Number of disagreement: 308\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8642    0.7794    0.8196      1233\n",
      "          1     0.3284    0.4683    0.3861       284\n",
      "\n",
      "avg / total     0.7639    0.7212    0.7385      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.0-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7534843205574913\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2724935732647815\n",
      "Original f1: 0.2694300518134715\n",
      "0.0095441055458\n",
      "0.469599290526\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 3\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8277    0.8769    0.8516       926\n",
      "          1     0.3174    0.2387    0.2725       222\n",
      "\n",
      "avg / total     0.7290    0.7535    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7369808833223468\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3294117647058824\n",
      "Original f1: 0.3050259965337955\n",
      "0.0166119480151\n",
      "0.754588143368\n",
      "399\n",
      "0.263019116678\n",
      "Number of disagreement: 18\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8458    0.8273    0.8364      1233\n",
      "          1     0.3151    0.3451    0.3294       284\n",
      "\n",
      "avg / total     0.7464    0.7370    0.7415      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.0-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6968641114982579\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3433962264150943\n",
      "Original f1: 0.2694300518134715\n",
      "0.191954098089\n",
      "0.9972835412\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 264\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8440    0.7657    0.8029       926\n",
      "          1     0.2955    0.4099    0.3434       222\n",
      "\n",
      "avg / total     0.7380    0.6969    0.7141      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7112722478576137\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.37960339943342775\n",
      "Original f1: 0.3050259965337955\n",
      "0.188894879741\n",
      "0.999999687053\n",
      "438\n",
      "0.288727752142\n",
      "Number of disagreement: 321\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8630    0.7664    0.8119      1233\n",
      "          1     0.3175    0.4718    0.3796       284\n",
      "\n",
      "avg / total     0.7609    0.7113    0.7309      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.0-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7604529616724739\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.32098765432098764\n",
      "Original f1: 0.2694300518134715\n",
      "0.0187475758644\n",
      "0.9932648758\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 19\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8373    0.8726    0.8546       926\n",
      "          1     0.3552    0.2928    0.3210       222\n",
      "\n",
      "avg / total     0.7441    0.7605    0.7514      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7350032959789057\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3474025974025974\n",
      "Original f1: 0.3050259965337955\n",
      "0.0331177008533\n",
      "0.959584562776\n",
      "402\n",
      "0.264996704021\n",
      "Number of disagreement: 39\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8506    0.8175    0.8337      1233\n",
      "          1     0.3223    0.3768    0.3474       284\n",
      "\n",
      "avg / total     0.7517    0.7350    0.7427      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.0-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.6925087108013938\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3570127504553734\n",
      "Original f1: 0.2694300518134715\n",
      "0.204665211914\n",
      "0.99728354107\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 283\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8490    0.7527    0.7979       926\n",
      "          1     0.2997    0.4414    0.3570       222\n",
      "\n",
      "avg / total     0.7427    0.6925    0.7127      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7013843111404087\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.37344398340248963\n",
      "Original f1: 0.3050259965337955\n",
      "0.198587278241\n",
      "0.999999687137\n",
      "453\n",
      "0.29861568886\n",
      "Number of disagreement: 338\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8618    0.7534    0.8040      1233\n",
      "          1     0.3075    0.4754    0.3734       284\n",
      "\n",
      "avg / total     0.7580    0.7014    0.7234      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.0-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7639372822299652\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36235294117647054\n",
      "Original f1: 0.2694300518134715\n",
      "0.0354376783347\n",
      "0.993667658882\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 39\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8466    0.8639    0.8552       926\n",
      "          1     0.3793    0.3468    0.3624       222\n",
      "\n",
      "avg / total     0.7562    0.7639    0.7599      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.39880059970014997\n",
      "Original f1: 0.3050259965337955\n",
      "0.0538481277683\n",
      "0.992866685231\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 90\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8668    0.7972    0.8306      1233\n",
      "          1     0.3473    0.4683    0.3988       284\n",
      "\n",
      "avg / total     0.7696    0.7357    0.7498      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.0-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6855400696864111\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3542039355992844\n",
      "Original f1: 0.2694300518134715\n",
      "0.212798992536\n",
      "0.99728354103\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 293\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8483    0.7430    0.7922       926\n",
      "          1     0.2938    0.4459    0.3542       222\n",
      "\n",
      "avg / total     0.7411    0.6855    0.7075      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6974291364535267\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.37551020408163266\n",
      "Original f1: 0.3050259965337955\n",
      "0.205774546001\n",
      "0.999999687403\n",
      "459\n",
      "0.302570863546\n",
      "Number of disagreement: 348\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8630    0.7461    0.8003      1233\n",
      "          1     0.3060    0.4859    0.3755       284\n",
      "\n",
      "avg / total     0.7588    0.6974    0.7208      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.0-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7526132404181185\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3799126637554585\n",
      "Original f1: 0.2694300518134715\n",
      "0.0565998328831\n",
      "0.993667657968\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 72\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8520    0.8391    0.8455       926\n",
      "          1     0.3686    0.3919    0.3799       222\n",
      "\n",
      "avg / total     0.7585    0.7526    0.7555      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7310481212920237\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4052478134110787\n",
      "Original f1: 0.3050259965337955\n",
      "0.0654976716655\n",
      "0.999999686728\n",
      "408\n",
      "0.268951878708\n",
      "Number of disagreement: 109\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8700    0.7867    0.8262      1233\n",
      "          1     0.3458    0.4894    0.4052       284\n",
      "\n",
      "avg / total     0.7718    0.7310    0.7474      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.0-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.681184668989547\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.35563380281690143\n",
      "Original f1: 0.2694300518134715\n",
      "0.218958918345\n",
      "0.997283541203\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 300\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8491    0.7354    0.7882       926\n",
      "          1     0.2919    0.4550    0.3556       222\n",
      "\n",
      "avg / total     0.7414    0.6812    0.7045      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6908371786420567\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3721552878179384\n",
      "Original f1: 0.3050259965337955\n",
      "0.210822641065\n",
      "0.999999687274\n",
      "469\n",
      "0.309162821358\n",
      "Number of disagreement: 360\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8624    0.7372    0.7949      1233\n",
      "          1     0.3002    0.4894    0.3722       284\n",
      "\n",
      "avg / total     0.7572    0.6908    0.7158      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.5-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.005003993248\n",
      "0.385180911471\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "0.00569605117377\n",
      "0.409200060642\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.5-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7813588850174216\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.21806853582554517\n",
      "Original f1: 0.2694300518134715\n",
      "0.0704517249378\n",
      "0.54237655689\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 79\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8217    0.9309    0.8729       926\n",
      "          1     0.3535    0.1577    0.2181       222\n",
      "\n",
      "avg / total     0.7312    0.7814    0.7463      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7930125247198417\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3203463203463203\n",
      "Original f1: 0.3050259965337955\n",
      "0.0882087426031\n",
      "0.593271340827\n",
      "314\n",
      "0.20698747528\n",
      "Number of disagreement: 137\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8432    0.9157    0.8779      1233\n",
      "          1     0.4157    0.2606    0.3203       284\n",
      "\n",
      "avg / total     0.7631    0.7930    0.7735      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.5-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.00529494581424\n",
      "0.288142268926\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7363216875411998\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3103448275862069\n",
      "Original f1: 0.3050259965337955\n",
      "0.00757335516351\n",
      "0.460831891703\n",
      "400\n",
      "0.263678312459\n",
      "Number of disagreement: 3\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8411    0.8329    0.8370      1233\n",
      "          1     0.3041    0.3169    0.3103       284\n",
      "\n",
      "avg / total     0.7406    0.7363    0.7384      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.5-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.710801393728223\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.32793522267206476\n",
      "Original f1: 0.2694300518134715\n",
      "0.16508243548\n",
      "0.997283540919\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 228\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8390    0.7937    0.8158       926\n",
      "          1     0.2978    0.3649    0.3279       222\n",
      "\n",
      "avg / total     0.7344    0.7108    0.7214      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7251153592617007\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38586156111929304\n",
      "Original f1: 0.3050259965337955\n",
      "0.169875947444\n",
      "0.992866689177\n",
      "417\n",
      "0.274884640738\n",
      "Number of disagreement: 288\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8636    0.7859    0.8229      1233\n",
      "          1     0.3316    0.4613    0.3859       284\n",
      "\n",
      "avg / total     0.7640    0.7251    0.7411      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.5-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.00648287849977\n",
      "0.289994248894\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7369808833223468\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3156089193825043\n",
      "Original f1: 0.3050259965337955\n",
      "0.0104119446218\n",
      "0.585709055269\n",
      "399\n",
      "0.263019116678\n",
      "Number of disagreement: 6\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8424    0.8321    0.8372      1233\n",
      "          1     0.3077    0.3239    0.3156       284\n",
      "\n",
      "avg / total     0.7423    0.7370    0.7396      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.5-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.6942508710801394\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.33648393194706994\n",
      "Original f1: 0.2694300518134715\n",
      "0.180132330361\n",
      "0.997283541215\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 255\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8419    0.7646    0.8014       926\n",
      "          1     0.2899    0.4009    0.3365       222\n",
      "\n",
      "avg / total     0.7351    0.6943    0.7115      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7132498352010547\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.375896700143472\n",
      "Original f1: 0.3050259965337955\n",
      "0.181144739245\n",
      "0.993179316758\n",
      "435\n",
      "0.286750164799\n",
      "Number of disagreement: 302\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8614    0.7713    0.8139      1233\n",
      "          1     0.3172    0.4613    0.3759       284\n",
      "\n",
      "avg / total     0.7595    0.7132    0.7319      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.5-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.27319587628865977\n",
      "Original f1: 0.2694300518134715\n",
      "0.00999948144817\n",
      "0.411289392965\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 2\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8279    0.8780    0.8522       926\n",
      "          1     0.3193    0.2387    0.2732       222\n",
      "\n",
      "avg / total     0.7295    0.7544    0.7402      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7382992748846408\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3327731092436974\n",
      "Original f1: 0.3050259965337955\n",
      "0.0174702220546\n",
      "0.763420209886\n",
      "397\n",
      "0.261700725115\n",
      "Number of disagreement: 18\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8466    0.8281    0.8372      1233\n",
      "          1     0.3183    0.3486    0.3328       284\n",
      "\n",
      "avg / total     0.7477    0.7383    0.7428      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.5-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6855400696864111\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3376146788990826\n",
      "Original f1: 0.2694300518134715\n",
      "0.19592855755\n",
      "0.997283541122\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 271\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8424    0.7505    0.7938       926\n",
      "          1     0.2848    0.4144    0.3376       222\n",
      "\n",
      "avg / total     0.7346    0.6855    0.7056      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7040210942649967\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.37552155771905427\n",
      "Original f1: 0.3050259965337955\n",
      "0.19222245411\n",
      "0.999999683971\n",
      "449\n",
      "0.295978905735\n",
      "Number of disagreement: 324\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8623    0.7567    0.8060      1233\n",
      "          1     0.3103    0.4754    0.3755       284\n",
      "\n",
      "avg / total     0.7590    0.7040    0.7254      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.5-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7621951219512195\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.32258064516129037\n",
      "Original f1: 0.2694300518134715\n",
      "0.0192883469416\n",
      "0.993264876565\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 17\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8376    0.8747    0.8558       926\n",
      "          1     0.3591    0.2928    0.3226       222\n",
      "\n",
      "avg / total     0.7451    0.7622    0.7527      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7343441001977588\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3468395461912479\n",
      "Original f1: 0.3050259965337955\n",
      "0.030200523631\n",
      "0.941206195927\n",
      "403\n",
      "0.265655899802\n",
      "Number of disagreement: 40\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8505    0.8167    0.8333      1233\n",
      "          1     0.3213    0.3768    0.3468       284\n",
      "\n",
      "avg / total     0.7514    0.7343    0.7422      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.5-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.676829268292683\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.34336283185840705\n",
      "Original f1: 0.2694300518134715\n",
      "0.20720460124\n",
      "0.99728354122\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 291\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8447    0.7343    0.7857       926\n",
      "          1     0.2828    0.4369    0.3434       222\n",
      "\n",
      "avg / total     0.7361    0.6768    0.7001      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6934739617666447\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3707713125845738\n",
      "Original f1: 0.3050259965337955\n",
      "0.201888088423\n",
      "0.999999686419\n",
      "465\n",
      "0.306526038233\n",
      "Number of disagreement: 340\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8616    0.7421    0.7974      1233\n",
      "          1     0.3011    0.4824    0.3708       284\n",
      "\n",
      "avg / total     0.7567    0.6935    0.7175      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.5-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7665505226480837\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3738317757009346\n",
      "Original f1: 0.2694300518134715\n",
      "0.0362166590226\n",
      "0.993264876474\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 42\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8493    0.8639    0.8565       926\n",
      "          1     0.3883    0.3604    0.3738       222\n",
      "\n",
      "avg / total     0.7601    0.7666    0.7632      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7317073170731707\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3970370370370371\n",
      "Original f1: 0.3050259965337955\n",
      "0.0576189310916\n",
      "0.992866688924\n",
      "407\n",
      "0.268292682927\n",
      "Number of disagreement: 98\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8668    0.7916    0.8275      1233\n",
      "          1     0.3427    0.4718    0.3970       284\n",
      "\n",
      "avg / total     0.7687    0.7317    0.7469      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.5-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6742160278745645\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.35517241379310344\n",
      "Original f1: 0.2694300518134715\n",
      "0.216626014298\n",
      "0.997283541131\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 304\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8494    0.7246    0.7821       926\n",
      "          1     0.2877    0.4640    0.3552       222\n",
      "\n",
      "avg / total     0.7408    0.6742    0.6995      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6875411997363217\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.368\n",
      "Original f1: 0.3050259965337955\n",
      "0.210573217742\n",
      "0.99999968706\n",
      "474\n",
      "0.312458800264\n",
      "Number of disagreement: 351\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8611    0.7340    0.7925      1233\n",
      "          1     0.2961    0.4859    0.3680       284\n",
      "\n",
      "avg / total     0.7553    0.6875    0.7130      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.5-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7517421602787456\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3790849673202614\n",
      "Original f1: 0.2694300518134715\n",
      "0.0569765565266\n",
      "0.993667645791\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 73\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8518    0.8380    0.8449       926\n",
      "          1     0.3671    0.3919    0.3791       222\n",
      "\n",
      "avg / total     0.7581    0.7517    0.7548      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7237969676994067\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.40057224606580827\n",
      "Original f1: 0.3050259965337955\n",
      "0.0694879325397\n",
      "0.992866688881\n",
      "419\n",
      "0.276203032301\n",
      "Number of disagreement: 122\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8693    0.7770    0.8206      1233\n",
      "          1     0.3373    0.4930    0.4006       284\n",
      "\n",
      "avg / total     0.7697    0.7238    0.7419      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.5-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6689895470383276\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.35593220338983045\n",
      "Original f1: 0.2694300518134715\n",
      "0.222430798049\n",
      "0.997283541219\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 314\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8500    0.7160    0.7773       926\n",
      "          1     0.2853    0.4730    0.3559       222\n",
      "\n",
      "avg / total     0.7408    0.6690    0.6958      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6822676334871457\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.36578947368421055\n",
      "Original f1: 0.3050259965337955\n",
      "0.215251296778\n",
      "0.99999968684\n",
      "482\n",
      "0.317732366513\n",
      "Number of disagreement: 361\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8607    0.7267    0.7880      1233\n",
      "          1     0.2920    0.4894    0.3658       284\n",
      "\n",
      "avg / total     0.7542    0.6823    0.7090      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.5-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.00426296352701\n",
      "0.364655239795\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "0.00502898005082\n",
      "0.416161461709\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.5-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7831010452961672\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.21451104100946372\n",
      "Original f1: 0.2694300518134715\n",
      "0.0740399001584\n",
      "0.557459072998\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 83\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8215    0.9341    0.8742       926\n",
      "          1     0.3579    0.1532    0.2145       222\n",
      "\n",
      "avg / total     0.7318    0.7831    0.7466      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7923533289386948\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.304635761589404\n",
      "Original f1: 0.3050259965337955\n",
      "0.0915587983098\n",
      "0.594990876749\n",
      "315\n",
      "0.207646671061\n",
      "Number of disagreement: 140\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8405    0.9189    0.8780      1233\n",
      "          1     0.4083    0.2430    0.3046       284\n",
      "\n",
      "avg / total     0.7596    0.7924    0.7706      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.5-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.00443104381335\n",
      "0.270082007596\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.307426597582038\n",
      "Original f1: 0.3050259965337955\n",
      "0.00648263772547\n",
      "0.468950535349\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 2\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8404    0.8329    0.8367      1233\n",
      "          1     0.3017    0.3134    0.3074       284\n",
      "\n",
      "avg / total     0.7396    0.7357    0.7376      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.5-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7038327526132404\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.31999999999999995\n",
      "Original f1: 0.2694300518134715\n",
      "0.170666022672\n",
      "0.997283540919\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 240\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8368    0.7862    0.8107       926\n",
      "          1     0.2878    0.3604    0.3200       222\n",
      "\n",
      "avg / total     0.7306    0.7038    0.7158      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7205009887936717\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.37829912023460416\n",
      "Original f1: 0.3050259965337955\n",
      "0.176828430643\n",
      "0.999999686953\n",
      "424\n",
      "0.279499011206\n",
      "Number of disagreement: 295\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8615    0.7818    0.8197      1233\n",
      "          1     0.3241    0.4542    0.3783       284\n",
      "\n",
      "avg / total     0.7609    0.7205    0.7371      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.5-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.0057041573931\n",
      "0.342549998708\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7363216875411998\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3127147766323024\n",
      "Original f1: 0.3050259965337955\n",
      "0.00915239020582\n",
      "0.576172021548\n",
      "400\n",
      "0.263678312459\n",
      "Number of disagreement: 5\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8417    0.8321    0.8369      1233\n",
      "          1     0.3054    0.3204    0.3127       284\n",
      "\n",
      "avg / total     0.7413    0.7363    0.7387      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.5-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6916376306620209\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.33458646616541354\n",
      "Original f1: 0.2694300518134715\n",
      "0.185416626477\n",
      "0.99728354111\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 266\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8413    0.7613    0.7993       926\n",
      "          1     0.2871    0.4009    0.3346       222\n",
      "\n",
      "avg / total     0.7341    0.6916    0.7094      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7079762689518787\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3716312056737589\n",
      "Original f1: 0.3050259965337955\n",
      "0.187765914372\n",
      "0.999999686862\n",
      "443\n",
      "0.292023731048\n",
      "Number of disagreement: 314\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8604    0.7648    0.8098      1233\n",
      "          1     0.3112    0.4613    0.3716       284\n",
      "\n",
      "avg / total     0.7576    0.7080    0.7278      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.5-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.27319587628865977\n",
      "Original f1: 0.2694300518134715\n",
      "0.00966321449172\n",
      "0.450849519253\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 2\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8279    0.8780    0.8522       926\n",
      "          1     0.3193    0.2387    0.2732       222\n",
      "\n",
      "avg / total     0.7295    0.7544    0.7402      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7369808833223468\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.327150084317032\n",
      "Original f1: 0.3050259965337955\n",
      "0.0158507654517\n",
      "0.740046808755\n",
      "399\n",
      "0.263019116678\n",
      "Number of disagreement: 16\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8452    0.8281    0.8365      1233\n",
      "          1     0.3139    0.3415    0.3272       284\n",
      "\n",
      "avg / total     0.7457    0.7370    0.7412      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.5-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.681184668989547\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.33935018050541516\n",
      "Original f1: 0.2694300518134715\n",
      "0.202525935533\n",
      "0.997283541197\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 286\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8431    0.7430    0.7899       926\n",
      "          1     0.2831    0.4234    0.3394       222\n",
      "\n",
      "avg / total     0.7348    0.6812    0.7028      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6987475280158207\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.36791147994467494\n",
      "Original f1: 0.3050259965337955\n",
      "0.198657236158\n",
      "0.999999687337\n",
      "457\n",
      "0.301252471984\n",
      "Number of disagreement: 332\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8599    0.7518    0.8023      1233\n",
      "          1     0.3030    0.4683    0.3679       284\n",
      "\n",
      "avg / total     0.7557    0.6987    0.7209      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.5-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7604529616724739\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3176178660049628\n",
      "Original f1: 0.2694300518134715\n",
      "0.0182095489202\n",
      "0.96752504741\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 17\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8366    0.8737    0.8547       926\n",
      "          1     0.3536    0.2883    0.3176       222\n",
      "\n",
      "avg / total     0.7432    0.7605    0.7509      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7350032959789057\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3409836065573771\n",
      "Original f1: 0.3050259965337955\n",
      "0.026962587677\n",
      "0.930245173023\n",
      "402\n",
      "0.264996704021\n",
      "Number of disagreement: 33\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8489    0.8200    0.8342      1233\n",
      "          1     0.3190    0.3662    0.3410       284\n",
      "\n",
      "avg / total     0.7497    0.7350    0.7418      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.5-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6742160278745645\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3506944444444444\n",
      "Original f1: 0.2694300518134715\n",
      "0.214640927716\n",
      "0.997283541201\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 306\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8476    0.7268    0.7826       926\n",
      "          1     0.2853    0.4550    0.3507       222\n",
      "\n",
      "avg / total     0.7389    0.6742    0.6990      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6882003955174687\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3616734143049933\n",
      "Original f1: 0.3050259965337955\n",
      "0.207824109863\n",
      "0.999999687295\n",
      "473\n",
      "0.311799604483\n",
      "Number of disagreement: 350\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8585    0.7380    0.7937      1233\n",
      "          1     0.2932    0.4718    0.3617       284\n",
      "\n",
      "avg / total     0.7527    0.6882    0.7128      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.5-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7639372822299652\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.35933806146572106\n",
      "Original f1: 0.2694300518134715\n",
      "0.0355406811283\n",
      "0.99366765883\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 37\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8458    0.8650    0.8553       926\n",
      "          1     0.3781    0.3423    0.3593       222\n",
      "\n",
      "avg / total     0.7554    0.7639    0.7594      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7284113381674358\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38872403560830854\n",
      "Original f1: 0.3050259965337955\n",
      "0.0557810980127\n",
      "0.993220087439\n",
      "412\n",
      "0.271588661833\n",
      "Number of disagreement: 97\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8642    0.7899    0.8254      1233\n",
      "          1     0.3359    0.4613    0.3887       284\n",
      "\n",
      "avg / total     0.7653    0.7284    0.7437      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.5-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6637630662020906\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3457627118644068\n",
      "Original f1: 0.2694300518134715\n",
      "0.222941321023\n",
      "0.997283541195\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 318\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8462    0.7127    0.7737       926\n",
      "          1     0.2772    0.4595    0.3458       222\n",
      "\n",
      "avg / total     0.7361    0.6638    0.6910      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.6842452208305867\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.36218375499334216\n",
      "Original f1: 0.3050259965337955\n",
      "0.215005610826\n",
      "0.999999687359\n",
      "479\n",
      "0.315754779169\n",
      "Number of disagreement: 360\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8590    0.7315    0.7902      1233\n",
      "          1     0.2912    0.4789    0.3622       284\n",
      "\n",
      "avg / total     0.7527    0.6842    0.7101      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.5-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7508710801393729\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.38095238095238093\n",
      "Original f1: 0.2694300518134715\n",
      "0.0576562489033\n",
      "0.993667658871\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 76\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8524    0.8359    0.8441       926\n",
      "          1     0.3667    0.3964    0.3810       222\n",
      "\n",
      "avg / total     0.7585    0.7509    0.7545      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7237969676994067\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3953823953823954\n",
      "Original f1: 0.3050259965337955\n",
      "0.0673353359198\n",
      "0.999999685604\n",
      "419\n",
      "0.276203032301\n",
      "Number of disagreement: 116\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8673    0.7794    0.8210      1233\n",
      "          1     0.3350    0.4824    0.3954       284\n",
      "\n",
      "avg / total     0.7677    0.7238    0.7413      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-1.5-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6602787456445993\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3521594684385382\n",
      "Original f1: 0.2694300518134715\n",
      "0.228522822428\n",
      "0.99999989503\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 328\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8490    0.7041    0.7698       926\n",
      "          1     0.2789    0.4775    0.3522       222\n",
      "\n",
      "avg / total     0.7387    0.6603    0.6890      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6763348714568227\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3581699346405229\n",
      "Original f1: 0.3050259965337955\n",
      "0.219504785444\n",
      "0.9999996874\n",
      "491\n",
      "0.323665128543\n",
      "Number of disagreement: 370\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8581    0.7210    0.7836      1233\n",
      "          1     0.2848    0.4824    0.3582       284\n",
      "\n",
      "avg / total     0.7508    0.6763    0.7040      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-2.0-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.00511523030893\n",
      "0.385462134141\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "0.00548707227696\n",
      "0.355915537074\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-2.0-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7804878048780488\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.21739130434782605\n",
      "Original f1: 0.2694300518134715\n",
      "0.0703091070848\n",
      "0.558788491026\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 78\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8216    0.9298    0.8723       926\n",
      "          1     0.3500    0.1577    0.2174       222\n",
      "\n",
      "avg / total     0.7304    0.7805    0.7457      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7936717205009888\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.31208791208791203\n",
      "Original f1: 0.3050259965337955\n",
      "0.08865588878\n",
      "0.548805233469\n",
      "313\n",
      "0.206328279499\n",
      "Number of disagreement: 138\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9189    0.8786      1233\n",
      "          1     0.4152    0.2500    0.3121       284\n",
      "\n",
      "avg / total     0.7619    0.7937    0.7726      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-2.0-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.00539864804407\n",
      "0.293745994694\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7363216875411998\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3103448275862069\n",
      "Original f1: 0.3050259965337955\n",
      "0.00730441898083\n",
      "0.447192618576\n",
      "400\n",
      "0.263678312459\n",
      "Number of disagreement: 3\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8411    0.8329    0.8370      1233\n",
      "          1     0.3041    0.3169    0.3103       284\n",
      "\n",
      "avg / total     0.7406    0.7363    0.7384      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-2.0-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7029616724738676\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.32475247524752476\n",
      "Original f1: 0.2694300518134715\n",
      "0.167951268188\n",
      "0.997283541092\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 235\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8382    0.7829    0.8096       926\n",
      "          1     0.2898    0.3694    0.3248       222\n",
      "\n",
      "avg / total     0.7321    0.7030    0.7158      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7231377719182597\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3823529411764705\n",
      "Original f1: 0.3050259965337955\n",
      "0.173172819402\n",
      "0.992866688749\n",
      "420\n",
      "0.276862228082\n",
      "Number of disagreement: 293\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8626    0.7843    0.8216      1233\n",
      "          1     0.3283    0.4577    0.3824       284\n",
      "\n",
      "avg / total     0.7626    0.7231    0.7394      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-2.0-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.00662984673277\n",
      "0.317585712027\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7369808833223468\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3156089193825043\n",
      "Original f1: 0.3050259965337955\n",
      "0.0101751223152\n",
      "0.579356416234\n",
      "399\n",
      "0.263019116678\n",
      "Number of disagreement: 6\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8424    0.8321    0.8372      1233\n",
      "          1     0.3077    0.3239    0.3156       284\n",
      "\n",
      "avg / total     0.7423    0.7370    0.7396      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-2.0-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6872822299651568\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.33147113594040967\n",
      "Original f1: 0.2694300518134715\n",
      "0.183705652373\n",
      "0.997283541173\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 261\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8403    0.7559    0.7959       926\n",
      "          1     0.2825    0.4009    0.3315       222\n",
      "\n",
      "avg / total     0.7325    0.6873    0.7061      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7112722478576137\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3742857142857143\n",
      "Original f1: 0.3050259965337955\n",
      "0.184530448472\n",
      "0.993179305077\n",
      "438\n",
      "0.288727752142\n",
      "Number of disagreement: 309\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8610    0.7689    0.8123      1233\n",
      "          1     0.3149    0.4613    0.3743       284\n",
      "\n",
      "avg / total     0.7588    0.7113    0.7303      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-2.0-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.27319587628865977\n",
      "Original f1: 0.2694300518134715\n",
      "0.0100835162968\n",
      "0.41814395725\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 2\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8279    0.8780    0.8522       926\n",
      "          1     0.3193    0.2387    0.2732       222\n",
      "\n",
      "avg / total     0.7295    0.7544    0.7402      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7376400791034937\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.33221476510067116\n",
      "Original f1: 0.3050259965337955\n",
      "0.0173656990541\n",
      "0.762039626387\n",
      "398\n",
      "0.262359920897\n",
      "Number of disagreement: 19\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8465    0.8273    0.8368      1233\n",
      "          1     0.3173    0.3486    0.3322       284\n",
      "\n",
      "avg / total     0.7474    0.7376    0.7423      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-2.0-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6750871080139372\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3303411131059246\n",
      "Original f1: 0.2694300518134715\n",
      "0.19980751325\n",
      "0.997283541191\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 281\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8401    0.7376    0.7855       926\n",
      "          1     0.2746    0.4144    0.3303       222\n",
      "\n",
      "avg / total     0.7307    0.6751    0.6975      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7013843111404087\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3699582753824756\n",
      "Original f1: 0.3050259965337955\n",
      "0.195026437108\n",
      "0.999999686149\n",
      "453\n",
      "0.29861568886\n",
      "Number of disagreement: 326\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8604    0.7551    0.8043      1233\n",
      "          1     0.3057    0.4683    0.3700       284\n",
      "\n",
      "avg / total     0.7566    0.7014    0.7230      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-2.0-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7604529616724739\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3176178660049628\n",
      "Original f1: 0.2694300518134715\n",
      "0.019089546532\n",
      "0.99326487649\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 17\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8366    0.8737    0.8547       926\n",
      "          1     0.3536    0.2883    0.3176       222\n",
      "\n",
      "avg / total     0.7432    0.7605    0.7509      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7330257086354647\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.34782608695652173\n",
      "Original f1: 0.3050259965337955\n",
      "0.0298322489743\n",
      "0.941206198472\n",
      "405\n",
      "0.266974291365\n",
      "Number of disagreement: 44\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8508    0.8143    0.8322      1233\n",
      "          1     0.3205    0.3803    0.3478       284\n",
      "\n",
      "avg / total     0.7516    0.7330    0.7415      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-2.0-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6698606271777003\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.34542314335060453\n",
      "Original f1: 0.2694300518134715\n",
      "0.211289857878\n",
      "0.997283541129\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 303\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8458    0.7225    0.7793       926\n",
      "          1     0.2801    0.4505    0.3454       222\n",
      "\n",
      "avg / total     0.7364    0.6699    0.6954      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6914963744232037\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.36585365853658536\n",
      "Original f1: 0.3050259965337955\n",
      "0.205148390858\n",
      "0.999999687367\n",
      "468\n",
      "0.308503625577\n",
      "Number of disagreement: 345\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8598    0.7413    0.7962      1233\n",
      "          1     0.2974    0.4754    0.3659       284\n",
      "\n",
      "avg / total     0.7545    0.6915    0.7156      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-2.0-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3691588785046729\n",
      "Original f1: 0.2694300518134715\n",
      "0.0361133905694\n",
      "0.993264876313\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 42\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8482    0.8629    0.8555       926\n",
      "          1     0.3835    0.3559    0.3692       222\n",
      "\n",
      "avg / total     0.7583    0.7648    0.7614      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7284113381674358\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.392330383480826\n",
      "Original f1: 0.3050259965337955\n",
      "0.0581760720707\n",
      "0.992866689058\n",
      "412\n",
      "0.271588661833\n",
      "Number of disagreement: 101\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8655    0.7883    0.8251      1233\n",
      "          1     0.3376    0.4683    0.3923       284\n",
      "\n",
      "avg / total     0.7667    0.7284    0.7441      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-2.0-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6646341463414634\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3507588532883642\n",
      "Original f1: 0.2694300518134715\n",
      "0.220588028423\n",
      "0.997283541208\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 313\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8481    0.7117    0.7739       926\n",
      "          1     0.2803    0.4685    0.3508       222\n",
      "\n",
      "avg / total     0.7383    0.6646    0.6921      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6816084377059987\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.36026490066225164\n",
      "Original f1: 0.3050259965337955\n",
      "0.214100135267\n",
      "0.999999686673\n",
      "483\n",
      "0.318391562294\n",
      "Number of disagreement: 360\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8585    0.7283    0.7881      1233\n",
      "          1     0.2887    0.4789    0.3603       284\n",
      "\n",
      "avg / total     0.7518    0.6816    0.7080      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-2.0-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7508710801393729\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3782608695652174\n",
      "Original f1: 0.2694300518134715\n",
      "0.0575087815704\n",
      "0.996912514842\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 74\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8516    0.8369    0.8442       926\n",
      "          1     0.3655    0.3919    0.3783       222\n",
      "\n",
      "avg / total     0.7576    0.7509    0.7541      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7224785761371127\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.39942938659058486\n",
      "Original f1: 0.3050259965337955\n",
      "0.0701418806273\n",
      "0.992866689208\n",
      "421\n",
      "0.277521423863\n",
      "Number of disagreement: 124\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8691    0.7753    0.8195      1233\n",
      "          1     0.3357    0.4930    0.3994       284\n",
      "\n",
      "avg / total     0.7692    0.7225    0.7409      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-2.0-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.662020905923345\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3533333333333333\n",
      "Original f1: 0.2694300518134715\n",
      "0.226291695075\n",
      "0.998870207032\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 320\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8494    0.7063    0.7712       926\n",
      "          1     0.2804    0.4775    0.3533       222\n",
      "\n",
      "avg / total     0.7393    0.6620    0.6904      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6763348714568227\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3581699346405229\n",
      "Original f1: 0.3050259965337955\n",
      "0.218047967449\n",
      "0.999999687193\n",
      "491\n",
      "0.323665128543\n",
      "Number of disagreement: 370\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8581    0.7210    0.7836      1233\n",
      "          1     0.2848    0.4824    0.3582       284\n",
      "\n",
      "avg / total     0.7508    0.6763    0.7040      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-2.0-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.00444397354314\n",
      "0.362024953156\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3050259965337955\n",
      "Original f1: 0.3050259965337955\n",
      "0.00490333664854\n",
      "0.373627807159\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-2.0-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7831010452961672\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.21451104100946372\n",
      "Original f1: 0.2694300518134715\n",
      "0.074467108394\n",
      "0.559623854175\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 81\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8215    0.9341    0.8742       926\n",
      "          1     0.3579    0.1532    0.2145       222\n",
      "\n",
      "avg / total     0.7318    0.7831    0.7466      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7877389584706658\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.28125\n",
      "Original f1: 0.3050259965337955\n",
      "0.09229890326\n",
      "0.552421679822\n",
      "322\n",
      "0.212261041529\n",
      "Number of disagreement: 143\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8367    0.9181    0.8755      1233\n",
      "          1     0.3841    0.2218    0.2812       284\n",
      "\n",
      "avg / total     0.7519    0.7877    0.7642      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-2.0-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.0046407613285\n",
      "0.284334198438\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7350032959789057\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3044982698961938\n",
      "Original f1: 0.3050259965337955\n",
      "0.00631070852776\n",
      "0.461170317797\n",
      "402\n",
      "0.264996704021\n",
      "Number of disagreement: 1\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8397    0.8329    0.8363      1233\n",
      "          1     0.2993    0.3099    0.3045       284\n",
      "\n",
      "avg / total     0.7386    0.7350    0.7368      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-2.0-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6968641114982579\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3176470588235294\n",
      "Original f1: 0.2694300518134715\n",
      "0.173955357663\n",
      "0.99728354118\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 246\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8360    0.7765    0.8052       926\n",
      "          1     0.2812    0.3649    0.3176       222\n",
      "\n",
      "avg / total     0.7288    0.6969    0.7109      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7073170731707317\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3602305475504323\n",
      "Original f1: 0.3050259965337955\n",
      "0.18065529407\n",
      "0.999999686575\n",
      "444\n",
      "0.292682926829\n",
      "Number of disagreement: 311\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8564    0.7689    0.8103      1233\n",
      "          1     0.3049    0.4401    0.3602       284\n",
      "\n",
      "avg / total     0.7531    0.7073    0.7260      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-2.0-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2694300518134715\n",
      "Original f1: 0.2694300518134715\n",
      "0.00592259096724\n",
      "0.349059662383\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7363216875411998\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3127147766323024\n",
      "Original f1: 0.3050259965337955\n",
      "0.00895745687406\n",
      "0.568877916299\n",
      "400\n",
      "0.263678312459\n",
      "Number of disagreement: 5\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8417    0.8321    0.8369      1233\n",
      "          1     0.3054    0.3204    0.3127       284\n",
      "\n",
      "avg / total     0.7413    0.7363    0.7387      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-2.0-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6820557491289199\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.32532347504621073\n",
      "Original f1: 0.2694300518134715\n",
      "0.189832606426\n",
      "0.997283541109\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 275\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8384    0.7505    0.7920       926\n",
      "          1     0.2759    0.3964    0.3253       222\n",
      "\n",
      "avg / total     0.7296    0.6821    0.7018      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6967699406723797\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3539325842696629\n",
      "Original f1: 0.3050259965337955\n",
      "0.191778167535\n",
      "0.999999687114\n",
      "460\n",
      "0.303230059328\n",
      "Number of disagreement: 327\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8549    0.7551    0.8019      1233\n",
      "          1     0.2944    0.4437    0.3539       284\n",
      "\n",
      "avg / total     0.7500    0.6968    0.7180      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-2.0-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.27319587628865977\n",
      "Original f1: 0.2694300518134715\n",
      "0.0097486101412\n",
      "0.478185824648\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 2\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8279    0.8780    0.8522       926\n",
      "          1     0.3193    0.2387    0.2732       222\n",
      "\n",
      "avg / total     0.7295    0.7544    0.7402      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7369808833223468\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.327150084317032\n",
      "Original f1: 0.3050259965337955\n",
      "0.01572418352\n",
      "0.733921577578\n",
      "399\n",
      "0.263019116678\n",
      "Number of disagreement: 16\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8452    0.8281    0.8365      1233\n",
      "          1     0.3139    0.3415    0.3272       284\n",
      "\n",
      "avg / total     0.7457    0.7370    0.7412      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-2.0-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6698606271777003\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3292035398230088\n",
      "Original f1: 0.2694300518134715\n",
      "0.207540894713\n",
      "0.997283541155\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 297\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8398    0.7300    0.7811       926\n",
      "          1     0.2711    0.4189    0.3292       222\n",
      "\n",
      "avg / total     0.7298    0.6699    0.6937      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6895187870797627\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3521320495185694\n",
      "Original f1: 0.3050259965337955\n",
      "0.202242421712\n",
      "0.999999687316\n",
      "471\n",
      "0.31048121292\n",
      "Number of disagreement: 342\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8547    0.7445    0.7958      1233\n",
      "          1     0.2889    0.4507    0.3521       284\n",
      "\n",
      "avg / total     0.7488    0.6895    0.7128      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-2.0-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.759581881533101\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3134328358208955\n",
      "Original f1: 0.2694300518134715\n",
      "0.0177274045813\n",
      "0.812055105288\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 16\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8357    0.8737    0.8543       926\n",
      "          1     0.3500    0.2838    0.3134       222\n",
      "\n",
      "avg / total     0.7418    0.7596    0.7497      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7350032959789057\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3431372549019608\n",
      "Original f1: 0.3050259965337955\n",
      "0.0267098396012\n",
      "0.922444833043\n",
      "402\n",
      "0.264996704021\n",
      "Number of disagreement: 35\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8495    0.8191    0.8340      1233\n",
      "          1     0.3201    0.3697    0.3431       284\n",
      "\n",
      "avg / total     0.7504    0.7350    0.7421      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-2.0-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.6559233449477352\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3293718166383701\n",
      "Original f1: 0.2694300518134715\n",
      "0.219210295069\n",
      "0.997283541189\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 317\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.7084    0.7686       926\n",
      "          1     0.2643    0.4369    0.3294       222\n",
      "\n",
      "avg / total     0.7286    0.6559    0.6837      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6796308503625577\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.34852546916890087\n",
      "Original f1: 0.3050259965337955\n",
      "0.211884348418\n",
      "0.999999687399\n",
      "486\n",
      "0.320369149637\n",
      "Number of disagreement: 361\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8540    0.7307    0.7876      1233\n",
      "          1     0.2814    0.4577    0.3485       284\n",
      "\n",
      "avg / total     0.7468    0.6796    0.7054      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-2.0-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7630662020905923\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.35849056603773594\n",
      "Original f1: 0.2694300518134715\n",
      "0.0356317060429\n",
      "0.993667658668\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 38\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8457    0.8639    0.8547       926\n",
      "          1     0.3762    0.3423    0.3585       222\n",
      "\n",
      "avg / total     0.7549    0.7631    0.7587      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7257745550428477\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3864306784660767\n",
      "Original f1: 0.3050259965337955\n",
      "0.0561623156127\n",
      "0.999999683229\n",
      "416\n",
      "0.274225444957\n",
      "Number of disagreement: 101\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8638    0.7867    0.8234      1233\n",
      "          1     0.3325    0.4613    0.3864       284\n",
      "\n",
      "avg / total     0.7643    0.7258    0.7416      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-2.0-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6472125435540069\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.33278418451400327\n",
      "Original f1: 0.2694300518134715\n",
      "0.227648171502\n",
      "0.999999896732\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 331\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8414    0.6933    0.7602       926\n",
      "          1     0.2623    0.4550    0.3328       222\n",
      "\n",
      "avg / total     0.7294    0.6472    0.6776      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6723796967699407\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3451910408432148\n",
      "Original f1: 0.3050259965337955\n",
      "0.218559148255\n",
      "0.999999687397\n",
      "497\n",
      "0.32762030323\n",
      "Number of disagreement: 372\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8532    0.7210    0.7815      1233\n",
      "          1     0.2758    0.4613    0.3452       284\n",
      "\n",
      "avg / total     0.7451    0.6724    0.6998      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-2.0-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7491289198606271\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.37662337662337664\n",
      "Original f1: 0.2694300518134715\n",
      "0.0577904977452\n",
      "0.99366765832\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 76\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8513    0.8348    0.8430       926\n",
      "          1     0.3625    0.3919    0.3766       222\n",
      "\n",
      "avg / total     0.7568    0.7491    0.7528      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7218193803559657\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3919308357348703\n",
      "Original f1: 0.3050259965337955\n",
      "0.0679742379847\n",
      "0.999999686594\n",
      "422\n",
      "0.278180619644\n",
      "Number of disagreement: 117\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8663    0.7778    0.8197      1233\n",
      "          1     0.3317    0.4789    0.3919       284\n",
      "\n",
      "avg / total     0.7662    0.7218    0.7396      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.0-2.0-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6489547038327527\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3447154471544715\n",
      "Original f1: 0.2694300518134715\n",
      "0.233014349807\n",
      "0.999999896781\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 339\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8464    0.6901    0.7603       926\n",
      "          1     0.2697    0.4775    0.3447       222\n",
      "\n",
      "avg / total     0.7348    0.6490    0.6799      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6664469347396177\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.34285714285714286\n",
      "Original f1: 0.3050259965337955\n",
      "0.222784951553\n",
      "0.999999687417\n",
      "506\n",
      "0.33355306526\n",
      "Number of disagreement: 381\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8526    0.7129    0.7765      1233\n",
      "          1     0.2716    0.4648    0.3429       284\n",
      "\n",
      "avg / total     0.7438    0.6664    0.6953      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.5-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7848432055749129\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2492401215805471\n",
      "Original f1: 0.2694300518134715\n",
      "0.0250515151554\n",
      "0.562676103078\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 59\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8261    0.9287    0.8744       926\n",
      "          1     0.3832    0.1847    0.2492       222\n",
      "\n",
      "avg / total     0.7405    0.7848    0.7535      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7686222808174028\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.267223382045929\n",
      "Original f1: 0.3050259965337955\n",
      "0.032692228193\n",
      "0.624635523643\n",
      "351\n",
      "0.231377719183\n",
      "Number of disagreement: 110\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8336    0.8938    0.8626      1233\n",
      "          1     0.3282    0.2254    0.2672       284\n",
      "\n",
      "avg / total     0.7390    0.7686    0.7512      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.5-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7970383275261324\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.1993127147766323\n",
      "Original f1: 0.2694300518134715\n",
      "0.101342049701\n",
      "0.707154840808\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 113\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8211    0.9568    0.8838       926\n",
      "          1     0.4203    0.1306    0.1993       222\n",
      "\n",
      "avg / total     0.7436    0.7970    0.7514      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7969676994067239\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.24878048780487808\n",
      "Original f1: 0.3050259965337955\n",
      "0.116489396108\n",
      "0.817790679174\n",
      "308\n",
      "0.203032300593\n",
      "Number of disagreement: 209\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8325    0.9392    0.8826      1233\n",
      "          1     0.4048    0.1796    0.2488       284\n",
      "\n",
      "avg / total     0.7524    0.7970    0.7640      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.5-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7848432055749129\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.271386430678466\n",
      "Original f1: 0.2694300518134715\n",
      "0.0253806826386\n",
      "0.491803623229\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 57\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8293    0.9233    0.8738       926\n",
      "          1     0.3932    0.2072    0.2714       222\n",
      "\n",
      "avg / total     0.7450    0.7848    0.7573      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7686222808174028\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.30495049504950494\n",
      "Original f1: 0.3050259965337955\n",
      "0.0345686759344\n",
      "0.624635523643\n",
      "351\n",
      "0.231377719183\n",
      "Number of disagreement: 106\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8403    0.8832    0.8612      1233\n",
      "          1     0.3484    0.2711    0.3050       284\n",
      "\n",
      "avg / total     0.7482    0.7686    0.7571      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.5-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7831010452961672\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.35989717223650386\n",
      "Original f1: 0.2694300518134715\n",
      "0.154322804765\n",
      "0.993264876402\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 183\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8451    0.8952    0.8694       926\n",
      "          1     0.4192    0.3153    0.3599       222\n",
      "\n",
      "avg / total     0.7627    0.7831    0.7709      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7679630850362558\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.34328358208955223\n",
      "Original f1: 0.3050259965337955\n",
      "0.156035415778\n",
      "0.979195607329\n",
      "352\n",
      "0.232036914964\n",
      "Number of disagreement: 287\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8482    0.8702    0.8591      1233\n",
      "          1     0.3651    0.3239    0.3433       284\n",
      "\n",
      "avg / total     0.7578    0.7680    0.7625      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.5-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7848432055749129\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2756598240469208\n",
      "Original f1: 0.2694300518134715\n",
      "0.0264259182653\n",
      "0.52642268719\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 57\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8299    0.9222    0.8737       926\n",
      "          1     0.3950    0.2117    0.2757       222\n",
      "\n",
      "avg / total     0.7458    0.7848    0.7580      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7633487145682267\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3001949317738792\n",
      "Original f1: 0.3050259965337955\n",
      "0.0362583181758\n",
      "0.624635523643\n",
      "359\n",
      "0.236651285432\n",
      "Number of disagreement: 110\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8393    0.8767    0.8576      1233\n",
      "          1     0.3362    0.2711    0.3002       284\n",
      "\n",
      "avg / total     0.7451    0.7633    0.7532      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.5-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7787456445993032\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.37438423645320196\n",
      "Original f1: 0.2694300518134715\n",
      "0.166131220182\n",
      "0.99326487646\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 200\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8485    0.8834    0.8656       926\n",
      "          1     0.4130    0.3423    0.3744       222\n",
      "\n",
      "avg / total     0.7643    0.7787    0.7706      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7646671061305208\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.35443037974683544\n",
      "Original f1: 0.3050259965337955\n",
      "0.165428711019\n",
      "0.993179313512\n",
      "357\n",
      "0.235332893869\n",
      "Number of disagreement: 296\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8510    0.8613    0.8561      1233\n",
      "          1     0.3643    0.3451    0.3544       284\n",
      "\n",
      "avg / total     0.7599    0.7647    0.7622      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.5-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7839721254355401\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.27485380116959063\n",
      "Original f1: 0.2694300518134715\n",
      "0.0289712024293\n",
      "0.578677284466\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 56\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8298    0.9212    0.8731       926\n",
      "          1     0.3917    0.2117    0.2749       222\n",
      "\n",
      "avg / total     0.7450    0.7840    0.7574      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7626895187870798\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.30769230769230765\n",
      "Original f1: 0.3050259965337955\n",
      "0.0407076981884\n",
      "0.744694330193\n",
      "360\n",
      "0.237310481213\n",
      "Number of disagreement: 117\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8407    0.8735    0.8568      1233\n",
      "          1     0.3390    0.2817    0.3077       284\n",
      "\n",
      "avg / total     0.7468    0.7627    0.7540      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.5-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7674216027874564\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.37762237762237766\n",
      "Original f1: 0.2694300518134715\n",
      "0.179561334444\n",
      "0.993264876509\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 223\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8502    0.8639    0.8570       926\n",
      "          1     0.3913    0.3649    0.3776       222\n",
      "\n",
      "avg / total     0.7614    0.7674    0.7643      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7574159525379037\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3588850174216028\n",
      "Original f1: 0.3050259965337955\n",
      "0.174570050073\n",
      "0.993179320039\n",
      "368\n",
      "0.242584047462\n",
      "Number of disagreement: 309\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8525    0.8483    0.8504      1233\n",
      "          1     0.3552    0.3627    0.3589       284\n",
      "\n",
      "avg / total     0.7594    0.7574    0.7584      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.5-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7935540069686411\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.33613445378151263\n",
      "Original f1: 0.2694300518134715\n",
      "0.0370898817854\n",
      "0.993264872962\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 71\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8401    0.9190    0.8778       926\n",
      "          1     0.4444    0.2703    0.3361       222\n",
      "\n",
      "avg / total     0.7636    0.7936    0.7730      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7673038892551087\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3450834879406308\n",
      "Original f1: 0.3050259965337955\n",
      "0.0530441518719\n",
      "0.959584896701\n",
      "353\n",
      "0.232696110745\n",
      "Number of disagreement: 136\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8487    0.8686    0.8585      1233\n",
      "          1     0.3647    0.3275    0.3451       284\n",
      "\n",
      "avg / total     0.7581    0.7673    0.7624      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.5-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7621951219512195\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.380952380952381\n",
      "Original f1: 0.2694300518134715\n",
      "0.189295552155\n",
      "0.996912524593\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 235\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8515    0.8542    0.8528       926\n",
      "          1     0.3836    0.3784    0.3810       222\n",
      "\n",
      "avg / total     0.7610    0.7622    0.7616      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7521423862887278\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3691275167785235\n",
      "Original f1: 0.3050259965337955\n",
      "0.183418248662\n",
      "0.99999968641\n",
      "376\n",
      "0.247857613711\n",
      "Number of disagreement: 329\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8556    0.8362    0.8458      1233\n",
      "          1     0.3526    0.3873    0.3691       284\n",
      "\n",
      "avg / total     0.7614    0.7521    0.7565      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.5-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7918118466898955\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3557951482479784\n",
      "Original f1: 0.2694300518134715\n",
      "0.0487398119359\n",
      "0.993264876203\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 83\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8438    0.9104    0.8758       926\n",
      "          1     0.4430    0.2973    0.3558       222\n",
      "\n",
      "avg / total     0.7663    0.7918    0.7753      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7673038892551087\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3662477558348295\n",
      "Original f1: 0.3050259965337955\n",
      "0.063846988421\n",
      "0.962421878722\n",
      "353\n",
      "0.232696110745\n",
      "Number of disagreement: 152\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8537    0.8613    0.8575      1233\n",
      "          1     0.3736    0.3592    0.3662       284\n",
      "\n",
      "avg / total     0.7638    0.7673    0.7655      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.5-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7587108013937283\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3912087912087912\n",
      "Original f1: 0.2694300518134715\n",
      "0.197496854783\n",
      "0.996912527535\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 249\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8546    0.8445    0.8495       926\n",
      "          1     0.3820    0.4009    0.3912       222\n",
      "\n",
      "avg / total     0.7632    0.7587    0.7609      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7462096242584048\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.369885433715221\n",
      "Original f1: 0.3050259965337955\n",
      "0.189754590055\n",
      "0.999999686891\n",
      "385\n",
      "0.253790375742\n",
      "Number of disagreement: 340\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8563    0.8264    0.8411      1233\n",
      "          1     0.3456    0.3979    0.3699       284\n",
      "\n",
      "avg / total     0.7607    0.7462    0.7529      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.5-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.789198606271777\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3826530612244898\n",
      "Original f1: 0.2694300518134715\n",
      "0.0613705529664\n",
      "0.993264876553\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 102\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8497    0.8974    0.8729       926\n",
      "          1     0.4412    0.3378    0.3827       222\n",
      "\n",
      "avg / total     0.7707    0.7892    0.7781      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7653263019116677\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3797909407665505\n",
      "Original f1: 0.3050259965337955\n",
      "0.0716006955027\n",
      "0.993179319064\n",
      "356\n",
      "0.234673698088\n",
      "Number of disagreement: 169\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8574    0.8532    0.8553      1233\n",
      "          1     0.3759    0.3838    0.3798       284\n",
      "\n",
      "avg / total     0.7672    0.7653    0.7663      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.5-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7534843205574913\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3965884861407249\n",
      "Original f1: 0.2694300518134715\n",
      "0.207717565948\n",
      "0.996912528268\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 261\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8568    0.8337    0.8451       926\n",
      "          1     0.3765    0.4189    0.3966       222\n",
      "\n",
      "avg / total     0.7639    0.7535    0.7584      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7363216875411998\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.36708860759493667\n",
      "Original f1: 0.3050259965337955\n",
      "0.195811141567\n",
      "0.999999686859\n",
      "400\n",
      "0.263678312459\n",
      "Number of disagreement: 355\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8563    0.8118    0.8335      1233\n",
      "          1     0.3333    0.4085    0.3671       284\n",
      "\n",
      "avg / total     0.7584    0.7363    0.7462      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.5-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7839721254355401\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.24848484848484848\n",
      "Original f1: 0.2694300518134715\n",
      "0.0244613921666\n",
      "0.562031030588\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 58\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8260    0.9276    0.8739       926\n",
      "          1     0.3796    0.1847    0.2485       222\n",
      "\n",
      "avg / total     0.7396    0.7840    0.7529      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7666446934739618\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.26556016597510373\n",
      "Original f1: 0.3050259965337955\n",
      "0.0320639220839\n",
      "0.624636078754\n",
      "354\n",
      "0.233355306526\n",
      "Number of disagreement: 107\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8332    0.8913    0.8613      1233\n",
      "          1     0.3232    0.2254    0.2656       284\n",
      "\n",
      "avg / total     0.7377    0.7666    0.7498      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.5-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7970383275261324\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.1993127147766323\n",
      "Original f1: 0.2694300518134715\n",
      "0.102479962135\n",
      "0.709882324796\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 113\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8211    0.9568    0.8838       926\n",
      "          1     0.4203    0.1306    0.1993       222\n",
      "\n",
      "avg / total     0.7436    0.7970    0.7514      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7996044825313118\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.2621359223300971\n",
      "Original f1: 0.3050259965337955\n",
      "0.117113462502\n",
      "0.817349001459\n",
      "304\n",
      "0.200395517469\n",
      "Number of disagreement: 209\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8344    0.9400    0.8841      1233\n",
      "          1     0.4219    0.1901    0.2621       284\n",
      "\n",
      "avg / total     0.7572    0.7996    0.7676      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.5-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7839721254355401\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2705882352941177\n",
      "Original f1: 0.2694300518134715\n",
      "0.024713985402\n",
      "0.49220443965\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 56\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8291    0.9222    0.8732       926\n",
      "          1     0.3898    0.2072    0.2706       222\n",
      "\n",
      "avg / total     0.7442    0.7840    0.7567      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7679630850362558\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.30434782608695654\n",
      "Original f1: 0.3050259965337955\n",
      "0.0340150598103\n",
      "0.624636078754\n",
      "352\n",
      "0.232036914964\n",
      "Number of disagreement: 105\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8402    0.8824    0.8608      1233\n",
      "          1     0.3468    0.2711    0.3043       284\n",
      "\n",
      "avg / total     0.7478    0.7680    0.7566      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.5-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7839721254355401\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36410256410256414\n",
      "Original f1: 0.2694300518134715\n",
      "0.155213015136\n",
      "0.993264876516\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 184\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8459    0.8952    0.8699       926\n",
      "          1     0.4226    0.3198    0.3641       222\n",
      "\n",
      "avg / total     0.7641    0.7840    0.7721      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7712590639419907\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3538175046554935\n",
      "Original f1: 0.3050259965337955\n",
      "0.157234068503\n",
      "0.979195607399\n",
      "347\n",
      "0.228740936058\n",
      "Number of disagreement: 284\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8505    0.8719    0.8610      1233\n",
      "          1     0.3755    0.3345    0.3538       284\n",
      "\n",
      "avg / total     0.7616    0.7713    0.7661      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.5-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7848432055749129\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2756598240469208\n",
      "Original f1: 0.2694300518134715\n",
      "0.0257990402087\n",
      "0.504063070427\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 55\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8299    0.9222    0.8737       926\n",
      "          1     0.3950    0.2117    0.2757       222\n",
      "\n",
      "avg / total     0.7458    0.7848    0.7580      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7633487145682267\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3001949317738792\n",
      "Original f1: 0.3050259965337955\n",
      "0.0359068577462\n",
      "0.624636078754\n",
      "359\n",
      "0.236651285432\n",
      "Number of disagreement: 108\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8393    0.8767    0.8576      1233\n",
      "          1     0.3362    0.2711    0.3002       284\n",
      "\n",
      "avg / total     0.7451    0.7633    0.7532      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.5-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7778745644599303\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3765281173594132\n",
      "Original f1: 0.2694300518134715\n",
      "0.167313221351\n",
      "0.993264876458\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 203\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8491    0.8812    0.8649       926\n",
      "          1     0.4118    0.3468    0.3765       222\n",
      "\n",
      "avg / total     0.7645    0.7779    0.7704      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7673038892551087\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3593466424682395\n",
      "Original f1: 0.3050259965337955\n",
      "0.16652655031\n",
      "0.992866677066\n",
      "353\n",
      "0.232696110745\n",
      "Number of disagreement: 296\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8520    0.8637    0.8578      1233\n",
      "          1     0.3708    0.3486    0.3593       284\n",
      "\n",
      "avg / total     0.7619    0.7673    0.7645      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.5-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7839721254355401\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2832369942196532\n",
      "Original f1: 0.2694300518134715\n",
      "0.0285288603699\n",
      "0.561572566051\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 58\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8311    0.9190    0.8728       926\n",
      "          1     0.3952    0.2207    0.2832       222\n",
      "\n",
      "avg / total     0.7468    0.7840    0.7588      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7620303230059328\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3071017274472169\n",
      "Original f1: 0.3050259965337955\n",
      "0.0405084702027\n",
      "0.744694330193\n",
      "361\n",
      "0.237969676994\n",
      "Number of disagreement: 114\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8406    0.8727    0.8563      1233\n",
      "          1     0.3376    0.2817    0.3071       284\n",
      "\n",
      "avg / total     0.7464    0.7620    0.7535      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.5-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7682926829268293\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3755868544600939\n",
      "Original f1: 0.2694300518134715\n",
      "0.180734885972\n",
      "0.993264876499\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 220\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8496    0.8661    0.8578       926\n",
      "          1     0.3922    0.3604    0.3756       222\n",
      "\n",
      "avg / total     0.7611    0.7683    0.7645      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7600527356624918\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3636363636363636\n",
      "Original f1: 0.3050259965337955\n",
      "0.175564556344\n",
      "0.999999678284\n",
      "364\n",
      "0.239947264338\n",
      "Number of disagreement: 307\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8535    0.8508    0.8522      1233\n",
      "          1     0.3611    0.3662    0.3636       284\n",
      "\n",
      "avg / total     0.7614    0.7601    0.7607      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.5-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7909407665505227\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3296089385474861\n",
      "Original f1: 0.2694300518134715\n",
      "0.0362552788889\n",
      "0.993264872572\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 68\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8389    0.9168    0.8762       926\n",
      "          1     0.4338    0.2658    0.3296       222\n",
      "\n",
      "avg / total     0.7606    0.7909    0.7705      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7653263019116677\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.34317343173431736\n",
      "Original f1: 0.3050259965337955\n",
      "0.0528091040164\n",
      "0.95958490155\n",
      "356\n",
      "0.234673698088\n",
      "Number of disagreement: 133\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8483    0.8662    0.8571      1233\n",
      "          1     0.3605    0.3275    0.3432       284\n",
      "\n",
      "avg / total     0.7570    0.7653    0.7609      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.5-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7604529616724739\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.38202247191011235\n",
      "Original f1: 0.2694300518134715\n",
      "0.190384777855\n",
      "0.996912524659\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 239\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8519    0.8510    0.8514       926\n",
      "          1     0.3812    0.3829    0.3820       222\n",
      "\n",
      "avg / total     0.7609    0.7605    0.7607      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7554383651944627\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3764705882352941\n",
      "Original f1: 0.3050259965337955\n",
      "0.184372106831\n",
      "0.999999687023\n",
      "371\n",
      "0.244561634806\n",
      "Number of disagreement: 324\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8574    0.8386    0.8479      1233\n",
      "          1     0.3601    0.3944    0.3765       284\n",
      "\n",
      "avg / total     0.7643    0.7554    0.7596      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.5-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7935540069686411\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3542234332425069\n",
      "Original f1: 0.2694300518134715\n",
      "0.046841321393\n",
      "0.993264876208\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 77\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8435    0.9136    0.8771       926\n",
      "          1     0.4483    0.2928    0.3542       222\n",
      "\n",
      "avg / total     0.7670    0.7936    0.7760      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7653263019116677\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3642857142857142\n",
      "Original f1: 0.3050259965337955\n",
      "0.0633159506828\n",
      "0.962421877403\n",
      "356\n",
      "0.234673698088\n",
      "Number of disagreement: 151\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8533    0.8589    0.8561      1233\n",
      "          1     0.3696    0.3592    0.3643       284\n",
      "\n",
      "avg / total     0.7628    0.7653    0.7640      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.5-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7560975609756098\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.388646288209607\n",
      "Original f1: 0.2694300518134715\n",
      "0.198857520837\n",
      "0.996912527562\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 252\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8542    0.8413    0.8477       926\n",
      "          1     0.3771    0.4009    0.3886       222\n",
      "\n",
      "avg / total     0.7619    0.7561    0.7589      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7475280158206987\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3752039151712887\n",
      "Original f1: 0.3050259965337955\n",
      "0.190594859268\n",
      "0.999999687204\n",
      "383\n",
      "0.252471984179\n",
      "Number of disagreement: 342\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8577    0.8264    0.8418      1233\n",
      "          1     0.3495    0.4049    0.3752       284\n",
      "\n",
      "avg / total     0.7626    0.7475    0.7544      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.5-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7883275261324042\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3848101265822784\n",
      "Original f1: 0.2694300518134715\n",
      "0.0606490402287\n",
      "0.993667650095\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 105\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8503    0.8952    0.8722       926\n",
      "          1     0.4393    0.3423    0.3848       222\n",
      "\n",
      "avg / total     0.7708    0.7883    0.7779      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7653263019116677\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3819444444444444\n",
      "Original f1: 0.3050259965337955\n",
      "0.07125421349\n",
      "0.992866683658\n",
      "356\n",
      "0.234673698088\n",
      "Number of disagreement: 167\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8580    0.8524    0.8552      1233\n",
      "          1     0.3767    0.3873    0.3819       284\n",
      "\n",
      "avg / total     0.7679    0.7653    0.7666      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.5-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7508710801393729\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.39662447257383965\n",
      "Original f1: 0.2694300518134715\n",
      "0.209284229867\n",
      "0.997283531481\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 266\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8571    0.8294    0.8430       926\n",
      "          1     0.3730    0.4234    0.3966       222\n",
      "\n",
      "avg / total     0.7635    0.7509    0.7567      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7376400791034937\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3722397476340695\n",
      "Original f1: 0.3050259965337955\n",
      "0.196361899277\n",
      "0.999999686893\n",
      "398\n",
      "0.262359920897\n",
      "Number of disagreement: 357\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8578    0.8118    0.8342      1233\n",
      "          1     0.3371    0.4155    0.3722       284\n",
      "\n",
      "avg / total     0.7603    0.7376    0.7477      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.75-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7717770034843205\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.24277456647398846\n",
      "Original f1: 0.2694300518134715\n",
      "0.0198620178458\n",
      "0.554137046103\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 40\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8242    0.9114    0.8656       926\n",
      "          1     0.3387    0.1892    0.2428       222\n",
      "\n",
      "avg / total     0.7303    0.7718    0.7452      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7626895187870798\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.29687499999999994\n",
      "Original f1: 0.3050259965337955\n",
      "0.024245933665\n",
      "0.624251192162\n",
      "360\n",
      "0.237310481213\n",
      "Number of disagreement: 73\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8386    0.8767    0.8573      1233\n",
      "          1     0.3333    0.2676    0.2969       284\n",
      "\n",
      "avg / total     0.7440    0.7627    0.7523      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.75-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7865853658536586\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2019543973941368\n",
      "Original f1: 0.2694300518134715\n",
      "0.0943615952785\n",
      "0.631084134943\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 109\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8203    0.9417    0.8768       926\n",
      "          1     0.3647    0.1396    0.2020       222\n",
      "\n",
      "avg / total     0.7322    0.7866    0.7463      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7996044825313118\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.2830188679245283\n",
      "Original f1: 0.3050259965337955\n",
      "0.110294027753\n",
      "0.773893733225\n",
      "304\n",
      "0.200395517469\n",
      "Number of disagreement: 197\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8373    0.9351    0.8835      1233\n",
      "          1     0.4286    0.2113    0.2830       284\n",
      "\n",
      "avg / total     0.7608    0.7996    0.7711      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.75-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7700348432055749\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2542372881355932\n",
      "Original f1: 0.2694300518134715\n",
      "0.0202873856335\n",
      "0.421610503729\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 34\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8258    0.9060    0.8641       926\n",
      "          1     0.3409    0.2027    0.2542       222\n",
      "\n",
      "avg / total     0.7320    0.7700    0.7461      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7580751483190508\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3114446529080675\n",
      "Original f1: 0.3050259965337955\n",
      "0.027077633466\n",
      "0.624251192162\n",
      "367\n",
      "0.241924851681\n",
      "Number of disagreement: 72\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8415    0.8654    0.8533      1233\n",
      "          1     0.3333    0.2923    0.3114       284\n",
      "\n",
      "avg / total     0.7464    0.7581    0.7518      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.75-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7508710801393729\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3440366972477064\n",
      "Original f1: 0.2694300518134715\n",
      "0.164446229756\n",
      "0.993264876422\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 216\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8426    0.8499    0.8462       926\n",
      "          1     0.3505    0.3378    0.3440       222\n",
      "\n",
      "avg / total     0.7474    0.7509    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7547791694133158\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38205980066445183\n",
      "Original f1: 0.3050259965337955\n",
      "0.168288835952\n",
      "0.992866687784\n",
      "372\n",
      "0.245220830587\n",
      "Number of disagreement: 301\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8590    0.8354    0.8470      1233\n",
      "          1     0.3616    0.4049    0.3821       284\n",
      "\n",
      "avg / total     0.7659    0.7548    0.7600      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.75-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7717770034843205\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2640449438202247\n",
      "Original f1: 0.2694300518134715\n",
      "0.0215954120853\n",
      "0.421610548924\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 34\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8274    0.9060    0.8649       926\n",
      "          1     0.3507    0.2117    0.2640       222\n",
      "\n",
      "avg / total     0.7352    0.7718    0.7487      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7560975609756098\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.31226765799256506\n",
      "Original f1: 0.3050259965337955\n",
      "0.0296217323506\n",
      "0.679488023781\n",
      "370\n",
      "0.243902439024\n",
      "Number of disagreement: 77\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8416    0.8621    0.8518      1233\n",
      "          1     0.3307    0.2958    0.3123       284\n",
      "\n",
      "avg / total     0.7460    0.7561    0.7508      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.75-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7456445993031359\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.35682819383259917\n",
      "Original f1: 0.2694300518134715\n",
      "0.178749374733\n",
      "0.993264876646\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 234\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8461    0.8369    0.8415       926\n",
      "          1     0.3491    0.3649    0.3568       222\n",
      "\n",
      "avg / total     0.7500    0.7456    0.7478      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7442320369149638\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3860759493670886\n",
      "Original f1: 0.3050259965337955\n",
      "0.177240295646\n",
      "0.992866689133\n",
      "388\n",
      "0.255767963085\n",
      "Number of disagreement: 321\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8614    0.8167    0.8385      1233\n",
      "          1     0.3506    0.4296    0.3861       284\n",
      "\n",
      "avg / total     0.7658    0.7442    0.7538      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.75-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7717770034843205\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2802197802197802\n",
      "Original f1: 0.2694300518134715\n",
      "0.0250380676346\n",
      "0.495133040706\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 40\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8300    0.9017    0.8644       926\n",
      "          1     0.3592    0.2297    0.2802       222\n",
      "\n",
      "avg / total     0.7390    0.7718    0.7514      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7541199736321688\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3155963302752294\n",
      "Original f1: 0.3050259965337955\n",
      "0.0351823537831\n",
      "0.818108900786\n",
      "373\n",
      "0.245880026368\n",
      "Number of disagreement: 84\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8424    0.8581    0.8501      1233\n",
      "          1     0.3295    0.3028    0.3156       284\n",
      "\n",
      "avg / total     0.7463    0.7541    0.7501      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.75-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.730836236933798\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3575883575883576\n",
      "Original f1: 0.2694300518134715\n",
      "0.191493654357\n",
      "0.993667658874\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 261\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8470    0.8132    0.8298       926\n",
      "          1     0.3320    0.3874    0.3576       222\n",
      "\n",
      "avg / total     0.7474    0.7308    0.7384      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7343441001977588\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38095238095238093\n",
      "Original f1: 0.3050259965337955\n",
      "0.187411580632\n",
      "0.993179318724\n",
      "403\n",
      "0.265655899802\n",
      "Number of disagreement: 340\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8609    0.8029    0.8309      1233\n",
      "          1     0.3379    0.4366    0.3810       284\n",
      "\n",
      "avg / total     0.7630    0.7343    0.7467      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.75-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7778745644599303\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3236074270557029\n",
      "Original f1: 0.2694300518134715\n",
      "0.0336717812591\n",
      "0.993264876014\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 51\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8379    0.8985    0.8671       926\n",
      "          1     0.3935    0.2748    0.3236       222\n",
      "\n",
      "avg / total     0.7519    0.7779    0.7620      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7567567567567568\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3492063492063492\n",
      "Original f1: 0.3050259965337955\n",
      "0.0491435320541\n",
      "0.962421871864\n",
      "369\n",
      "0.243243243243\n",
      "Number of disagreement: 106\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8501    0.8508    0.8504      1233\n",
      "          1     0.3498    0.3486    0.3492       284\n",
      "\n",
      "avg / total     0.7564    0.7568    0.7566      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.75-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7238675958188153\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3621730382293763\n",
      "Original f1: 0.2694300518134715\n",
      "0.200765199734\n",
      "0.997283539791\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 271\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8488    0.8002    0.8238       926\n",
      "          1     0.3273    0.4054    0.3622       222\n",
      "\n",
      "avg / total     0.7479    0.7239    0.7345      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7257745550428477\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.37910447761194027\n",
      "Original f1: 0.3050259965337955\n",
      "0.196346329762\n",
      "0.999999686929\n",
      "416\n",
      "0.274225444957\n",
      "Number of disagreement: 357\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8612    0.7899    0.8240      1233\n",
      "          1     0.3290    0.4472    0.3791       284\n",
      "\n",
      "avg / total     0.7616    0.7258    0.7407      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.75-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7787456445993032\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3520408163265306\n",
      "Original f1: 0.2694300518134715\n",
      "0.0466800359024\n",
      "0.993264876609\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 64\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8436    0.8909    0.8666       926\n",
      "          1     0.4059    0.3108    0.3520       222\n",
      "\n",
      "avg / total     0.7589    0.7787    0.7671      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7593935398813447\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.39267886855241263\n",
      "Original f1: 0.3050259965337955\n",
      "0.0637852681744\n",
      "0.992866688087\n",
      "365\n",
      "0.240606460119\n",
      "Number of disagreement: 138\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8617    0.8386    0.8500      1233\n",
      "          1     0.3722    0.4155    0.3927       284\n",
      "\n",
      "avg / total     0.7700    0.7594    0.7644      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.75-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7195121951219512\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.37109375000000006\n",
      "Original f1: 0.2694300518134715\n",
      "0.210653655354\n",
      "0.997283541121\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 286\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8520    0.7894    0.8195       926\n",
      "          1     0.3276    0.4279    0.3711       222\n",
      "\n",
      "avg / total     0.7506    0.7195    0.7328      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7198417930125247\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.37591776798825255\n",
      "Original f1: 0.3050259965337955\n",
      "0.203819098677\n",
      "0.999999686633\n",
      "425\n",
      "0.280158206987\n",
      "Number of disagreement: 368\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8607    0.7818    0.8194      1233\n",
      "          1     0.3224    0.4507    0.3759       284\n",
      "\n",
      "avg / total     0.7599    0.7198    0.7364      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.75-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7717770034843205\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.37320574162679426\n",
      "Original f1: 0.2694300518134715\n",
      "0.0628497789607\n",
      "0.993667658475\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 90\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8487    0.8726    0.8605       926\n",
      "          1     0.3980    0.3514    0.3732       222\n",
      "\n",
      "avg / total     0.7616    0.7718    0.7663      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7593935398813447\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.40456769983686786\n",
      "Original f1: 0.3050259965337955\n",
      "0.0723925075119\n",
      "0.992866688673\n",
      "365\n",
      "0.240606460119\n",
      "Number of disagreement: 150\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8653    0.8337    0.8492      1233\n",
      "          1     0.3769    0.4366    0.4046       284\n",
      "\n",
      "avg / total     0.7739    0.7594    0.7660      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.75-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7125435540069687\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.37022900763358774\n",
      "Original f1: 0.2694300518134715\n",
      "0.219476186237\n",
      "0.997283540831\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 298\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8522    0.7786    0.8138       926\n",
      "          1     0.3212    0.4369    0.3702       222\n",
      "\n",
      "avg / total     0.7496    0.7125    0.7280      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7099538562953197\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.367816091954023\n",
      "Original f1: 0.3050259965337955\n",
      "0.210003484827\n",
      "0.999999687369\n",
      "440\n",
      "0.290046143705\n",
      "Number of disagreement: 377\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8588    0.7697    0.8118      1233\n",
      "          1     0.3107    0.4507    0.3678       284\n",
      "\n",
      "avg / total     0.7562    0.7100    0.7287      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.75-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7726480836236934\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2521489971346705\n",
      "Original f1: 0.2694300518134715\n",
      "0.0187850829466\n",
      "0.547465544494\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 37\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8257    0.9104    0.8659       926\n",
      "          1     0.3465    0.1982    0.2521       222\n",
      "\n",
      "avg / total     0.7330    0.7726    0.7473      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7574159525379037\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.2868217054263566\n",
      "Original f1: 0.3050259965337955\n",
      "0.0235121950113\n",
      "0.624273496614\n",
      "368\n",
      "0.242584047462\n",
      "Number of disagreement: 65\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8366    0.8719    0.8539      1233\n",
      "          1     0.3190    0.2606    0.2868       284\n",
      "\n",
      "avg / total     0.7397    0.7574    0.7477      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.75-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7848432055749129\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.17391304347826086\n",
      "Original f1: 0.2694300518134715\n",
      "0.0965426303101\n",
      "0.639065398656\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 115\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8170    0.9449    0.8763       926\n",
      "          1     0.3377    0.1171    0.1739       222\n",
      "\n",
      "avg / total     0.7243    0.7848    0.7405      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7996044825313118\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.2796208530805687\n",
      "Original f1: 0.3050259965337955\n",
      "0.112264367298\n",
      "0.776855032528\n",
      "304\n",
      "0.200395517469\n",
      "Number of disagreement: 197\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8368    0.9359    0.8836      1233\n",
      "          1     0.4275    0.2077    0.2796       284\n",
      "\n",
      "avg / total     0.7602    0.7996    0.7705      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.75-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7709059233449478\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.26330532212885155\n",
      "Original f1: 0.2694300518134715\n",
      "0.0191679154369\n",
      "0.425493868649\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 31\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.9050    0.8644       926\n",
      "          1     0.3481    0.2117    0.2633       222\n",
      "\n",
      "avg / total     0.7346    0.7709    0.7481      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7554383651944627\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.30654205607476637\n",
      "Original f1: 0.3050259965337955\n",
      "0.0261345508056\n",
      "0.624273496614\n",
      "371\n",
      "0.244561634806\n",
      "Number of disagreement: 68\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8404    0.8629    0.8515      1233\n",
      "          1     0.3267    0.2887    0.3065       284\n",
      "\n",
      "avg / total     0.7443    0.7554    0.7495      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.75-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.75\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3462414578587699\n",
      "Original f1: 0.2694300518134715\n",
      "0.167653490275\n",
      "0.993264876346\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 225\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8432    0.8477    0.8454       926\n",
      "          1     0.3502    0.3423    0.3462       222\n",
      "\n",
      "avg / total     0.7479    0.7500    0.7489      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7501647989452868\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.37561779242174637\n",
      "Original f1: 0.3050259965337955\n",
      "0.17280298038\n",
      "0.992866689148\n",
      "379\n",
      "0.249835201055\n",
      "Number of disagreement: 306\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8576    0.8305    0.8438      1233\n",
      "          1     0.3529    0.4014    0.3756       284\n",
      "\n",
      "avg / total     0.7631    0.7502    0.7562      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.75-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7717770034843205\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2681564245810056\n",
      "Original f1: 0.2694300518134715\n",
      "0.0205793004335\n",
      "0.433322934091\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 32\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8281    0.9050    0.8648       926\n",
      "          1     0.3529    0.2162    0.2682       222\n",
      "\n",
      "avg / total     0.7362    0.7718    0.7494      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7534607778510217\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3048327137546469\n",
      "Original f1: 0.3050259965337955\n",
      "0.0286624631645\n",
      "0.67472547186\n",
      "374\n",
      "0.246539222149\n",
      "Number of disagreement: 71\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8401    0.8605    0.8502      1233\n",
      "          1     0.3228    0.2887    0.3048       284\n",
      "\n",
      "avg / total     0.7432    0.7535    0.7481      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.75-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7456445993031359\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3539823008849557\n",
      "Original f1: 0.2694300518134715\n",
      "0.181187384058\n",
      "0.993667659041\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 238\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8453    0.8380    0.8416       926\n",
      "          1     0.3478    0.3604    0.3540       222\n",
      "\n",
      "avg / total     0.7491    0.7456    0.7473      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7429136453526698\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.38291139240506333\n",
      "Original f1: 0.3050259965337955\n",
      "0.181128073671\n",
      "0.992866689101\n",
      "390\n",
      "0.257086354647\n",
      "Number of disagreement: 325\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8606    0.8159    0.8376      1233\n",
      "          1     0.3477    0.4261    0.3829       284\n",
      "\n",
      "avg / total     0.7646    0.7429    0.7525      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.75-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7717770034843205\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.28415300546448086\n",
      "Original f1: 0.2694300518134715\n",
      "0.0242397618869\n",
      "0.511666159925\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 38\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8307    0.9006    0.8642       926\n",
      "          1     0.3611    0.2342    0.2842       222\n",
      "\n",
      "avg / total     0.7399    0.7718    0.7521      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7534607778510217\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.31501831501831495\n",
      "Original f1: 0.3050259965337955\n",
      "0.0344328265146\n",
      "0.806533317726\n",
      "374\n",
      "0.246539222149\n",
      "Number of disagreement: 79\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8422    0.8573    0.8497      1233\n",
      "          1     0.3282    0.3028    0.3150       284\n",
      "\n",
      "avg / total     0.7460    0.7535    0.7496      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.75-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7264808362369338\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3512396694214876\n",
      "Original f1: 0.2694300518134715\n",
      "0.194406351642\n",
      "0.997283540799\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 270\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8454    0.8089    0.8267       926\n",
      "          1     0.3244    0.3829    0.3512       222\n",
      "\n",
      "avg / total     0.7446    0.7265    0.7348      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7323665128543178\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3734567901234568\n",
      "Original f1: 0.3050259965337955\n",
      "0.190887541293\n",
      "0.999999687197\n",
      "406\n",
      "0.267633487146\n",
      "Number of disagreement: 339\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8586    0.8029    0.8298      1233\n",
      "          1     0.3324    0.4261    0.3735       284\n",
      "\n",
      "avg / total     0.7601    0.7324    0.7444      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.75-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7778745644599303\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3271767810026386\n",
      "Original f1: 0.2694300518134715\n",
      "0.0324526544101\n",
      "0.993264876029\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 49\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8385    0.8974    0.8670       926\n",
      "          1     0.3949    0.2793    0.3272       222\n",
      "\n",
      "avg / total     0.7528    0.7779    0.7626      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7554383651944627\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.34797891036906853\n",
      "Original f1: 0.3050259965337955\n",
      "0.0488803642316\n",
      "0.962421847436\n",
      "371\n",
      "0.244561634806\n",
      "Number of disagreement: 100\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8498    0.8491    0.8495      1233\n",
      "          1     0.3474    0.3486    0.3480       284\n",
      "\n",
      "avg / total     0.7558    0.7554    0.7556      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.75-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7186411149825784\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3552894211576847\n",
      "Original f1: 0.2694300518134715\n",
      "0.204659910212\n",
      "0.997283540652\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 279\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8470    0.7948    0.8201       926\n",
      "          1     0.3190    0.4009    0.3553       222\n",
      "\n",
      "avg / total     0.7449    0.7186    0.7302      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7224785761371127\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.37257824143070045\n",
      "Original f1: 0.3050259965337955\n",
      "0.199393327973\n",
      "0.999999686542\n",
      "421\n",
      "0.277521423863\n",
      "Number of disagreement: 360\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8593    0.7875    0.8218      1233\n",
      "          1     0.3230    0.4401    0.3726       284\n",
      "\n",
      "avg / total     0.7589    0.7225    0.7377      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.75-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7804878048780488\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.35714285714285715\n",
      "Original f1: 0.2694300518134715\n",
      "0.045196857467\n",
      "0.993667658586\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 62\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8446    0.8920    0.8676       926\n",
      "          1     0.4118    0.3153    0.3571       222\n",
      "\n",
      "avg / total     0.7609    0.7805    0.7689      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7534607778510217\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.37666666666666665\n",
      "Original f1: 0.3050259965337955\n",
      "0.06245516808\n",
      "0.992866688809\n",
      "374\n",
      "0.246539222149\n",
      "Number of disagreement: 127\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8576    0.8354    0.8463      1233\n",
      "          1     0.3576    0.3979    0.3767       284\n",
      "\n",
      "avg / total     0.7640    0.7535    0.7584      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.75-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7142857142857143\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36434108527131787\n",
      "Original f1: 0.2694300518134715\n",
      "0.214924793304\n",
      "0.997283541209\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 294\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8501    0.7840    0.8157       926\n",
      "          1     0.3197    0.4234    0.3643       222\n",
      "\n",
      "avg / total     0.7476    0.7143    0.7284      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7165458141067897\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.36950146627565983\n",
      "Original f1: 0.3050259965337955\n",
      "0.206123778799\n",
      "0.999999687045\n",
      "430\n",
      "0.283454185893\n",
      "Number of disagreement: 369\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8588    0.7794    0.8172      1233\n",
      "          1     0.3166    0.4437    0.3695       284\n",
      "\n",
      "avg / total     0.7573    0.7165    0.7334      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.75-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7674216027874564\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36879432624113484\n",
      "Original f1: 0.2694300518134715\n",
      "0.0631866769262\n",
      "0.993667658206\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 91\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8479    0.8672    0.8574       926\n",
      "          1     0.3881    0.3514    0.3688       222\n",
      "\n",
      "avg / total     0.7590    0.7674    0.7630      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7547791694133158\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.4\n",
      "Original f1: 0.3050259965337955\n",
      "0.0717354096505\n",
      "0.992866688425\n",
      "372\n",
      "0.245220830587\n",
      "Number of disagreement: 147\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8645    0.8281    0.8459      1233\n",
      "          1     0.3690    0.4366    0.4000       284\n",
      "\n",
      "avg / total     0.7718    0.7548    0.7624      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-0.75-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.705574912891986\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3622641509433962\n",
      "Original f1: 0.2694300518134715\n",
      "0.223540121809\n",
      "0.997283541161\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 308\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8500    0.7711    0.8086       926\n",
      "          1     0.3117    0.4324    0.3623       222\n",
      "\n",
      "avg / total     0.7459    0.7056    0.7223      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7086354647330257\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3631123919308357\n",
      "Original f1: 0.3050259965337955\n",
      "0.211926889856\n",
      "0.999999687266\n",
      "442\n",
      "0.291364535267\n",
      "Number of disagreement: 379\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8573    0.7697    0.8111      1233\n",
      "          1     0.3073    0.4437    0.3631       284\n",
      "\n",
      "avg / total     0.7543    0.7086    0.7272      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.0-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7700348432055749\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.24137931034482757\n",
      "Original f1: 0.2694300518134715\n",
      "0.0177707185148\n",
      "0.551976553315\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 38\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8239    0.9093    0.8645       926\n",
      "          1     0.3333    0.1892    0.2414       222\n",
      "\n",
      "avg / total     0.7290    0.7700    0.7440      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7534607778510217\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.2916666666666667\n",
      "Original f1: 0.3050259965337955\n",
      "0.0213466445329\n",
      "0.618753442552\n",
      "374\n",
      "0.246539222149\n",
      "Number of disagreement: 53\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8374    0.8646    0.8508      1233\n",
      "          1     0.3156    0.2711    0.2917       284\n",
      "\n",
      "avg / total     0.7397    0.7535    0.7461      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.0-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7865853658536586\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.19672131147540983\n",
      "Original f1: 0.2694300518134715\n",
      "0.0922617615237\n",
      "0.608744091046\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 103\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8197    0.9428    0.8769       926\n",
      "          1     0.3614    0.1351    0.1967       222\n",
      "\n",
      "avg / total     0.7311    0.7866    0.7454      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7963085036255768\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.2863741339491917\n",
      "Original f1: 0.3050259965337955\n",
      "0.109327437008\n",
      "0.752151968022\n",
      "309\n",
      "0.203691496374\n",
      "Number of disagreement: 188\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8377    0.9294    0.8812      1233\n",
      "          1     0.4161    0.2183    0.2864       284\n",
      "\n",
      "avg / total     0.7588    0.7963    0.7698      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.0-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.769163763066202\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2535211267605634\n",
      "Original f1: 0.2694300518134715\n",
      "0.0181219520385\n",
      "0.430295565694\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 31\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8256    0.9050    0.8635       926\n",
      "          1     0.3383    0.2027    0.2535       222\n",
      "\n",
      "avg / total     0.7314    0.7692    0.7455      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7508239947264338\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.30514705882352944\n",
      "Original f1: 0.3050259965337955\n",
      "0.0242821835874\n",
      "0.618753442552\n",
      "378\n",
      "0.249176005274\n",
      "Number of disagreement: 53\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8401    0.8564    0.8482      1233\n",
      "          1     0.3192    0.2923    0.3051       284\n",
      "\n",
      "avg / total     0.7426    0.7508    0.7465      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.0-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7395470383275261\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.34285714285714286\n",
      "Original f1: 0.2694300518134715\n",
      "0.172836703908\n",
      "0.993264876568\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 227\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8426    0.8326    0.8376       926\n",
      "          1     0.3348    0.3514    0.3429       222\n",
      "\n",
      "avg / total     0.7444    0.7395    0.7419      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7350032959789057\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3796296296296296\n",
      "Original f1: 0.3050259965337955\n",
      "0.176470177596\n",
      "0.992866689079\n",
      "402\n",
      "0.264996704021\n",
      "Number of disagreement: 319\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8604    0.8045    0.8315      1233\n",
      "          1     0.3379    0.4331    0.3796       284\n",
      "\n",
      "avg / total     0.7626    0.7350    0.7469      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.0-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.769163763066202\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.26183844011142066\n",
      "Original f1: 0.2694300518134715\n",
      "0.0197619459522\n",
      "0.430295195433\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 31\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8269    0.9028    0.8632       926\n",
      "          1     0.3431    0.2117    0.2618       222\n",
      "\n",
      "avg / total     0.7333    0.7692    0.7469      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7495056031641397\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.30909090909090914\n",
      "Original f1: 0.3050259965337955\n",
      "0.0271238203792\n",
      "0.676286589537\n",
      "380\n",
      "0.250494396836\n",
      "Number of disagreement: 59\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8409    0.8532    0.8470      1233\n",
      "          1     0.3195    0.2993    0.3091       284\n",
      "\n",
      "avg / total     0.7433    0.7495    0.7463      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.0-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7264808362369338\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.34854771784232363\n",
      "Original f1: 0.2694300518134715\n",
      "0.18548378328\n",
      "0.997283539871\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 248\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8446    0.8099    0.8269       926\n",
      "          1     0.3231    0.3784    0.3485       222\n",
      "\n",
      "avg / total     0.7437    0.7265    0.7344      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7231377719182597\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.37125748502994016\n",
      "Original f1: 0.3050259965337955\n",
      "0.186037490094\n",
      "0.992866689206\n",
      "420\n",
      "0.276862228082\n",
      "Number of disagreement: 333\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8588    0.7891    0.8225      1233\n",
      "          1     0.3229    0.4366    0.3713       284\n",
      "\n",
      "avg / total     0.7585    0.7231    0.7380      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.0-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7682926829268293\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2651933701657459\n",
      "Original f1: 0.2694300518134715\n",
      "0.0236954640202\n",
      "0.465387698317\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 34\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8274    0.9006    0.8625       926\n",
      "          1     0.3429    0.2162    0.2652       222\n",
      "\n",
      "avg / total     0.7337    0.7683    0.7470      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7488464073829928\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3184257602862254\n",
      "Original f1: 0.3050259965337955\n",
      "0.0329483523886\n",
      "0.817015632648\n",
      "381\n",
      "0.251153592617\n",
      "Number of disagreement: 68\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8430    0.8491    0.8461      1233\n",
      "          1     0.3236    0.3134    0.3184       284\n",
      "\n",
      "avg / total     0.7458    0.7488    0.7473      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.0-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7047038327526133\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.344294003868472\n",
      "Original f1: 0.2694300518134715\n",
      "0.199828813157\n",
      "0.997283541154\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 277\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8441    0.7775    0.8094       926\n",
      "          1     0.3017    0.4009    0.3443       222\n",
      "\n",
      "avg / total     0.7392    0.7047    0.7195      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7132498352010547\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3686502177068215\n",
      "Original f1: 0.3050259965337955\n",
      "0.196761222967\n",
      "0.992866689139\n",
      "435\n",
      "0.286750164799\n",
      "Number of disagreement: 350\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8588    0.7745    0.8145      1233\n",
      "          1     0.3136    0.4472    0.3687       284\n",
      "\n",
      "avg / total     0.7567    0.7132    0.7310      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.0-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7717770034843205\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3105263157894737\n",
      "Original f1: 0.2694300518134715\n",
      "0.0320151750076\n",
      "0.993264875986\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 48\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8354    0.8931    0.8633       926\n",
      "          1     0.3734    0.2658    0.3105       222\n",
      "\n",
      "avg / total     0.7460    0.7718    0.7564      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7462096242584048\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3257443082311734\n",
      "Original f1: 0.3050259965337955\n",
      "0.0433724250944\n",
      "0.914764337901\n",
      "385\n",
      "0.253790375742\n",
      "Number of disagreement: 80\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8447    0.8427    0.8437      1233\n",
      "          1     0.3240    0.3275    0.3257       284\n",
      "\n",
      "avg / total     0.7472    0.7462    0.7467      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.0-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7029616724738676\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3553875236294896\n",
      "Original f1: 0.2694300518134715\n",
      "0.210404050168\n",
      "0.997283541055\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 289\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8478    0.7700    0.8070       926\n",
      "          1     0.3062    0.4234    0.3554       222\n",
      "\n",
      "avg / total     0.7431    0.7030    0.7197      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7066578773895847\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.36519258202567756\n",
      "Original f1: 0.3050259965337955\n",
      "0.205810322834\n",
      "0.999999681182\n",
      "445\n",
      "0.29334212261\n",
      "Number of disagreement: 360\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8582    0.7656    0.8093      1233\n",
      "          1     0.3070    0.4507    0.3652       284\n",
      "\n",
      "avg / total     0.7550    0.7067    0.7261      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.0-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7752613240418118\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3484848484848485\n",
      "Original f1: 0.2694300518134715\n",
      "0.0457218166737\n",
      "0.993264876455\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 64\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8429    0.8866    0.8642       926\n",
      "          1     0.3966    0.3108    0.3485       222\n",
      "\n",
      "avg / total     0.7566    0.7753    0.7645      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7508239947264338\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.39228295819935693\n",
      "Original f1: 0.3050259965337955\n",
      "0.0642831391419\n",
      "0.992866688787\n",
      "378\n",
      "0.249176005274\n",
      "Number of disagreement: 129\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8626    0.8248    0.8433      1233\n",
      "          1     0.3609    0.4296    0.3923       284\n",
      "\n",
      "avg / total     0.7687    0.7508    0.7589      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.0-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6977351916376306\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3609576427255985\n",
      "Original f1: 0.2694300518134715\n",
      "0.219803992317\n",
      "0.997283541152\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 303\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8501    0.7592    0.8021       926\n",
      "          1     0.3053    0.4414    0.3610       222\n",
      "\n",
      "avg / total     0.7447    0.6977    0.7168      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6980883322346737\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.362116991643454\n",
      "Original f1: 0.3050259965337955\n",
      "0.214592033262\n",
      "0.999999686699\n",
      "458\n",
      "0.301911667765\n",
      "Number of disagreement: 373\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8578    0.7534    0.8022      1233\n",
      "          1     0.2995    0.4577    0.3621       284\n",
      "\n",
      "avg / total     0.7533    0.6981    0.7198      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.0-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7709059233449478\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3811764705882353\n",
      "Original f1: 0.2694300518134715\n",
      "0.0627574943777\n",
      "0.993667657173\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 91\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8508    0.8683    0.8594       926\n",
      "          1     0.3990    0.3649    0.3812       222\n",
      "\n",
      "avg / total     0.7634    0.7709    0.7669      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7462096242584048\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3993759750390016\n",
      "Original f1: 0.3050259965337955\n",
      "0.0742099391109\n",
      "0.992866688426\n",
      "385\n",
      "0.253790375742\n",
      "Number of disagreement: 148\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8655    0.8143    0.8391      1233\n",
      "          1     0.3585    0.4507    0.3994       284\n",
      "\n",
      "avg / total     0.7706    0.7462    0.7568      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.0-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6916376306620209\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3586956521739131\n",
      "Original f1: 0.2694300518134715\n",
      "0.225629795985\n",
      "0.997283541072\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 310\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8496    0.7505    0.7970       926\n",
      "          1     0.3000    0.4459    0.3587       222\n",
      "\n",
      "avg / total     0.7433    0.6916    0.7123      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6941331575477917\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.35911602209944754\n",
      "Original f1: 0.3050259965337955\n",
      "0.220093197908\n",
      "0.999999686206\n",
      "464\n",
      "0.305866842452\n",
      "Number of disagreement: 379\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8570    0.7486    0.7991      1233\n",
      "          1     0.2955    0.4577    0.3591       284\n",
      "\n",
      "avg / total     0.7519    0.6941    0.7168      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.0-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7726480836236934\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2606232294617563\n",
      "Original f1: 0.2694300518134715\n",
      "0.0166935967623\n",
      "0.538632519963\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 35\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8269    0.9082    0.8657       926\n",
      "          1     0.3511    0.2072    0.2606       222\n",
      "\n",
      "avg / total     0.7349    0.7726    0.7487      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7528015820698748\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.29378531073446335\n",
      "Original f1: 0.3050259965337955\n",
      "0.0206920389414\n",
      "0.619246143774\n",
      "375\n",
      "0.24719841793\n",
      "Number of disagreement: 46\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8378    0.8629    0.8502      1233\n",
      "          1     0.3158    0.2746    0.2938       284\n",
      "\n",
      "avg / total     0.7401    0.7528    0.7460      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.0-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7848432055749129\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.18481848184818478\n",
      "Original f1: 0.2694300518134715\n",
      "0.095445258816\n",
      "0.625334517537\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 109\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8182    0.9428    0.8761       926\n",
      "          1     0.3457    0.1261    0.1848       222\n",
      "\n",
      "avg / total     0.7268    0.7848    0.7424      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7976268951878708\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.2776470588235294\n",
      "Original f1: 0.3050259965337955\n",
      "0.112589576185\n",
      "0.753952790584\n",
      "307\n",
      "0.202373104812\n",
      "Number of disagreement: 196\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8365    0.9335    0.8823      1233\n",
      "          1     0.4184    0.2077    0.2776       284\n",
      "\n",
      "avg / total     0.7582    0.7976    0.7691      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.0-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7709059233449478\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.26740947075208915\n",
      "Original f1: 0.2694300518134715\n",
      "0.0171117344082\n",
      "0.426478169907\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 29\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8279    0.9039    0.8642       926\n",
      "          1     0.3504    0.2162    0.2674       222\n",
      "\n",
      "avg / total     0.7355    0.7709    0.7488      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7514831905075807\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3082568807339449\n",
      "Original f1: 0.3050259965337955\n",
      "0.0232129928855\n",
      "0.619246143774\n",
      "377\n",
      "0.248516809492\n",
      "Number of disagreement: 48\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8408    0.8564    0.8485      1233\n",
      "          1     0.3218    0.2958    0.3083       284\n",
      "\n",
      "avg / total     0.7436    0.7515    0.7474      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.0-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.730836236933798\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3383297644539614\n",
      "Original f1: 0.2694300518134715\n",
      "0.177766551061\n",
      "0.997283539529\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 239\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8416    0.8207    0.8311       926\n",
      "          1     0.3224    0.3559    0.3383       222\n",
      "\n",
      "avg / total     0.7412    0.7308    0.7358      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7350032959789057\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3796296296296296\n",
      "Original f1: 0.3050259965337955\n",
      "0.182889994266\n",
      "0.992866689126\n",
      "402\n",
      "0.264996704021\n",
      "Number of disagreement: 327\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8604    0.8045    0.8315      1233\n",
      "          1     0.3379    0.4331    0.3796       284\n",
      "\n",
      "avg / total     0.7626    0.7350    0.7469      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.0-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7709059233449478\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.27146814404432135\n",
      "Original f1: 0.2694300518134715\n",
      "0.0189409413446\n",
      "0.426478169907\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 31\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8285    0.9028    0.8641       926\n",
      "          1     0.3525    0.2207    0.2715       222\n",
      "\n",
      "avg / total     0.7365    0.7709    0.7495      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7495056031641397\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3065693430656934\n",
      "Original f1: 0.3050259965337955\n",
      "0.0259541738608\n",
      "0.664179377602\n",
      "380\n",
      "0.250494396836\n",
      "Number of disagreement: 51\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8404    0.8540    0.8471      1233\n",
      "          1     0.3182    0.2958    0.3066       284\n",
      "\n",
      "avg / total     0.7426    0.7495    0.7459      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.0-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7168989547038328\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.33808553971486766\n",
      "Original f1: 0.2694300518134715\n",
      "0.189540887883\n",
      "0.997283541079\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 261\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8419    0.7991    0.8199       926\n",
      "          1     0.3086    0.3739    0.3381       222\n",
      "\n",
      "avg / total     0.7387    0.7169    0.7268      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7244561634805537\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3704819277108434\n",
      "Original f1: 0.3050259965337955\n",
      "0.191766377628\n",
      "0.999999687271\n",
      "418\n",
      "0.275543836519\n",
      "Number of disagreement: 343\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8584    0.7916    0.8236      1233\n",
      "          1     0.3237    0.4331    0.3705       284\n",
      "\n",
      "avg / total     0.7583    0.7245    0.7388      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.0-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7709059233449478\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.27945205479452057\n",
      "Original f1: 0.2694300518134715\n",
      "0.0229495967385\n",
      "0.499813409315\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 33\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8299    0.9006    0.8638       926\n",
      "          1     0.3566    0.2297    0.2795       222\n",
      "\n",
      "avg / total     0.7383    0.7709    0.7508      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7514831905075807\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.32315978456014366\n",
      "Original f1: 0.3050259965337955\n",
      "0.0318926749869\n",
      "0.791505579159\n",
      "377\n",
      "0.248516809492\n",
      "Number of disagreement: 60\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8441    0.8516    0.8478      1233\n",
      "          1     0.3297    0.3169    0.3232       284\n",
      "\n",
      "avg / total     0.7478    0.7515    0.7496      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.0-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7020905923344948\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.34230769230769237\n",
      "Original f1: 0.2694300518134715\n",
      "0.203577318309\n",
      "0.997283540898\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 282\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8435    0.7743    0.8074       926\n",
      "          1     0.2987    0.4009    0.3423       222\n",
      "\n",
      "avg / total     0.7382    0.7021    0.7175      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7139090309822017\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3654970760233919\n",
      "Original f1: 0.3050259965337955\n",
      "0.201637510349\n",
      "0.999999687318\n",
      "434\n",
      "0.286090969018\n",
      "Number of disagreement: 359\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8577    0.7770    0.8153      1233\n",
      "          1     0.3125    0.4401    0.3655       284\n",
      "\n",
      "avg / total     0.7556    0.7139    0.7311      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.0-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7726480836236934\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.31853785900783294\n",
      "Original f1: 0.2694300518134715\n",
      "0.031146064559\n",
      "0.99326487599\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 49\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8369    0.8920    0.8636       926\n",
      "          1     0.3789    0.2748    0.3185       222\n",
      "\n",
      "avg / total     0.7483    0.7726    0.7582      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7462096242584048\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3327556325823223\n",
      "Original f1: 0.3050259965337955\n",
      "0.0461879352691\n",
      "0.961080401763\n",
      "385\n",
      "0.253790375742\n",
      "Number of disagreement: 80\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8464    0.8402    0.8433      1233\n",
      "          1     0.3276    0.3380    0.3328       284\n",
      "\n",
      "avg / total     0.7493    0.7462    0.7477      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.0-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6916376306620209\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3468634686346863\n",
      "Original f1: 0.2694300518134715\n",
      "0.21686098658\n",
      "0.997283541196\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 304\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8454    0.7559    0.7982       926\n",
      "          1     0.2938    0.4234    0.3469       222\n",
      "\n",
      "avg / total     0.7387    0.6916    0.7109      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7007251153592617\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3569405099150142\n",
      "Original f1: 0.3050259965337955\n",
      "0.210401734277\n",
      "0.999999687123\n",
      "454\n",
      "0.299274884641\n",
      "Number of disagreement: 375\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8557    0.7599    0.8050      1233\n",
      "          1     0.2986    0.4437    0.3569       284\n",
      "\n",
      "avg / total     0.7514    0.7007    0.7211      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.0-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7770034843205574\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3567839195979899\n",
      "Original f1: 0.2694300518134715\n",
      "0.0441799686396\n",
      "0.993667658266\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 62\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8447    0.8866    0.8651       926\n",
      "          1     0.4034    0.3198    0.3568       222\n",
      "\n",
      "avg / total     0.7593    0.7770    0.7668      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7435728411338167\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3715670436187399\n",
      "Original f1: 0.3050259965337955\n",
      "0.0628445212764\n",
      "0.992866684623\n",
      "389\n",
      "0.256427158866\n",
      "Number of disagreement: 120\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8570    0.8216    0.8389      1233\n",
      "          1     0.3433    0.4049    0.3716       284\n",
      "\n",
      "avg / total     0.7608    0.7436    0.7514      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.0-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6855400696864111\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3542039355992844\n",
      "Original f1: 0.2694300518134715\n",
      "0.226014790709\n",
      "0.997283541113\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 319\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8483    0.7430    0.7922       926\n",
      "          1     0.2938    0.4459    0.3542       222\n",
      "\n",
      "avg / total     0.7411    0.6855    0.7075      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6947923533289387\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.35605006954102913\n",
      "Original f1: 0.3050259965337955\n",
      "0.21807236125\n",
      "0.999999687384\n",
      "463\n",
      "0.305207646671\n",
      "Number of disagreement: 388\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8558    0.7510    0.8000      1233\n",
      "          1     0.2943    0.4507    0.3561       284\n",
      "\n",
      "avg / total     0.7507    0.6948    0.7169      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.0-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7674216027874564\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.37470725995316156\n",
      "Original f1: 0.2694300518134715\n",
      "0.0626638807942\n",
      "0.993667659118\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 91\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8494    0.8650    0.8571       926\n",
      "          1     0.3902    0.3604    0.3747       222\n",
      "\n",
      "avg / total     0.7606    0.7674    0.7638      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7442320369149638\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.39375000000000004\n",
      "Original f1: 0.3050259965337955\n",
      "0.0735259182394\n",
      "0.997666362999\n",
      "388\n",
      "0.255767963085\n",
      "Number of disagreement: 141\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8639    0.8135    0.8379      1233\n",
      "          1     0.3539    0.4437    0.3938       284\n",
      "\n",
      "avg / total     0.7684    0.7442    0.7548      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.0-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6837979094076655\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3552397868561279\n",
      "Original f1: 0.2694300518134715\n",
      "0.231548134398\n",
      "0.99728354113\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 323\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8488    0.7397    0.7905       926\n",
      "          1     0.2933    0.4505    0.3552       222\n",
      "\n",
      "avg / total     0.7414    0.6838    0.7064      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6862228081740277\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.34972677595628415\n",
      "Original f1: 0.3050259965337955\n",
      "0.22382058714\n",
      "0.999999687029\n",
      "476\n",
      "0.313777191826\n",
      "Number of disagreement: 399\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8541    0.7405    0.7932      1233\n",
      "          1     0.2857    0.4507    0.3497       284\n",
      "\n",
      "avg / total     0.7477    0.6862    0.7102      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.5-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7682926829268293\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2485875706214689\n",
      "Original f1: 0.2694300518134715\n",
      "0.0171402556196\n",
      "0.551847320064\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 32\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8248    0.9050    0.8630       926\n",
      "          1     0.3333    0.1982    0.2486       222\n",
      "\n",
      "avg / total     0.7298    0.7683    0.7442      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7495056031641397\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.28838951310861427\n",
      "Original f1: 0.3050259965337955\n",
      "0.0198902753821\n",
      "0.575510989959\n",
      "380\n",
      "0.250494396836\n",
      "Number of disagreement: 47\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8366    0.8597    0.8480      1233\n",
      "          1     0.3080    0.2711    0.2884       284\n",
      "\n",
      "avg / total     0.7377    0.7495    0.7432      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.5-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7874564459930313\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.1920529801324503\n",
      "Original f1: 0.2694300518134715\n",
      "0.0913283784107\n",
      "0.610520951494\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 106\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8193    0.9449    0.8776       926\n",
      "          1     0.3625    0.1306    0.1921       222\n",
      "\n",
      "avg / total     0.7310    0.7875    0.7451      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7963085036255768\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.26950354609929084\n",
      "Original f1: 0.3050259965337955\n",
      "0.109855375808\n",
      "0.684292676704\n",
      "309\n",
      "0.203691496374\n",
      "Number of disagreement: 184\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8353    0.9335    0.8817      1233\n",
      "          1     0.4101    0.2007    0.2695       284\n",
      "\n",
      "avg / total     0.7557    0.7963    0.7671      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.5-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7682926829268293\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2611111111111111\n",
      "Original f1: 0.2694300518134715\n",
      "0.0177795707096\n",
      "0.430871849925\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 26\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8267    0.9017    0.8626       926\n",
      "          1     0.3406    0.2117    0.2611       222\n",
      "\n",
      "avg / total     0.7327    0.7683    0.7463      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7475280158206987\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.29981718464351004\n",
      "Original f1: 0.3050259965337955\n",
      "0.0228664247989\n",
      "0.575510989959\n",
      "383\n",
      "0.252471984179\n",
      "Number of disagreement: 46\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8389    0.8532    0.8460      1233\n",
      "          1     0.3118    0.2887    0.2998       284\n",
      "\n",
      "avg / total     0.7402    0.7475    0.7437      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.5-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7142857142857143\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.32231404958677684\n",
      "Original f1: 0.2694300518134715\n",
      "0.179628652261\n",
      "0.997283539615\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 252\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8375    0.8013    0.8190       926\n",
      "          1     0.2977    0.3514    0.3223       222\n",
      "\n",
      "avg / total     0.7331    0.7143    0.7229      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7198417930125247\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.35703479576399394\n",
      "Original f1: 0.3050259965337955\n",
      "0.184569295781\n",
      "0.992866689262\n",
      "425\n",
      "0.280158206987\n",
      "Number of disagreement: 336\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8544    0.7899    0.8209      1233\n",
      "          1     0.3130    0.4155    0.3570       284\n",
      "\n",
      "avg / total     0.7530    0.7198    0.7341      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.5-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7682926829268293\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2692307692307692\n",
      "Original f1: 0.2694300518134715\n",
      "0.0193343807851\n",
      "0.429291151947\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 26\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8280    0.8996    0.8623       926\n",
      "          1     0.3451    0.2207    0.2692       222\n",
      "\n",
      "avg / total     0.7346    0.7683    0.7476      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7475280158206987\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.30741410488245935\n",
      "Original f1: 0.3050259965337955\n",
      "0.025913208657\n",
      "0.666769957918\n",
      "383\n",
      "0.252471984179\n",
      "Number of disagreement: 52\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8405    0.8508    0.8456      1233\n",
      "          1     0.3160    0.2993    0.3074       284\n",
      "\n",
      "avg / total     0.7423    0.7475    0.7449      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.5-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7003484320557491\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.33333333333333337\n",
      "Original f1: 0.2694300518134715\n",
      "0.192885529141\n",
      "0.997283541021\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 278\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8407    0.7754    0.8067       926\n",
      "          1     0.2925    0.3874    0.3333       222\n",
      "\n",
      "avg / total     0.7347    0.7003    0.7152      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7092946605141727\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3524229074889868\n",
      "Original f1: 0.3050259965337955\n",
      "0.194926413356\n",
      "0.992866689099\n",
      "441\n",
      "0.290705339486\n",
      "Number of disagreement: 352\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8536    0.7753    0.8126      1233\n",
      "          1     0.3023    0.4225    0.3524       284\n",
      "\n",
      "avg / total     0.7504    0.7093    0.7264      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.5-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7665505226480837\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2717391304347826\n",
      "Original f1: 0.2694300518134715\n",
      "0.0230700028731\n",
      "0.46247047539\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 28\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8283    0.8963    0.8610       926\n",
      "          1     0.3425    0.2252    0.2717       222\n",
      "\n",
      "avg / total     0.7344    0.7666    0.7470      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7462096242584048\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.31616341030195383\n",
      "Original f1: 0.3050259965337955\n",
      "0.0320093391909\n",
      "0.789925324517\n",
      "385\n",
      "0.253790375742\n",
      "Number of disagreement: 62\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8425    0.8459    0.8442      1233\n",
      "          1     0.3190    0.3134    0.3162       284\n",
      "\n",
      "avg / total     0.7445    0.7462    0.7453      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.5-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6890243902439024\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.33766233766233766\n",
      "Original f1: 0.2694300518134715\n",
      "0.208325587468\n",
      "0.99728354101\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 299\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8424    0.7559    0.7968       926\n",
      "          1     0.2871    0.4099    0.3377       222\n",
      "\n",
      "avg / total     0.7350    0.6890    0.7080      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7020435069215557\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.34870317002881845\n",
      "Original f1: 0.3050259965337955\n",
      "0.20550248853\n",
      "0.992866689204\n",
      "452\n",
      "0.297956493078\n",
      "Number of disagreement: 363\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8528    0.7656    0.8068      1233\n",
      "          1     0.2951    0.4261    0.3487       284\n",
      "\n",
      "avg / total     0.7484    0.7020    0.7211      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.5-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7709059233449478\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3168831168831169\n",
      "Original f1: 0.2694300518134715\n",
      "0.0309121190447\n",
      "0.993264876497\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 43\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8365    0.8898    0.8624       926\n",
      "          1     0.3742    0.2748    0.3169       222\n",
      "\n",
      "avg / total     0.7471    0.7709    0.7569      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7435728411338167\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3281519861830743\n",
      "Original f1: 0.3050259965337955\n",
      "0.0416727067311\n",
      "0.929341281449\n",
      "389\n",
      "0.256427158866\n",
      "Number of disagreement: 78\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8453    0.8378    0.8415      1233\n",
      "          1     0.3220    0.3345    0.3282       284\n",
      "\n",
      "avg / total     0.7474    0.7436    0.7454      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.5-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6794425087108014\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.34285714285714286\n",
      "Original f1: 0.2694300518134715\n",
      "0.219985208894\n",
      "0.99728354119\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 318\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8444    0.7387    0.7880       926\n",
      "          1     0.2840    0.4324    0.3429       222\n",
      "\n",
      "avg / total     0.7361    0.6794    0.7019      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6941331575477917\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3446327683615819\n",
      "Original f1: 0.3050259965337955\n",
      "0.214906165864\n",
      "0.999999662687\n",
      "464\n",
      "0.305866842452\n",
      "Number of disagreement: 373\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8518    0.7551    0.8005      1233\n",
      "          1     0.2877    0.4296    0.3446       284\n",
      "\n",
      "avg / total     0.7462    0.6941    0.7152      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.5-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7752613240418118\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3582089552238806\n",
      "Original f1: 0.2694300518134715\n",
      "0.0450972544594\n",
      "0.993264876502\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 60\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8450    0.8834    0.8638       926\n",
      "          1     0.4000    0.3243    0.3582       222\n",
      "\n",
      "avg / total     0.7590    0.7753    0.7660      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7435728411338167\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3874015748031496\n",
      "Original f1: 0.3050259965337955\n",
      "0.0658222096817\n",
      "0.992866688435\n",
      "389\n",
      "0.256427158866\n",
      "Number of disagreement: 134\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8619    0.8151    0.8378      1233\n",
      "          1     0.3504    0.4331    0.3874       284\n",
      "\n",
      "avg / total     0.7662    0.7436    0.7535      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.5-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.6733449477351916\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.35008665511265163\n",
      "Original f1: 0.2694300518134715\n",
      "0.229494316096\n",
      "0.997283541093\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 335\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8474    0.7257    0.7818       926\n",
      "          1     0.2845    0.4550    0.3501       222\n",
      "\n",
      "avg / total     0.7386    0.6733    0.6984      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6849044166117337\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.34520547945205476\n",
      "Original f1: 0.3050259965337955\n",
      "0.225190234299\n",
      "0.999999684228\n",
      "478\n",
      "0.315095583388\n",
      "Number of disagreement: 393\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8525    0.7405    0.7925      1233\n",
      "          1     0.2825    0.4437    0.3452       284\n",
      "\n",
      "avg / total     0.7458    0.6849    0.7088      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.5-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7665505226480837\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3708920187793427\n",
      "Original f1: 0.2694300518134715\n",
      "0.0626176420512\n",
      "0.994041927757\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 82\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8485    0.8650    0.8567       926\n",
      "          1     0.3873    0.3559    0.3709       222\n",
      "\n",
      "avg / total     0.7593    0.7666    0.7627      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7343441001977588\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3884673748103187\n",
      "Original f1: 0.3050259965337955\n",
      "0.0762086122464\n",
      "0.992866689187\n",
      "403\n",
      "0.265655899802\n",
      "Number of disagreement: 156\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8634    0.7997    0.8303      1233\n",
      "          1     0.3413    0.4507    0.3885       284\n",
      "\n",
      "avg / total     0.7657    0.7343    0.7476      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.5-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6707317073170732\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.35051546391752575\n",
      "Original f1: 0.2694300518134715\n",
      "0.235336726646\n",
      "0.997283541065\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 340\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8477    0.7214    0.7795       926\n",
      "          1     0.2833    0.4595    0.3505       222\n",
      "\n",
      "avg / total     0.7386    0.6707    0.6965      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6796308503625577\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.34146341463414637\n",
      "Original f1: 0.3050259965337955\n",
      "0.230091311168\n",
      "0.999999685491\n",
      "486\n",
      "0.320369149637\n",
      "Number of disagreement: 401\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8514    0.7340    0.7883      1233\n",
      "          1     0.2775    0.4437    0.3415       284\n",
      "\n",
      "avg / total     0.7439    0.6796    0.7047      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.5-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7682926829268293\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.25698324022346364\n",
      "Original f1: 0.2694300518134715\n",
      "0.0161475963238\n",
      "0.531321754663\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 30\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8261    0.9028    0.8627       926\n",
      "          1     0.3382    0.2072    0.2570       222\n",
      "\n",
      "avg / total     0.7317    0.7683    0.7456      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7481872116018458\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.28996282527881045\n",
      "Original f1: 0.3050259965337955\n",
      "0.0193617692169\n",
      "0.582622793011\n",
      "382\n",
      "0.251812788398\n",
      "Number of disagreement: 39\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8369    0.8573    0.8470      1233\n",
      "          1     0.3071    0.2746    0.2900       284\n",
      "\n",
      "avg / total     0.7377    0.7482    0.7427      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.5-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7839721254355401\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.18421052631578946\n",
      "Original f1: 0.2694300518134715\n",
      "0.0954188936351\n",
      "0.623773744334\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 106\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8180    0.9417    0.8755       926\n",
      "          1     0.3415    0.1261    0.1842       222\n",
      "\n",
      "avg / total     0.7259    0.7840    0.7418      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7936717205009888\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.234718826405868\n",
      "Original f1: 0.3050259965337955\n",
      "0.114114260552\n",
      "0.686334279423\n",
      "313\n",
      "0.206328279499\n",
      "Number of disagreement: 200\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8305    0.9376    0.8808      1233\n",
      "          1     0.3840    0.1690    0.2347       284\n",
      "\n",
      "avg / total     0.7469    0.7937    0.7598      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.5-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7674216027874564\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2644628099173553\n",
      "Original f1: 0.2694300518134715\n",
      "0.0167251799822\n",
      "0.439443171362\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 25\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8996    0.8619       926\n",
      "          1     0.3404    0.2162    0.2645       222\n",
      "\n",
      "avg / total     0.7331    0.7674    0.7463      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7481872116018458\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3029197080291971\n",
      "Original f1: 0.3050259965337955\n",
      "0.0217258068029\n",
      "0.582622793011\n",
      "382\n",
      "0.251812788398\n",
      "Number of disagreement: 41\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8396    0.8532    0.8463      1233\n",
      "          1     0.3144    0.2923    0.3029       284\n",
      "\n",
      "avg / total     0.7413    0.7482    0.7446      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.5-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7081881533101045\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3204868154158215\n",
      "Original f1: 0.2694300518134715\n",
      "0.186004062641\n",
      "0.997283541036\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 259\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8369    0.7927    0.8142       926\n",
      "          1     0.2915    0.3559    0.3205       222\n",
      "\n",
      "avg / total     0.7315    0.7082    0.7187      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7132498352010547\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.34190620272314676\n",
      "Original f1: 0.3050259965337955\n",
      "0.192788875109\n",
      "0.999999686607\n",
      "435\n",
      "0.286750164799\n",
      "Number of disagreement: 356\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8500    0.7859    0.8167      1233\n",
      "          1     0.2997    0.3979    0.3419       284\n",
      "\n",
      "avg / total     0.7470    0.7132    0.7278      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.5-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7656794425087108\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2670299727520436\n",
      "Original f1: 0.2694300518134715\n",
      "0.0185259370633\n",
      "0.439443171362\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 25\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8275    0.8963    0.8605       926\n",
      "          1     0.3379    0.2207    0.2670       222\n",
      "\n",
      "avg / total     0.7328    0.7657    0.7458      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7481872116018458\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.30797101449275366\n",
      "Original f1: 0.3050259965337955\n",
      "0.0246207584434\n",
      "0.647906009523\n",
      "382\n",
      "0.251812788398\n",
      "Number of disagreement: 45\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8407    0.8516    0.8461      1233\n",
      "          1     0.3172    0.2993    0.3080       284\n",
      "\n",
      "avg / total     0.7427    0.7482    0.7453      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.5-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6977351916376306\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3365200764818355\n",
      "Original f1: 0.2694300518134715\n",
      "0.198749325371\n",
      "0.997283541192\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 281\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.7700    0.8043       926\n",
      "          1     0.2924    0.3964    0.3365       222\n",
      "\n",
      "avg / total     0.7355    0.6977    0.7138      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7040210942649967\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.33481481481481484\n",
      "Original f1: 0.3050259965337955\n",
      "0.20225316109\n",
      "0.999999687224\n",
      "449\n",
      "0.295978905735\n",
      "Number of disagreement: 364\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8481    0.7745    0.8097      1233\n",
      "          1     0.2890    0.3979    0.3348       284\n",
      "\n",
      "avg / total     0.7435    0.7040    0.7208      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.5-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7656794425087108\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.274932614555256\n",
      "Original f1: 0.2694300518134715\n",
      "0.022395521212\n",
      "0.51799280392\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 29\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8288    0.8942    0.8603       926\n",
      "          1     0.3423    0.2297    0.2749       222\n",
      "\n",
      "avg / total     0.7347    0.7657    0.7471      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7475280158206987\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3197158081705151\n",
      "Original f1: 0.3050259965337955\n",
      "0.0306791114454\n",
      "0.769007920983\n",
      "383\n",
      "0.252471984179\n",
      "Number of disagreement: 56\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8433    0.8467    0.8450      1233\n",
      "          1     0.3226    0.3169    0.3197       284\n",
      "\n",
      "avg / total     0.7458    0.7475    0.7467      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.5-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.681184668989547\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.33935018050541516\n",
      "Original f1: 0.2694300518134715\n",
      "0.214681762296\n",
      "0.997283541183\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 308\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8431    0.7430    0.7899       926\n",
      "          1     0.2831    0.4234    0.3394       222\n",
      "\n",
      "avg / total     0.7348    0.6812    0.7028      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6921555702043507\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3319027181688126\n",
      "Original f1: 0.3050259965337955\n",
      "0.212283666334\n",
      "0.999999687373\n",
      "467\n",
      "0.307844429796\n",
      "Number of disagreement: 388\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8475    0.7575    0.8000      1233\n",
      "          1     0.2795    0.4085    0.3319       284\n",
      "\n",
      "avg / total     0.7412    0.6922    0.7124      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.5-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.769163763066202\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3116883116883117\n",
      "Original f1: 0.2694300518134715\n",
      "0.0299332193289\n",
      "0.930473320807\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 41\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8355    0.8888    0.8613       926\n",
      "          1     0.3681    0.2703    0.3117       222\n",
      "\n",
      "avg / total     0.7451    0.7692    0.7550      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7442320369149638\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3263888888888889\n",
      "Original f1: 0.3050259965337955\n",
      "0.0399758170234\n",
      "0.905271795515\n",
      "388\n",
      "0.255767963085\n",
      "Number of disagreement: 69\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8449    0.8394    0.8421      1233\n",
      "          1     0.3219    0.3310    0.3264       284\n",
      "\n",
      "avg / total     0.7470    0.7442    0.7456      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.5-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.662020905923345\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3333333333333333\n",
      "Original f1: 0.2694300518134715\n",
      "0.228289863522\n",
      "0.997283541198\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 332\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8414    0.7160    0.7736       926\n",
      "          1     0.2694    0.4369    0.3333       222\n",
      "\n",
      "avg / total     0.7308    0.6620    0.6885      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6829268292682927\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.32538569424964936\n",
      "Original f1: 0.3050259965337955\n",
      "0.221452338983\n",
      "0.999999687353\n",
      "481\n",
      "0.317073170732\n",
      "Number of disagreement: 400\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8456    0.7461    0.7928      1233\n",
      "          1     0.2704    0.4085    0.3254       284\n",
      "\n",
      "avg / total     0.7379    0.6829    0.7053      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.5-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7726480836236934\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.34912718204488774\n",
      "Original f1: 0.2694300518134715\n",
      "0.0442825097748\n",
      "0.993667656447\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 57\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8431    0.8823    0.8623       926\n",
      "          1     0.3911    0.3153    0.3491       222\n",
      "\n",
      "avg / total     0.7557    0.7726    0.7630      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7297297297297297\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.34920634920634924\n",
      "Original f1: 0.3050259965337955\n",
      "0.0645772142112\n",
      "0.97257081583\n",
      "410\n",
      "0.27027027027\n",
      "Number of disagreement: 121\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8514    0.8086    0.8295      1233\n",
      "          1     0.3179    0.3873    0.3492       284\n",
      "\n",
      "avg / total     0.7515    0.7297    0.7395      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.5-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6585365853658537\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.34228187919463093\n",
      "Original f1: 0.2694300518134715\n",
      "0.237491899302\n",
      "0.997283541165\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 344\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8450    0.7063    0.7694       926\n",
      "          1     0.2727    0.4595    0.3423       222\n",
      "\n",
      "avg / total     0.7343    0.6585    0.6868      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6730388925510876\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.32608695652173914\n",
      "Original f1: 0.3050259965337955\n",
      "0.230317562148\n",
      "0.999999687366\n",
      "496\n",
      "0.326961107449\n",
      "Number of disagreement: 421\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8460    0.7307    0.7842      1233\n",
      "          1     0.2655    0.4225    0.3261       284\n",
      "\n",
      "avg / total     0.7373    0.6730    0.6984      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.5-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.759581881533101\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36111111111111116\n",
      "Original f1: 0.2694300518134715\n",
      "0.0630320875684\n",
      "0.993667658775\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 84\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8465    0.8575    0.8519       926\n",
      "          1     0.3714    0.3514    0.3611       222\n",
      "\n",
      "avg / total     0.7546    0.7596    0.7570      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7330257086354647\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3835616438356164\n",
      "Original f1: 0.3050259965337955\n",
      "0.0753290232396\n",
      "0.999999687124\n",
      "405\n",
      "0.266974291365\n",
      "Number of disagreement: 146\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8619    0.7997    0.8296      1233\n",
      "          1     0.3378    0.4437    0.3836       284\n",
      "\n",
      "avg / total     0.7638    0.7330    0.7461      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-1.5-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6559233449477352\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.34494195688225543\n",
      "Original f1: 0.2694300518134715\n",
      "0.242947284795\n",
      "0.997283541167\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 351\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8462    0.7009    0.7667       926\n",
      "          1     0.2730    0.4685    0.3449       222\n",
      "\n",
      "avg / total     0.7353    0.6559    0.6851      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6657877389584707\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.321285140562249\n",
      "Original f1: 0.3050259965337955\n",
      "0.234872665318\n",
      "0.999999687414\n",
      "507\n",
      "0.334212261042\n",
      "Number of disagreement: 430\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8444    0.7218    0.7783      1233\n",
      "          1     0.2592    0.4225    0.3213       284\n",
      "\n",
      "avg / total     0.7348    0.6658    0.6928      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-2.0-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7682926829268293\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.25280898876404495\n",
      "Original f1: 0.2694300518134715\n",
      "0.0171251117123\n",
      "0.552128562898\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 30\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8254    0.9039    0.8629       926\n",
      "          1     0.3358    0.2027    0.2528       222\n",
      "\n",
      "avg / total     0.7308    0.7683    0.7449      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7468688200395518\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.2862453531598513\n",
      "Original f1: 0.3050259965337955\n",
      "0.0195882062209\n",
      "0.522587596685\n",
      "384\n",
      "0.25313117996\n",
      "Number of disagreement: 43\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8361    0.8564    0.8462      1233\n",
      "          1     0.3031    0.2711    0.2862       284\n",
      "\n",
      "avg / total     0.7363    0.7469    0.7413      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-2.0-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7883275261324042\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.198019801980198\n",
      "Original f1: 0.2694300518134715\n",
      "0.0912686049558\n",
      "0.628740424066\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 103\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8201    0.9449    0.8781       926\n",
      "          1     0.3704    0.1351    0.1980       222\n",
      "\n",
      "avg / total     0.7331    0.7883    0.7466      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7949901120632828\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.2577565632458234\n",
      "Original f1: 0.3050259965337955\n",
      "0.110380817772\n",
      "0.62023915834\n",
      "311\n",
      "0.205009887937\n",
      "Number of disagreement: 184\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8336    0.9343    0.8811      1233\n",
      "          1     0.4000    0.1901    0.2578       284\n",
      "\n",
      "avg / total     0.7524    0.7950    0.7644      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-2.0-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7665505226480837\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2596685082872928\n",
      "Original f1: 0.2694300518134715\n",
      "0.0177827020873\n",
      "0.462376340867\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 24\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8264    0.8996    0.8614       926\n",
      "          1     0.3357    0.2117    0.2597       222\n",
      "\n",
      "avg / total     0.7315    0.7666    0.7451      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7462096242584048\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3012704174228675\n",
      "Original f1: 0.3050259965337955\n",
      "0.0226173747895\n",
      "0.563208267497\n",
      "385\n",
      "0.253790375742\n",
      "Number of disagreement: 44\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8392    0.8508    0.8449      1233\n",
      "          1     0.3109    0.2923    0.3013       284\n",
      "\n",
      "avg / total     0.7403    0.7462    0.7432      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-2.0-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7047038327526133\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.32335329341317365\n",
      "Original f1: 0.2694300518134715\n",
      "0.182720517875\n",
      "0.997283541013\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 263\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8377    0.7862    0.8111       926\n",
      "          1     0.2903    0.3649    0.3234       222\n",
      "\n",
      "avg / total     0.7319    0.7047    0.7168      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7172050098879367\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3509833585476551\n",
      "Original f1: 0.3050259965337955\n",
      "0.18807687133\n",
      "0.9928666892\n",
      "429\n",
      "0.282794990112\n",
      "Number of disagreement: 340\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8526    0.7883    0.8192      1233\n",
      "          1     0.3077    0.4085    0.3510       284\n",
      "\n",
      "avg / total     0.7506    0.7172    0.7316      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-2.0-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7665505226480837\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2677595628415301\n",
      "Original f1: 0.2694300518134715\n",
      "0.0193175200837\n",
      "0.462376340867\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 24\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8277    0.8974    0.8611       926\n",
      "          1     0.3403    0.2207    0.2678       222\n",
      "\n",
      "avg / total     0.7334    0.7666    0.7464      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7455504284772577\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3057553956834532\n",
      "Original f1: 0.3050259965337955\n",
      "0.025636606479\n",
      "0.661915890695\n",
      "386\n",
      "0.254449571523\n",
      "Number of disagreement: 49\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8402    0.8483    0.8442      1233\n",
      "          1     0.3125    0.2993    0.3058       284\n",
      "\n",
      "avg / total     0.7414    0.7456    0.7434      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-2.0-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6977351916376306\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.33904761904761904\n",
      "Original f1: 0.2694300518134715\n",
      "0.196522643565\n",
      "0.997283541175\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 283\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8426    0.7689    0.8041       926\n",
      "          1     0.2937    0.4009    0.3390       222\n",
      "\n",
      "avg / total     0.7365    0.6977    0.7141      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7059986816084377\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3460410557184751\n",
      "Original f1: 0.3050259965337955\n",
      "0.198543954561\n",
      "0.992866689267\n",
      "446\n",
      "0.294001318392\n",
      "Number of disagreement: 355\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8517    0.7729    0.8104      1233\n",
      "          1     0.2965    0.4155    0.3460       284\n",
      "\n",
      "avg / total     0.7477    0.7060    0.7234      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-2.0-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7665505226480837\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2717391304347826\n",
      "Original f1: 0.2694300518134715\n",
      "0.0229058866421\n",
      "0.496260410693\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 26\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8283    0.8963    0.8610       926\n",
      "          1     0.3425    0.2252    0.2717       222\n",
      "\n",
      "avg / total     0.7344    0.7666    0.7470      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7448912326961108\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.31504424778761064\n",
      "Original f1: 0.3050259965337955\n",
      "0.0320551926907\n",
      "0.787096843086\n",
      "387\n",
      "0.255108767304\n",
      "Number of disagreement: 58\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8422    0.8443    0.8433      1233\n",
      "          1     0.3167    0.3134    0.3150       284\n",
      "\n",
      "avg / total     0.7439    0.7449    0.7444      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-2.0-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6837979094076655\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.34119782214156075\n",
      "Original f1: 0.2694300518134715\n",
      "0.212896316006\n",
      "0.997283541146\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 307\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8437    0.7462    0.7920       926\n",
      "          1     0.2857    0.4234    0.3412       222\n",
      "\n",
      "avg / total     0.7358    0.6838    0.7048      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6987475280158207\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3424460431654676\n",
      "Original f1: 0.3050259965337955\n",
      "0.208979501626\n",
      "0.992866689186\n",
      "457\n",
      "0.301252471984\n",
      "Number of disagreement: 368\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8508    0.7632    0.8046      1233\n",
      "          1     0.2895    0.4190    0.3424       284\n",
      "\n",
      "avg / total     0.7457    0.6987    0.7181      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-2.0-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.769163763066202\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.30446194225721784\n",
      "Original f1: 0.2694300518134715\n",
      "0.0306338958834\n",
      "0.993264873678\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 39\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8342    0.8909    0.8616       926\n",
      "          1     0.3648    0.2613    0.3045       222\n",
      "\n",
      "avg / total     0.7434    0.7692    0.7539      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7415952537903757\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3287671232876712\n",
      "Original f1: 0.3050259965337955\n",
      "0.0417316462648\n",
      "0.933801863783\n",
      "392\n",
      "0.25840474621\n",
      "Number of disagreement: 77\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8455    0.8345    0.8400      1233\n",
      "          1     0.3200    0.3380    0.3288       284\n",
      "\n",
      "avg / total     0.7471    0.7416    0.7443      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-2.0-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6733449477351916\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3432574430823117\n",
      "Original f1: 0.2694300518134715\n",
      "0.224181662482\n",
      "0.997283541156\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 325\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8448    0.7289    0.7826       926\n",
      "          1     0.2808    0.4414    0.3433       222\n",
      "\n",
      "avg / total     0.7357    0.6733    0.6976      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6842452208305867\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.33193863319386335\n",
      "Original f1: 0.3050259965337955\n",
      "0.219064168527\n",
      "0.997565927181\n",
      "479\n",
      "0.315754779169\n",
      "Number of disagreement: 386\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8478    0.7453    0.7933      1233\n",
      "          1     0.2748    0.4190    0.3319       284\n",
      "\n",
      "avg / total     0.7405    0.6842    0.7069      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-2.0-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7709059233449478\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3441396508728179\n",
      "Original f1: 0.2694300518134715\n",
      "0.0451719868928\n",
      "0.993264876372\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 57\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8421    0.8812    0.8612       926\n",
      "          1     0.3855    0.3108    0.3441       222\n",
      "\n",
      "avg / total     0.7538    0.7709    0.7612      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7350032959789057\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.375776397515528\n",
      "Original f1: 0.3050259965337955\n",
      "0.0664839119703\n",
      "0.992866686105\n",
      "402\n",
      "0.264996704021\n",
      "Number of disagreement: 137\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8591    0.8062    0.8318      1233\n",
      "          1     0.3361    0.4261    0.3758       284\n",
      "\n",
      "avg / total     0.7612    0.7350    0.7464      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-2.0-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6689895470383276\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3493150684931507\n",
      "Original f1: 0.2694300518134715\n",
      "0.233988057951\n",
      "0.99728354119\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 338\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8473    0.7192    0.7780       926\n",
      "          1     0.2818    0.4595    0.3493       222\n",
      "\n",
      "avg / total     0.7380    0.6690    0.6951      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6763348714568227\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.33378561736770684\n",
      "Original f1: 0.3050259965337955\n",
      "0.229473564896\n",
      "0.999999681821\n",
      "491\n",
      "0.323665128543\n",
      "Number of disagreement: 406\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8487    0.7324    0.7862      1233\n",
      "          1     0.2715    0.4331    0.3338       284\n",
      "\n",
      "avg / total     0.7406    0.6763    0.7015      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-2.0-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7613240418118467\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3627906976744187\n",
      "Original f1: 0.2694300518134715\n",
      "0.0626812556363\n",
      "0.996912516545\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 82\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8468    0.8596    0.8532       926\n",
      "          1     0.3750    0.3514    0.3628       222\n",
      "\n",
      "avg / total     0.7556    0.7613    0.7583      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7317073170731707\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3861236802413273\n",
      "Original f1: 0.3050259965337955\n",
      "0.0771900158858\n",
      "0.992866689144\n",
      "407\n",
      "0.268292682927\n",
      "Number of disagreement: 154\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8629    0.7964    0.8283      1233\n",
      "          1     0.3377    0.4507    0.3861       284\n",
      "\n",
      "avg / total     0.7646    0.7317    0.7456      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-2.0-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.6637630662020906\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.35451505016722407\n",
      "Original f1: 0.2694300518134715\n",
      "0.240185651864\n",
      "0.997283541194\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 350\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8497    0.7084    0.7727       926\n",
      "          1     0.2819    0.4775    0.3545       222\n",
      "\n",
      "avg / total     0.7399    0.6638    0.6918      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6690837178642056\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.32887700534759357\n",
      "Original f1: 0.3050259965337955\n",
      "0.234005216953\n",
      "0.999999686853\n",
      "502\n",
      "0.330916282136\n",
      "Number of disagreement: 417\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8471    0.7234    0.7804      1233\n",
      "          1     0.2651    0.4331    0.3289       284\n",
      "\n",
      "avg / total     0.7381    0.6691    0.6959      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-2.0-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7656794425087108\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.25069637883008355\n",
      "Original f1: 0.2694300518134715\n",
      "0.0162483706752\n",
      "0.528691452335\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 29\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8249    0.9006    0.8611       926\n",
      "          1     0.3285    0.2027    0.2507       222\n",
      "\n",
      "avg / total     0.7289    0.7657    0.7431      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7475280158206987\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.2894248608534323\n",
      "Original f1: 0.3050259965337955\n",
      "0.0194084152327\n",
      "0.53968240069\n",
      "383\n",
      "0.252471984179\n",
      "Number of disagreement: 38\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8368    0.8564    0.8465      1233\n",
      "          1     0.3059    0.2746    0.2894       284\n",
      "\n",
      "avg / total     0.7374    0.7475    0.7422      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-2.0-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7848432055749129\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.17391304347826086\n",
      "Original f1: 0.2694300518134715\n",
      "0.095878247304\n",
      "0.631373267123\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 109\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8170    0.9449    0.8763       926\n",
      "          1     0.3377    0.1171    0.1739       222\n",
      "\n",
      "avg / total     0.7243    0.7848    0.7405      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7910349373764007\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.23244552058111378\n",
      "Original f1: 0.3050259965337955\n",
      "0.114948650014\n",
      "0.624552403421\n",
      "317\n",
      "0.208965062624\n",
      "Number of disagreement: 198\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8300    0.9343    0.8791      1233\n",
      "          1     0.3721    0.1690    0.2324       284\n",
      "\n",
      "avg / total     0.7443    0.7910    0.7580      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-2.0-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2582417582417582\n",
      "Original f1: 0.2694300518134715\n",
      "0.0167798286269\n",
      "0.504007293822\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 24\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8260    0.8974    0.8602       926\n",
      "          1     0.3310    0.2117    0.2582       222\n",
      "\n",
      "avg / total     0.7303    0.7648    0.7438      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7495056031641397\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.304029304029304\n",
      "Original f1: 0.3050259965337955\n",
      "0.0217247636197\n",
      "0.556327394412\n",
      "380\n",
      "0.250494396836\n",
      "Number of disagreement: 41\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8398    0.8548    0.8473      1233\n",
      "          1     0.3168    0.2923    0.3040       284\n",
      "\n",
      "avg / total     0.7419    0.7495    0.7456      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-2.0-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6977351916376306\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3101391650099404\n",
      "Original f1: 0.2694300518134715\n",
      "0.189450373117\n",
      "0.997283541165\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 273\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8339    0.7808    0.8065       926\n",
      "          1     0.2776    0.3514    0.3101       222\n",
      "\n",
      "avg / total     0.7263    0.6977    0.7105      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7013843111404087\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.33284241531664216\n",
      "Original f1: 0.3050259965337955\n",
      "0.196813813983\n",
      "0.99999968717\n",
      "453\n",
      "0.29861568886\n",
      "Number of disagreement: 362\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8476    0.7713    0.8076      1233\n",
      "          1     0.2861    0.3979    0.3328       284\n",
      "\n",
      "avg / total     0.7425    0.7014    0.7188      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-2.0-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7630662020905923\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2608695652173913\n",
      "Original f1: 0.2694300518134715\n",
      "0.0185543660446\n",
      "0.504007293822\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 24\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8263    0.8942    0.8589       926\n",
      "          1     0.3288    0.2162    0.2609       222\n",
      "\n",
      "avg / total     0.7301    0.7631    0.7433      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7488464073829928\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.30852994555353896\n",
      "Original f1: 0.3050259965337955\n",
      "0.0246062592757\n",
      "0.641088790884\n",
      "381\n",
      "0.251153592617\n",
      "Number of disagreement: 46\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8408    0.8524    0.8466      1233\n",
      "          1     0.3184    0.2993    0.3085       284\n",
      "\n",
      "avg / total     0.7430    0.7488    0.7458      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-2.0-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6898954703832753\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3257575757575758\n",
      "Original f1: 0.2694300518134715\n",
      "0.203432474024\n",
      "0.997283541124\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 294\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8385    0.7624    0.7986       926\n",
      "          1     0.2810    0.3874    0.3258       222\n",
      "\n",
      "avg / total     0.7307    0.6899    0.7072      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6921555702043507\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3280575539568345\n",
      "Original f1: 0.3050259965337955\n",
      "0.206486983207\n",
      "0.999999687238\n",
      "467\n",
      "0.307844429796\n",
      "Number of disagreement: 376\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8463    0.7591    0.8003      1233\n",
      "          1     0.2774    0.4014    0.3281       284\n",
      "\n",
      "avg / total     0.7398    0.6922    0.7119      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-2.0-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7604529616724739\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.25876010781671155\n",
      "Original f1: 0.2694300518134715\n",
      "0.0223173555788\n",
      "0.563809675305\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 25\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8258    0.8909    0.8571       926\n",
      "          1     0.3221    0.2162    0.2588       222\n",
      "\n",
      "avg / total     0.7284    0.7605    0.7414      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7475280158206987\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.31729055258467026\n",
      "Original f1: 0.3050259965337955\n",
      "0.030825285078\n",
      "0.760721794767\n",
      "383\n",
      "0.252471984179\n",
      "Number of disagreement: 56\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8427    0.8475    0.8451      1233\n",
      "          1     0.3213    0.3134    0.3173       284\n",
      "\n",
      "avg / total     0.7451    0.7475    0.7463      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-2.0-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6724738675958188\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.32857142857142857\n",
      "Original f1: 0.2694300518134715\n",
      "0.220142830557\n",
      "0.997283541183\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 322\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8395    0.7343    0.7834       926\n",
      "          1     0.2722    0.4144    0.3286       222\n",
      "\n",
      "avg / total     0.7298    0.6725    0.6955      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6835860250494397\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.32584269662921345\n",
      "Original f1: 0.3050259965337955\n",
      "0.216367044904\n",
      "0.999999687394\n",
      "480\n",
      "0.316413974951\n",
      "Number of disagreement: 391\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8457    0.7470    0.7933      1233\n",
      "          1     0.2710    0.4085    0.3258       284\n",
      "\n",
      "avg / total     0.7381    0.6836    0.7058      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-2.0-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7665505226480837\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.29842931937172773\n",
      "Original f1: 0.2694300518134715\n",
      "0.0293433302412\n",
      "0.78478646278\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 36\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8330    0.8888    0.8600       926\n",
      "          1     0.3563    0.2568    0.2984       222\n",
      "\n",
      "avg / total     0.7408    0.7666    0.7514      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7468688200395518\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3333333333333333\n",
      "Original f1: 0.3050259965337955\n",
      "0.0400490211335\n",
      "0.896100153667\n",
      "384\n",
      "0.25313117996\n",
      "Number of disagreement: 71\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8465    0.8410    0.8438      1233\n",
      "          1     0.3288    0.3380    0.3333       284\n",
      "\n",
      "avg / total     0.7496    0.7469    0.7482      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-2.0-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.6515679442508711\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.32203389830508466\n",
      "Original f1: 0.2694300518134715\n",
      "0.233504324227\n",
      "0.9972835412\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 344\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8372    0.7052    0.7655       926\n",
      "          1     0.2582    0.4279    0.3220       222\n",
      "\n",
      "avg / total     0.7252    0.6516    0.6798      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6730388925510876\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.31868131868131866\n",
      "Original f1: 0.3050259965337955\n",
      "0.226142390413\n",
      "0.999999687198\n",
      "496\n",
      "0.326961107449\n",
      "Number of disagreement: 405\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8434    0.7340    0.7849      1233\n",
      "          1     0.2613    0.4085    0.3187       284\n",
      "\n",
      "avg / total     0.7344    0.6730    0.6976      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-2.0-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7665505226480837\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3366336633663366\n",
      "Original f1: 0.2694300518134715\n",
      "0.0446054515031\n",
      "0.993667650775\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 54\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8406    0.8769    0.8584       926\n",
      "          1     0.3736    0.3063    0.3366       222\n",
      "\n",
      "avg / total     0.7503    0.7666    0.7575      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7270929466051417\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3470031545741325\n",
      "Original f1: 0.3050259965337955\n",
      "0.0656208035562\n",
      "0.977355955289\n",
      "414\n",
      "0.272907053395\n",
      "Number of disagreement: 125\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8509    0.8054    0.8275      1233\n",
      "          1     0.3143    0.3873    0.3470       284\n",
      "\n",
      "avg / total     0.7504    0.7271    0.7375      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-2.0-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6480836236933798\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.33333333333333337\n",
      "Original f1: 0.2694300518134715\n",
      "0.242837701721\n",
      "0.999999889107\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 360\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8416    0.6944    0.7609       926\n",
      "          1     0.2630    0.4550    0.3333       222\n",
      "\n",
      "avg / total     0.7297    0.6481    0.6783      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6618325642715887\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3187250996015936\n",
      "Original f1: 0.3050259965337955\n",
      "0.234643937742\n",
      "0.999999687296\n",
      "513\n",
      "0.338167435728\n",
      "Number of disagreement: 428\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8435    0.7170    0.7751      1233\n",
      "          1     0.2559    0.4225    0.3187       284\n",
      "\n",
      "avg / total     0.7335    0.6618    0.6897      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-2.0-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7560975609756098\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3548387096774193\n",
      "Original f1: 0.2694300518134715\n",
      "0.0629213948179\n",
      "0.993667657988\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 84\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8451    0.8542    0.8496       926\n",
      "          1     0.3632    0.3468    0.3548       222\n",
      "\n",
      "avg / total     0.7519    0.7561    0.7539      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7330257086354647\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3816793893129771\n",
      "Original f1: 0.3050259965337955\n",
      "0.07625130423\n",
      "0.999999685572\n",
      "405\n",
      "0.266974291365\n",
      "Number of disagreement: 146\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8613    0.8005    0.8298      1233\n",
      "          1     0.3369    0.4401    0.3817       284\n",
      "\n",
      "avg / total     0.7631    0.7330    0.7459      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  1.5-2.0-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6480836236933798\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.34201954397394135\n",
      "Original f1: 0.2694300518134715\n",
      "0.248319378735\n",
      "0.999999896463\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 366\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8452    0.6901    0.7598       926\n",
      "          1     0.2679    0.4730    0.3420       222\n",
      "\n",
      "avg / total     0.7336    0.6481    0.6790      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6565589980224127\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.31537450722733246\n",
      "Original f1: 0.3050259965337955\n",
      "0.238988184037\n",
      "0.999999687407\n",
      "521\n",
      "0.343441001978\n",
      "Number of disagreement: 436\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8423    0.7105    0.7708      1233\n",
      "          1     0.2516    0.4225    0.3154       284\n",
      "\n",
      "avg / total     0.7317    0.6566    0.6855      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.5-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7900696864111498\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2300319488817891\n",
      "Original f1: 0.2694300518134715\n",
      "0.0384144590086\n",
      "0.646008577319\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 83\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8240    0.9406    0.8785       926\n",
      "          1     0.3956    0.1622    0.2300       222\n",
      "\n",
      "avg / total     0.7412    0.7901    0.7531      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7818061964403428\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.2460136674259681\n",
      "Original f1: 0.3050259965337955\n",
      "0.0494805267559\n",
      "0.707968257605\n",
      "331\n",
      "0.21819380356\n",
      "Number of disagreement: 156\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8311    0.9181    0.8724      1233\n",
      "          1     0.3484    0.1901    0.2460       284\n",
      "\n",
      "avg / total     0.7408    0.7818    0.7552      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.5-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7961672473867596\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.1818181818181818\n",
      "Original f1: 0.2694300518134715\n",
      "0.112626052605\n",
      "0.751661718772\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 118\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8192    0.9590    0.8836       926\n",
      "          1     0.4062    0.1171    0.1818       222\n",
      "\n",
      "avg / total     0.7393    0.7962    0.7479      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7976268951878708\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.2493887530562347\n",
      "Original f1: 0.3050259965337955\n",
      "0.127007245031\n",
      "0.848024955054\n",
      "307\n",
      "0.202373104812\n",
      "Number of disagreement: 216\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8326    0.9400    0.8830      1233\n",
      "          1     0.4080    0.1796    0.2494       284\n",
      "\n",
      "avg / total     0.7531    0.7976    0.7644      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.5-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7918118466898955\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2691131498470948\n",
      "Original f1: 0.2694300518134715\n",
      "0.0388128464921\n",
      "0.575141996104\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 77\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8293    0.9341    0.8786       926\n",
      "          1     0.4190    0.1982    0.2691       222\n",
      "\n",
      "avg / total     0.7500    0.7918    0.7608      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7765326301911668\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.28025477707006374\n",
      "Original f1: 0.3050259965337955\n",
      "0.0509821499699\n",
      "0.707968257605\n",
      "339\n",
      "0.223467369809\n",
      "Number of disagreement: 154\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8361    0.9019    0.8677      1233\n",
      "          1     0.3529    0.2324    0.2803       284\n",
      "\n",
      "avg / total     0.7456    0.7765    0.7578      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.5-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7813588850174216\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.35142118863049093\n",
      "Original f1: 0.2694300518134715\n",
      "0.161697233224\n",
      "0.993264876397\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 191\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8433    0.8952    0.8685       926\n",
      "          1     0.4121    0.3063    0.3514       222\n",
      "\n",
      "avg / total     0.7599    0.7814    0.7685      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7679630850362558\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3333333333333333\n",
      "Original f1: 0.3050259965337955\n",
      "0.162868059874\n",
      "0.979195607363\n",
      "352\n",
      "0.232036914964\n",
      "Number of disagreement: 285\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8460    0.8735    0.8595      1233\n",
      "          1     0.3607    0.3099    0.3333       284\n",
      "\n",
      "avg / total     0.7552    0.7680    0.7610      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.5-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7918118466898955\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.27355623100303955\n",
      "Original f1: 0.2694300518134715\n",
      "0.0401620934558\n",
      "0.575141996104\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 77\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8300    0.9330    0.8785       926\n",
      "          1     0.4206    0.2027    0.2736       222\n",
      "\n",
      "avg / total     0.7508    0.7918    0.7615      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7732366512854317\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.2833333333333333\n",
      "Original f1: 0.3050259965337955\n",
      "0.0529307602787\n",
      "0.707968257605\n",
      "344\n",
      "0.226763348715\n",
      "Number of disagreement: 155\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8365    0.8962    0.8653      1233\n",
      "          1     0.3469    0.2394    0.2833       284\n",
      "\n",
      "avg / total     0.7448    0.7732    0.7564      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.5-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7804878048780488\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.37\n",
      "Original f1: 0.2694300518134715\n",
      "0.172383829947\n",
      "0.993264876653\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 202\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8474    0.8877    0.8671       926\n",
      "          1     0.4157    0.3333    0.3700       222\n",
      "\n",
      "avg / total     0.7639    0.7805    0.7710      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7679630850362558\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3553113553113553\n",
      "Original f1: 0.3050259965337955\n",
      "0.171208243248\n",
      "0.979195607427\n",
      "352\n",
      "0.232036914964\n",
      "Number of disagreement: 299\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8510    0.8662    0.8585      1233\n",
      "          1     0.3702    0.3415    0.3553       284\n",
      "\n",
      "avg / total     0.7610    0.7680    0.7643      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.5-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7935540069686411\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.29253731343283584\n",
      "Original f1: 0.2694300518134715\n",
      "0.0434997491714\n",
      "0.605726255456\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 81\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8329    0.9309    0.8791       926\n",
      "          1     0.4336    0.2207    0.2925       222\n",
      "\n",
      "avg / total     0.7556    0.7936    0.7657      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7732366512854317\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.29218106995884774\n",
      "Original f1: 0.3050259965337955\n",
      "0.0562588244353\n",
      "0.74469433025\n",
      "344\n",
      "0.226763348715\n",
      "Number of disagreement: 159\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8380    0.8938    0.8650      1233\n",
      "          1     0.3515    0.2500    0.2922       284\n",
      "\n",
      "avg / total     0.7469    0.7732    0.7578      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.5-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7761324041811847\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3836930455635491\n",
      "Original f1: 0.2694300518134715\n",
      "0.184794011052\n",
      "0.993264876621\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 219\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8510    0.8758    0.8632       926\n",
      "          1     0.4103    0.3604    0.3837       222\n",
      "\n",
      "avg / total     0.7658    0.7761    0.7705      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7600527356624918\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.35231316725978645\n",
      "Original f1: 0.3050259965337955\n",
      "0.178810955188\n",
      "0.993179320102\n",
      "364\n",
      "0.239947264338\n",
      "Number of disagreement: 309\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8507    0.8548    0.8528      1233\n",
      "          1     0.3561    0.3486    0.3523       284\n",
      "\n",
      "avg / total     0.7581    0.7601    0.7591      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.5-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7987804878048781\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3342939481268012\n",
      "Original f1: 0.2694300518134715\n",
      "0.0503048091094\n",
      "0.993264873418\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 91\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8397    0.9276    0.8815       926\n",
      "          1     0.4640    0.2613    0.3343       222\n",
      "\n",
      "avg / total     0.7670    0.7988    0.7757      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7752142386288727\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3326810176125245\n",
      "Original f1: 0.3050259965337955\n",
      "0.0680326746266\n",
      "0.959584900868\n",
      "341\n",
      "0.224785761371\n",
      "Number of disagreement: 178\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8457    0.8848    0.8648      1233\n",
      "          1     0.3744    0.2993    0.3327       284\n",
      "\n",
      "avg / total     0.7575    0.7752    0.7652      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.5-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7639372822299652\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3741339491916859\n",
      "Original f1: 0.2694300518134715\n",
      "0.193230892499\n",
      "0.996912526916\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 235\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8495    0.8596    0.8545       926\n",
      "          1     0.3839    0.3649    0.3741       222\n",
      "\n",
      "avg / total     0.7595    0.7639    0.7616      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7547791694133158\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.36082474226804123\n",
      "Original f1: 0.3050259965337955\n",
      "0.186640760112\n",
      "0.993179319068\n",
      "372\n",
      "0.245220830587\n",
      "Number of disagreement: 327\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8532    0.8435    0.8483      1233\n",
      "          1     0.3523    0.3697    0.3608       284\n",
      "\n",
      "avg / total     0.7594    0.7548    0.7570      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.5-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7987804878048781\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.35654596100278546\n",
      "Original f1: 0.2694300518134715\n",
      "0.0600875945106\n",
      "0.993264876451\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 101\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8437    0.9212    0.8807       926\n",
      "          1     0.4672    0.2883    0.3565       222\n",
      "\n",
      "avg / total     0.7709    0.7988    0.7794      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7738958470665788\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.349146110056926\n",
      "Original f1: 0.3050259965337955\n",
      "0.0766367128121\n",
      "0.962421878734\n",
      "343\n",
      "0.226104152933\n",
      "Number of disagreement: 192\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8493    0.8775    0.8632      1233\n",
      "          1     0.3786    0.3239    0.3491       284\n",
      "\n",
      "avg / total     0.7612    0.7739    0.7669      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.5-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7587108013937283\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3775280898876404\n",
      "Original f1: 0.2694300518134715\n",
      "0.200743280047\n",
      "0.996912528728\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 247\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8508    0.8499    0.8504       926\n",
      "          1     0.3767    0.3784    0.3775       222\n",
      "\n",
      "avg / total     0.7591    0.7587    0.7589      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7501647989452868\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.36515912897822445\n",
      "Original f1: 0.3050259965337955\n",
      "0.192450142979\n",
      "0.999999685422\n",
      "379\n",
      "0.249835201055\n",
      "Number of disagreement: 336\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8547    0.8345    0.8445      1233\n",
      "          1     0.3482    0.3838    0.3652       284\n",
      "\n",
      "avg / total     0.7598    0.7502    0.7547      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.5-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7970383275261324\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.38845144356955374\n",
      "Original f1: 0.2694300518134715\n",
      "0.072155278865\n",
      "0.993264876651\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 121\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8504    0.9082    0.8783       926\n",
      "          1     0.4654    0.3333    0.3885       222\n",
      "\n",
      "avg / total     0.7759    0.7970    0.7836      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7725774555042848\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.36229205175600737\n",
      "Original f1: 0.3050259965337955\n",
      "0.0829113184241\n",
      "0.983985517504\n",
      "345\n",
      "0.227422544496\n",
      "Number of disagreement: 202\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8524    0.8710    0.8616      1233\n",
      "          1     0.3813    0.3451    0.3623       284\n",
      "\n",
      "avg / total     0.7642    0.7726    0.7681      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.5-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3869565217391304\n",
      "Original f1: 0.2694300518134715\n",
      "0.210146606263\n",
      "0.996912528395\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 262\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8538    0.8391    0.8464       926\n",
      "          1     0.3739    0.4009    0.3870       222\n",
      "\n",
      "avg / total     0.7610    0.7544    0.7576      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7462096242584048\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.367816091954023\n",
      "Original f1: 0.3050259965337955\n",
      "0.197989962671\n",
      "0.999999686334\n",
      "385\n",
      "0.253790375742\n",
      "Number of disagreement: 346\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8557    0.8273    0.8412      1233\n",
      "          1     0.3446    0.3944    0.3678       284\n",
      "\n",
      "avg / total     0.7600    0.7462    0.7526      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.5-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7865853658536586\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.22222222222222218\n",
      "Original f1: 0.2694300518134715\n",
      "0.0379915896199\n",
      "0.64536371706\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 79\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8227    0.9374    0.8763       926\n",
      "          1     0.3763    0.1577    0.2222       222\n",
      "\n",
      "avg / total     0.7364    0.7866    0.7498      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7798286090969018\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.24774774774774777\n",
      "Original f1: 0.3050259965337955\n",
      "0.0489832113466\n",
      "0.707968311718\n",
      "334\n",
      "0.220171390903\n",
      "Number of disagreement: 151\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8312    0.9148    0.8710      1233\n",
      "          1     0.3438    0.1937    0.2477       284\n",
      "\n",
      "avg / total     0.7400    0.7798    0.7544      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.5-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7979094076655052\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.1773049645390071\n",
      "Original f1: 0.2694300518134715\n",
      "0.113909251864\n",
      "0.751064896372\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 122\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8189    0.9622    0.8848       926\n",
      "          1     0.4167    0.1126    0.1773       222\n",
      "\n",
      "avg / total     0.7411    0.7979    0.7480      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7969676994067239\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.24878048780487808\n",
      "Original f1: 0.3050259965337955\n",
      "0.127764704792\n",
      "0.847636468985\n",
      "308\n",
      "0.203032300593\n",
      "Number of disagreement: 217\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8325    0.9392    0.8826      1233\n",
      "          1     0.4048    0.1796    0.2488       284\n",
      "\n",
      "avg / total     0.7524    0.7970    0.7640      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.5-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7883275261324042\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.26139817629179335\n",
      "Original f1: 0.2694300518134715\n",
      "0.038428306339\n",
      "0.581722362339\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 73\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8280    0.9309    0.8765       926\n",
      "          1     0.4019    0.1937    0.2614       222\n",
      "\n",
      "avg / total     0.7456    0.7883    0.7575      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7745550428477258\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.27848101265822783\n",
      "Original f1: 0.3050259965337955\n",
      "0.0507197959763\n",
      "0.707968311718\n",
      "342\n",
      "0.225444957152\n",
      "Number of disagreement: 153\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8357    0.8994    0.8664      1233\n",
      "          1     0.3474    0.2324    0.2785       284\n",
      "\n",
      "avg / total     0.7443    0.7746    0.7563      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.5-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7874564459930313\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36125654450261774\n",
      "Original f1: 0.2694300518134715\n",
      "0.162602758367\n",
      "0.993264876406\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 192\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8451    0.9017    0.8725       926\n",
      "          1     0.4313    0.3108    0.3613       222\n",
      "\n",
      "avg / total     0.7651    0.7875    0.7737      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7679630850362558\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3358490566037736\n",
      "Original f1: 0.3050259965337955\n",
      "0.164050556844\n",
      "0.979195607436\n",
      "352\n",
      "0.232036914964\n",
      "Number of disagreement: 285\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8466    0.8727    0.8594      1233\n",
      "          1     0.3618    0.3134    0.3358       284\n",
      "\n",
      "avg / total     0.7558    0.7680    0.7614      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.5-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7883275261324042\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.26586102719033233\n",
      "Original f1: 0.2694300518134715\n",
      "0.0397265608791\n",
      "0.581722362339\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 73\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8287    0.9298    0.8763       926\n",
      "          1     0.4037    0.1982    0.2659       222\n",
      "\n",
      "avg / total     0.7465    0.7883    0.7583      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7725774555042848\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.28274428274428276\n",
      "Original f1: 0.3050259965337955\n",
      "0.0527449516694\n",
      "0.707968311718\n",
      "345\n",
      "0.227422544496\n",
      "Number of disagreement: 152\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8364    0.8954    0.8649      1233\n",
      "          1     0.3452    0.2394    0.2827       284\n",
      "\n",
      "avg / total     0.7444    0.7726    0.7559      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.5-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7804878048780488\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3668341708542714\n",
      "Original f1: 0.2694300518134715\n",
      "0.173824111722\n",
      "0.993264876652\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 208\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8467    0.8888    0.8672       926\n",
      "          1     0.4148    0.3288    0.3668       222\n",
      "\n",
      "avg / total     0.7632    0.7805    0.7705      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7679630850362558\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3553113553113553\n",
      "Original f1: 0.3050259965337955\n",
      "0.172294168545\n",
      "0.979195607425\n",
      "352\n",
      "0.232036914964\n",
      "Number of disagreement: 299\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8510    0.8662    0.8585      1233\n",
      "          1     0.3702    0.3415    0.3553       284\n",
      "\n",
      "avg / total     0.7610    0.7680    0.7643      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.5-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7918118466898955\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.29080118694362017\n",
      "Original f1: 0.2694300518134715\n",
      "0.0432716171243\n",
      "0.593986224579\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 79\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8325    0.9287    0.8780       926\n",
      "          1     0.4261    0.2207    0.2908       222\n",
      "\n",
      "avg / total     0.7539    0.7918    0.7644      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7712590639419907\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.2903885480572597\n",
      "Original f1: 0.3050259965337955\n",
      "0.0560953162997\n",
      "0.74469433025\n",
      "347\n",
      "0.228740936058\n",
      "Number of disagreement: 156\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8377    0.8913    0.8637      1233\n",
      "          1     0.3463    0.2500    0.2904       284\n",
      "\n",
      "avg / total     0.7457    0.7713    0.7563      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.5-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7752613240418118\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.37681159420289856\n",
      "Original f1: 0.2694300518134715\n",
      "0.185685163233\n",
      "0.993264876621\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 222\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8494    0.8769    0.8629       926\n",
      "          1     0.4062    0.3514    0.3768       222\n",
      "\n",
      "avg / total     0.7637    0.7753    0.7689      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7593935398813447\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3493761140819964\n",
      "Original f1: 0.3050259965337955\n",
      "0.17977649888\n",
      "0.992866683986\n",
      "365\n",
      "0.240606460119\n",
      "Number of disagreement: 310\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8500    0.8548    0.8524      1233\n",
      "          1     0.3538    0.3451    0.3494       284\n",
      "\n",
      "avg / total     0.7571    0.7594    0.7582      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.5-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7952961672473867\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.32276657060518726\n",
      "Original f1: 0.2694300518134715\n",
      "0.0494715156482\n",
      "0.993264874138\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 87\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8377    0.9255    0.8794       926\n",
      "          1     0.4480    0.2523    0.3228       222\n",
      "\n",
      "avg / total     0.7624    0.7953    0.7718      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7712590639419907\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.32093933463796476\n",
      "Original f1: 0.3050259965337955\n",
      "0.0679495623854\n",
      "0.959584900507\n",
      "347\n",
      "0.228740936058\n",
      "Number of disagreement: 172\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8434    0.8824    0.8625      1233\n",
      "          1     0.3612    0.2887    0.3209       284\n",
      "\n",
      "avg / total     0.7531    0.7713    0.7611      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.5-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7665505226480837\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3767441860465116\n",
      "Original f1: 0.2694300518134715\n",
      "0.19434957695\n",
      "0.996912526931\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 238\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8500    0.8629    0.8564       926\n",
      "          1     0.3894    0.3649    0.3767       222\n",
      "\n",
      "avg / total     0.7609    0.7666    0.7636      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7534607778510217\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3573883161512027\n",
      "Original f1: 0.3050259965337955\n",
      "0.187709238671\n",
      "0.999999655291\n",
      "374\n",
      "0.246539222149\n",
      "Number of disagreement: 325\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8523    0.8427    0.8475      1233\n",
      "          1     0.3490    0.3662    0.3574       284\n",
      "\n",
      "avg / total     0.7581    0.7535    0.7557      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.5-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7987804878048781\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.34929577464788736\n",
      "Original f1: 0.2694300518134715\n",
      "0.0582694059466\n",
      "0.993264876434\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 93\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8424    0.9233    0.8810       926\n",
      "          1     0.4662    0.2793    0.3493       222\n",
      "\n",
      "avg / total     0.7696    0.7988    0.7782      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7719182597231378\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3446969696969697\n",
      "Original f1: 0.3050259965337955\n",
      "0.0759969772029\n",
      "0.962421878305\n",
      "346\n",
      "0.228081740277\n",
      "Number of disagreement: 187\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8484    0.8759    0.8619      1233\n",
      "          1     0.3730    0.3204    0.3447       284\n",
      "\n",
      "avg / total     0.7594    0.7719    0.7651      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.5-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7621951219512195\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.38374717832957106\n",
      "Original f1: 0.2694300518134715\n",
      "0.201989162523\n",
      "0.99691252874\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 251\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8522    0.8531    0.8527       926\n",
      "          1     0.3846    0.3829    0.3837       222\n",
      "\n",
      "avg / total     0.7618    0.7622    0.7620      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7475280158206987\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3606010016694491\n",
      "Original f1: 0.3050259965337955\n",
      "0.19349858258\n",
      "0.999999682723\n",
      "383\n",
      "0.252471984179\n",
      "Number of disagreement: 338\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8536    0.8321    0.8427      1233\n",
      "          1     0.3429    0.3803    0.3606       284\n",
      "\n",
      "avg / total     0.7580    0.7475    0.7525      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.5-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7909407665505227\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36842105263157887\n",
      "Original f1: 0.2694300518134715\n",
      "0.0715530294976\n",
      "0.993264876649\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 118\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8465    0.9050    0.8747       926\n",
      "          1     0.4430    0.3153    0.3684       222\n",
      "\n",
      "avg / total     0.7685    0.7909    0.7768      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7712590639419907\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3609576427255985\n",
      "Original f1: 0.3050259965337955\n",
      "0.0822505258149\n",
      "0.978851604783\n",
      "347\n",
      "0.228740936058\n",
      "Number of disagreement: 200\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8521    0.8694    0.8607      1233\n",
      "          1     0.3784    0.3451    0.3610       284\n",
      "\n",
      "avg / total     0.7635    0.7713    0.7671      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.5-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7569686411149826\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.39215686274509803\n",
      "Original f1: 0.2694300518134715\n",
      "0.211623500953\n",
      "0.996912528388\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 267\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8551    0.8413    0.8481       926\n",
      "          1     0.3797    0.4054    0.3922       222\n",
      "\n",
      "avg / total     0.7632    0.7570    0.7599      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7415952537903757\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.36156351791530944\n",
      "Original f1: 0.3050259965337955\n",
      "0.19870888689\n",
      "0.999999686436\n",
      "392\n",
      "0.25840474621\n",
      "Number of disagreement: 349\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8543    0.8224    0.8380      1233\n",
      "          1     0.3364    0.3908    0.3616       284\n",
      "\n",
      "avg / total     0.7573    0.7416    0.7488      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.75-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7813588850174216\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.22769230769230767\n",
      "Original f1: 0.2694300518134715\n",
      "0.0319579550071\n",
      "0.637470057033\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 69\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8230    0.9287    0.8727       926\n",
      "          1     0.3592    0.1667    0.2277       222\n",
      "\n",
      "avg / total     0.7333    0.7814    0.7479      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7686222808174028\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.27329192546583847\n",
      "Original f1: 0.3050259965337955\n",
      "0.039869334949\n",
      "0.707351496099\n",
      "351\n",
      "0.231377719183\n",
      "Number of disagreement: 106\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8346    0.8921    0.8624      1233\n",
      "          1     0.3317    0.2324    0.2733       284\n",
      "\n",
      "avg / total     0.7404    0.7686    0.7521      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.75-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7883275261324042\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.1706484641638225\n",
      "Original f1: 0.2694300518134715\n",
      "0.105946135539\n",
      "0.674693877611\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 125\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8171    0.9503    0.8787       926\n",
      "          1     0.3521    0.1126    0.1706       222\n",
      "\n",
      "avg / total     0.7272    0.7883    0.7418      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7956493078444298\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.2548076923076923\n",
      "Original f1: 0.3050259965337955\n",
      "0.121586699767\n",
      "0.821590824123\n",
      "310\n",
      "0.204350692156\n",
      "Number of disagreement: 215\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8332    0.9359    0.8816      1233\n",
      "          1     0.4015    0.1866    0.2548       284\n",
      "\n",
      "avg / total     0.7524    0.7956    0.7642      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.75-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7822299651567944\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.255952380952381\n",
      "Original f1: 0.2694300518134715\n",
      "0.0326088146766\n",
      "0.536361328421\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 62\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8269    0.9233    0.8724       926\n",
      "          1     0.3772    0.1937    0.2560       222\n",
      "\n",
      "avg / total     0.7399    0.7822    0.7532      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7633487145682267\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3056092843326886\n",
      "Original f1: 0.3050259965337955\n",
      "0.0426241620742\n",
      "0.707351496099\n",
      "359\n",
      "0.236651285432\n",
      "Number of disagreement: 102\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8403    0.8751    0.8574      1233\n",
      "          1     0.3391    0.2782    0.3056       284\n",
      "\n",
      "avg / total     0.7465    0.7633    0.7541      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.75-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7526132404181185\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3395348837209302\n",
      "Original f1: 0.2694300518134715\n",
      "0.17213151197\n",
      "0.993264876635\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 228\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8415    0.8542    0.8478       926\n",
      "          1     0.3510    0.3288    0.3395       222\n",
      "\n",
      "avg / total     0.7466    0.7526    0.7495      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7567567567567568\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3756345177664975\n",
      "Original f1: 0.3050259965337955\n",
      "0.17541946322\n",
      "0.992866689136\n",
      "369\n",
      "0.243243243243\n",
      "Number of disagreement: 318\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8570    0.8410    0.8490      1233\n",
      "          1     0.3616    0.3908    0.3756       284\n",
      "\n",
      "avg / total     0.7643    0.7568    0.7603      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.75-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7787456445993032\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2529411764705882\n",
      "Original f1: 0.2694300518134715\n",
      "0.034172308943\n",
      "0.508357387398\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 62\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8262    0.9190    0.8701       926\n",
      "          1     0.3644    0.1937    0.2529       222\n",
      "\n",
      "avg / total     0.7369    0.7787    0.7508      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7607119314436388\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3059273422562141\n",
      "Original f1: 0.3050259965337955\n",
      "0.0448323273456\n",
      "0.719240957694\n",
      "363\n",
      "0.239288068556\n",
      "Number of disagreement: 104\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8404    0.8710    0.8554      1233\n",
      "          1     0.3347    0.2817    0.3059       284\n",
      "\n",
      "avg / total     0.7457    0.7607    0.7526      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.75-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7508710801393729\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3587443946188341\n",
      "Original f1: 0.2694300518134715\n",
      "0.184771202502\n",
      "0.993264876636\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 244\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8463    0.8445    0.8454       926\n",
      "          1     0.3571    0.3604    0.3587       222\n",
      "\n",
      "avg / total     0.7517    0.7509    0.7513      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7442320369149638\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.36601307189542487\n",
      "Original f1: 0.3050259965337955\n",
      "0.183358361114\n",
      "0.992866689018\n",
      "388\n",
      "0.255767963085\n",
      "Number of disagreement: 335\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8553    0.8248    0.8398      1233\n",
      "          1     0.3415    0.3944    0.3660       284\n",
      "\n",
      "avg / total     0.7591    0.7442    0.7511      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.75-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7839721254355401\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.28735632183908044\n",
      "Original f1: 0.2694300518134715\n",
      "0.0382710334602\n",
      "0.512754467937\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 70\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8317    0.9179    0.8727       926\n",
      "          1     0.3968    0.2252    0.2874       222\n",
      "\n",
      "avg / total     0.7476    0.7840    0.7595      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7600527356624918\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.31320754716981136\n",
      "Original f1: 0.3050259965337955\n",
      "0.0500882555514\n",
      "0.877880613006\n",
      "364\n",
      "0.239947264338\n",
      "Number of disagreement: 107\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8419    0.8678    0.8546      1233\n",
      "          1     0.3374    0.2923    0.3132       284\n",
      "\n",
      "avg / total     0.7474    0.7601    0.7533      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.75-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.740418118466899\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3577586206896552\n",
      "Original f1: 0.2694300518134715\n",
      "0.197185232674\n",
      "0.993667658988\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 262\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8466    0.8283    0.8373       926\n",
      "          1     0.3430    0.3739    0.3578       222\n",
      "\n",
      "avg / total     0.7492    0.7404    0.7446      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7343441001977588\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.36535433070866136\n",
      "Original f1: 0.3050259965337955\n",
      "0.192634483345\n",
      "0.992866688925\n",
      "403\n",
      "0.265655899802\n",
      "Number of disagreement: 352\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8559    0.8094    0.8320      1233\n",
      "          1     0.3305    0.4085    0.3654       284\n",
      "\n",
      "avg / total     0.7576    0.7343    0.7446      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.75-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7874564459930313\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.31843575418994413\n",
      "Original f1: 0.2694300518134715\n",
      "0.0462078373002\n",
      "0.993264875602\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 78\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8370    0.9147    0.8741       926\n",
      "          1     0.4191    0.2568    0.3184       222\n",
      "\n",
      "avg / total     0.7562    0.7875    0.7666      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7613711272247857\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.34657039711191334\n",
      "Original f1: 0.3050259965337955\n",
      "0.062799420007\n",
      "0.96242186498\n",
      "362\n",
      "0.238628872775\n",
      "Number of disagreement: 127\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8492    0.8589    0.8540      1233\n",
      "          1     0.3556    0.3380    0.3466       284\n",
      "\n",
      "avg / total     0.7568    0.7614    0.7590      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.75-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.730836236933798\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3628865979381444\n",
      "Original f1: 0.2694300518134715\n",
      "0.206238840173\n",
      "0.996912526254\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 281\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8486    0.8110    0.8294       926\n",
      "          1     0.3346    0.3964    0.3629       222\n",
      "\n",
      "avg / total     0.7492    0.7308    0.7392      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7270929466051417\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3669724770642202\n",
      "Original f1: 0.3050259965337955\n",
      "0.200889541007\n",
      "0.992866689248\n",
      "414\n",
      "0.272907053395\n",
      "Number of disagreement: 365\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8570    0.7972    0.8261      1233\n",
      "          1     0.3243    0.4225    0.3670       284\n",
      "\n",
      "avg / total     0.7573    0.7271    0.7401      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.75-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.789198606271777\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.345945945945946\n",
      "Original f1: 0.2694300518134715\n",
      "0.057814366509\n",
      "0.993264876438\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 88\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8420    0.9093    0.8744       926\n",
      "          1     0.4324    0.2883    0.3459       222\n",
      "\n",
      "avg / total     0.7628    0.7892    0.7722      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7607119314436388\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3752151462994836\n",
      "Original f1: 0.3050259965337955\n",
      "0.0746674145909\n",
      "0.992866688655\n",
      "363\n",
      "0.239288068556\n",
      "Number of disagreement: 154\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8566    0.8475    0.8520      1233\n",
      "          1     0.3670    0.3838    0.3752       284\n",
      "\n",
      "avg / total     0.7649    0.7607    0.7628      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.75-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7273519163763066\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.37274549098196386\n",
      "Original f1: 0.2694300518134715\n",
      "0.215118482665\n",
      "0.99728353954\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 291\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8519    0.8013    0.8258       926\n",
      "          1     0.3357    0.4189    0.3727       222\n",
      "\n",
      "avg / total     0.7521    0.7274    0.7382      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7178642056690837\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3630952380952381\n",
      "Original f1: 0.3050259965337955\n",
      "0.208224204169\n",
      "0.995662987174\n",
      "428\n",
      "0.282135794331\n",
      "Number of disagreement: 383\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8565    0.7843    0.8188      1233\n",
      "          1     0.3144    0.4296    0.3631       284\n",
      "\n",
      "avg / total     0.7550    0.7179    0.7335      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.75-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7831010452961672\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.37593984962406013\n",
      "Original f1: 0.2694300518134715\n",
      "0.0723258249179\n",
      "0.993667657619\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 115\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8486    0.8898    0.8687       926\n",
      "          1     0.4237    0.3378    0.3759       222\n",
      "\n",
      "avg / total     0.7664    0.7831    0.7734      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7613711272247857\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.39464882943143814\n",
      "Original f1: 0.3050259965337955\n",
      "0.0823012236885\n",
      "0.992866688833\n",
      "362\n",
      "0.238628872775\n",
      "Number of disagreement: 167\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8620    0.8410    0.8514      1233\n",
      "          1     0.3758    0.4155    0.3946       284\n",
      "\n",
      "avg / total     0.7710    0.7614    0.7659      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.75-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7229965156794426\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3740157480314961\n",
      "Original f1: 0.2694300518134715\n",
      "0.223509026999\n",
      "0.997283541033\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 300\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8527    0.7937    0.8221       926\n",
      "          1     0.3322    0.4279    0.3740       222\n",
      "\n",
      "avg / total     0.7520    0.7230    0.7355      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7066578773895847\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.35413642960812775\n",
      "Original f1: 0.3050259965337955\n",
      "0.213753063977\n",
      "0.999999686295\n",
      "445\n",
      "0.29334212261\n",
      "Number of disagreement: 396\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8543    0.7705    0.8102      1233\n",
      "          1     0.3012    0.4296    0.3541       284\n",
      "\n",
      "avg / total     0.7508    0.7067    0.7248      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.75-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7813588850174216\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.22769230769230767\n",
      "Original f1: 0.2694300518134715\n",
      "0.0314995082846\n",
      "0.630799152003\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 65\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8230    0.9287    0.8727       926\n",
      "          1     0.3592    0.1667    0.2277       222\n",
      "\n",
      "avg / total     0.7333    0.7814    0.7479      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7705998681608438\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.2719665271966527\n",
      "Original f1: 0.3050259965337955\n",
      "0.0391062445518\n",
      "0.707258997541\n",
      "348\n",
      "0.229400131839\n",
      "Number of disagreement: 109\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8345    0.8954    0.8638      1233\n",
      "          1     0.3351    0.2289    0.2720       284\n",
      "\n",
      "avg / total     0.7410    0.7706    0.7530      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.75-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7883275261324042\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.16494845360824742\n",
      "Original f1: 0.2694300518134715\n",
      "0.10838842699\n",
      "0.673941539493\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 125\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8165    0.9514    0.8788       926\n",
      "          1     0.3478    0.1081    0.1649       222\n",
      "\n",
      "avg / total     0.7259    0.7883    0.7408      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7969676994067239\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.2631578947368421\n",
      "Original f1: 0.3050259965337955\n",
      "0.123894207216\n",
      "0.823747066046\n",
      "308\n",
      "0.203032300593\n",
      "Number of disagreement: 215\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8344    0.9359    0.8823      1233\n",
      "          1     0.4104    0.1937    0.2632       284\n",
      "\n",
      "avg / total     0.7550    0.7970    0.7664      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.75-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7831010452961672\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.26112759643916916\n",
      "Original f1: 0.2694300518134715\n",
      "0.0322248305572\n",
      "0.531496317112\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 59\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8277    0.9233    0.8729       926\n",
      "          1     0.3826    0.1982    0.2611       222\n",
      "\n",
      "avg / total     0.7416    0.7831    0.7546      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7679630850362558\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3070866141732284\n",
      "Original f1: 0.3050259965337955\n",
      "0.0418438704062\n",
      "0.707258997541\n",
      "352\n",
      "0.232036914964\n",
      "Number of disagreement: 105\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8407    0.8816    0.8606      1233\n",
      "          1     0.3482    0.2746    0.3071       284\n",
      "\n",
      "avg / total     0.7485    0.7680    0.7570      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.75-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7517421602787456\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.33874709976798145\n",
      "Original f1: 0.2694300518134715\n",
      "0.175532152255\n",
      "0.993264876636\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 235\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8413    0.8531    0.8472       926\n",
      "          1     0.3493    0.3288    0.3387       222\n",
      "\n",
      "avg / total     0.7462    0.7517    0.7489      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7528015820698748\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3739565943238731\n",
      "Original f1: 0.3050259965337955\n",
      "0.180307518352\n",
      "0.992866687671\n",
      "375\n",
      "0.24719841793\n",
      "Number of disagreement: 324\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8569    0.8354    0.8460      1233\n",
      "          1     0.3556    0.3944    0.3740       284\n",
      "\n",
      "avg / total     0.7630    0.7528    0.7576      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.75-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7813588850174216\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2595870206489676\n",
      "Original f1: 0.2694300518134715\n",
      "0.0339750585265\n",
      "0.531496317112\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 57\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8274    0.9212    0.8717       926\n",
      "          1     0.3761    0.1982    0.2596       222\n",
      "\n",
      "avg / total     0.7401    0.7814    0.7534      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7653263019116677\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.30739299610894943\n",
      "Original f1: 0.3050259965337955\n",
      "0.0442424876189\n",
      "0.707258997541\n",
      "356\n",
      "0.234673698088\n",
      "Number of disagreement: 109\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8407    0.8775    0.8587      1233\n",
      "          1     0.3435    0.2782    0.3074       284\n",
      "\n",
      "avg / total     0.7476    0.7653    0.7555      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.75-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7491289198606271\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3542600896860987\n",
      "Original f1: 0.2694300518134715\n",
      "0.187742845708\n",
      "0.993264876536\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 248\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8452    0.8434    0.8443       926\n",
      "          1     0.3527    0.3559    0.3543       222\n",
      "\n",
      "avg / total     0.7500    0.7491    0.7496      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7429136453526698\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.36893203883495146\n",
      "Original f1: 0.3050259965337955\n",
      "0.187574217107\n",
      "0.992866688775\n",
      "390\n",
      "0.257086354647\n",
      "Number of disagreement: 337\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8563    0.8216    0.8386      1233\n",
      "          1     0.3413    0.4014    0.3689       284\n",
      "\n",
      "avg / total     0.7599    0.7429    0.7507      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.75-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7848432055749129\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2922636103151863\n",
      "Original f1: 0.2694300518134715\n",
      "0.0379220252556\n",
      "0.531496317112\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 65\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8325    0.9179    0.8731       926\n",
      "          1     0.4016    0.2297    0.2923       222\n",
      "\n",
      "avg / total     0.7492    0.7848    0.7608      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7646671061305208\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3173996175908222\n",
      "Original f1: 0.3050259965337955\n",
      "0.049643969133\n",
      "0.877880613006\n",
      "357\n",
      "0.235332893869\n",
      "Number of disagreement: 114\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8427    0.8735    0.8578      1233\n",
      "          1     0.3473    0.2923    0.3174       284\n",
      "\n",
      "avg / total     0.7500    0.7647    0.7567      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.75-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7325783972125436\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3481953290870488\n",
      "Original f1: 0.2694300518134715\n",
      "0.200437324991\n",
      "0.993667659111\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 273\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8443    0.8197    0.8318       926\n",
      "          1     0.3293    0.3694    0.3482       222\n",
      "\n",
      "avg / total     0.7447    0.7326    0.7383      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7350032959789057\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.36990595611285265\n",
      "Original f1: 0.3050259965337955\n",
      "0.196352097622\n",
      "0.992866689063\n",
      "402\n",
      "0.264996704021\n",
      "Number of disagreement: 351\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8573    0.8086    0.8322      1233\n",
      "          1     0.3333    0.4155    0.3699       284\n",
      "\n",
      "avg / total     0.7592    0.7350    0.7457      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.75-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7900696864111498\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3286908077994429\n",
      "Original f1: 0.2694300518134715\n",
      "0.0457318811064\n",
      "0.993264876046\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 75\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8388    0.9158    0.8756       926\n",
      "          1     0.4307    0.2658    0.3287       222\n",
      "\n",
      "avg / total     0.7599    0.7901    0.7698      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7640079103493738\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.34432234432234426\n",
      "Original f1: 0.3050259965337955\n",
      "0.0627281496749\n",
      "0.962421864737\n",
      "358\n",
      "0.235992089651\n",
      "Number of disagreement: 133\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8486    0.8637    0.8561      1233\n",
      "          1     0.3588    0.3310    0.3443       284\n",
      "\n",
      "avg / total     0.7569    0.7640    0.7603      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.75-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7299651567944251\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.359504132231405\n",
      "Original f1: 0.2694300518134715\n",
      "0.210298032855\n",
      "0.997283539945\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 286\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8476    0.8110    0.8289       926\n",
      "          1     0.3321    0.3919    0.3595       222\n",
      "\n",
      "avg / total     0.7479    0.7300    0.7381      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7284113381674358\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.37003058103975534\n",
      "Original f1: 0.3050259965337955\n",
      "0.204534080452\n",
      "0.999999686927\n",
      "412\n",
      "0.271588661833\n",
      "Number of disagreement: 365\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8579    0.7981    0.8269      1233\n",
      "          1     0.3270    0.4261    0.3700       284\n",
      "\n",
      "avg / total     0.7585    0.7284    0.7414      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.75-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7909407665505227\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3548387096774193\n",
      "Original f1: 0.2694300518134715\n",
      "0.0568017140053\n",
      "0.993264876543\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 84\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8437    0.9093    0.8753       926\n",
      "          1     0.4400    0.2973    0.3548       222\n",
      "\n",
      "avg / total     0.7656    0.7909    0.7746      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7607119314436388\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3597883597883598\n",
      "Original f1: 0.3050259965337955\n",
      "0.0737068312065\n",
      "0.977230990115\n",
      "363\n",
      "0.239288068556\n",
      "Number of disagreement: 152\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8525    0.8532    0.8529      1233\n",
      "          1     0.3604    0.3592    0.3598       284\n",
      "\n",
      "avg / total     0.7604    0.7607    0.7605      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.75-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7186411149825784\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36039603960396044\n",
      "Original f1: 0.2694300518134715\n",
      "0.219789366345\n",
      "0.997283541031\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 299\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8486    0.7927    0.8197       926\n",
      "          1     0.3216    0.4099    0.3604       222\n",
      "\n",
      "avg / total     0.7466    0.7186    0.7308      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7165458141067897\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.363905325443787\n",
      "Original f1: 0.3050259965337955\n",
      "0.211026141519\n",
      "0.999999685812\n",
      "430\n",
      "0.283454185893\n",
      "Number of disagreement: 383\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8569    0.7818    0.8176      1233\n",
      "          1     0.3138    0.4331    0.3639       284\n",
      "\n",
      "avg / total     0.7552    0.7165    0.7327      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.75-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7804878048780488\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.37\n",
      "Original f1: 0.2694300518134715\n",
      "0.0726444849872\n",
      "0.993667658825\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 112\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8474    0.8877    0.8671       926\n",
      "          1     0.4157    0.3333    0.3700       222\n",
      "\n",
      "avg / total     0.7639    0.7805    0.7710      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7613711272247857\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3843537414965986\n",
      "Original f1: 0.3050259965337955\n",
      "0.0817904564948\n",
      "0.992866689255\n",
      "362\n",
      "0.238628872775\n",
      "Number of disagreement: 171\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8590    0.8451    0.8520      1233\n",
      "          1     0.3717    0.3979    0.3844       284\n",
      "\n",
      "avg / total     0.7678    0.7614    0.7645      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-0.75-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7142857142857143\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36434108527131787\n",
      "Original f1: 0.2694300518134715\n",
      "0.227804953967\n",
      "0.997283541093\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 310\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8501    0.7840    0.8157       926\n",
      "          1     0.3197    0.4234    0.3643       222\n",
      "\n",
      "avg / total     0.7476    0.7143    0.7284      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7086354647330257\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.35755813953488363\n",
      "Original f1: 0.3050259965337955\n",
      "0.216028190487\n",
      "0.999999687068\n",
      "442\n",
      "0.291364535267\n",
      "Number of disagreement: 393\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8553    0.7721    0.8116      1233\n",
      "          1     0.3045    0.4331    0.3576       284\n",
      "\n",
      "avg / total     0.7522    0.7086    0.7266      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.0-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7778745644599303\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.229607250755287\n",
      "Original f1: 0.2694300518134715\n",
      "0.0294599201051\n",
      "0.635310211609\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 65\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8229    0.9233    0.8702       926\n",
      "          1     0.3486    0.1712    0.2296       222\n",
      "\n",
      "avg / total     0.7312    0.7779    0.7463      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7686222808174028\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.2822085889570552\n",
      "Original f1: 0.3050259965337955\n",
      "0.0363049781818\n",
      "0.69940323535\n",
      "351\n",
      "0.231377719183\n",
      "Number of disagreement: 94\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8361    0.8897    0.8621      1233\n",
      "          1     0.3366    0.2430    0.2822       284\n",
      "\n",
      "avg / total     0.7426    0.7686    0.7535      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.0-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7839721254355401\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.16216216216216217\n",
      "Original f1: 0.2694300518134715\n",
      "0.103945165306\n",
      "0.651191068573\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 116\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8156    0.9460    0.8760       926\n",
      "          1     0.3243    0.1081    0.1622       222\n",
      "\n",
      "avg / total     0.7206    0.7840    0.7380      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7956493078444298\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.26540284360189575\n",
      "Original f1: 0.3050259965337955\n",
      "0.121143088939\n",
      "0.800584778721\n",
      "310\n",
      "0.204350692156\n",
      "Number of disagreement: 209\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8347    0.9335    0.8813      1233\n",
      "          1     0.4058    0.1972    0.2654       284\n",
      "\n",
      "avg / total     0.7544    0.7956    0.7660      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.0-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7778745644599303\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2565597667638484\n",
      "Original f1: 0.2694300518134715\n",
      "0.030617511019\n",
      "0.534201298478\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 57\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8267    0.9168    0.8694       926\n",
      "          1     0.3636    0.1982    0.2566       222\n",
      "\n",
      "avg / total     0.7371    0.7779    0.7509      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7613711272247857\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.30651340996168586\n",
      "Original f1: 0.3050259965337955\n",
      "0.0394456200204\n",
      "0.69940323535\n",
      "362\n",
      "0.238628872775\n",
      "Number of disagreement: 89\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8405    0.8719    0.8559      1233\n",
      "          1     0.3361    0.2817    0.3065       284\n",
      "\n",
      "avg / total     0.7461    0.7614    0.7530      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.0-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7378048780487805\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3266219239373601\n",
      "Original f1: 0.2694300518134715\n",
      "0.180359728016\n",
      "0.993264876375\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 239\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8386    0.8359    0.8372       926\n",
      "          1     0.3244    0.3288    0.3266       222\n",
      "\n",
      "avg / total     0.7391    0.7378    0.7385      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7376400791034937\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3742138364779874\n",
      "Original f1: 0.3050259965337955\n",
      "0.184273335558\n",
      "0.992866687025\n",
      "398\n",
      "0.262359920897\n",
      "Number of disagreement: 343\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8584    0.8110    0.8340      1233\n",
      "          1     0.3381    0.4190    0.3742       284\n",
      "\n",
      "avg / total     0.7610    0.7376    0.7479      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.0-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7778745644599303\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2608695652173913\n",
      "Original f1: 0.2694300518134715\n",
      "0.0322963097561\n",
      "0.512143182291\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 59\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8273    0.9158    0.8693       926\n",
      "          1     0.3659    0.2027    0.2609       222\n",
      "\n",
      "avg / total     0.7381    0.7779    0.7516      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7613711272247857\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.31698113207547174\n",
      "Original f1: 0.3050259965337955\n",
      "0.0423196064748\n",
      "0.716170487689\n",
      "362\n",
      "0.238628872775\n",
      "Number of disagreement: 91\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8426    0.8686    0.8554      1233\n",
      "          1     0.3415    0.2958    0.3170       284\n",
      "\n",
      "avg / total     0.7488    0.7614    0.7546      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.0-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7290940766550522\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.34249471458773784\n",
      "Original f1: 0.2694300518134715\n",
      "0.192079824242\n",
      "0.993264876647\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 263\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8428    0.8164    0.8294       926\n",
      "          1     0.3227    0.3649    0.3425       222\n",
      "\n",
      "avg / total     0.7422    0.7291    0.7352      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7251153592617007\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3633587786259542\n",
      "Original f1: 0.3050259965337955\n",
      "0.192507118204\n",
      "0.99286668915\n",
      "417\n",
      "0.274884640738\n",
      "Number of disagreement: 350\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8560    0.7956    0.8247      1233\n",
      "          1     0.3208    0.4190    0.3634       284\n",
      "\n",
      "avg / total     0.7558    0.7251    0.7383      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.0-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7752613240418118\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.26704545454545453\n",
      "Original f1: 0.2694300518134715\n",
      "0.0361438177015\n",
      "0.506718795809\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 64\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8281    0.9104    0.8673       926\n",
      "          1     0.3615    0.2117    0.2670       222\n",
      "\n",
      "avg / total     0.7379    0.7753    0.7512      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7580751483190508\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3165735567970205\n",
      "Original f1: 0.3050259965337955\n",
      "0.0472378629164\n",
      "0.82669672085\n",
      "367\n",
      "0.241924851681\n",
      "Number of disagreement: 96\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8426    0.8637    0.8530      1233\n",
      "          1     0.3360    0.2993    0.3166       284\n",
      "\n",
      "avg / total     0.7477    0.7581    0.7526      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.0-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7090592334494773\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3425196850393701\n",
      "Original f1: 0.2694300518134715\n",
      "0.205689691137\n",
      "0.997283538258\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 288\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8434    0.7851    0.8132       926\n",
      "          1     0.3042    0.3919    0.3425       222\n",
      "\n",
      "avg / total     0.7391    0.7091    0.7222      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7158866183256427\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.35958395245170877\n",
      "Original f1: 0.3050259965337955\n",
      "0.202591973107\n",
      "0.992866689282\n",
      "431\n",
      "0.284113381674\n",
      "Number of disagreement: 366\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8555    0.7826    0.8175      1233\n",
      "          1     0.3111    0.4261    0.3596       284\n",
      "\n",
      "avg / total     0.7536    0.7159    0.7317      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.0-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7796167247386759\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.31062670299727524\n",
      "Original f1: 0.2694300518134715\n",
      "0.0438255385725\n",
      "0.993264876626\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 75\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8355    0.9050    0.8688       926\n",
      "          1     0.3931    0.2568    0.3106       222\n",
      "\n",
      "avg / total     0.7499    0.7796    0.7609      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7567567567567568\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3254113345521024\n",
      "Original f1: 0.3050259965337955\n",
      "0.0556840850803\n",
      "0.899571280116\n",
      "369\n",
      "0.243243243243\n",
      "Number of disagreement: 106\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8445    0.8589    0.8516      1233\n",
      "          1     0.3384    0.3134    0.3254       284\n",
      "\n",
      "avg / total     0.7498    0.7568    0.7531      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.0-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.6986062717770035\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3422053231939163\n",
      "Original f1: 0.2694300518134715\n",
      "0.216559343373\n",
      "0.997283540416\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 306\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8436    0.7689    0.8045       926\n",
      "          1     0.2961    0.4054    0.3422       222\n",
      "\n",
      "avg / total     0.7377    0.6986    0.7151      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7079762689518787\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3570391872278665\n",
      "Original f1: 0.3050259965337955\n",
      "0.210993840929\n",
      "0.992866689151\n",
      "443\n",
      "0.292023731048\n",
      "Number of disagreement: 378\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8552    0.7713    0.8111      1233\n",
      "          1     0.3037    0.4331    0.3570       284\n",
      "\n",
      "avg / total     0.7520    0.7080    0.7261      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.0-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7839721254355401\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3507853403141362\n",
      "Original f1: 0.2694300518134715\n",
      "0.0558059882159\n",
      "0.993264876605\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 86\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8431    0.8996    0.8704       926\n",
      "          1     0.4188    0.3018    0.3508       222\n",
      "\n",
      "avg / total     0.7611    0.7840    0.7699      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7593935398813447\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3824027072758038\n",
      "Original f1: 0.3050259965337955\n",
      "0.0746779100193\n",
      "0.992866670938\n",
      "365\n",
      "0.240606460119\n",
      "Number of disagreement: 150\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8587    0.8427    0.8506      1233\n",
      "          1     0.3681    0.3979    0.3824       284\n",
      "\n",
      "avg / total     0.7668    0.7594    0.7629      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.0-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.695993031358885\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3500931098696462\n",
      "Original f1: 0.2694300518134715\n",
      "0.225235965941\n",
      "0.997283540902\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 315\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8463    0.7613    0.8016       926\n",
      "          1     0.2984    0.4234    0.3501       222\n",
      "\n",
      "avg / total     0.7404    0.6960    0.7143      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6954515491100857\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.351123595505618\n",
      "Original f1: 0.3050259965337955\n",
      "0.219998044421\n",
      "0.999999682794\n",
      "462\n",
      "0.30454845089\n",
      "Number of disagreement: 397\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8540    0.7543    0.8010      1233\n",
      "          1     0.2921    0.4401    0.3511       284\n",
      "\n",
      "avg / total     0.7488    0.6955    0.7168      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.0-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7770034843205574\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36945812807881767\n",
      "Original f1: 0.2694300518134715\n",
      "0.0712664924131\n",
      "0.993264876633\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 108\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8475    0.8823    0.8646       926\n",
      "          1     0.4076    0.3378    0.3695       222\n",
      "\n",
      "avg / total     0.7624    0.7770    0.7688      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7574159525379037\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.40065146579804556\n",
      "Original f1: 0.3050259965337955\n",
      "0.0842718604727\n",
      "0.992866689189\n",
      "368\n",
      "0.242584047462\n",
      "Number of disagreement: 171\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8644    0.8321    0.8479      1233\n",
      "          1     0.3727    0.4331    0.4007       284\n",
      "\n",
      "avg / total     0.7723    0.7574    0.7642      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.0-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6925087108013938\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.34990791896869244\n",
      "Original f1: 0.2694300518134715\n",
      "0.230877165999\n",
      "0.997283541214\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 321\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8464    0.7559    0.7986       926\n",
      "          1     0.2960    0.4279    0.3499       222\n",
      "\n",
      "avg / total     0.7400    0.6925    0.7119      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6914963744232037\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3481894150417827\n",
      "Original f1: 0.3050259965337955\n",
      "0.225633572673\n",
      "0.999999679196\n",
      "468\n",
      "0.308503625577\n",
      "Number of disagreement: 401\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8532    0.7494    0.7979      1233\n",
      "          1     0.2880    0.4401    0.3482       284\n",
      "\n",
      "avg / total     0.7474    0.6915    0.7137      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.0-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7761324041811847\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.22356495468277943\n",
      "Original f1: 0.2694300518134715\n",
      "0.0294112706114\n",
      "0.621967950347\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 59\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8219    0.9222    0.8692       926\n",
      "          1     0.3394    0.1667    0.2236       222\n",
      "\n",
      "avg / total     0.7286    0.7761    0.7444      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7692814765985497\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.27983539094650206\n",
      "Original f1: 0.3050259965337955\n",
      "0.0358588502729\n",
      "0.699245587074\n",
      "350\n",
      "0.230718523401\n",
      "Number of disagreement: 97\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8357    0.8913    0.8626      1233\n",
      "          1     0.3366    0.2394    0.2798       284\n",
      "\n",
      "avg / total     0.7423    0.7693    0.7535      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.0-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7857142857142857\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.163265306122449\n",
      "Original f1: 0.2694300518134715\n",
      "0.107284274533\n",
      "0.660011974055\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 118\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8160    0.9482    0.8771       926\n",
      "          1     0.3333    0.1081    0.1633       222\n",
      "\n",
      "avg / total     0.7227    0.7857    0.7391      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7890573500329597\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.23076923076923075\n",
      "Original f1: 0.3050259965337955\n",
      "0.124672814071\n",
      "0.802031602313\n",
      "320\n",
      "0.210942649967\n",
      "Number of disagreement: 215\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8296    0.9319    0.8778      1233\n",
      "          1     0.3636    0.1690    0.2308       284\n",
      "\n",
      "avg / total     0.7424    0.7891    0.7566      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.0-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7770034843205574\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.25581395348837205\n",
      "Original f1: 0.2694300518134715\n",
      "0.0306590617929\n",
      "0.53157909355\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 52\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8265    0.9158    0.8689       926\n",
      "          1     0.3607    0.1982    0.2558       222\n",
      "\n",
      "avg / total     0.7364    0.7770    0.7503      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7633487145682267\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3056092843326886\n",
      "Original f1: 0.3050259965337955\n",
      "0.038688098393\n",
      "0.699245587074\n",
      "359\n",
      "0.236651285432\n",
      "Number of disagreement: 92\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8403    0.8751    0.8574      1233\n",
      "          1     0.3391    0.2782    0.3056       284\n",
      "\n",
      "avg / total     0.7465    0.7633    0.7541      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.0-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.735191637630662\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.33624454148471616\n",
      "Original f1: 0.2694300518134715\n",
      "0.185382222733\n",
      "0.993264876471\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 244\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8410    0.8283    0.8346       926\n",
      "          1     0.3263    0.3468    0.3362       222\n",
      "\n",
      "avg / total     0.7415    0.7352    0.7382      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7297297297297297\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.35736677115987464\n",
      "Original f1: 0.3050259965337955\n",
      "0.191076554227\n",
      "0.992866689002\n",
      "410\n",
      "0.27027027027\n",
      "Number of disagreement: 347\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8538    0.8054    0.8289      1233\n",
      "          1     0.3220    0.4014    0.3574       284\n",
      "\n",
      "avg / total     0.7543    0.7297    0.7406      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.0-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7778745644599303\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2608695652173913\n",
      "Original f1: 0.2694300518134715\n",
      "0.0327097160335\n",
      "0.53157909355\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 53\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8273    0.9158    0.8693       926\n",
      "          1     0.3659    0.2027    0.2609       222\n",
      "\n",
      "avg / total     0.7381    0.7779    0.7516      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7640079103493738\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.31417624521072796\n",
      "Original f1: 0.3050259965337955\n",
      "0.0416103393643\n",
      "0.703459736452\n",
      "358\n",
      "0.235992089651\n",
      "Number of disagreement: 97\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8421    0.8735    0.8575      1233\n",
      "          1     0.3445    0.2887    0.3142       284\n",
      "\n",
      "avg / total     0.7489    0.7640    0.7558      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.0-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7238675958188153\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3382045929018789\n",
      "Original f1: 0.2694300518134715\n",
      "0.196536853408\n",
      "0.997283540114\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 265\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.8099    0.8255       926\n",
      "          1     0.3152    0.3649    0.3382       222\n",
      "\n",
      "avg / total     0.7399    0.7239    0.7313      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7211601845748187\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.35023041474654376\n",
      "Original f1: 0.3050259965337955\n",
      "0.198607804479\n",
      "0.997336278616\n",
      "423\n",
      "0.278839815425\n",
      "Number of disagreement: 354\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8522    0.7948    0.8225      1233\n",
      "          1     0.3106    0.4014    0.3502       284\n",
      "\n",
      "avg / total     0.7508    0.7212    0.7341      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.0-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7770034843205574\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2727272727272727\n",
      "Original f1: 0.2694300518134715\n",
      "0.03620160028\n",
      "0.53157909355\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 58\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8291    0.9114    0.8683       926\n",
      "          1     0.3692    0.2162    0.2727       222\n",
      "\n",
      "avg / total     0.7402    0.7770    0.7531      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7613711272247857\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.31698113207547174\n",
      "Original f1: 0.3050259965337955\n",
      "0.0468870002225\n",
      "0.819032959807\n",
      "362\n",
      "0.238628872775\n",
      "Number of disagreement: 101\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8426    0.8686    0.8554      1233\n",
      "          1     0.3415    0.2958    0.3170       284\n",
      "\n",
      "avg / total     0.7488    0.7614    0.7546      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.0-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7090592334494773\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3450980392156863\n",
      "Original f1: 0.2694300518134715\n",
      "0.209813099561\n",
      "0.997283540774\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 292\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8442    0.7840    0.8130       926\n",
      "          1     0.3056    0.3964    0.3451       222\n",
      "\n",
      "avg / total     0.7400    0.7091    0.7225      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7086354647330257\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.34421364985163205\n",
      "Original f1: 0.3050259965337955\n",
      "0.208004502782\n",
      "0.999999687211\n",
      "442\n",
      "0.291364535267\n",
      "Number of disagreement: 375\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8509    0.7778    0.8127      1233\n",
      "          1     0.2974    0.4085    0.3442       284\n",
      "\n",
      "avg / total     0.7473    0.7086    0.7250      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.0-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7796167247386759\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.30684931506849317\n",
      "Original f1: 0.2694300518134715\n",
      "0.0440442719355\n",
      "0.993264876345\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 69\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8348    0.9060    0.8690       926\n",
      "          1     0.3916    0.2523    0.3068       222\n",
      "\n",
      "avg / total     0.7491    0.7796    0.7603      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7567567567567568\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3254113345521024\n",
      "Original f1: 0.3050259965337955\n",
      "0.0596836033249\n",
      "0.962420794276\n",
      "369\n",
      "0.243243243243\n",
      "Number of disagreement: 116\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8445    0.8589    0.8516      1233\n",
      "          1     0.3384    0.3134    0.3254       284\n",
      "\n",
      "avg / total     0.7498    0.7568    0.7531      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.0-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6925087108013938\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.34264432029795155\n",
      "Original f1: 0.2694300518134715\n",
      "0.223004022813\n",
      "0.997283541178\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 313\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8439    0.7592    0.7993       926\n",
      "          1     0.2921    0.4144    0.3426       222\n",
      "\n",
      "avg / total     0.7372    0.6925    0.7110      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6987475280158207\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3386396526772793\n",
      "Original f1: 0.3050259965337955\n",
      "0.215929648041\n",
      "0.999999686607\n",
      "457\n",
      "0.301252471984\n",
      "Number of disagreement: 388\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8495    0.7648    0.8050      1233\n",
      "          1     0.2875    0.4120    0.3386       284\n",
      "\n",
      "avg / total     0.7443    0.6987    0.7177      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.0-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7848432055749129\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.34828496042216367\n",
      "Original f1: 0.2694300518134715\n",
      "0.0553858687398\n",
      "0.99366765522\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 81\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8426    0.9017    0.8712       926\n",
      "          1     0.4204    0.2973    0.3483       222\n",
      "\n",
      "avg / total     0.7609    0.7848    0.7700      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7534607778510217\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3595890410958904\n",
      "Original f1: 0.3050259965337955\n",
      "0.0742329954293\n",
      "0.979901961372\n",
      "374\n",
      "0.246539222149\n",
      "Number of disagreement: 151\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8529    0.8418    0.8473      1233\n",
      "          1     0.3500    0.3697    0.3596       284\n",
      "\n",
      "avg / total     0.7588    0.7535    0.7560      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.0-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6898954703832753\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3527272727272728\n",
      "Original f1: 0.2694300518134715\n",
      "0.231659825188\n",
      "0.997283541051\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 326\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8476    0.7505    0.7961       926\n",
      "          1     0.2957    0.4369    0.3527       222\n",
      "\n",
      "avg / total     0.7408    0.6899    0.7104      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6882003955174687\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.33473980309423346\n",
      "Original f1: 0.3050259965337955\n",
      "0.223577249291\n",
      "0.999999686955\n",
      "473\n",
      "0.311799604483\n",
      "Number of disagreement: 406\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8486    0.7502    0.7964      1233\n",
      "          1     0.2787    0.4190    0.3347       284\n",
      "\n",
      "avg / total     0.7419    0.6882    0.7100      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.0-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7761324041811847\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.36855036855036855\n",
      "Original f1: 0.2694300518134715\n",
      "0.0719323592459\n",
      "0.993667658048\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 109\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8474    0.8812    0.8639       926\n",
      "          1     0.4054    0.3378    0.3686       222\n",
      "\n",
      "avg / total     0.7619    0.7761    0.7681      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7560975609756098\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.39344262295081966\n",
      "Original f1: 0.3050259965337955\n",
      "0.0836974609972\n",
      "0.992866688608\n",
      "370\n",
      "0.243902439024\n",
      "Number of disagreement: 173\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8623    0.8329    0.8474      1233\n",
      "          1     0.3681    0.4225    0.3934       284\n",
      "\n",
      "avg / total     0.7698    0.7561    0.7624      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.0-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6837979094076655\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3506261180679785\n",
      "Original f1: 0.2694300518134715\n",
      "0.23728390102\n",
      "0.997283541064\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 333\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8471    0.7419    0.7910       926\n",
      "          1     0.2908    0.4414    0.3506       222\n",
      "\n",
      "avg / total     0.7395    0.6838    0.7059      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6796308503625577\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.32872928176795574\n",
      "Original f1: 0.3050259965337955\n",
      "0.229457345192\n",
      "0.999999687205\n",
      "486\n",
      "0.320369149637\n",
      "Number of disagreement: 417\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8468    0.7397    0.7896      1233\n",
      "          1     0.2705    0.4190    0.3287       284\n",
      "\n",
      "avg / total     0.7389    0.6796    0.7033      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.5-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7717770034843205\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2155688622754491\n",
      "Original f1: 0.2694300518134715\n",
      "0.0282507105252\n",
      "0.635181862912\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 60\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8205    0.9179    0.8665       926\n",
      "          1     0.3214    0.1622    0.2156       222\n",
      "\n",
      "avg / total     0.7240    0.7718    0.7406      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7686222808174028\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.2937625754527163\n",
      "Original f1: 0.3050259965337955\n",
      "0.0346869721785\n",
      "0.648748446585\n",
      "351\n",
      "0.231377719183\n",
      "Number of disagreement: 84\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8382    0.8865    0.8616      1233\n",
      "          1     0.3427    0.2570    0.2938       284\n",
      "\n",
      "avg / total     0.7454    0.7686    0.7553      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.5-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7857142857142857\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.163265306122449\n",
      "Original f1: 0.2694300518134715\n",
      "0.103189118073\n",
      "0.648478025154\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 114\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8160    0.9482    0.8771       926\n",
      "          1     0.3333    0.1081    0.1633       222\n",
      "\n",
      "avg / total     0.7227    0.7857    0.7391      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7949901120632828\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.24697336561743344\n",
      "Original f1: 0.3050259965337955\n",
      "0.121861326603\n",
      "0.72895009779\n",
      "311\n",
      "0.205009887937\n",
      "Number of disagreement: 202\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8321    0.9367    0.8813      1233\n",
      "          1     0.3953    0.1796    0.2470       284\n",
      "\n",
      "avg / total     0.7504    0.7950    0.7626      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.5-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7752613240418118\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2543352601156069\n",
      "Original f1: 0.2694300518134715\n",
      "0.0294902984282\n",
      "0.534072081305\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 52\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8262    0.9136    0.8677       926\n",
      "          1     0.3548    0.1982    0.2543       222\n",
      "\n",
      "avg / total     0.7350    0.7753    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7626895187870798\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.31558935361216733\n",
      "Original f1: 0.3050259965337955\n",
      "0.0378681357604\n",
      "0.648748446585\n",
      "360\n",
      "0.237310481213\n",
      "Number of disagreement: 77\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8424    0.8710    0.8565      1233\n",
      "          1     0.3430    0.2923    0.3156       284\n",
      "\n",
      "avg / total     0.7489    0.7627    0.7552      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.5-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7177700348432056\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.31063829787234043\n",
      "Original f1: 0.2694300518134715\n",
      "0.187151935393\n",
      "0.993264876605\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 258\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8344    0.8110    0.8226       926\n",
      "          1     0.2944    0.3288    0.3106       222\n",
      "\n",
      "avg / total     0.7300    0.7178    0.7236      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7178642056690837\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3534743202416919\n",
      "Original f1: 0.3050259965337955\n",
      "0.192667240956\n",
      "0.992866689235\n",
      "428\n",
      "0.282135794331\n",
      "Number of disagreement: 353\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8534    0.7883    0.8196      1233\n",
      "          1     0.3095    0.4120    0.3535       284\n",
      "\n",
      "avg / total     0.7516    0.7179    0.7323      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.5-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7752613240418118\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.25862068965517243\n",
      "Original f1: 0.2694300518134715\n",
      "0.0310530278948\n",
      "0.523612199988\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 52\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8268    0.9125    0.8676       926\n",
      "          1     0.3571    0.2027    0.2586       222\n",
      "\n",
      "avg / total     0.7360    0.7753    0.7498      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7600527356624918\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.31835205992509363\n",
      "Original f1: 0.3050259965337955\n",
      "0.0405982655407\n",
      "0.707533063465\n",
      "364\n",
      "0.239947264338\n",
      "Number of disagreement: 81\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8429    0.8662    0.8544      1233\n",
      "          1     0.3400    0.2993    0.3184       284\n",
      "\n",
      "avg / total     0.7488    0.7601    0.7540      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.5-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7029616724738676\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.32475247524752476\n",
      "Original f1: 0.2694300518134715\n",
      "0.19968877708\n",
      "0.997283541073\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 281\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8382    0.7829    0.8096       926\n",
      "          1     0.2898    0.3694    0.3248       222\n",
      "\n",
      "avg / total     0.7321    0.7030    0.7158      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7092946605141727\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.34859675036927623\n",
      "Original f1: 0.3050259965337955\n",
      "0.201888144838\n",
      "0.992866689268\n",
      "441\n",
      "0.290705339486\n",
      "Number of disagreement: 364\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8523    0.7770    0.8129      1233\n",
      "          1     0.3003    0.4155    0.3486       284\n",
      "\n",
      "avg / total     0.7490    0.7093    0.7260      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.5-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7700348432055749\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2542372881355932\n",
      "Original f1: 0.2694300518134715\n",
      "0.0345275744281\n",
      "0.524039660596\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 56\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8258    0.9060    0.8641       926\n",
      "          1     0.3409    0.2027    0.2542       222\n",
      "\n",
      "avg / total     0.7320    0.7700    0.7461      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7580751483190508\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3241252302025782\n",
      "Original f1: 0.3050259965337955\n",
      "0.0463704915399\n",
      "0.812340279974\n",
      "367\n",
      "0.241924851681\n",
      "Number of disagreement: 88\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8442    0.8613    0.8527      1233\n",
      "          1     0.3398    0.3099    0.3241       284\n",
      "\n",
      "avg / total     0.7498    0.7581    0.7537      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.5-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6898954703832753\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3358208955223881\n",
      "Original f1: 0.2694300518134715\n",
      "0.21434931425\n",
      "0.997283540876\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 310\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8417    0.7581    0.7977       926\n",
      "          1     0.2866    0.4054    0.3358       222\n",
      "\n",
      "avg / total     0.7344    0.6899    0.7084      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7000659195781147\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3434343434343434\n",
      "Original f1: 0.3050259965337955\n",
      "0.212018437818\n",
      "0.992866689217\n",
      "455\n",
      "0.299934080422\n",
      "Number of disagreement: 378\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8511    0.7648    0.8056      1233\n",
      "          1     0.2910    0.4190    0.3434       284\n",
      "\n",
      "avg / total     0.7462    0.7001    0.7191      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.5-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7761324041811847\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3035230352303523\n",
      "Original f1: 0.2694300518134715\n",
      "0.0419565116394\n",
      "0.993264874577\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 67\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8342    0.9017    0.8666       926\n",
      "          1     0.3810    0.2523    0.3035       222\n",
      "\n",
      "avg / total     0.7465    0.7761    0.7577      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7547791694133158\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3309352517985612\n",
      "Original f1: 0.3050259965337955\n",
      "0.0548712062598\n",
      "0.910413029568\n",
      "372\n",
      "0.245220830587\n",
      "Number of disagreement: 101\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8458    0.8540    0.8499      1233\n",
      "          1     0.3382    0.3239    0.3309       284\n",
      "\n",
      "avg / total     0.7508    0.7548    0.7527      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.5-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6750871080139372\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.332737030411449\n",
      "Original f1: 0.2694300518134715\n",
      "0.225887108574\n",
      "0.997283541115\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 331\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8409    0.7365    0.7853       926\n",
      "          1     0.2760    0.4189    0.3327       222\n",
      "\n",
      "avg / total     0.7317    0.6751    0.6978      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6934739617666447\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3385490753911807\n",
      "Original f1: 0.3050259965337955\n",
      "0.221077703299\n",
      "0.99286668925\n",
      "465\n",
      "0.306526038233\n",
      "Number of disagreement: 386\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8497    0.7567    0.8005      1233\n",
      "          1     0.2840    0.4190    0.3385       284\n",
      "\n",
      "avg / total     0.7438    0.6935    0.7140      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.5-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7804878048780488\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3471502590673576\n",
      "Original f1: 0.2694300518134715\n",
      "0.0548011261042\n",
      "0.993264876536\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 82\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8425    0.8952    0.8681       926\n",
      "          1     0.4085    0.3018    0.3472       222\n",
      "\n",
      "avg / total     0.7586    0.7805    0.7673      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7495056031641397\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.36877076411960136\n",
      "Original f1: 0.3050259965337955\n",
      "0.0765262003621\n",
      "0.992866669194\n",
      "380\n",
      "0.250494396836\n",
      "Number of disagreement: 147\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8557    0.8321    0.8438      1233\n",
      "          1     0.3491    0.3908    0.3688       284\n",
      "\n",
      "avg / total     0.7609    0.7495    0.7548      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.5-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.6724738675958188\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3426573426573427\n",
      "Original f1: 0.2694300518134715\n",
      "0.235825346108\n",
      "0.997283541064\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 344\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8446    0.7279    0.7819       926\n",
      "          1     0.2800    0.4414    0.3427       222\n",
      "\n",
      "avg / total     0.7354    0.6725    0.6970      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6822676334871457\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.33972602739726027\n",
      "Original f1: 0.3050259965337955\n",
      "0.231916095898\n",
      "0.995662987741\n",
      "482\n",
      "0.317732366513\n",
      "Number of disagreement: 411\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8506    0.7388    0.7908      1233\n",
      "          1     0.2780    0.4366    0.3397       284\n",
      "\n",
      "avg / total     0.7434    0.6823    0.7064      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.5-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7735191637630662\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.35960591133004927\n",
      "Original f1: 0.2694300518134715\n",
      "0.0705631012731\n",
      "0.993264876431\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 100\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8454    0.8801    0.8624       926\n",
      "          1     0.3967    0.3288    0.3596       222\n",
      "\n",
      "avg / total     0.7587    0.7735    0.7652      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7488464073829928\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3981042654028436\n",
      "Original f1: 0.3050259965337955\n",
      "0.0860555943095\n",
      "0.992866689051\n",
      "381\n",
      "0.251153592617\n",
      "Number of disagreement: 178\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8647    0.8191    0.8413      1233\n",
      "          1     0.3610    0.4437    0.3981       284\n",
      "\n",
      "avg / total     0.7704    0.7488    0.7583      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.5-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6672473867595818\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3413793103448276\n",
      "Original f1: 0.2694300518134715\n",
      "0.241518534626\n",
      "0.997283541218\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 352\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8443    0.7203    0.7774       926\n",
      "          1     0.2765    0.4459    0.3414       222\n",
      "\n",
      "avg / total     0.7345    0.6672    0.6931      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6763348714568227\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3355886332882273\n",
      "Original f1: 0.3050259965337955\n",
      "0.236493335343\n",
      "0.999999684623\n",
      "491\n",
      "0.323665128543\n",
      "Number of disagreement: 418\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8493    0.7315    0.7861      1233\n",
      "          1     0.2725    0.4366    0.3356       284\n",
      "\n",
      "avg / total     0.7414    0.6763    0.7017      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.5-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7726480836236934\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.21148036253776437\n",
      "Original f1: 0.2694300518134715\n",
      "0.0285535055503\n",
      "0.614656248833\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 59\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8200    0.9201    0.8672       926\n",
      "          1     0.3211    0.1577    0.2115       222\n",
      "\n",
      "avg / total     0.7235    0.7726    0.7404      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7653263019116677\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.2793522267206478\n",
      "Original f1: 0.3050259965337955\n",
      "0.0351685055232\n",
      "0.653038472904\n",
      "356\n",
      "0.234673698088\n",
      "Number of disagreement: 85\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8355    0.8856    0.8598      1233\n",
      "          1     0.3286    0.2430    0.2794       284\n",
      "\n",
      "avg / total     0.7406    0.7653    0.7512      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.5-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7839721254355401\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.1506849315068493\n",
      "Original f1: 0.2694300518134715\n",
      "0.107339597396\n",
      "0.658312018845\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 118\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8145    0.9482    0.8762       926\n",
      "          1     0.3143    0.0991    0.1507       222\n",
      "\n",
      "avg / total     0.7177    0.7840    0.7359      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7936717205009888\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.23095823095823093\n",
      "Original f1: 0.3050259965337955\n",
      "0.126395491827\n",
      "0.730866975638\n",
      "313\n",
      "0.206328279499\n",
      "Number of disagreement: 208\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8300    0.9384    0.8809      1233\n",
      "          1     0.3821    0.1655    0.2310       284\n",
      "\n",
      "avg / total     0.7461    0.7937    0.7592      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.5-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7761324041811847\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.25072886297376096\n",
      "Original f1: 0.2694300518134715\n",
      "0.0298832931972\n",
      "0.560638798205\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 51\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8257    0.9158    0.8684       926\n",
      "          1     0.3554    0.1937    0.2507       222\n",
      "\n",
      "avg / total     0.7348    0.7761    0.7490      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7626895187870798\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.31034482758620685\n",
      "Original f1: 0.3050259965337955\n",
      "0.0377921966127\n",
      "0.653038472904\n",
      "360\n",
      "0.237310481213\n",
      "Number of disagreement: 75\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8413    0.8727    0.8567      1233\n",
      "          1     0.3403    0.2852    0.3103       284\n",
      "\n",
      "avg / total     0.7475    0.7627    0.7544      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.5-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7090592334494773\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3099173553719008\n",
      "Original f1: 0.2694300518134715\n",
      "0.194406294499\n",
      "0.997283540943\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 274\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8341    0.7981    0.8157       926\n",
      "          1     0.2863    0.3378    0.3099       222\n",
      "\n",
      "avg / total     0.7281    0.7091    0.7179      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7125906394199077\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.34337349397590367\n",
      "Original f1: 0.3050259965337955\n",
      "0.201218219438\n",
      "0.999999685618\n",
      "436\n",
      "0.28740936058\n",
      "Number of disagreement: 363\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8505    0.7843    0.8160      1233\n",
      "          1     0.3000    0.4014    0.3434       284\n",
      "\n",
      "avg / total     0.7474    0.7126    0.7275      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.5-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.774390243902439\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.24927536231884057\n",
      "Original f1: 0.2694300518134715\n",
      "0.0317543523452\n",
      "0.560638798205\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 51\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8254    0.9136    0.8672       926\n",
      "          1     0.3496    0.1937    0.2493       222\n",
      "\n",
      "avg / total     0.7334    0.7744    0.7477      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7600527356624918\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.30798479087452474\n",
      "Original f1: 0.3050259965337955\n",
      "0.0405600730193\n",
      "0.690180284009\n",
      "364\n",
      "0.239947264338\n",
      "Number of disagreement: 79\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8408    0.8694    0.8549      1233\n",
      "          1     0.3347    0.2852    0.3080       284\n",
      "\n",
      "avg / total     0.7460    0.7601    0.7525      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.5-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7003484320557491\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3228346456692914\n",
      "Original f1: 0.2694300518134715\n",
      "0.205992268356\n",
      "0.997283540996\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 294\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8376    0.7797    0.8076       926\n",
      "          1     0.2867    0.3694    0.3228       222\n",
      "\n",
      "avg / total     0.7311    0.7003    0.7139      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7040210942649967\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.33677991137370755\n",
      "Original f1: 0.3050259965337955\n",
      "0.209750206839\n",
      "0.999999687115\n",
      "449\n",
      "0.295978905735\n",
      "Number of disagreement: 372\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8488    0.7737    0.8095      1233\n",
      "          1     0.2901    0.4014    0.3368       284\n",
      "\n",
      "avg / total     0.7442    0.7040    0.7210      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.5-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.774390243902439\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2621082621082621\n",
      "Original f1: 0.2694300518134715\n",
      "0.0350567112658\n",
      "0.560638798205\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 55\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8273    0.9104    0.8668       926\n",
      "          1     0.3566    0.2072    0.2621       222\n",
      "\n",
      "avg / total     0.7363    0.7744    0.7499      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7593935398813447\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.32282003710575136\n",
      "Original f1: 0.3050259965337955\n",
      "0.0464541633612\n",
      "0.794289638333\n",
      "365\n",
      "0.240606460119\n",
      "Number of disagreement: 90\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8439    0.8637    0.8537      1233\n",
      "          1     0.3412    0.3063    0.3228       284\n",
      "\n",
      "avg / total     0.7498    0.7594    0.7543      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.5-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.6829268292682927\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3284132841328413\n",
      "Original f1: 0.2694300518134715\n",
      "0.221001948727\n",
      "0.997283541062\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 320\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8394    0.7505    0.7925       926\n",
      "          1     0.2781    0.4009    0.3284       222\n",
      "\n",
      "avg / total     0.7308    0.6829    0.7027      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6934739617666447\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.33285509325681495\n",
      "Original f1: 0.3050259965337955\n",
      "0.219112234516\n",
      "0.999999686944\n",
      "465\n",
      "0.306526038233\n",
      "Number of disagreement: 388\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8478    0.7591    0.8010      1233\n",
      "          1     0.2809    0.4085    0.3329       284\n",
      "\n",
      "avg / total     0.7417    0.6935    0.7134      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.5-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7778745644599303\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.30136986301369867\n",
      "Original f1: 0.2694300518134715\n",
      "0.0427562373769\n",
      "0.993264870294\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 65\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8338    0.9050    0.8679       926\n",
      "          1     0.3846    0.2477    0.3014       222\n",
      "\n",
      "avg / total     0.7470    0.7779    0.7584      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7574159525379037\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.33333333333333337\n",
      "Original f1: 0.3050259965337955\n",
      "0.0543994420618\n",
      "0.896837666109\n",
      "368\n",
      "0.242584047462\n",
      "Number of disagreement: 97\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8463    0.8573    0.8517      1233\n",
      "          1     0.3433    0.3239    0.3333       284\n",
      "\n",
      "avg / total     0.7521    0.7574    0.7547      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.5-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6611498257839721\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.32347826086956516\n",
      "Original f1: 0.2694300518134715\n",
      "0.234766780677\n",
      "0.997283541032\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 347\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8377    0.7192    0.7740       926\n",
      "          1     0.2635    0.4189    0.3235       222\n",
      "\n",
      "avg / total     0.7267    0.6611    0.6869      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6849044166117337\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3286516853932584\n",
      "Original f1: 0.3050259965337955\n",
      "0.22752242765\n",
      "0.999999687362\n",
      "478\n",
      "0.315095583388\n",
      "Number of disagreement: 401\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8466    0.7478    0.7941      1233\n",
      "          1     0.2734    0.4120    0.3287       284\n",
      "\n",
      "avg / total     0.7393    0.6849    0.7070      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.5-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7813588850174216\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.33773087071240104\n",
      "Original f1: 0.2694300518134715\n",
      "0.0551974983898\n",
      "0.993667657801\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 79\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8406    0.8996    0.8691       926\n",
      "          1     0.4076    0.2883    0.3377       222\n",
      "\n",
      "avg / total     0.7568    0.7814    0.7663      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7389584706657878\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.34868421052631576\n",
      "Original f1: 0.3050259965337955\n",
      "0.0766047457886\n",
      "0.962421878764\n",
      "396\n",
      "0.261041529334\n",
      "Number of disagreement: 147\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8508    0.8232    0.8368      1233\n",
      "          1     0.3272    0.3732    0.3487       284\n",
      "\n",
      "avg / total     0.7528    0.7390    0.7454      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.5-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6576655052264808\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.33049403747870526\n",
      "Original f1: 0.2694300518134715\n",
      "0.244309448562\n",
      "0.997283541206\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 359\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8404    0.7106    0.7700       926\n",
      "          1     0.2658    0.4369    0.3305       222\n",
      "\n",
      "avg / total     0.7292    0.6577    0.6850      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6684245220830587\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.32301480484522205\n",
      "Original f1: 0.3050259965337955\n",
      "0.236646112368\n",
      "0.999999687401\n",
      "503\n",
      "0.331575477917\n",
      "Number of disagreement: 428\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8450    0.7251    0.7804      1233\n",
      "          1     0.2614    0.4225    0.3230       284\n",
      "\n",
      "avg / total     0.7357    0.6684    0.6948      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.5-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7717770034843205\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.35784313725490197\n",
      "Original f1: 0.2694300518134715\n",
      "0.0712694174616\n",
      "0.993667658733\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 106\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8451    0.8780    0.8612       926\n",
      "          1     0.3925    0.3288    0.3578       222\n",
      "\n",
      "avg / total     0.7576    0.7718    0.7639      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7396176664469347\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3740095087163233\n",
      "Original f1: 0.3050259965337955\n",
      "0.0859558019068\n",
      "0.999999685667\n",
      "395\n",
      "0.260382333553\n",
      "Number of disagreement: 170\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8581    0.8143    0.8356      1233\n",
      "          1     0.3401    0.4155    0.3740       284\n",
      "\n",
      "avg / total     0.7611    0.7396    0.7492      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-1.5-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6533101045296167\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.32996632996632996\n",
      "Original f1: 0.2694300518134715\n",
      "0.249872581843\n",
      "0.997283541178\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 366\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8402    0.7041    0.7662       926\n",
      "          1     0.2634    0.4414    0.3300       222\n",
      "\n",
      "avg / total     0.7287    0.6533    0.6818      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6624917600527357\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3209549071618037\n",
      "Original f1: 0.3050259965337955\n",
      "0.241698925426\n",
      "0.999999687406\n",
      "512\n",
      "0.337508239947\n",
      "Number of disagreement: 439\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8443    0.7170    0.7754      1233\n",
      "          1     0.2574    0.4261    0.3210       284\n",
      "\n",
      "avg / total     0.7344    0.6625    0.6904      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-2.0-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7726480836236934\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.21621621621621623\n",
      "Original f1: 0.2694300518134715\n",
      "0.0281044114461\n",
      "0.635462610328\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 61\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8206    0.9190    0.8670       926\n",
      "          1     0.3243    0.1622    0.2162       222\n",
      "\n",
      "avg / total     0.7247    0.7726    0.7412      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7673038892551087\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.2925851703406813\n",
      "Original f1: 0.3050259965337955\n",
      "0.0347762960862\n",
      "0.590900262911\n",
      "353\n",
      "0.232696110745\n",
      "Number of disagreement: 82\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8379    0.8848    0.8607      1233\n",
      "          1     0.3395    0.2570    0.2926       284\n",
      "\n",
      "avg / total     0.7446    0.7673    0.7544      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-2.0-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7857142857142857\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.1517241379310345\n",
      "Original f1: 0.2694300518134715\n",
      "0.103150004054\n",
      "0.667292044862\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 118\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8148    0.9503    0.8774       926\n",
      "          1     0.3235    0.0991    0.1517       222\n",
      "\n",
      "avg / total     0.7198    0.7857    0.7370      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7943309162821358\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.2390243902439024\n",
      "Original f1: 0.3050259965337955\n",
      "0.122450277943\n",
      "0.660874347848\n",
      "312\n",
      "0.205669083718\n",
      "Number of disagreement: 203\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8311    0.9376    0.8811      1233\n",
      "          1     0.3889    0.1725    0.2390       284\n",
      "\n",
      "avg / total     0.7483    0.7943    0.7609      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-2.0-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7761324041811847\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.25507246376811593\n",
      "Original f1: 0.2694300518134715\n",
      "0.0292672315028\n",
      "0.583523908255\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 53\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8263    0.9147    0.8683       926\n",
      "          1     0.3577    0.1982    0.2551       222\n",
      "\n",
      "avg / total     0.7357    0.7761    0.7497      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7626895187870798\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.31558935361216733\n",
      "Original f1: 0.3050259965337955\n",
      "0.037888994076\n",
      "0.624748718985\n",
      "360\n",
      "0.237310481213\n",
      "Number of disagreement: 77\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8424    0.8710    0.8565      1233\n",
      "          1     0.3430    0.2923    0.3156       284\n",
      "\n",
      "avg / total     0.7489    0.7627    0.7552      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-2.0-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.705574912891986\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2987551867219917\n",
      "Original f1: 0.2694300518134715\n",
      "0.190283778773\n",
      "0.997283540559\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 276\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8311    0.7970    0.8137       926\n",
      "          1     0.2769    0.3243    0.2988       222\n",
      "\n",
      "avg / total     0.7239    0.7056    0.7141      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7119314436387607\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3448275862068965\n",
      "Original f1: 0.3050259965337955\n",
      "0.196161234975\n",
      "0.992866689119\n",
      "437\n",
      "0.288068556361\n",
      "Number of disagreement: 356\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8510    0.7826    0.8154      1233\n",
      "          1     0.3003    0.4049    0.3448       284\n",
      "\n",
      "avg / total     0.7479    0.7119    0.7273      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-2.0-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7761324041811847\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.25936599423631124\n",
      "Original f1: 0.2694300518134715\n",
      "0.0307852208872\n",
      "0.583523908255\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 53\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8270    0.9136    0.8681       926\n",
      "          1     0.3600    0.2027    0.2594       222\n",
      "\n",
      "avg / total     0.7367    0.7761    0.7504      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7600527356624918\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3157894736842105\n",
      "Original f1: 0.3050259965337955\n",
      "0.0406316095344\n",
      "0.702361923012\n",
      "364\n",
      "0.239947264338\n",
      "Number of disagreement: 79\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8424    0.8670    0.8545      1233\n",
      "          1     0.3387    0.2958    0.3158       284\n",
      "\n",
      "avg / total     0.7481    0.7601    0.7537      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-2.0-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6968641114982579\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3176470588235294\n",
      "Original f1: 0.2694300518134715\n",
      "0.203258283525\n",
      "0.997283541086\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 294\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8360    0.7765    0.8052       926\n",
      "          1     0.2812    0.3649    0.3176       222\n",
      "\n",
      "avg / total     0.7288    0.6969    0.7109      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7040210942649967\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.34260614934114203\n",
      "Original f1: 0.3050259965337955\n",
      "0.205959391541\n",
      "0.992866688994\n",
      "449\n",
      "0.295978905735\n",
      "Number of disagreement: 368\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8506    0.7713    0.8090      1233\n",
      "          1     0.2932    0.4120    0.3426       284\n",
      "\n",
      "avg / total     0.7463    0.7040    0.7217      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-2.0-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7709059233449478\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.254957507082153\n",
      "Original f1: 0.2694300518134715\n",
      "0.0341610369879\n",
      "0.583523908255\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 57\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8260    0.9071    0.8646       926\n",
      "          1     0.3435    0.2027    0.2550       222\n",
      "\n",
      "avg / total     0.7327    0.7709    0.7467      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7587343441001978\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3272058823529412\n",
      "Original f1: 0.3050259965337955\n",
      "0.0468810639486\n",
      "0.802499700983\n",
      "366\n",
      "0.2412656559\n",
      "Number of disagreement: 89\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8449    0.8613    0.8530      1233\n",
      "          1     0.3423    0.3134    0.3272       284\n",
      "\n",
      "avg / total     0.7508    0.7587    0.7546      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-2.0-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6820557491289199\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.32780847145488023\n",
      "Original f1: 0.2694300518134715\n",
      "0.21886667683\n",
      "0.997283541146\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 325\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8392    0.7495    0.7918       926\n",
      "          1     0.2773    0.4009    0.3278       222\n",
      "\n",
      "avg / total     0.7305    0.6821    0.7021      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6941331575477917\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.33714285714285713\n",
      "Original f1: 0.3050259965337955\n",
      "0.21552771676\n",
      "0.99286668916\n",
      "464\n",
      "0.305866842452\n",
      "Number of disagreement: 383\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8492    0.7583    0.8012      1233\n",
      "          1     0.2837    0.4155    0.3371       284\n",
      "\n",
      "avg / total     0.7433    0.6941    0.7143      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-2.0-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.774390243902439\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2904109589041096\n",
      "Original f1: 0.2694300518134715\n",
      "0.0415681251864\n",
      "0.993264874188\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 65\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8318    0.9028    0.8659       926\n",
      "          1     0.3706    0.2387    0.2904       222\n",
      "\n",
      "avg / total     0.7427    0.7744    0.7546      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7554383651944627\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3363148479427549\n",
      "Original f1: 0.3050259965337955\n",
      "0.0553611529623\n",
      "0.912065012388\n",
      "371\n",
      "0.244561634806\n",
      "Number of disagreement: 104\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8470    0.8532    0.8501      1233\n",
      "          1     0.3418    0.3310    0.3363       284\n",
      "\n",
      "avg / total     0.7524    0.7554    0.7539      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-2.0-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6707317073170732\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.32499999999999996\n",
      "Original f1: 0.2694300518134715\n",
      "0.230243258474\n",
      "0.997283541187\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 340\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8383    0.7333    0.7823       926\n",
      "          1     0.2692    0.4099    0.3250       222\n",
      "\n",
      "avg / total     0.7282    0.6707    0.6938      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6816084377059987\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3282336578581363\n",
      "Original f1: 0.3050259965337955\n",
      "0.225506643263\n",
      "0.997565891773\n",
      "483\n",
      "0.318391562294\n",
      "Number of disagreement: 398\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8466    0.7429    0.7914      1233\n",
      "          1     0.2713    0.4155    0.3282       284\n",
      "\n",
      "avg / total     0.7389    0.6816    0.7047      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-2.0-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7796167247386759\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.33942558746736295\n",
      "Original f1: 0.2694300518134715\n",
      "0.0546455804873\n",
      "0.993264876199\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 81\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8409    0.8963    0.8677       926\n",
      "          1     0.4037    0.2928    0.3394       222\n",
      "\n",
      "avg / total     0.7564    0.7796    0.7656      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7442320369149638\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.36393442622950817\n",
      "Original f1: 0.3050259965337955\n",
      "0.0775650101973\n",
      "0.992866670209\n",
      "388\n",
      "0.255767963085\n",
      "Number of disagreement: 155\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8547    0.8256    0.8399      1233\n",
      "          1     0.3405    0.3908    0.3639       284\n",
      "\n",
      "avg / total     0.7585    0.7442    0.7508      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-2.0-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6646341463414634\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3327556325823224\n",
      "Original f1: 0.2694300518134715\n",
      "0.2406806795\n",
      "0.997283541189\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 357\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8411    0.7203    0.7760       926\n",
      "          1     0.2704    0.4324    0.3328       222\n",
      "\n",
      "avg / total     0.7308    0.6646    0.6903      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6684245220830587\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3266398929049531\n",
      "Original f1: 0.3050259965337955\n",
      "0.236461281148\n",
      "0.997565927157\n",
      "503\n",
      "0.331575477917\n",
      "Number of disagreement: 426\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8463    0.7234    0.7801      1233\n",
      "          1     0.2635    0.4296    0.3266       284\n",
      "\n",
      "avg / total     0.7372    0.6684    0.6952      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-2.0-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7709059233449478\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3538083538083538\n",
      "Original f1: 0.2694300518134715\n",
      "0.0707223240199\n",
      "0.996912521842\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 103\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8442    0.8780    0.8608       926\n",
      "          1     0.3892    0.3243    0.3538       222\n",
      "\n",
      "avg / total     0.7562    0.7709    0.7627      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7475280158206987\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.39685039370078745\n",
      "Original f1: 0.3050259965337955\n",
      "0.0872098195345\n",
      "0.992866689082\n",
      "383\n",
      "0.252471984179\n",
      "Number of disagreement: 180\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8645    0.8175    0.8404      1233\n",
      "          1     0.3590    0.4437    0.3969       284\n",
      "\n",
      "avg / total     0.7699    0.7475    0.7573      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-2.0-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.6628919860627178\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.34071550255536626\n",
      "Original f1: 0.2694300518134715\n",
      "0.246701941844\n",
      "0.997283541206\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 365\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8442    0.7138    0.7736       926\n",
      "          1     0.2740    0.4505    0.3407       222\n",
      "\n",
      "avg / total     0.7339    0.6629    0.6898      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6644693473961767\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3240371845949535\n",
      "Original f1: 0.3050259965337955\n",
      "0.240924492379\n",
      "0.999999685245\n",
      "509\n",
      "0.335530652604\n",
      "Number of disagreement: 432\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8454    0.7186    0.7769      1233\n",
      "          1     0.2601    0.4296    0.3240       284\n",
      "\n",
      "avg / total     0.7358    0.6645    0.6921      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-2.0-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7717770034843205\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.20121951219512196\n",
      "Original f1: 0.2694300518134715\n",
      "0.0285919305368\n",
      "0.613844147227\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 60\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8186    0.9212    0.8669       926\n",
      "          1     0.3113    0.1486    0.2012       222\n",
      "\n",
      "avg / total     0.7205    0.7718    0.7381      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7626895187870798\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.27419354838709675\n",
      "Original f1: 0.3050259965337955\n",
      "0.0355270401782\n",
      "0.602486703393\n",
      "360\n",
      "0.237310481213\n",
      "Number of disagreement: 83\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8345    0.8832    0.8582      1233\n",
      "          1     0.3208    0.2394    0.2742       284\n",
      "\n",
      "avg / total     0.7383    0.7627    0.7488      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-2.0-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7831010452961672\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.15017064846416384\n",
      "Original f1: 0.2694300518134715\n",
      "0.107792817847\n",
      "0.669881916313\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 117\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8143    0.9471    0.8757       926\n",
      "          1     0.3099    0.0991    0.1502       222\n",
      "\n",
      "avg / total     0.7168    0.7831    0.7354      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7890573500329597\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.21182266009852216\n",
      "Original f1: 0.3050259965337955\n",
      "0.127262386884\n",
      "0.664394896066\n",
      "320\n",
      "0.210942649967\n",
      "Number of disagreement: 207\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.9359    0.8782      1233\n",
      "          1     0.3525    0.1514    0.2118       284\n",
      "\n",
      "avg / total     0.7384    0.7891    0.7535      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-2.0-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7752613240418118\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.24117647058823527\n",
      "Original f1: 0.2694300518134715\n",
      "0.0298499491189\n",
      "0.613844147227\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 52\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8243    0.9168    0.8681       926\n",
      "          1     0.3475    0.1847    0.2412       222\n",
      "\n",
      "avg / total     0.7321    0.7753    0.7469      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7593935398813447\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.30476190476190473\n",
      "Original f1: 0.3050259965337955\n",
      "0.03792835944\n",
      "0.602486703393\n",
      "365\n",
      "0.240606460119\n",
      "Number of disagreement: 72\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8401    0.8694    0.8545      1233\n",
      "          1     0.3320    0.2817    0.3048       284\n",
      "\n",
      "avg / total     0.7450    0.7594    0.7516      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-2.0-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6968641114982579\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.30400000000000005\n",
      "Original f1: 0.2694300518134715\n",
      "0.197860885058\n",
      "0.997283541012\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 286\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8322    0.7819    0.8062       926\n",
      "          1     0.2734    0.3423    0.3040       222\n",
      "\n",
      "avg / total     0.7241    0.6969    0.7091      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6967699406723797\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3255131964809384\n",
      "Original f1: 0.3050259965337955\n",
      "0.20524560664\n",
      "0.999999687246\n",
      "460\n",
      "0.303230059328\n",
      "Number of disagreement: 375\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8454    0.7672    0.8044      1233\n",
      "          1     0.2789    0.3908    0.3255       284\n",
      "\n",
      "avg / total     0.7393    0.6968    0.7148      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-2.0-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7735191637630662\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.23976608187134504\n",
      "Original f1: 0.2694300518134715\n",
      "0.0316475775167\n",
      "0.613844147227\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 52\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8239    0.9147    0.8669       926\n",
      "          1     0.3417    0.1847    0.2398       222\n",
      "\n",
      "avg / total     0.7307    0.7735    0.7457      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7567567567567568\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.30245746691871456\n",
      "Original f1: 0.3050259965337955\n",
      "0.0406435156546\n",
      "0.683989607845\n",
      "369\n",
      "0.243243243243\n",
      "Number of disagreement: 76\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8396    0.8662    0.8527      1233\n",
      "          1     0.3265    0.2817    0.3025       284\n",
      "\n",
      "avg / total     0.7436    0.7568    0.7497      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-2.0-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.686411149825784\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3129770992366412\n",
      "Original f1: 0.2694300518134715\n",
      "0.210661685345\n",
      "0.997283541179\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 304\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8345    0.7624    0.7968       926\n",
      "          1     0.2715    0.3694    0.3130       222\n",
      "\n",
      "avg / total     0.7256    0.6864    0.7033      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6901779828609097\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3227665706051873\n",
      "Original f1: 0.3050259965337955\n",
      "0.214050082308\n",
      "0.999999686723\n",
      "470\n",
      "0.309822017139\n",
      "Number of disagreement: 385\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8446    0.7583    0.7991      1233\n",
      "          1     0.2732    0.3944    0.3228       284\n",
      "\n",
      "avg / total     0.7376    0.6902    0.7100      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-2.0-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7735191637630662\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.25287356321839083\n",
      "Original f1: 0.2694300518134715\n",
      "0.0349104973645\n",
      "0.613844147046\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 54\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8258    0.9114    0.8665       926\n",
      "          1     0.3492    0.1982    0.2529       222\n",
      "\n",
      "avg / total     0.7337    0.7735    0.7479      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7560975609756098\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.31985294117647056\n",
      "Original f1: 0.3050259965337955\n",
      "0.0469229792275\n",
      "0.78556995254\n",
      "370\n",
      "0.243902439024\n",
      "Number of disagreement: 85\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8433    0.8597    0.8514      1233\n",
      "          1     0.3346    0.3063    0.3199       284\n",
      "\n",
      "avg / total     0.7481    0.7561    0.7519      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-2.0-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.671602787456446\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3182640144665461\n",
      "Original f1: 0.2694300518134715\n",
      "0.226540409153\n",
      "0.997283541225\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 329\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8360    0.7376    0.7837       926\n",
      "          1     0.2659    0.3964    0.3183       222\n",
      "\n",
      "avg / total     0.7257    0.6716    0.6937      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6829268292682927\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3215796897038082\n",
      "Original f1: 0.3050259965337955\n",
      "0.223280400646\n",
      "0.999999687312\n",
      "481\n",
      "0.317073170732\n",
      "Number of disagreement: 400\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8443    0.7478    0.7931      1233\n",
      "          1     0.2682    0.4014    0.3216       284\n",
      "\n",
      "avg / total     0.7365    0.6829    0.7048      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-2.0-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7770034843205574\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.2928176795580111\n",
      "Original f1: 0.2694300518134715\n",
      "0.0422873323758\n",
      "0.865230884431\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 66\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8323    0.9060    0.8676       926\n",
      "          1     0.3786    0.2387    0.2928       222\n",
      "\n",
      "avg / total     0.7446    0.7770    0.7565      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7541199736321688\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3279279279279279\n",
      "Original f1: 0.3050259965337955\n",
      "0.0549597227404\n",
      "0.888507232344\n",
      "373\n",
      "0.245880026368\n",
      "Number of disagreement: 94\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8451    0.8540    0.8495      1233\n",
      "          1     0.3358    0.3204    0.3279       284\n",
      "\n",
      "avg / total     0.7498    0.7541    0.7519      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-2.0-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.6506968641114983\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3168654173764906\n",
      "Original f1: 0.2694300518134715\n",
      "0.24038267442\n",
      "0.997283541076\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 355\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8352    0.7063    0.7654       926\n",
      "          1     0.2548    0.4189    0.3169       222\n",
      "\n",
      "avg / total     0.7230    0.6507    0.6786      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6743572841133817\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3157894736842105\n",
      "Original f1: 0.3050259965337955\n",
      "0.232311009935\n",
      "0.999999687374\n",
      "494\n",
      "0.325642715887\n",
      "Number of disagreement: 411\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8424    0.7372    0.7863      1233\n",
      "          1     0.2603    0.4014    0.3158       284\n",
      "\n",
      "avg / total     0.7335    0.6744    0.6982      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-2.0-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7796167247386759\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.32891246684350134\n",
      "Original f1: 0.2694300518134715\n",
      "0.0554718774538\n",
      "0.993264876428\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 81\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8389    0.8996    0.8682       926\n",
      "          1     0.4000    0.2793    0.3289       222\n",
      "\n",
      "avg / total     0.7540    0.7796    0.7639      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7363216875411998\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3442622950819672\n",
      "Original f1: 0.3050259965337955\n",
      "0.0781198310679\n",
      "0.962421878799\n",
      "400\n",
      "0.263678312459\n",
      "Number of disagreement: 149\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8497    0.8208    0.8350      1233\n",
      "          1     0.3221    0.3697    0.3443       284\n",
      "\n",
      "avg / total     0.7509    0.7363    0.7431      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-2.0-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6463414634146342\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3255813953488372\n",
      "Original f1: 0.2694300518134715\n",
      "0.249894147427\n",
      "0.997283541213\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 370\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8385    0.6955    0.7603       926\n",
      "          1     0.2579    0.4414    0.3256       222\n",
      "\n",
      "avg / total     0.7263    0.6463    0.6763      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6585365853658537\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3129973474801061\n",
      "Original f1: 0.3050259965337955\n",
      "0.241861840667\n",
      "0.99999968741\n",
      "518\n",
      "0.341463414634\n",
      "Number of disagreement: 439\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8415    0.7145    0.7728      1233\n",
      "          1     0.2511    0.4155    0.3130       284\n",
      "\n",
      "avg / total     0.7309    0.6585    0.6867      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-2.0-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7682926829268293\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3415841584158416\n",
      "Original f1: 0.2694300518134715\n",
      "0.0711489041268\n",
      "0.993667656828\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 106\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8416    0.8780    0.8594       926\n",
      "          1     0.3791    0.3108    0.3416       222\n",
      "\n",
      "avg / total     0.7522    0.7683    0.7593      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7356624917600527\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3665086887835703\n",
      "Original f1: 0.3050259965337955\n",
      "0.0872517054874\n",
      "0.999999686864\n",
      "401\n",
      "0.26433750824\n",
      "Number of disagreement: 170\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8562    0.8110    0.8330      1233\n",
      "          1     0.3324    0.4085    0.3665       284\n",
      "\n",
      "avg / total     0.7581    0.7357    0.7457      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  NB\n",
      "rank propagation parameters:  2.0-2.0-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.6445993031358885\n",
      "Original accuracy: 0.7543554006968641\n",
      "Adjusted f1: 0.3311475409836066\n",
      "Original f1: 0.2694300518134715\n",
      "0.255368427188\n",
      "0.999999895433\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 378\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8408    0.6901    0.7580       926\n",
      "          1     0.2603    0.4550    0.3311       222\n",
      "\n",
      "avg / total     0.7285    0.6446    0.6755      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8272    0.8790    0.8524       926\n",
      "          1     0.3171    0.2342    0.2694       222\n",
      "\n",
      "avg / total     0.7286    0.7544    0.7396      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.6565589980224127\n",
      "Original accuracy: 0.7356624917600527\n",
      "Adjusted f1: 0.3117569352708058\n",
      "Original f1: 0.3050259965337955\n",
      "0.24638910767\n",
      "0.999999687356\n",
      "521\n",
      "0.343441001978\n",
      "Number of disagreement: 442\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8410    0.7121    0.7712      1233\n",
      "          1     0.2495    0.4155    0.3118       284\n",
      "\n",
      "avg / total     0.7303    0.6566    0.6852      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8399    0.8337    0.8368      1233\n",
      "          1     0.3003    0.3099    0.3050       284\n",
      "\n",
      "avg / total     0.7389    0.7357    0.7372      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.5-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "1.94173662341e-12\n",
      "4.83490435188e-11\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.68347178787e-12\n",
      "7.8710815643e-11\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.5-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "1.7111344467e-11\n",
      "1.92036719859e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.72559721584e-11\n",
      "1.97221336484e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.5-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "2.67961054405e-12\n",
      "1.11982478845e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "3.11964479212e-12\n",
      "2.44789910564e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.5-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7682926829268293\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3072916666666667\n",
      "Original f1: 0.1484375\n",
      "0.104928169426\n",
      "0.977222412764\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 128\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8347    0.8888    0.8609       926\n",
      "          1     0.3642    0.2658    0.3073       222\n",
      "\n",
      "avg / total     0.7437    0.7683    0.7538      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7956493078444298\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44244604316546765\n",
      "Original f1: 0.31182795698924726\n",
      "0.113072959088\n",
      "0.985480375751\n",
      "310\n",
      "0.204350692156\n",
      "Number of disagreement: 184\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8707    0.8792    0.8749      1233\n",
      "          1     0.4522    0.4331    0.4424       284\n",
      "\n",
      "avg / total     0.7923    0.7956    0.7939      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.5-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "4.27986782284e-12\n",
      "2.49928855389e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "9.04481690439e-12\n",
      "1.97314098394e-09\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.5-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3283582089552239\n",
      "Original f1: 0.1484375\n",
      "0.11886814487\n",
      "0.977222413397\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 146\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8388    0.8769    0.8574       926\n",
      "          1     0.3667    0.2973    0.3284       222\n",
      "\n",
      "avg / total     0.7475    0.7648    0.7551      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7930125247198417\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44912280701754387\n",
      "Original f1: 0.31182795698924726\n",
      "0.12225242006\n",
      "0.98840205272\n",
      "314\n",
      "0.20698747528\n",
      "Number of disagreement: 198\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8733    0.8719    0.8726      1233\n",
      "          1     0.4476    0.4507    0.4491       284\n",
      "\n",
      "avg / total     0.7936    0.7930    0.7933      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.5-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "0.000133452806745\n",
      "0.153203804379\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8365194462755439\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.3507853403141361\n",
      "Original f1: 0.31182795698924726\n",
      "0.00521951812455\n",
      "0.914491845661\n",
      "248\n",
      "0.163480553724\n",
      "Number of disagreement: 10\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8471    0.9749    0.9065      1233\n",
      "          1     0.6837    0.2359    0.3508       284\n",
      "\n",
      "avg / total     0.8165    0.8365    0.8025      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.5-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7630662020905923\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.34299516908212563\n",
      "Original f1: 0.1484375\n",
      "0.128000537779\n",
      "0.97722241378\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 158\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8421    0.8693    0.8555       926\n",
      "          1     0.3698    0.3198    0.3430       222\n",
      "\n",
      "avg / total     0.7507    0.7631    0.7564      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7857613711272248\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4444444444444444\n",
      "Original f1: 0.31182795698924726\n",
      "0.13128675451\n",
      "0.988402054615\n",
      "325\n",
      "0.214238628873\n",
      "Number of disagreement: 213\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8734    0.8613    0.8673      1233\n",
      "          1     0.4319    0.4577    0.4444       284\n",
      "\n",
      "avg / total     0.7907    0.7858    0.7881      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.5-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8222996515679443\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.26086956521739135\n",
      "Original f1: 0.1484375\n",
      "0.0141028982926\n",
      "0.974713447439\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 20\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8300    0.9806    0.8990       926\n",
      "          1     0.6667    0.1622    0.2609       222\n",
      "\n",
      "avg / total     0.7984    0.8223    0.7756      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8444297956493079\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4587155963302752\n",
      "Original f1: 0.31182795698924726\n",
      "0.0362148853866\n",
      "0.963170436383\n",
      "236\n",
      "0.155570204351\n",
      "Number of disagreement: 64\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8652    0.9578    0.9092      1233\n",
      "          1     0.6579    0.3521    0.4587       284\n",
      "\n",
      "avg / total     0.8264    0.8444    0.8248      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.5-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3509615384615385\n",
      "Original f1: 0.1484375\n",
      "0.131950988409\n",
      "0.986554666476\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 160\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8438    0.8693    0.8564       926\n",
      "          1     0.3763    0.3288    0.3510       222\n",
      "\n",
      "avg / total     0.7534    0.7648    0.7586      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7837837837837838\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4440677966101695\n",
      "Original f1: 0.31182795698924726\n",
      "0.135767807039\n",
      "0.99034446757\n",
      "328\n",
      "0.216216216216\n",
      "Number of disagreement: 218\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8737    0.8581    0.8658      1233\n",
      "          1     0.4281    0.4613    0.4441       284\n",
      "\n",
      "avg / total     0.7902    0.7838    0.7868      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.5-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8310104529616724\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.4156626506024096\n",
      "Original f1: 0.1484375\n",
      "0.0560330356873\n",
      "0.974713447266\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 76\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8526    0.9557    0.9012       926\n",
      "          1     0.6273    0.3108    0.4157       222\n",
      "\n",
      "avg / total     0.8090    0.8310    0.8073      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8253131179960448\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4731610337972167\n",
      "Original f1: 0.31182795698924726\n",
      "0.077686936139\n",
      "0.985480373627\n",
      "265\n",
      "0.174686882004\n",
      "Number of disagreement: 131\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8729    0.9189    0.8953      1233\n",
      "          1     0.5434    0.4190    0.4732       284\n",
      "\n",
      "avg / total     0.8112    0.8253    0.8163      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.5-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7630662020905923\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35545023696682465\n",
      "Original f1: 0.1484375\n",
      "0.135851423646\n",
      "0.986554666699\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 166\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8449    0.8650    0.8549       926\n",
      "          1     0.3750    0.3378    0.3555       222\n",
      "\n",
      "avg / total     0.7541    0.7631    0.7583      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7837837837837838\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4440677966101695\n",
      "Original f1: 0.31182795698924726\n",
      "0.136540271313\n",
      "0.990344467859\n",
      "328\n",
      "0.216216216216\n",
      "Number of disagreement: 218\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8737    0.8581    0.8658      1233\n",
      "          1     0.4281    0.4613    0.4441       284\n",
      "\n",
      "avg / total     0.7902    0.7838    0.7868      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.5-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8013937282229965\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3903743315508021\n",
      "Original f1: 0.1484375\n",
      "0.0907407518032\n",
      "0.975701875702\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 118\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8504    0.9147    0.8814       926\n",
      "          1     0.4803    0.3288    0.3904       222\n",
      "\n",
      "avg / total     0.7788    0.8014    0.7864      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8029004614370469\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.46126126126126127\n",
      "Original f1: 0.31182795698924726\n",
      "0.107774921644\n",
      "0.985480375387\n",
      "299\n",
      "0.197099538563\n",
      "Number of disagreement: 183\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8748    0.8840    0.8794      1233\n",
      "          1     0.4723    0.4507    0.4613       284\n",
      "\n",
      "avg / total     0.7995    0.8029    0.8011      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.5-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7630662020905923\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35545023696682465\n",
      "Original f1: 0.1484375\n",
      "0.137130753471\n",
      "0.986554666981\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 166\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8449    0.8650    0.8549       926\n",
      "          1     0.3750    0.3378    0.3555       222\n",
      "\n",
      "avg / total     0.7541    0.7631    0.7583      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7837837837837838\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4459459459459459\n",
      "Original f1: 0.31182795698924726\n",
      "0.137928841761\n",
      "0.99034446792\n",
      "328\n",
      "0.216216216216\n",
      "Number of disagreement: 220\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8743    0.8573    0.8657      1233\n",
      "          1     0.4286    0.4648    0.4459       284\n",
      "\n",
      "avg / total     0.7908    0.7838    0.7871      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.5-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "2.11342726191e-12\n",
      "4.83496402637e-11\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.66333129954e-12\n",
      "7.8710815643e-11\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.5-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "1.26022932003e-11\n",
      "1.74939757125e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.85418694367e-11\n",
      "1.97108787625e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.5-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "2.82063828444e-12\n",
      "1.07685776962e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "3.06988191414e-12\n",
      "2.44789910564e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.5-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7682926829268293\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3072916666666667\n",
      "Original f1: 0.1484375\n",
      "0.104877268059\n",
      "0.977222414015\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 128\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8347    0.8888    0.8609       926\n",
      "          1     0.3642    0.2658    0.3073       222\n",
      "\n",
      "avg / total     0.7437    0.7683    0.7538      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7956493078444298\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44244604316546765\n",
      "Original f1: 0.31182795698924726\n",
      "0.113377752102\n",
      "0.985480375842\n",
      "310\n",
      "0.204350692156\n",
      "Number of disagreement: 184\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8707    0.8792    0.8749      1233\n",
      "          1     0.4522    0.4331    0.4424       284\n",
      "\n",
      "avg / total     0.7923    0.7956    0.7939      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.5-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "4.47154771622e-12\n",
      "2.49928855389e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "8.69585252451e-12\n",
      "1.97314098394e-09\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.5-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7656794425087108\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.32917705735660846\n",
      "Original f1: 0.1484375\n",
      "0.118900714294\n",
      "0.977222413509\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 145\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8390    0.8780    0.8580       926\n",
      "          1     0.3687    0.2973    0.3292       222\n",
      "\n",
      "avg / total     0.7481    0.7657    0.7558      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7930125247198417\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44912280701754387\n",
      "Original f1: 0.31182795698924726\n",
      "0.122507560343\n",
      "0.988402052564\n",
      "314\n",
      "0.20698747528\n",
      "Number of disagreement: 198\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8733    0.8719    0.8726      1233\n",
      "          1     0.4476    0.4507    0.4491       284\n",
      "\n",
      "avg / total     0.7936    0.7930    0.7933      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.5-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "0.000121796185951\n",
      "0.139821999578\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8365194462755439\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.3507853403141361\n",
      "Original f1: 0.31182795698924726\n",
      "0.00515983827092\n",
      "0.914491847427\n",
      "248\n",
      "0.163480553724\n",
      "Number of disagreement: 10\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8471    0.9749    0.9065      1233\n",
      "          1     0.6837    0.2359    0.3508       284\n",
      "\n",
      "avg / total     0.8165    0.8365    0.8025      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.5-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7630662020905923\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.34299516908212563\n",
      "Original f1: 0.1484375\n",
      "0.128050261825\n",
      "0.977222413829\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 158\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8421    0.8693    0.8555       926\n",
      "          1     0.3698    0.3198    0.3430       222\n",
      "\n",
      "avg / total     0.7507    0.7631    0.7564      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7857613711272248\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4444444444444444\n",
      "Original f1: 0.31182795698924726\n",
      "0.13160100308\n",
      "0.988402054778\n",
      "325\n",
      "0.214238628873\n",
      "Number of disagreement: 213\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8734    0.8613    0.8673      1233\n",
      "          1     0.4319    0.4577    0.4444       284\n",
      "\n",
      "avg / total     0.7907    0.7858    0.7881      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.5-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8222996515679443\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.26086956521739135\n",
      "Original f1: 0.1484375\n",
      "0.0141816812068\n",
      "0.974713436254\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 20\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8300    0.9806    0.8990       926\n",
      "          1     0.6667    0.1622    0.2609       222\n",
      "\n",
      "avg / total     0.7984    0.8223    0.7756      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8464073829927489\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4618937644341802\n",
      "Original f1: 0.31182795698924726\n",
      "0.0360766392045\n",
      "0.963170434981\n",
      "233\n",
      "0.153592617007\n",
      "Number of disagreement: 61\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8655    0.9603    0.9104      1233\n",
      "          1     0.6711    0.3521    0.4619       284\n",
      "\n",
      "avg / total     0.8291    0.8464    0.8264      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.5-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3509615384615385\n",
      "Original f1: 0.1484375\n",
      "0.132001933078\n",
      "0.986554666471\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 160\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8438    0.8693    0.8564       926\n",
      "          1     0.3763    0.3288    0.3510       222\n",
      "\n",
      "avg / total     0.7534    0.7648    0.7586      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7837837837837838\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4440677966101695\n",
      "Original f1: 0.31182795698924726\n",
      "0.136071597374\n",
      "0.990344467483\n",
      "328\n",
      "0.216216216216\n",
      "Number of disagreement: 218\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8737    0.8581    0.8658      1233\n",
      "          1     0.4281    0.4613    0.4441       284\n",
      "\n",
      "avg / total     0.7902    0.7838    0.7868      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.5-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8310104529616724\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.4156626506024096\n",
      "Original f1: 0.1484375\n",
      "0.0560133364809\n",
      "0.974713448153\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 76\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8526    0.9557    0.9012       926\n",
      "          1     0.6273    0.3108    0.4157       222\n",
      "\n",
      "avg / total     0.8090    0.8310    0.8073      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8246539222148979\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4722222222222222\n",
      "Original f1: 0.31182795698924726\n",
      "0.0779821377683\n",
      "0.985480375137\n",
      "266\n",
      "0.175346077785\n",
      "Number of disagreement: 132\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8728    0.9181    0.8949      1233\n",
      "          1     0.5409    0.4190    0.4722       284\n",
      "\n",
      "avg / total     0.8107    0.8247    0.8157      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.5-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7630662020905923\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35545023696682465\n",
      "Original f1: 0.1484375\n",
      "0.135872689405\n",
      "0.9865546667\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 166\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8449    0.8650    0.8549       926\n",
      "          1     0.3750    0.3378    0.3555       222\n",
      "\n",
      "avg / total     0.7541    0.7631    0.7583      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7837837837837838\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4440677966101695\n",
      "Original f1: 0.31182795698924726\n",
      "0.136841929226\n",
      "0.990344467862\n",
      "328\n",
      "0.216216216216\n",
      "Number of disagreement: 218\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8737    0.8581    0.8658      1233\n",
      "          1     0.4281    0.4613    0.4441       284\n",
      "\n",
      "avg / total     0.7902    0.7838    0.7868      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.5-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8013937282229965\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3903743315508021\n",
      "Original f1: 0.1484375\n",
      "0.0911159627645\n",
      "0.975701875214\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 118\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8504    0.9147    0.8814       926\n",
      "          1     0.4803    0.3288    0.3904       222\n",
      "\n",
      "avg / total     0.7788    0.8014    0.7864      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8029004614370469\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.46126126126126127\n",
      "Original f1: 0.31182795698924726\n",
      "0.107731485486\n",
      "0.985480375435\n",
      "299\n",
      "0.197099538563\n",
      "Number of disagreement: 183\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8748    0.8840    0.8794      1233\n",
      "          1     0.4723    0.4507    0.4613       284\n",
      "\n",
      "avg / total     0.7995    0.8029    0.8011      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.5-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7630662020905923\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35545023696682465\n",
      "Original f1: 0.1484375\n",
      "0.137170338463\n",
      "0.986554666984\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 166\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8449    0.8650    0.8549       926\n",
      "          1     0.3750    0.3378    0.3555       222\n",
      "\n",
      "avg / total     0.7541    0.7631    0.7583      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7837837837837838\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4459459459459459\n",
      "Original f1: 0.31182795698924726\n",
      "0.138234444459\n",
      "0.990344467905\n",
      "328\n",
      "0.216216216216\n",
      "Number of disagreement: 220\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8743    0.8573    0.8657      1233\n",
      "          1     0.4286    0.4648    0.4459       284\n",
      "\n",
      "avg / total     0.7908    0.7838    0.7871      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.75-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "1.90324464776e-12\n",
      "3.72766956191e-11\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.62999668856e-12\n",
      "7.87108121736e-11\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.75-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "1.06779328773e-11\n",
      "1.77403022827e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.6973956435e-11\n",
      "1.93840693496e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.75-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "3.85341939228e-12\n",
      "1.32379662787e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "4.52808623244e-12\n",
      "1.63144608933e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.75-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7665505226480837\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.30927835051546393\n",
      "Original f1: 0.1484375\n",
      "0.106968249597\n",
      "0.97722240972\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 132\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8350    0.8855    0.8595       926\n",
      "          1     0.3614    0.2703    0.3093       222\n",
      "\n",
      "avg / total     0.7434    0.7666    0.7531      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7963085036255768\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44524236983842\n",
      "Original f1: 0.31182795698924726\n",
      "0.11554846969\n",
      "0.985480375438\n",
      "309\n",
      "0.203691496374\n",
      "Number of disagreement: 185\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8714    0.8792    0.8753      1233\n",
      "          1     0.4542    0.4366    0.4452       284\n",
      "\n",
      "avg / total     0.7933    0.7963    0.7947      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.75-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "6.42195793585e-12\n",
      "2.46631048917e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "8.54845668658e-12\n",
      "1.88051940686e-09\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.75-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3316831683168317\n",
      "Original f1: 0.1484375\n",
      "0.120211617241\n",
      "0.977222413728\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 148\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8395    0.8758    0.8573       926\n",
      "          1     0.3681    0.3018    0.3317       222\n",
      "\n",
      "avg / total     0.7484    0.7648    0.7557      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7930125247198417\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44912280701754387\n",
      "Original f1: 0.31182795698924726\n",
      "0.123733099751\n",
      "0.988402052715\n",
      "314\n",
      "0.20698747528\n",
      "Number of disagreement: 198\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8733    0.8719    0.8726      1233\n",
      "          1     0.4476    0.4507    0.4491       284\n",
      "\n",
      "avg / total     0.7936    0.7930    0.7933      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.75-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "0.000147767562182\n",
      "0.169637038012\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8365194462755439\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.3507853403141361\n",
      "Original f1: 0.31182795698924726\n",
      "0.0053385291486\n",
      "0.942344772603\n",
      "248\n",
      "0.163480553724\n",
      "Number of disagreement: 10\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8471    0.9749    0.9065      1233\n",
      "          1     0.6837    0.2359    0.3508       284\n",
      "\n",
      "avg / total     0.8165    0.8365    0.8025      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.75-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7621951219512195\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.34216867469879514\n",
      "Original f1: 0.1484375\n",
      "0.129199513498\n",
      "0.977222413959\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 159\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8419    0.8683    0.8549       926\n",
      "          1     0.3679    0.3198    0.3422       222\n",
      "\n",
      "avg / total     0.7502    0.7622    0.7557      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7857613711272248\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4444444444444444\n",
      "Original f1: 0.31182795698924726\n",
      "0.133300149274\n",
      "0.988402054348\n",
      "325\n",
      "0.214238628873\n",
      "Number of disagreement: 213\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8734    0.8613    0.8673      1233\n",
      "          1     0.4319    0.4577    0.4444       284\n",
      "\n",
      "avg / total     0.7907    0.7858    0.7881      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.75-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8222996515679443\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.26086956521739135\n",
      "Original f1: 0.1484375\n",
      "0.0141752289442\n",
      "0.974713441183\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 20\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8300    0.9806    0.8990       926\n",
      "          1     0.6667    0.1622    0.2609       222\n",
      "\n",
      "avg / total     0.7984    0.8223    0.7756      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8444297956493079\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4587155963302752\n",
      "Original f1: 0.31182795698924726\n",
      "0.0370366206501\n",
      "0.968186813448\n",
      "236\n",
      "0.155570204351\n",
      "Number of disagreement: 64\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8652    0.9578    0.9092      1233\n",
      "          1     0.6579    0.3521    0.4587       284\n",
      "\n",
      "avg / total     0.8264    0.8444    0.8248      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.75-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7639372822299652\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35011990407673865\n",
      "Original f1: 0.1484375\n",
      "0.13304275806\n",
      "0.986554666645\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 161\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8437    0.8683    0.8558       926\n",
      "          1     0.3744    0.3288    0.3501       222\n",
      "\n",
      "avg / total     0.7529    0.7639    0.7580      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7837837837837838\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4440677966101695\n",
      "Original f1: 0.31182795698924726\n",
      "0.137415223968\n",
      "0.990344468521\n",
      "328\n",
      "0.216216216216\n",
      "Number of disagreement: 218\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8737    0.8581    0.8658      1233\n",
      "          1     0.4281    0.4613    0.4441       284\n",
      "\n",
      "avg / total     0.7902    0.7838    0.7868      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.75-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8301393728222997\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.41087613293051356\n",
      "Original f1: 0.1484375\n",
      "0.0565743324347\n",
      "0.974713447959\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 75\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8518    0.9557    0.9008       926\n",
      "          1     0.6239    0.3063    0.4109       222\n",
      "\n",
      "avg / total     0.8077    0.8301    0.8060      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8239947264337508\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.47337278106508873\n",
      "Original f1: 0.31182795698924726\n",
      "0.0799822062347\n",
      "0.985480372456\n",
      "267\n",
      "0.176005273566\n",
      "Number of disagreement: 135\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8733    0.9165    0.8943      1233\n",
      "          1     0.5381    0.4225    0.4734       284\n",
      "\n",
      "avg / total     0.8105    0.8240    0.8155      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.75-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7630662020905923\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35545023696682465\n",
      "Original f1: 0.1484375\n",
      "0.136427983306\n",
      "0.986554666984\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 166\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8449    0.8650    0.8549       926\n",
      "          1     0.3750    0.3378    0.3555       222\n",
      "\n",
      "avg / total     0.7541    0.7631    0.7583      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7837837837837838\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4440677966101695\n",
      "Original f1: 0.31182795698924726\n",
      "0.138118455948\n",
      "0.990344468228\n",
      "328\n",
      "0.216216216216\n",
      "Number of disagreement: 218\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8737    0.8581    0.8658      1233\n",
      "          1     0.4281    0.4613    0.4441       284\n",
      "\n",
      "avg / total     0.7902    0.7838    0.7868      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.75-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8005226480836237\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3893333333333333\n",
      "Original f1: 0.1484375\n",
      "0.0925661831771\n",
      "0.986554665467\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 119\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8503    0.9136    0.8808       926\n",
      "          1     0.4771    0.3288    0.3893       222\n",
      "\n",
      "avg / total     0.7781    0.8005    0.7858      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8022412656558998\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.460431654676259\n",
      "Original f1: 0.31182795698924726\n",
      "0.108962168258\n",
      "0.985480374411\n",
      "300\n",
      "0.197758734344\n",
      "Number of disagreement: 184\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8747    0.8832    0.8789      1233\n",
      "          1     0.4706    0.4507    0.4604       284\n",
      "\n",
      "avg / total     0.7990    0.8022    0.8006      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.75-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7621951219512195\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35460992907801414\n",
      "Original f1: 0.1484375\n",
      "0.138236084798\n",
      "0.986554667064\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 167\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8448    0.8639    0.8542       926\n",
      "          1     0.3731    0.3378    0.3546       222\n",
      "\n",
      "avg / total     0.7536    0.7622    0.7576      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7831245880026367\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44519392917369305\n",
      "Original f1: 0.31182795698924726\n",
      "0.139585485744\n",
      "0.990344468161\n",
      "329\n",
      "0.216875411997\n",
      "Number of disagreement: 221\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8742    0.8564    0.8652      1233\n",
      "          1     0.4272    0.4648    0.4452       284\n",
      "\n",
      "avg / total     0.7905    0.7831    0.7866      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.75-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "1.86921224724e-12\n",
      "3.32002897396e-11\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.60692796756e-12\n",
      "7.87108121736e-11\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.75-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "1.57782266658e-11\n",
      "1.76932593576e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.58867822307e-11\n",
      "1.90168381042e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.75-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "3.07515254429e-12\n",
      "1.32379662787e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "4.91580655892e-12\n",
      "1.63144608933e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.75-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7674216027874564\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.31007751937984496\n",
      "Original f1: 0.1484375\n",
      "0.107015398224\n",
      "0.977222409302\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 131\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8352    0.8866    0.8601       926\n",
      "          1     0.3636    0.2703    0.3101       222\n",
      "\n",
      "avg / total     0.7440    0.7674    0.7538      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7956493078444298\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4444444444444444\n",
      "Original f1: 0.31182795698924726\n",
      "0.116093776343\n",
      "0.985480375683\n",
      "310\n",
      "0.204350692156\n",
      "Number of disagreement: 186\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8713    0.8783    0.8748      1233\n",
      "          1     0.4526    0.4366    0.4444       284\n",
      "\n",
      "avg / total     0.7929    0.7956    0.7942      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.75-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "5.20715730594e-12\n",
      "2.46631048917e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "7.6057993939e-12\n",
      "1.88051940686e-09\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.75-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7656794425087108\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3325062034739454\n",
      "Original f1: 0.1484375\n",
      "0.120364067262\n",
      "0.977222413765\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 147\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8397    0.8769    0.8579       926\n",
      "          1     0.3702    0.3018    0.3325       222\n",
      "\n",
      "avg / total     0.7489    0.7657    0.7563      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7930125247198417\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44912280701754387\n",
      "Original f1: 0.31182795698924726\n",
      "0.124224359536\n",
      "0.988402054472\n",
      "314\n",
      "0.20698747528\n",
      "Number of disagreement: 198\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8733    0.8719    0.8726      1233\n",
      "          1     0.4476    0.4507    0.4491       284\n",
      "\n",
      "avg / total     0.7936    0.7930    0.7933      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.75-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "0.000115447684684\n",
      "0.132533887137\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8365194462755439\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.3507853403141361\n",
      "Original f1: 0.31182795698924726\n",
      "0.00521726148323\n",
      "0.942344773729\n",
      "248\n",
      "0.163480553724\n",
      "Number of disagreement: 10\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8471    0.9749    0.9065      1233\n",
      "          1     0.6837    0.2359    0.3508       284\n",
      "\n",
      "avg / total     0.8165    0.8365    0.8025      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.75-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7630662020905923\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.34299516908212563\n",
      "Original f1: 0.1484375\n",
      "0.12950722819\n",
      "0.977222413817\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 158\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8421    0.8693    0.8555       926\n",
      "          1     0.3698    0.3198    0.3430       222\n",
      "\n",
      "avg / total     0.7507    0.7631    0.7564      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7851021753460777\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4436860068259385\n",
      "Original f1: 0.31182795698924726\n",
      "0.133864525178\n",
      "0.988402054534\n",
      "326\n",
      "0.214897824654\n",
      "Number of disagreement: 214\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8733    0.8605    0.8668      1233\n",
      "          1     0.4305    0.4577    0.4437       284\n",
      "\n",
      "avg / total     0.7904    0.7851    0.7876      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.75-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8222996515679443\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.26086956521739135\n",
      "Original f1: 0.1484375\n",
      "0.0141392829235\n",
      "0.974713444994\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 20\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8300    0.9806    0.8990       926\n",
      "          1     0.6667    0.1622    0.2609       222\n",
      "\n",
      "avg / total     0.7984    0.8223    0.7756      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8437705998681608\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.45517241379310347\n",
      "Original f1: 0.31182795698924726\n",
      "0.0362997654159\n",
      "0.968187414085\n",
      "237\n",
      "0.156229400132\n",
      "Number of disagreement: 63\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8646    0.9578    0.9088      1233\n",
      "          1     0.6556    0.3486    0.4552       284\n",
      "\n",
      "avg / total     0.8255    0.8438    0.8239      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.75-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3509615384615385\n",
      "Original f1: 0.1484375\n",
      "0.133364428153\n",
      "0.986554666611\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 160\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8438    0.8693    0.8564       926\n",
      "          1     0.3763    0.3288    0.3510       222\n",
      "\n",
      "avg / total     0.7534    0.7648    0.7586      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7831245880026367\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4433164128595601\n",
      "Original f1: 0.31182795698924726\n",
      "0.137989788318\n",
      "0.990344468531\n",
      "329\n",
      "0.216875411997\n",
      "Number of disagreement: 219\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8736    0.8573    0.8653      1233\n",
      "          1     0.4267    0.4613    0.4433       284\n",
      "\n",
      "avg / total     0.7899    0.7831    0.7863      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.75-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8310104529616724\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.4121212121212121\n",
      "Original f1: 0.1484375\n",
      "0.0564640360265\n",
      "0.974713448163\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 74\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8519    0.9568    0.9013       926\n",
      "          1     0.6296    0.3063    0.4121       222\n",
      "\n",
      "avg / total     0.8089    0.8310    0.8067      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8246539222148979\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4763779527559055\n",
      "Original f1: 0.31182795698924726\n",
      "0.0802171154674\n",
      "0.98548037018\n",
      "266\n",
      "0.175346077785\n",
      "Number of disagreement: 136\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8739    0.9165    0.8947      1233\n",
      "          1     0.5402    0.4261    0.4764       284\n",
      "\n",
      "avg / total     0.8115    0.8247    0.8164      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.75-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7639372822299652\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3562945368171021\n",
      "Original f1: 0.1484375\n",
      "0.136642345796\n",
      "0.986554666955\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 165\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8451    0.8661    0.8555       926\n",
      "          1     0.3769    0.3378    0.3563       222\n",
      "\n",
      "avg / total     0.7546    0.7639    0.7589      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7831245880026367\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4433164128595601\n",
      "Original f1: 0.31182795698924726\n",
      "0.13866682973\n",
      "0.990344467974\n",
      "329\n",
      "0.216875411997\n",
      "Number of disagreement: 219\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8736    0.8573    0.8653      1233\n",
      "          1     0.4267    0.4613    0.4433       284\n",
      "\n",
      "avg / total     0.7899    0.7831    0.7863      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.75-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7987804878048781\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3872679045092839\n",
      "Original f1: 0.1484375\n",
      "0.0931472605457\n",
      "0.986554659715\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 121\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8499    0.9114    0.8796       926\n",
      "          1     0.4710    0.3288    0.3873       222\n",
      "\n",
      "avg / total     0.7767    0.7988    0.7844      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8022412656558998\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.460431654676259\n",
      "Original f1: 0.31182795698924726\n",
      "0.109069620241\n",
      "0.985480375679\n",
      "300\n",
      "0.197758734344\n",
      "Number of disagreement: 184\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8747    0.8832    0.8789      1233\n",
      "          1     0.4706    0.4507    0.4604       284\n",
      "\n",
      "avg / total     0.7990    0.8022    0.8006      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-0.75-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7630662020905923\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35545023696682465\n",
      "Original f1: 0.1484375\n",
      "0.138514344922\n",
      "0.986554667064\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 166\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8449    0.8650    0.8549       926\n",
      "          1     0.3750    0.3378    0.3555       222\n",
      "\n",
      "avg / total     0.7541    0.7631    0.7583      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7824653922214898\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44444444444444436\n",
      "Original f1: 0.31182795698924726\n",
      "0.14014672576\n",
      "0.990344467954\n",
      "330\n",
      "0.217534607779\n",
      "Number of disagreement: 222\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8741    0.8556    0.8648      1233\n",
      "          1     0.4258    0.4648    0.4444       284\n",
      "\n",
      "avg / total     0.7901    0.7825    0.7861      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.0-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "1.89542757276e-12\n",
      "4.11456771432e-11\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.58017685058e-12\n",
      "7.8710815643e-11\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.0-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "1.53962401e-11\n",
      "1.60191943044e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.85833499341e-11\n",
      "2.48529037628e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.0-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "3.62881855444e-12\n",
      "1.31984756457e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "3.82380675181e-12\n",
      "1.35097266707e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.0-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7656794425087108\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.30848329048843187\n",
      "Original f1: 0.1484375\n",
      "0.108140065704\n",
      "0.977222411703\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 133\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8349    0.8844    0.8589       926\n",
      "          1     0.3593    0.2703    0.3085       222\n",
      "\n",
      "avg / total     0.7429    0.7657    0.7525      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7969676994067239\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44604316546762585\n",
      "Original f1: 0.31182795698924726\n",
      "0.116301762037\n",
      "0.985480375672\n",
      "308\n",
      "0.203032300593\n",
      "Number of disagreement: 184\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8715    0.8800    0.8757      1233\n",
      "          1     0.4559    0.4366    0.4460       284\n",
      "\n",
      "avg / total     0.7937    0.7970    0.7953      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.0-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "4.65150234465e-12\n",
      "2.45833131629e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "9.86814959839e-12\n",
      "1.41321476743e-09\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.0-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7639372822299652\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.33086419753086427\n",
      "Original f1: 0.1484375\n",
      "0.121285189962\n",
      "0.977222413776\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 149\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8394    0.8747    0.8567       926\n",
      "          1     0.3661    0.3018    0.3309       222\n",
      "\n",
      "avg / total     0.7479    0.7639    0.7550      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7936717205009888\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4499121265377856\n",
      "Original f1: 0.31182795698924726\n",
      "0.124488281972\n",
      "0.988402054599\n",
      "313\n",
      "0.206328279499\n",
      "Number of disagreement: 197\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8734    0.8727    0.8730      1233\n",
      "          1     0.4491    0.4507    0.4499       284\n",
      "\n",
      "avg / total     0.7940    0.7937    0.7938      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.0-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "0.000149951911926\n",
      "0.17214465363\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8365194462755439\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.3507853403141361\n",
      "Original f1: 0.31182795698924726\n",
      "0.0052524992606\n",
      "0.942344772448\n",
      "248\n",
      "0.163480553724\n",
      "Number of disagreement: 10\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8471    0.9749    0.9065      1233\n",
      "          1     0.6837    0.2359    0.3508       284\n",
      "\n",
      "avg / total     0.8165    0.8365    0.8025      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.0-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7621951219512195\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.34216867469879514\n",
      "Original f1: 0.1484375\n",
      "0.130331383668\n",
      "0.977222413856\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 159\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8419    0.8683    0.8549       926\n",
      "          1     0.3679    0.3198    0.3422       222\n",
      "\n",
      "avg / total     0.7502    0.7622    0.7557      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7857613711272248\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4444444444444444\n",
      "Original f1: 0.31182795698924726\n",
      "0.13408613552\n",
      "0.988402054772\n",
      "325\n",
      "0.214238628873\n",
      "Number of disagreement: 213\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8734    0.8613    0.8673      1233\n",
      "          1     0.4319    0.4577    0.4444       284\n",
      "\n",
      "avg / total     0.7907    0.7858    0.7881      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.0-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8205574912891986\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.24817518248175183\n",
      "Original f1: 0.1484375\n",
      "0.0139344692495\n",
      "0.974713443702\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 18\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8285    0.9806    0.8981       926\n",
      "          1     0.6538    0.1532    0.2482       222\n",
      "\n",
      "avg / total     0.7947    0.8206    0.7724      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8450889914304548\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.46224256292906185\n",
      "Original f1: 0.31182795698924726\n",
      "0.0368508797614\n",
      "0.968187425884\n",
      "235\n",
      "0.15491100857\n",
      "Number of disagreement: 65\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8658    0.9578    0.9095      1233\n",
      "          1     0.6601    0.3556    0.4622       284\n",
      "\n",
      "avg / total     0.8273    0.8451    0.8258      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.0-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7639372822299652\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35011990407673865\n",
      "Original f1: 0.1484375\n",
      "0.134153097264\n",
      "0.986554666552\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 161\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8437    0.8683    0.8558       926\n",
      "          1     0.3744    0.3288    0.3501       222\n",
      "\n",
      "avg / total     0.7529    0.7639    0.7580      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7844429795649308\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4448217317487267\n",
      "Original f1: 0.31182795698924726\n",
      "0.138199953987\n",
      "0.990344466409\n",
      "327\n",
      "0.215557020435\n",
      "Number of disagreement: 217\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8738    0.8589    0.8663      1233\n",
      "          1     0.4295    0.4613    0.4448       284\n",
      "\n",
      "avg / total     0.7906    0.7844    0.7874      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.0-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8301393728222997\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.41087613293051356\n",
      "Original f1: 0.1484375\n",
      "0.0567166293899\n",
      "0.974713447443\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 75\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8518    0.9557    0.9008       926\n",
      "          1     0.6239    0.3063    0.4109       222\n",
      "\n",
      "avg / total     0.8077    0.8301    0.8060      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8226763348714569\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4715127701375246\n",
      "Original f1: 0.31182795698924726\n",
      "0.0811157643478\n",
      "0.985480372202\n",
      "269\n",
      "0.177323665129\n",
      "Number of disagreement: 137\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8731    0.9148    0.8935      1233\n",
      "          1     0.5333    0.4225    0.4715       284\n",
      "\n",
      "avg / total     0.8095    0.8227    0.8145      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.0-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7630662020905923\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35545023696682465\n",
      "Original f1: 0.1484375\n",
      "0.137418891049\n",
      "0.986554667063\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 166\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8449    0.8650    0.8549       926\n",
      "          1     0.3750    0.3378    0.3555       222\n",
      "\n",
      "avg / total     0.7541    0.7631    0.7583      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7844429795649308\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4448217317487267\n",
      "Original f1: 0.31182795698924726\n",
      "0.138823288489\n",
      "0.990344467687\n",
      "327\n",
      "0.215557020435\n",
      "Number of disagreement: 217\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8738    0.8589    0.8663      1233\n",
      "          1     0.4295    0.4613    0.4448       284\n",
      "\n",
      "avg / total     0.7906    0.7844    0.7874      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.0-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7970383275261324\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.38522427440633245\n",
      "Original f1: 0.1484375\n",
      "0.0933459094951\n",
      "0.986554661273\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 123\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8496    0.9093    0.8785       926\n",
      "          1     0.4650    0.3288    0.3852       222\n",
      "\n",
      "avg / total     0.7753    0.7970    0.7831      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8022412656558998\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.460431654676259\n",
      "Original f1: 0.31182795698924726\n",
      "0.109572229393\n",
      "0.985480374738\n",
      "300\n",
      "0.197758734344\n",
      "Number of disagreement: 184\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8747    0.8832    0.8789      1233\n",
      "          1     0.4706    0.4507    0.4604       284\n",
      "\n",
      "avg / total     0.7990    0.8022    0.8006      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.0-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7621951219512195\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35460992907801414\n",
      "Original f1: 0.1484375\n",
      "0.139356354233\n",
      "0.986554667066\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 167\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8448    0.8639    0.8542       926\n",
      "          1     0.3731    0.3378    0.3546       222\n",
      "\n",
      "avg / total     0.7536    0.7622    0.7576      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7837837837837838\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4459459459459459\n",
      "Original f1: 0.31182795698924726\n",
      "0.14037724656\n",
      "0.990344468482\n",
      "328\n",
      "0.216216216216\n",
      "Number of disagreement: 220\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8743    0.8573    0.8657      1233\n",
      "          1     0.4286    0.4648    0.4459       284\n",
      "\n",
      "avg / total     0.7908    0.7838    0.7871      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.0-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "2.06591565652e-12\n",
      "3.60239407748e-11\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.69417523755e-12\n",
      "7.8710815643e-11\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.0-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "1.61057397653e-11\n",
      "1.52844570334e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.29368599544e-11\n",
      "1.41521031005e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.0-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "3.30733974343e-12\n",
      "1.35102318222e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "3.7659954716e-12\n",
      "1.35097266707e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.0-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7665505226480837\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.30927835051546393\n",
      "Original f1: 0.1484375\n",
      "0.108386524678\n",
      "0.977222410375\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 132\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8350    0.8855    0.8595       926\n",
      "          1     0.3614    0.2703    0.3093       222\n",
      "\n",
      "avg / total     0.7434    0.7666    0.7531      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7956493078444298\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4444444444444444\n",
      "Original f1: 0.31182795698924726\n",
      "0.117025755133\n",
      "0.985480375536\n",
      "310\n",
      "0.204350692156\n",
      "Number of disagreement: 186\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8713    0.8783    0.8748      1233\n",
      "          1     0.4526    0.4366    0.4444       284\n",
      "\n",
      "avg / total     0.7929    0.7956    0.7942      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.0-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "4.67999572325e-12\n",
      "2.45833131629e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.21517296987e-11\n",
      "1.41321476743e-09\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.0-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7656794425087108\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3325062034739454\n",
      "Original f1: 0.1484375\n",
      "0.121466230183\n",
      "0.977222414118\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 147\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8397    0.8769    0.8579       926\n",
      "          1     0.3702    0.3018    0.3325       222\n",
      "\n",
      "avg / total     0.7489    0.7657    0.7563      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7923533289386948\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4483362521891419\n",
      "Original f1: 0.31182795698924726\n",
      "0.125220120785\n",
      "0.988402054319\n",
      "315\n",
      "0.207646671061\n",
      "Number of disagreement: 199\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8732    0.8710    0.8721      1233\n",
      "          1     0.4460    0.4507    0.4483       284\n",
      "\n",
      "avg / total     0.7932    0.7924    0.7928      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.0-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "0.000104703311502\n",
      "0.120079032605\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8365194462755439\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.3507853403141361\n",
      "Original f1: 0.31182795698924726\n",
      "0.00513058900451\n",
      "0.942344768796\n",
      "248\n",
      "0.163480553724\n",
      "Number of disagreement: 10\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8471    0.9749    0.9065      1233\n",
      "          1     0.6837    0.2359    0.3508       284\n",
      "\n",
      "avg / total     0.8165    0.8365    0.8025      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.0-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7630662020905923\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.34299516908212563\n",
      "Original f1: 0.1484375\n",
      "0.130772803525\n",
      "0.986554403005\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 158\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8421    0.8693    0.8555       926\n",
      "          1     0.3698    0.3198    0.3430       222\n",
      "\n",
      "avg / total     0.7507    0.7631    0.7564      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7844429795649308\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44293015332197616\n",
      "Original f1: 0.31182795698924726\n",
      "0.134841851001\n",
      "0.988402054811\n",
      "327\n",
      "0.215557020435\n",
      "Number of disagreement: 215\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8731    0.8597    0.8664      1233\n",
      "          1     0.4290    0.4577    0.4429       284\n",
      "\n",
      "avg / total     0.7900    0.7844    0.7871      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.0-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8205574912891986\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.24817518248175183\n",
      "Original f1: 0.1484375\n",
      "0.0139480515678\n",
      "0.974713438989\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 18\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8285    0.9806    0.8981       926\n",
      "          1     0.6538    0.1532    0.2482       222\n",
      "\n",
      "avg / total     0.7947    0.8206    0.7724      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8437705998681608\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.45517241379310347\n",
      "Original f1: 0.31182795698924726\n",
      "0.0358043057032\n",
      "0.968187444788\n",
      "237\n",
      "0.156229400132\n",
      "Number of disagreement: 63\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8646    0.9578    0.9088      1233\n",
      "          1     0.6556    0.3486    0.4552       284\n",
      "\n",
      "avg / total     0.8255    0.8438    0.8239      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.0-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3509615384615385\n",
      "Original f1: 0.1484375\n",
      "0.134624874043\n",
      "0.986554666501\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 160\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8438    0.8693    0.8564       926\n",
      "          1     0.3763    0.3288    0.3510       222\n",
      "\n",
      "avg / total     0.7534    0.7648    0.7586      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7837837837837838\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4459459459459459\n",
      "Original f1: 0.31182795698924726\n",
      "0.138972366581\n",
      "0.990344466907\n",
      "328\n",
      "0.216216216216\n",
      "Number of disagreement: 220\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8743    0.8573    0.8657      1233\n",
      "          1     0.4286    0.4648    0.4459       284\n",
      "\n",
      "avg / total     0.7908    0.7838    0.7871      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.0-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8310104529616724\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.4121212121212121\n",
      "Original f1: 0.1484375\n",
      "0.0565049587934\n",
      "0.974713448116\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 74\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8519    0.9568    0.9013       926\n",
      "          1     0.6296    0.3063    0.4121       222\n",
      "\n",
      "avg / total     0.8089    0.8310    0.8067      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8226763348714569\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4735812133072407\n",
      "Original f1: 0.31182795698924726\n",
      "0.081328378348\n",
      "0.985480375519\n",
      "269\n",
      "0.177323665129\n",
      "Number of disagreement: 139\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8736    0.9140    0.8934      1233\n",
      "          1     0.5330    0.4261    0.4736       284\n",
      "\n",
      "avg / total     0.8099    0.8227    0.8148      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.0-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3571428571428571\n",
      "Original f1: 0.1484375\n",
      "0.137794377904\n",
      "0.986554667064\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 164\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8453    0.8672    0.8561       926\n",
      "          1     0.3788    0.3378    0.3571       222\n",
      "\n",
      "avg / total     0.7551    0.7648    0.7596      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7837837837837838\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4459459459459459\n",
      "Original f1: 0.31182795698924726\n",
      "0.139561755771\n",
      "0.990344468276\n",
      "328\n",
      "0.216216216216\n",
      "Number of disagreement: 220\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8743    0.8573    0.8657      1233\n",
      "          1     0.4286    0.4648    0.4459       284\n",
      "\n",
      "avg / total     0.7908    0.7838    0.7871      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.0-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7970383275261324\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.38522427440633245\n",
      "Original f1: 0.1484375\n",
      "0.0938276161347\n",
      "0.986554659797\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 123\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8496    0.9093    0.8785       926\n",
      "          1     0.4650    0.3288    0.3852       222\n",
      "\n",
      "avg / total     0.7753    0.7970    0.7831      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8029004614370469\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.46126126126126127\n",
      "Original f1: 0.31182795698924726\n",
      "0.109720795824\n",
      "0.985480374829\n",
      "299\n",
      "0.197099538563\n",
      "Number of disagreement: 183\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8748    0.8840    0.8794      1233\n",
      "          1     0.4723    0.4507    0.4613       284\n",
      "\n",
      "avg / total     0.7995    0.8029    0.8011      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.0-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7630662020905923\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35545023696682465\n",
      "Original f1: 0.1484375\n",
      "0.139783788837\n",
      "0.98655466639\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 166\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8449    0.8650    0.8549       926\n",
      "          1     0.3750    0.3378    0.3555       222\n",
      "\n",
      "avg / total     0.7541    0.7631    0.7583      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7831245880026367\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4470588235294118\n",
      "Original f1: 0.31182795698924726\n",
      "0.141124199581\n",
      "0.99034446847\n",
      "329\n",
      "0.216875411997\n",
      "Number of disagreement: 223\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8748    0.8556    0.8651      1233\n",
      "          1     0.4277    0.4683    0.4471       284\n",
      "\n",
      "avg / total     0.7911    0.7831    0.7868      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.5-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "1.87639561022e-12\n",
      "4.60705119887e-11\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.73525847179e-12\n",
      "7.87108121736e-11\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.5-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "2.27736655511e-11\n",
      "1.76974553068e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.62637244343e-11\n",
      "1.51872750487e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.5-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "2.99877078834e-12\n",
      "1.25583266009e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "3.2394733537e-12\n",
      "1.11215064935e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.5-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7656794425087108\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.30848329048843187\n",
      "Original f1: 0.1484375\n",
      "0.109338064598\n",
      "0.977222414017\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 133\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8349    0.8844    0.8589       926\n",
      "          1     0.3593    0.2703    0.3085       222\n",
      "\n",
      "avg / total     0.7429    0.7657    0.7525      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7969676994067239\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44604316546762585\n",
      "Original f1: 0.31182795698924726\n",
      "0.116996746419\n",
      "0.98548037551\n",
      "308\n",
      "0.203032300593\n",
      "Number of disagreement: 184\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8715    0.8800    0.8757      1233\n",
      "          1     0.4559    0.4366    0.4460       284\n",
      "\n",
      "avg / total     0.7937    0.7970    0.7953      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.5-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "4.38631908059e-12\n",
      "2.29888108549e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "8.20694717506e-12\n",
      "4.35185276704e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.5-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7639372822299652\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.33086419753086427\n",
      "Original f1: 0.1484375\n",
      "0.122451595943\n",
      "0.977222413825\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 149\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8394    0.8747    0.8567       926\n",
      "          1     0.3661    0.3018    0.3309       222\n",
      "\n",
      "avg / total     0.7479    0.7639    0.7550      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7936717205009888\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4499121265377856\n",
      "Original f1: 0.31182795698924726\n",
      "0.125344062512\n",
      "0.988402054565\n",
      "313\n",
      "0.206328279499\n",
      "Number of disagreement: 197\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8734    0.8727    0.8730      1233\n",
      "          1     0.4491    0.4507    0.4499       284\n",
      "\n",
      "avg / total     0.7940    0.7937    0.7938      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.5-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "0.000150526428088\n",
      "0.172804259095\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8365194462755439\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.3507853403141361\n",
      "Original f1: 0.31182795698924726\n",
      "0.00519867712316\n",
      "0.942344766674\n",
      "248\n",
      "0.163480553724\n",
      "Number of disagreement: 10\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8471    0.9749    0.9065      1233\n",
      "          1     0.6837    0.2359    0.3508       284\n",
      "\n",
      "avg / total     0.8165    0.8365    0.8025      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.5-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7621951219512195\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.34216867469879514\n",
      "Original f1: 0.1484375\n",
      "0.131527123145\n",
      "0.986554644692\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 159\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8419    0.8683    0.8549       926\n",
      "          1     0.3679    0.3198    0.3422       222\n",
      "\n",
      "avg / total     0.7502    0.7622    0.7557      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7857613711272248\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4444444444444444\n",
      "Original f1: 0.31182795698924726\n",
      "0.134819284516\n",
      "0.98840205472\n",
      "325\n",
      "0.214238628873\n",
      "Number of disagreement: 213\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8734    0.8613    0.8673      1233\n",
      "          1     0.4319    0.4577    0.4444       284\n",
      "\n",
      "avg / total     0.7907    0.7858    0.7881      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.5-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8205574912891986\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.24817518248175183\n",
      "Original f1: 0.1484375\n",
      "0.0137250422455\n",
      "0.974713426616\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 18\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8285    0.9806    0.8981       926\n",
      "          1     0.6538    0.1532    0.2482       222\n",
      "\n",
      "avg / total     0.7947    0.8206    0.7724      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8444297956493079\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.456221198156682\n",
      "Original f1: 0.31182795698924726\n",
      "0.0365554282857\n",
      "0.968187441327\n",
      "236\n",
      "0.155570204351\n",
      "Number of disagreement: 62\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8647    0.9586    0.9092      1233\n",
      "          1     0.6600    0.3486    0.4562       284\n",
      "\n",
      "avg / total     0.8264    0.8444    0.8244      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.5-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7639372822299652\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35011990407673865\n",
      "Original f1: 0.1484375\n",
      "0.135383227489\n",
      "0.986554666757\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 161\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8437    0.8683    0.8558       926\n",
      "          1     0.3744    0.3288    0.3501       222\n",
      "\n",
      "avg / total     0.7529    0.7639    0.7580      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7844429795649308\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4448217317487267\n",
      "Original f1: 0.31182795698924726\n",
      "0.138962603646\n",
      "0.99034446713\n",
      "327\n",
      "0.215557020435\n",
      "Number of disagreement: 217\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8738    0.8589    0.8663      1233\n",
      "          1     0.4295    0.4613    0.4448       284\n",
      "\n",
      "avg / total     0.7906    0.7844    0.7874      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.5-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8301393728222997\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.41087613293051356\n",
      "Original f1: 0.1484375\n",
      "0.0566827255756\n",
      "0.974713447577\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 75\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8518    0.9557    0.9008       926\n",
      "          1     0.6239    0.3063    0.4109       222\n",
      "\n",
      "avg / total     0.8077    0.8301    0.8060      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8226763348714569\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4715127701375246\n",
      "Original f1: 0.31182795698924726\n",
      "0.0818853088401\n",
      "0.985480369686\n",
      "269\n",
      "0.177323665129\n",
      "Number of disagreement: 137\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8731    0.9148    0.8935      1233\n",
      "          1     0.5333    0.4225    0.4715       284\n",
      "\n",
      "avg / total     0.8095    0.8227    0.8145      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.5-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7639372822299652\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3562945368171021\n",
      "Original f1: 0.1484375\n",
      "0.138589840012\n",
      "0.986554667062\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 165\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8451    0.8661    0.8555       926\n",
      "          1     0.3769    0.3378    0.3563       222\n",
      "\n",
      "avg / total     0.7546    0.7639    0.7589      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7844429795649308\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4448217317487267\n",
      "Original f1: 0.31182795698924726\n",
      "0.139507734724\n",
      "0.990344467945\n",
      "327\n",
      "0.215557020435\n",
      "Number of disagreement: 217\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8738    0.8589    0.8663      1233\n",
      "          1     0.4295    0.4613    0.4448       284\n",
      "\n",
      "avg / total     0.7906    0.7844    0.7874      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.5-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7961672473867596\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3842105263157895\n",
      "Original f1: 0.1484375\n",
      "0.0939611474639\n",
      "0.986554657115\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 124\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8495    0.9082    0.8779       926\n",
      "          1     0.4620    0.3288    0.3842       222\n",
      "\n",
      "avg / total     0.7746    0.7962    0.7824      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8022412656558998\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.460431654676259\n",
      "Original f1: 0.31182795698924726\n",
      "0.109523629814\n",
      "0.985480374696\n",
      "300\n",
      "0.197758734344\n",
      "Number of disagreement: 184\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8747    0.8832    0.8789      1233\n",
      "          1     0.4706    0.4507    0.4604       284\n",
      "\n",
      "avg / total     0.7990    0.8022    0.8006      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.5-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7621951219512195\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35460992907801414\n",
      "Original f1: 0.1484375\n",
      "0.140585809969\n",
      "0.986554666448\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 167\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8448    0.8639    0.8542       926\n",
      "          1     0.3731    0.3378    0.3546       222\n",
      "\n",
      "avg / total     0.7536    0.7622    0.7576      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7837837837837838\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4459459459459459\n",
      "Original f1: 0.31182795698924726\n",
      "0.141145432469\n",
      "0.990344467984\n",
      "328\n",
      "0.216216216216\n",
      "Number of disagreement: 220\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8743    0.8573    0.8657      1233\n",
      "          1     0.4286    0.4648    0.4459       284\n",
      "\n",
      "avg / total     0.7908    0.7838    0.7871      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.5-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "1.95489418364e-12\n",
      "4.40459613227e-11\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.75102493663e-12\n",
      "7.87108121736e-11\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.5-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "2.0958295568e-11\n",
      "1.6059509278e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.40763021627e-11\n",
      "1.75184353135e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.5-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "2.97008937207e-12\n",
      "1.24218524356e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "3.21457516268e-12\n",
      "9.0363161398e-11\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.5-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7656794425087108\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.30848329048843187\n",
      "Original f1: 0.1484375\n",
      "0.109757667503\n",
      "0.977222410891\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 133\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8349    0.8844    0.8589       926\n",
      "          1     0.3593    0.2703    0.3085       222\n",
      "\n",
      "avg / total     0.7429    0.7657    0.7525      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7963085036255768\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44524236983842\n",
      "Original f1: 0.31182795698924726\n",
      "0.117883502071\n",
      "0.985480375377\n",
      "309\n",
      "0.203691496374\n",
      "Number of disagreement: 185\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8714    0.8792    0.8753      1233\n",
      "          1     0.4542    0.4366    0.4452       284\n",
      "\n",
      "avg / total     0.7933    0.7963    0.7947      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.5-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "4.73651937273e-12\n",
      "2.29888108549e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "8.82413885676e-12\n",
      "4.35185276704e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.5-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3316831683168317\n",
      "Original f1: 0.1484375\n",
      "0.12269290692\n",
      "0.977222413877\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 148\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8395    0.8758    0.8573       926\n",
      "          1     0.3681    0.3018    0.3317       222\n",
      "\n",
      "avg / total     0.7484    0.7648    0.7557      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7930125247198417\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44912280701754387\n",
      "Original f1: 0.31182795698924726\n",
      "0.126300429958\n",
      "0.988402054744\n",
      "314\n",
      "0.20698747528\n",
      "Number of disagreement: 198\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8733    0.8719    0.8726      1233\n",
      "          1     0.4476    0.4507    0.4491       284\n",
      "\n",
      "avg / total     0.7936    0.7930    0.7933      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.5-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "9.39099313945e-05\n",
      "0.107477484678\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8358602504943968\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.3464566929133858\n",
      "Original f1: 0.31182795698924726\n",
      "0.00505054734804\n",
      "0.942344747299\n",
      "249\n",
      "0.164139749506\n",
      "Number of disagreement: 9\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8465    0.9749    0.9061      1233\n",
      "          1     0.6804    0.2324    0.3465       284\n",
      "\n",
      "avg / total     0.8154    0.8359    0.8014      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.5-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7621951219512195\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.34216867469879514\n",
      "Original f1: 0.1484375\n",
      "0.132101711151\n",
      "0.986554662867\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 159\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8419    0.8683    0.8549       926\n",
      "          1     0.3679    0.3198    0.3422       222\n",
      "\n",
      "avg / total     0.7502    0.7622    0.7557      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7857613711272248\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4463373083475298\n",
      "Original f1: 0.31182795698924726\n",
      "0.135689997188\n",
      "0.98840205486\n",
      "325\n",
      "0.214238628873\n",
      "Number of disagreement: 215\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8740    0.8605    0.8672      1233\n",
      "          1     0.4323    0.4613    0.4463       284\n",
      "\n",
      "avg / total     0.7913    0.7858    0.7884      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.5-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8205574912891986\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.24817518248175183\n",
      "Original f1: 0.1484375\n",
      "0.0136194177137\n",
      "0.97471344457\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 18\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8285    0.9806    0.8981       926\n",
      "          1     0.6538    0.1532    0.2482       222\n",
      "\n",
      "avg / total     0.7947    0.8206    0.7724      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8437705998681608\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.45011600928074247\n",
      "Original f1: 0.31182795698924726\n",
      "0.0353509792699\n",
      "0.968187445265\n",
      "237\n",
      "0.156229400132\n",
      "Number of disagreement: 59\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8635    0.9594    0.9090      1233\n",
      "          1     0.6599    0.3415    0.4501       284\n",
      "\n",
      "avg / total     0.8254    0.8438    0.8231      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.5-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7639372822299652\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35011990407673865\n",
      "Original f1: 0.1484375\n",
      "0.13602197487\n",
      "0.986554666879\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 161\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8437    0.8683    0.8558       926\n",
      "          1     0.3744    0.3288    0.3501       222\n",
      "\n",
      "avg / total     0.7529    0.7639    0.7580      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7844429795649308\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4467005076142132\n",
      "Original f1: 0.31182795698924726\n",
      "0.13984457253\n",
      "0.990344468413\n",
      "327\n",
      "0.215557020435\n",
      "Number of disagreement: 219\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8744    0.8581    0.8661      1233\n",
      "          1     0.4300    0.4648    0.4467       284\n",
      "\n",
      "avg / total     0.7912    0.7844    0.7876      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.5-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8318815331010453\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.41337386018237077\n",
      "Original f1: 0.1484375\n",
      "0.0564622797623\n",
      "0.974713447039\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 73\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8521    0.9579    0.9019       926\n",
      "          1     0.6355    0.3063    0.4134       222\n",
      "\n",
      "avg / total     0.8102    0.8319    0.8074      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8226763348714569\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4735812133072407\n",
      "Original f1: 0.31182795698924726\n",
      "0.0820099389417\n",
      "0.985480374752\n",
      "269\n",
      "0.177323665129\n",
      "Number of disagreement: 139\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8736    0.9140    0.8934      1233\n",
      "          1     0.5330    0.4261    0.4736       284\n",
      "\n",
      "avg / total     0.8099    0.8227    0.8148      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.5-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3571428571428571\n",
      "Original f1: 0.1484375\n",
      "0.139167071736\n",
      "0.986554666167\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 164\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8453    0.8672    0.8561       926\n",
      "          1     0.3788    0.3378    0.3571       222\n",
      "\n",
      "avg / total     0.7551    0.7648    0.7596      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7844429795649308\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4467005076142132\n",
      "Original f1: 0.31182795698924726\n",
      "0.140368174211\n",
      "0.990344467344\n",
      "327\n",
      "0.215557020435\n",
      "Number of disagreement: 219\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8744    0.8581    0.8661      1233\n",
      "          1     0.4300    0.4648    0.4467       284\n",
      "\n",
      "avg / total     0.7912    0.7844    0.7876      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.5-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7961672473867596\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3842105263157895\n",
      "Original f1: 0.1484375\n",
      "0.0943619535974\n",
      "0.986554661904\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 124\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8495    0.9082    0.8779       926\n",
      "          1     0.4620    0.3288    0.3842       222\n",
      "\n",
      "avg / total     0.7746    0.7962    0.7824      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8022412656558998\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.460431654676259\n",
      "Original f1: 0.31182795698924726\n",
      "0.109781747517\n",
      "0.985480375851\n",
      "300\n",
      "0.197758734344\n",
      "Number of disagreement: 184\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8747    0.8832    0.8789      1233\n",
      "          1     0.4706    0.4507    0.4604       284\n",
      "\n",
      "avg / total     0.7990    0.8022    0.8006      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-1.5-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7621951219512195\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35460992907801414\n",
      "Original f1: 0.1484375\n",
      "0.141179000602\n",
      "0.986554666548\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 167\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8448    0.8639    0.8542       926\n",
      "          1     0.3731    0.3378    0.3546       222\n",
      "\n",
      "avg / total     0.7536    0.7622    0.7576      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7837837837837838\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4478114478114478\n",
      "Original f1: 0.31182795698924726\n",
      "0.142013225235\n",
      "0.990344468536\n",
      "328\n",
      "0.216216216216\n",
      "Number of disagreement: 222\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8749    0.8564    0.8656      1233\n",
      "          1     0.4290    0.4683    0.4478       284\n",
      "\n",
      "avg / total     0.7914    0.7838    0.7874      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-2.0-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "1.82030503113e-12\n",
      "4.12829319341e-11\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.85826521258e-12\n",
      "7.8710815643e-11\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-2.0-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "2.5097695738e-11\n",
      "1.88099195941e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.4258596104e-11\n",
      "2.61378696464e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-2.0-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "2.84573594334e-12\n",
      "1.2592760168e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "3.32582972826e-12\n",
      "7.8710815643e-11\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-2.0-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7656794425087108\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.30848329048843187\n",
      "Original f1: 0.1484375\n",
      "0.109808655931\n",
      "0.977222413963\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 133\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8349    0.8844    0.8589       926\n",
      "          1     0.3593    0.2703    0.3085       222\n",
      "\n",
      "avg / total     0.7429    0.7657    0.7525      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7963085036255768\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44524236983842\n",
      "Original f1: 0.31182795698924726\n",
      "0.117241276101\n",
      "0.985480375626\n",
      "309\n",
      "0.203691496374\n",
      "Number of disagreement: 185\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8714    0.8792    0.8753      1233\n",
      "          1     0.4542    0.4366    0.4452       284\n",
      "\n",
      "avg / total     0.7933    0.7963    0.7947      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-2.0-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "4.13918776607e-12\n",
      "2.21951984569e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.22569793137e-11\n",
      "6.11875168588e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-2.0-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7630662020905923\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3300492610837439\n",
      "Original f1: 0.1484375\n",
      "0.122920359985\n",
      "0.977222413742\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 150\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8392    0.8737    0.8561       926\n",
      "          1     0.3641    0.3018    0.3300       222\n",
      "\n",
      "avg / total     0.7473    0.7631    0.7544      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7930125247198417\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44912280701754387\n",
      "Original f1: 0.31182795698924726\n",
      "0.125735945723\n",
      "0.988402054561\n",
      "314\n",
      "0.20698747528\n",
      "Number of disagreement: 198\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8733    0.8719    0.8726      1233\n",
      "          1     0.4476    0.4507    0.4491       284\n",
      "\n",
      "avg / total     0.7936    0.7930    0.7933      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-2.0-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "0.00015052858225\n",
      "0.172806763871\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8365194462755439\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.3507853403141361\n",
      "Original f1: 0.31182795698924726\n",
      "0.00519201362972\n",
      "0.942344770924\n",
      "248\n",
      "0.163480553724\n",
      "Number of disagreement: 10\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8471    0.9749    0.9065      1233\n",
      "          1     0.6837    0.2359    0.3508       284\n",
      "\n",
      "avg / total     0.8165    0.8365    0.8025      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-2.0-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7613240418118467\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.34134615384615385\n",
      "Original f1: 0.1484375\n",
      "0.131991103657\n",
      "0.986554663342\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 160\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8417    0.8672    0.8543       926\n",
      "          1     0.3660    0.3198    0.3413       222\n",
      "\n",
      "avg / total     0.7497    0.7613    0.7551      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7857613711272248\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4444444444444444\n",
      "Original f1: 0.31182795698924726\n",
      "0.135088514167\n",
      "0.988402054752\n",
      "325\n",
      "0.214238628873\n",
      "Number of disagreement: 213\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8734    0.8613    0.8673      1233\n",
      "          1     0.4319    0.4577    0.4444       284\n",
      "\n",
      "avg / total     0.7907    0.7858    0.7881      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-2.0-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8205574912891986\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.24817518248175183\n",
      "Original f1: 0.1484375\n",
      "0.0136219385943\n",
      "0.97471341683\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 18\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8285    0.9806    0.8981       926\n",
      "          1     0.6538    0.1532    0.2482       222\n",
      "\n",
      "avg / total     0.7947    0.8206    0.7724      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8450889914304548\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.45977011494252873\n",
      "Original f1: 0.31182795698924726\n",
      "0.0363882684451\n",
      "0.968187441902\n",
      "235\n",
      "0.15491100857\n",
      "Number of disagreement: 63\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8653    0.9586    0.9096      1233\n",
      "          1     0.6623    0.3521    0.4598       284\n",
      "\n",
      "avg / total     0.8273    0.8451    0.8254      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-2.0-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7630662020905923\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3492822966507177\n",
      "Original f1: 0.1484375\n",
      "0.135870654107\n",
      "0.986554666819\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 162\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8435    0.8672    0.8552       926\n",
      "          1     0.3724    0.3288    0.3493       222\n",
      "\n",
      "avg / total     0.7524    0.7631    0.7573      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7844429795649308\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4448217317487267\n",
      "Original f1: 0.31182795698924726\n",
      "0.139207153604\n",
      "0.990344467787\n",
      "327\n",
      "0.215557020435\n",
      "Number of disagreement: 217\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8738    0.8589    0.8663      1233\n",
      "          1     0.4295    0.4613    0.4448       284\n",
      "\n",
      "avg / total     0.7906    0.7844    0.7874      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-2.0-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8301393728222997\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.41087613293051356\n",
      "Original f1: 0.1484375\n",
      "0.0565922748395\n",
      "0.974713447714\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 75\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8518    0.9557    0.9008       926\n",
      "          1     0.6239    0.3063    0.4109       222\n",
      "\n",
      "avg / total     0.8077    0.8301    0.8060      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8226763348714569\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4715127701375246\n",
      "Original f1: 0.31182795698924726\n",
      "0.0820695848816\n",
      "0.985480366499\n",
      "269\n",
      "0.177323665129\n",
      "Number of disagreement: 137\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8731    0.9148    0.8935      1233\n",
      "          1     0.5333    0.4225    0.4715       284\n",
      "\n",
      "avg / total     0.8095    0.8227    0.8145      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-2.0-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7639372822299652\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3562945368171021\n",
      "Original f1: 0.1484375\n",
      "0.138971207234\n",
      "0.986554666115\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 165\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8451    0.8661    0.8555       926\n",
      "          1     0.3769    0.3378    0.3563       222\n",
      "\n",
      "avg / total     0.7546    0.7639    0.7589      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7844429795649308\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4448217317487267\n",
      "Original f1: 0.31182795698924726\n",
      "0.139757354449\n",
      "0.990344468214\n",
      "327\n",
      "0.215557020435\n",
      "Number of disagreement: 217\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8738    0.8589    0.8663      1233\n",
      "          1     0.4295    0.4613    0.4448       284\n",
      "\n",
      "avg / total     0.7906    0.7844    0.7874      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-2.0-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7961672473867596\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3842105263157895\n",
      "Original f1: 0.1484375\n",
      "0.094211594348\n",
      "0.986554661495\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 124\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8495    0.9082    0.8779       926\n",
      "          1     0.4620    0.3288    0.3842       222\n",
      "\n",
      "avg / total     0.7746    0.7962    0.7824      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8022412656558998\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.460431654676259\n",
      "Original f1: 0.31182795698924726\n",
      "0.109621415312\n",
      "0.985480375781\n",
      "300\n",
      "0.197758734344\n",
      "Number of disagreement: 184\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8747    0.8832    0.8789      1233\n",
      "          1     0.4706    0.4507    0.4604       284\n",
      "\n",
      "avg / total     0.7990    0.8022    0.8006      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-2.0-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7613240418118467\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35377358490566035\n",
      "Original f1: 0.1484375\n",
      "0.141070142218\n",
      "0.986554666503\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 168\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8446    0.8629    0.8536       926\n",
      "          1     0.3713    0.3378    0.3538       222\n",
      "\n",
      "avg / total     0.7531    0.7613    0.7570      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7837837837837838\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4459459459459459\n",
      "Original f1: 0.31182795698924726\n",
      "0.141424927098\n",
      "0.990344468055\n",
      "328\n",
      "0.216216216216\n",
      "Number of disagreement: 220\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8743    0.8573    0.8657      1233\n",
      "          1     0.4286    0.4648    0.4459       284\n",
      "\n",
      "avg / total     0.7908    0.7838    0.7871      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-2.0-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "1.8866932053e-12\n",
      "3.79443525211e-11\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.90637092535e-12\n",
      "7.8710815643e-11\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-2.0-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "2.03189521215e-11\n",
      "1.49365686486e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.34228680641e-11\n",
      "1.49274523298e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-2.0-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "2.82815393461e-12\n",
      "1.12994780199e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "3.64498182516e-12\n",
      "9.34790578278e-11\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-2.0-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7656794425087108\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.30848329048843187\n",
      "Original f1: 0.1484375\n",
      "0.110293683344\n",
      "0.977222409352\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 133\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8349    0.8844    0.8589       926\n",
      "          1     0.3593    0.2703    0.3085       222\n",
      "\n",
      "avg / total     0.7429    0.7657    0.7525      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7963085036255768\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44524236983842\n",
      "Original f1: 0.31182795698924726\n",
      "0.118182469841\n",
      "0.985480375891\n",
      "309\n",
      "0.203691496374\n",
      "Number of disagreement: 185\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8714    0.8792    0.8753      1233\n",
      "          1     0.4542    0.4366    0.4452       284\n",
      "\n",
      "avg / total     0.7933    0.7963    0.7947      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-2.0-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "4.37275515533e-12\n",
      "2.21951984569e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.11245581934e-11\n",
      "6.00861582711e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-2.0-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7639372822299652\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3275434243176179\n",
      "Original f1: 0.1484375\n",
      "0.123181726031\n",
      "0.977222413829\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 147\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8387    0.8758    0.8568       926\n",
      "          1     0.3646    0.2973    0.3275       222\n",
      "\n",
      "avg / total     0.7470    0.7639    0.7545      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7923533289386948\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4483362521891419\n",
      "Original f1: 0.31182795698924726\n",
      "0.126780624216\n",
      "0.988402054544\n",
      "315\n",
      "0.207646671061\n",
      "Number of disagreement: 199\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8732    0.8710    0.8721      1233\n",
      "          1     0.4460    0.4507    0.4483       284\n",
      "\n",
      "avg / total     0.7932    0.7924    0.7928      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-2.0-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "8.91821103628e-05\n",
      "0.102380674579\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8358602504943968\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.3464566929133858\n",
      "Original f1: 0.31182795698924726\n",
      "0.0050405610275\n",
      "0.942344773909\n",
      "249\n",
      "0.164139749506\n",
      "Number of disagreement: 9\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8465    0.9749    0.9061      1233\n",
      "          1     0.6804    0.2324    0.3465       284\n",
      "\n",
      "avg / total     0.8154    0.8359    0.8014      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-2.0-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7621951219512195\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.34216867469879514\n",
      "Original f1: 0.1484375\n",
      "0.132608137964\n",
      "0.986554661104\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 159\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8419    0.8683    0.8549       926\n",
      "          1     0.3679    0.3198    0.3422       222\n",
      "\n",
      "avg / total     0.7502    0.7622    0.7557      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7857613711272248\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4463373083475298\n",
      "Original f1: 0.31182795698924726\n",
      "0.13599566047\n",
      "0.98840205497\n",
      "325\n",
      "0.214238628873\n",
      "Number of disagreement: 215\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8740    0.8605    0.8672      1233\n",
      "          1     0.4323    0.4613    0.4463       284\n",
      "\n",
      "avg / total     0.7913    0.7858    0.7884      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-2.0-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8205574912891986\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.24817518248175183\n",
      "Original f1: 0.1484375\n",
      "0.0134593780001\n",
      "0.974713440198\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 18\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8285    0.9806    0.8981       926\n",
      "          1     0.6538    0.1532    0.2482       222\n",
      "\n",
      "avg / total     0.7947    0.8206    0.7724      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8437705998681608\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.45011600928074247\n",
      "Original f1: 0.31182795698924726\n",
      "0.03514443159\n",
      "0.968187446029\n",
      "237\n",
      "0.156229400132\n",
      "Number of disagreement: 59\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8635    0.9594    0.9090      1233\n",
      "          1     0.6599    0.3415    0.4501       284\n",
      "\n",
      "avg / total     0.8254    0.8438    0.8231      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-2.0-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7639372822299652\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35011990407673865\n",
      "Original f1: 0.1484375\n",
      "0.136560949008\n",
      "0.986554666922\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 161\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8437    0.8683    0.8558       926\n",
      "          1     0.3744    0.3288    0.3501       222\n",
      "\n",
      "avg / total     0.7529    0.7639    0.7580      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7844429795649308\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4467005076142132\n",
      "Original f1: 0.31182795698924726\n",
      "0.14013141344\n",
      "0.990344468315\n",
      "327\n",
      "0.215557020435\n",
      "Number of disagreement: 219\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8744    0.8581    0.8661      1233\n",
      "          1     0.4300    0.4648    0.4467       284\n",
      "\n",
      "avg / total     0.7912    0.7844    0.7876      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-2.0-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8318815331010453\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.41337386018237077\n",
      "Original f1: 0.1484375\n",
      "0.0563992700369\n",
      "0.974713446952\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 73\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8521    0.9579    0.9019       926\n",
      "          1     0.6355    0.3063    0.4134       222\n",
      "\n",
      "avg / total     0.8102    0.8319    0.8074      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8220171390903098\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4705882352941177\n",
      "Original f1: 0.31182795698924726\n",
      "0.0820354982359\n",
      "0.985480370687\n",
      "270\n",
      "0.17798286091\n",
      "Number of disagreement: 138\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8730    0.9140    0.8930      1233\n",
      "          1     0.5310    0.4225    0.4706       284\n",
      "\n",
      "avg / total     0.8089    0.8220    0.8139      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-2.0-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3571428571428571\n",
      "Original f1: 0.1484375\n",
      "0.139618548968\n",
      "0.986554666254\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 164\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8453    0.8672    0.8561       926\n",
      "          1     0.3788    0.3378    0.3571       222\n",
      "\n",
      "avg / total     0.7551    0.7648    0.7596      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7844429795649308\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4467005076142132\n",
      "Original f1: 0.31182795698924726\n",
      "0.14065978298\n",
      "0.990344468513\n",
      "327\n",
      "0.215557020435\n",
      "Number of disagreement: 219\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8744    0.8581    0.8661      1233\n",
      "          1     0.4300    0.4648    0.4467       284\n",
      "\n",
      "avg / total     0.7912    0.7844    0.7876      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-2.0-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7961672473867596\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3842105263157895\n",
      "Original f1: 0.1484375\n",
      "0.0945453349368\n",
      "0.986554664143\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 124\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8495    0.9082    0.8779       926\n",
      "          1     0.4620    0.3288    0.3842       222\n",
      "\n",
      "avg / total     0.7746    0.7962    0.7824      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8029004614370469\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.46319569120287246\n",
      "Original f1: 0.31182795698924726\n",
      "0.109936349821\n",
      "0.985480375417\n",
      "299\n",
      "0.197099538563\n",
      "Number of disagreement: 185\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8754    0.8832    0.8793      1233\n",
      "          1     0.4725    0.4542    0.4632       284\n",
      "\n",
      "avg / total     0.8000    0.8029    0.8014      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.05-2.0-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7621951219512195\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35460992907801414\n",
      "Original f1: 0.1484375\n",
      "0.141709979149\n",
      "0.986554666566\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 167\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8448    0.8639    0.8542       926\n",
      "          1     0.3731    0.3378    0.3546       222\n",
      "\n",
      "avg / total     0.7536    0.7622    0.7576      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7837837837837838\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4478114478114478\n",
      "Original f1: 0.31182795698924726\n",
      "0.142336238614\n",
      "0.990344467993\n",
      "328\n",
      "0.216216216216\n",
      "Number of disagreement: 222\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8749    0.8564    0.8656      1233\n",
      "          1     0.4290    0.4683    0.4478       284\n",
      "\n",
      "avg / total     0.7914    0.7838    0.7874      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.5-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "1.0134357799e-12\n",
      "5.10454456482e-11\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.18087252329e-12\n",
      "8.95583815441e-11\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.5-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "2.863521697e-11\n",
      "2.78364220563e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.64346806016e-11\n",
      "2.26548203808e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.5-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "1.92667834872e-12\n",
      "1.05519148974e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "3.83937068855e-12\n",
      "3.39739791855e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.5-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7700348432055749\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3089005235602094\n",
      "Original f1: 0.1484375\n",
      "0.102675569168\n",
      "0.977222410295\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 128\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8350    0.8909    0.8621       926\n",
      "          1     0.3688    0.2658    0.3089       222\n",
      "\n",
      "avg / total     0.7449    0.7700    0.7551      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7930125247198417\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.43115942028985504\n",
      "Original f1: 0.31182795698924726\n",
      "0.112905595199\n",
      "0.985480375375\n",
      "314\n",
      "0.20698747528\n",
      "Number of disagreement: 182\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8679    0.8792    0.8735      1233\n",
      "          1     0.4440    0.4190    0.4312       284\n",
      "\n",
      "avg / total     0.7885    0.7930    0.7907      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.5-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "3.61454660815e-12\n",
      "2.09174899624e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "8.43242543011e-12\n",
      "6.60832166766e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.5-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3283582089552239\n",
      "Original f1: 0.1484375\n",
      "0.120117800086\n",
      "0.977222413376\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 148\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8388    0.8769    0.8574       926\n",
      "          1     0.3667    0.2973    0.3284       222\n",
      "\n",
      "avg / total     0.7475    0.7648    0.7551      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7916941331575478\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.441696113074205\n",
      "Original f1: 0.31182795698924726\n",
      "0.122985676658\n",
      "0.985480375885\n",
      "316\n",
      "0.208305866842\n",
      "Number of disagreement: 196\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8713    0.8727    0.8720      1233\n",
      "          1     0.4433    0.4401    0.4417       284\n",
      "\n",
      "avg / total     0.7911    0.7917    0.7914      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.5-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "3.06370871054e-05\n",
      "0.0351713347829\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8345418589321029\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.33773087071240104\n",
      "Original f1: 0.31182795698924726\n",
      "0.00378874785858\n",
      "0.914491847764\n",
      "251\n",
      "0.165458141068\n",
      "Number of disagreement: 7\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8453    0.9749    0.9055      1233\n",
      "          1     0.6737    0.2254    0.3377       284\n",
      "\n",
      "avg / total     0.8132    0.8345    0.7992      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.5-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7621951219512195\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.34216867469879514\n",
      "Original f1: 0.1484375\n",
      "0.131047552593\n",
      "0.977222413649\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 161\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8419    0.8683    0.8549       926\n",
      "          1     0.3679    0.3198    0.3422       222\n",
      "\n",
      "avg / total     0.7502    0.7622    0.7557      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7857613711272248\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4444444444444444\n",
      "Original f1: 0.31182795698924726\n",
      "0.133350014609\n",
      "0.988402053431\n",
      "325\n",
      "0.214238628873\n",
      "Number of disagreement: 215\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8734    0.8613    0.8673      1233\n",
      "          1     0.4319    0.4577    0.4444       284\n",
      "\n",
      "avg / total     0.7907    0.7858    0.7881      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.5-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.823170731707317\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.26181818181818184\n",
      "Original f1: 0.1484375\n",
      "0.0120013584409\n",
      "0.964480125787\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 19\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8301    0.9816    0.8996       926\n",
      "          1     0.6792    0.1622    0.2618       222\n",
      "\n",
      "avg / total     0.8010    0.8232    0.7762      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8450889914304548\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4522144522144523\n",
      "Original f1: 0.31182795698924726\n",
      "0.0325581594067\n",
      "0.962322967372\n",
      "235\n",
      "0.15491100857\n",
      "Number of disagreement: 57\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8637    0.9611    0.9098      1233\n",
      "          1     0.6690    0.3415    0.4522       284\n",
      "\n",
      "avg / total     0.8272    0.8451    0.8241      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.5-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7639372822299652\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3532219570405728\n",
      "Original f1: 0.1484375\n",
      "0.135615356214\n",
      "0.981576845272\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 165\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8444    0.8672    0.8556       926\n",
      "          1     0.3756    0.3333    0.3532       222\n",
      "\n",
      "avg / total     0.7537    0.7639    0.7585      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7818061964403428\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44182124789207416\n",
      "Original f1: 0.31182795698924726\n",
      "0.139518707168\n",
      "0.98840205445\n",
      "331\n",
      "0.21819380356\n",
      "Number of disagreement: 223\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8733    0.8556    0.8644      1233\n",
      "          1     0.4239    0.4613    0.4418       284\n",
      "\n",
      "avg / total     0.7892    0.7818    0.7853      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.5-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8292682926829268\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.4024390243902439\n",
      "Original f1: 0.1484375\n",
      "0.0512045156344\n",
      "0.974713447808\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 72\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8503    0.9568    0.9004       926\n",
      "          1     0.6226    0.2973    0.4024       222\n",
      "\n",
      "avg / total     0.8063    0.8293    0.8041      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8292682926829268\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4788732394366197\n",
      "Original f1: 0.31182795698924726\n",
      "0.0724632529509\n",
      "0.985480375426\n",
      "259\n",
      "0.170731707317\n",
      "Number of disagreement: 125\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8735    0.9238    0.8979      1233\n",
      "          1     0.5587    0.4190    0.4789       284\n",
      "\n",
      "avg / total     0.8145    0.8293    0.8195      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.5-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7630662020905923\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35849056603773594\n",
      "Original f1: 0.1484375\n",
      "0.14001909909\n",
      "0.986554666691\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 170\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8457    0.8639    0.8547       926\n",
      "          1     0.3762    0.3423    0.3585       222\n",
      "\n",
      "avg / total     0.7549    0.7631    0.7587      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7818061964403428\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44182124789207416\n",
      "Original f1: 0.31182795698924726\n",
      "0.140884954509\n",
      "0.99034446473\n",
      "331\n",
      "0.21819380356\n",
      "Number of disagreement: 223\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8733    0.8556    0.8644      1233\n",
      "          1     0.4239    0.4613    0.4418       284\n",
      "\n",
      "avg / total     0.7892    0.7818    0.7853      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.5-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8057491289198606\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3923705722070845\n",
      "Original f1: 0.1484375\n",
      "0.0838653175308\n",
      "0.974713448078\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 111\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8504    0.9212    0.8844       926\n",
      "          1     0.4966    0.3243    0.3924       222\n",
      "\n",
      "avg / total     0.7820    0.8057    0.7892      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8068556361239289\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.46435100548446073\n",
      "Original f1: 0.31182795698924726\n",
      "0.103835398021\n",
      "0.985480372416\n",
      "293\n",
      "0.193144363876\n",
      "Number of disagreement: 175\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8748    0.8897    0.8822      1233\n",
      "          1     0.4829    0.4472    0.4644       284\n",
      "\n",
      "avg / total     0.8014    0.8069    0.8040      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.5-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7621951219512195\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3576470588235294\n",
      "Original f1: 0.1484375\n",
      "0.141805353683\n",
      "0.986554666535\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 171\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8455    0.8629    0.8541       926\n",
      "          1     0.3744    0.3423    0.3576       222\n",
      "\n",
      "avg / total     0.7544    0.7622    0.7581      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7818061964403428\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4436974789915966\n",
      "Original f1: 0.31182795698924726\n",
      "0.142523270799\n",
      "0.990344468217\n",
      "331\n",
      "0.21819380356\n",
      "Number of disagreement: 225\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8740    0.8548    0.8643      1233\n",
      "          1     0.4244    0.4648    0.4437       284\n",
      "\n",
      "avg / total     0.7898    0.7818    0.7855      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.5-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "9.93771389765e-13\n",
      "5.10454456482e-11\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.15100630836e-12\n",
      "8.95583815441e-11\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.5-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "2.25672919712e-11\n",
      "1.90252702481e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.50348094682e-11\n",
      "2.26548203808e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.5-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "3.27690881622e-12\n",
      "1.78835557474e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "3.79432012114e-12\n",
      "3.39739791855e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.5-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.769163763066202\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.30446194225721784\n",
      "Original f1: 0.1484375\n",
      "0.102540494976\n",
      "0.977222408579\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 127\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8342    0.8909    0.8616       926\n",
      "          1     0.3648    0.2613    0.3045       222\n",
      "\n",
      "avg / total     0.7434    0.7692    0.7539      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7923533289386948\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.430379746835443\n",
      "Original f1: 0.31182795698924726\n",
      "0.11338599845\n",
      "0.985480375737\n",
      "315\n",
      "0.207646671061\n",
      "Number of disagreement: 183\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8678    0.8783    0.8730      1233\n",
      "          1     0.4424    0.4190    0.4304       284\n",
      "\n",
      "avg / total     0.7881    0.7924    0.7902      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.5-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "3.58587497614e-12\n",
      "2.09174899624e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "8.16975576607e-12\n",
      "6.60832166766e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.5-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7639372822299652\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.32418952618453867\n",
      "Original f1: 0.1484375\n",
      "0.120212441878\n",
      "0.977222414154\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 147\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8380    0.8769    0.8570       926\n",
      "          1     0.3631    0.2928    0.3242       222\n",
      "\n",
      "avg / total     0.7462    0.7639    0.7540      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7910349373764007\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4409171075837743\n",
      "Original f1: 0.31182795698924726\n",
      "0.12349789034\n",
      "0.985480375891\n",
      "317\n",
      "0.208965062624\n",
      "Number of disagreement: 197\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8712    0.8719    0.8715      1233\n",
      "          1     0.4417    0.4401    0.4409       284\n",
      "\n",
      "avg / total     0.7908    0.7910    0.7909      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.5-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "1.8973963182e-05\n",
      "0.021782074501\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8338826631509558\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.3333333333333333\n",
      "Original f1: 0.31182795698924726\n",
      "0.00368409930376\n",
      "0.914491848168\n",
      "252\n",
      "0.166117336849\n",
      "Number of disagreement: 6\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8447    0.9749    0.9051      1233\n",
      "          1     0.6702    0.2218    0.3333       284\n",
      "\n",
      "avg / total     0.8120    0.8339    0.7981      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.5-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7613240418118467\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3381642512077294\n",
      "Original f1: 0.1484375\n",
      "0.131217881656\n",
      "0.977222413839\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 160\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8410    0.8683    0.8544       926\n",
      "          1     0.3646    0.3153    0.3382       222\n",
      "\n",
      "avg / total     0.7489    0.7613    0.7546      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7851021753460777\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4436860068259385\n",
      "Original f1: 0.31182795698924726\n",
      "0.133889011565\n",
      "0.988402051786\n",
      "326\n",
      "0.214897824654\n",
      "Number of disagreement: 216\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8733    0.8605    0.8668      1233\n",
      "          1     0.4305    0.4577    0.4437       284\n",
      "\n",
      "avg / total     0.7904    0.7851    0.7876      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.5-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8222996515679443\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.25547445255474455\n",
      "Original f1: 0.1484375\n",
      "0.0120614379282\n",
      "0.964480055957\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 18\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8294    0.9816    0.8991       926\n",
      "          1     0.6731    0.1577    0.2555       222\n",
      "\n",
      "avg / total     0.7992    0.8223    0.7746      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8457481872116018\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4558139534883721\n",
      "Original f1: 0.31182795698924726\n",
      "0.0324754081701\n",
      "0.962322967279\n",
      "234\n",
      "0.154251812788\n",
      "Number of disagreement: 58\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8643    0.9611    0.9101      1233\n",
      "          1     0.6712    0.3451    0.4558       284\n",
      "\n",
      "avg / total     0.8282    0.8457    0.8251      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.5-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7630662020905923\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3492822966507177\n",
      "Original f1: 0.1484375\n",
      "0.135781015433\n",
      "0.982483531895\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 164\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8435    0.8672    0.8552       926\n",
      "          1     0.3724    0.3288    0.3493       222\n",
      "\n",
      "avg / total     0.7524    0.7631    0.7573      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7811470006591957\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44107744107744107\n",
      "Original f1: 0.31182795698924726\n",
      "0.140051323379\n",
      "0.988402054226\n",
      "332\n",
      "0.218852999341\n",
      "Number of disagreement: 224\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8732    0.8548    0.8639      1233\n",
      "          1     0.4226    0.4613    0.4411       284\n",
      "\n",
      "avg / total     0.7889    0.7811    0.7848      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.5-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8301393728222997\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.40366972477064217\n",
      "Original f1: 0.1484375\n",
      "0.0511489288956\n",
      "0.974713447617\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 71\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8504    0.9579    0.9010       926\n",
      "          1     0.6286    0.2973    0.4037       222\n",
      "\n",
      "avg / total     0.8075    0.8301    0.8048      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8286090969017799\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.47791164658634533\n",
      "Original f1: 0.31182795698924726\n",
      "0.0726956044985\n",
      "0.985480372581\n",
      "260\n",
      "0.171390903098\n",
      "Number of disagreement: 126\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8734    0.9230    0.8975      1233\n",
      "          1     0.5561    0.4190    0.4779       284\n",
      "\n",
      "avg / total     0.8140    0.8286    0.8189      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.5-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7621951219512195\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35460992907801414\n",
      "Original f1: 0.1484375\n",
      "0.140166980332\n",
      "0.986554666682\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 169\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8448    0.8639    0.8542       926\n",
      "          1     0.3731    0.3378    0.3546       222\n",
      "\n",
      "avg / total     0.7536    0.7622    0.7576      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7811470006591957\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44107744107744107\n",
      "Original f1: 0.31182795698924726\n",
      "0.141419875926\n",
      "0.99034446463\n",
      "332\n",
      "0.218852999341\n",
      "Number of disagreement: 224\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8732    0.8548    0.8639      1233\n",
      "          1     0.4226    0.4613    0.4411       284\n",
      "\n",
      "avg / total     0.7889    0.7811    0.7848      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.5-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8048780487804879\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.391304347826087\n",
      "Original f1: 0.1484375\n",
      "0.0842521847478\n",
      "0.974713448191\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 112\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8503    0.9201    0.8838       926\n",
      "          1     0.4932    0.3243    0.3913       222\n",
      "\n",
      "avg / total     0.7812    0.8049    0.7886      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8081740276862228\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4660550458715596\n",
      "Original f1: 0.31182795698924726\n",
      "0.10379835414\n",
      "0.985480375832\n",
      "291\n",
      "0.191825972314\n",
      "Number of disagreement: 173\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8750    0.8913    0.8831      1233\n",
      "          1     0.4866    0.4472    0.4661       284\n",
      "\n",
      "avg / total     0.8023    0.8082    0.8050      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.5-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7613240418118467\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35377358490566035\n",
      "Original f1: 0.1484375\n",
      "0.14196642471\n",
      "0.986554666531\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 170\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8446    0.8629    0.8536       926\n",
      "          1     0.3713    0.3378    0.3538       222\n",
      "\n",
      "avg / total     0.7531    0.7613    0.7570      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7811470006591957\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44295302013422816\n",
      "Original f1: 0.31182795698924726\n",
      "0.14305565566\n",
      "0.990344468174\n",
      "332\n",
      "0.218852999341\n",
      "Number of disagreement: 226\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8739    0.8540    0.8638      1233\n",
      "          1     0.4231    0.4648    0.4430       284\n",
      "\n",
      "avg / total     0.7895    0.7811    0.7850      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.75-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "1.06991050504e-12\n",
      "5.10455566705e-11\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.19955379014e-12\n",
      "8.95583919525e-11\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.75-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "2.410838538e-11\n",
      "2.56273696708e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.76172233022e-11\n",
      "2.26548203808e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.75-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "2.63409648937e-12\n",
      "1.07985620446e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "3.19685477483e-12\n",
      "1.32070909764e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.75-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3005181347150259\n",
      "Original f1: 0.1484375\n",
      "0.106583020407\n",
      "0.977222411234\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 130\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8333    0.8855    0.8586       926\n",
      "          1     0.3537    0.2613    0.3005       222\n",
      "\n",
      "avg / total     0.7406    0.7648    0.7507      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7936717205009888\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4420677361853832\n",
      "Original f1: 0.31182795698924726\n",
      "0.117953182549\n",
      "0.985480375747\n",
      "313\n",
      "0.206328279499\n",
      "Number of disagreement: 189\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8710    0.8759    0.8734      1233\n",
      "          1     0.4477    0.4366    0.4421       284\n",
      "\n",
      "avg / total     0.7917    0.7937    0.7927      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.75-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "3.18419528398e-12\n",
      "2.42361061775e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "7.01008285812e-12\n",
      "3.23373466893e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.75-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7630662020905923\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.32673267326732675\n",
      "Original f1: 0.1484375\n",
      "0.123632601555\n",
      "0.97722241344\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 148\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8385    0.8747    0.8562       926\n",
      "          1     0.3626    0.2973    0.3267       222\n",
      "\n",
      "avg / total     0.7465    0.7631    0.7538      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7910349373764007\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44677137870855155\n",
      "Original f1: 0.31182795698924726\n",
      "0.126319094078\n",
      "0.985480375609\n",
      "317\n",
      "0.208965062624\n",
      "Number of disagreement: 201\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8730    0.8694    0.8712      1233\n",
      "          1     0.4429    0.4507    0.4468       284\n",
      "\n",
      "avg / total     0.7925    0.7910    0.7917      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.75-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "4.49498694481e-05\n",
      "0.0516024242326\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8352010547132498\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.34210526315789475\n",
      "Original f1: 0.31182795698924726\n",
      "0.00407324469144\n",
      "0.914491847145\n",
      "250\n",
      "0.164798945287\n",
      "Number of disagreement: 8\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8459    0.9749    0.9058      1233\n",
      "          1     0.6771    0.2289    0.3421       284\n",
      "\n",
      "avg / total     0.8143    0.8352    0.8003      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.75-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7604529616724739\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3405275779376499\n",
      "Original f1: 0.1484375\n",
      "0.133341014085\n",
      "0.977222414076\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 161\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8416    0.8661    0.8536       926\n",
      "          1     0.3641    0.3198    0.3405       222\n",
      "\n",
      "avg / total     0.7492    0.7605    0.7544      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7824653922214898\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4425675675675676\n",
      "Original f1: 0.31182795698924726\n",
      "0.137045945829\n",
      "0.98840205301\n",
      "330\n",
      "0.217534607779\n",
      "Number of disagreement: 220\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8734    0.8564    0.8649      1233\n",
      "          1     0.4253    0.4613    0.4426       284\n",
      "\n",
      "avg / total     0.7896    0.7825    0.7858      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.75-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8240418118466899\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.26811594202898553\n",
      "Original f1: 0.1484375\n",
      "0.0124561136267\n",
      "0.953311613583\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 20\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8309    0.9816    0.9000       926\n",
      "          1     0.6852    0.1667    0.2681       222\n",
      "\n",
      "avg / total     0.8027    0.8240    0.7778      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8457481872116018\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4583333333333333\n",
      "Original f1: 0.31182795698924726\n",
      "0.0333753122609\n",
      "0.963170435052\n",
      "234\n",
      "0.154251812788\n",
      "Number of disagreement: 60\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8649    0.9603    0.9101      1233\n",
      "          1     0.6689    0.3486    0.4583       284\n",
      "\n",
      "avg / total     0.8282    0.8457    0.8255      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.75-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7613240418118467\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3476190476190476\n",
      "Original f1: 0.1484375\n",
      "0.137855168725\n",
      "0.98655466567\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 164\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8432    0.8650    0.8539       926\n",
      "          1     0.3687    0.3288    0.3476       222\n",
      "\n",
      "avg / total     0.7514    0.7613    0.7560      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7804878048780488\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44221105527638194\n",
      "Original f1: 0.31182795698924726\n",
      "0.142713755216\n",
      "0.988402054918\n",
      "333\n",
      "0.219512195122\n",
      "Number of disagreement: 225\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8738    0.8532    0.8634      1233\n",
      "          1     0.4217    0.4648    0.4422       284\n",
      "\n",
      "avg / total     0.7891    0.7805    0.7845      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.75-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8327526132404182\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.4181818181818182\n",
      "Original f1: 0.1484375\n",
      "0.0529027569235\n",
      "0.974713448135\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 74\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8529    0.9579    0.9023       926\n",
      "          1     0.6389    0.3108    0.4182       222\n",
      "\n",
      "avg / total     0.8115    0.8328    0.8087      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8266315095583389\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.47504990019960075\n",
      "Original f1: 0.31182795698924726\n",
      "0.0760798462922\n",
      "0.985480359707\n",
      "263\n",
      "0.173368490442\n",
      "Number of disagreement: 129\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8731    0.9205    0.8962      1233\n",
      "          1     0.5484    0.4190    0.4750       284\n",
      "\n",
      "avg / total     0.8123    0.8266    0.8173      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.75-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7621951219512195\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35460992907801414\n",
      "Original f1: 0.1484375\n",
      "0.141883728468\n",
      "0.986554666789\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 167\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8448    0.8639    0.8542       926\n",
      "          1     0.3731    0.3378    0.3546       222\n",
      "\n",
      "avg / total     0.7536    0.7622    0.7576      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7798286090969018\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44147157190635455\n",
      "Original f1: 0.31182795698924726\n",
      "0.14386101798\n",
      "0.990344467479\n",
      "334\n",
      "0.220171390903\n",
      "Number of disagreement: 226\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8736    0.8524    0.8629      1233\n",
      "          1     0.4204    0.4648    0.4415       284\n",
      "\n",
      "avg / total     0.7888    0.7798    0.7840      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.75-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8031358885017421\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3924731182795699\n",
      "Original f1: 0.1484375\n",
      "0.0873022048247\n",
      "0.974713448184\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 116\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8507    0.9168    0.8825       926\n",
      "          1     0.4867    0.3288    0.3925       222\n",
      "\n",
      "avg / total     0.7803    0.8031    0.7878      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8055372445616348\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.46460980036297644\n",
      "Original f1: 0.31182795698924726\n",
      "0.106253671825\n",
      "0.985480373726\n",
      "295\n",
      "0.194462755438\n",
      "Number of disagreement: 179\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8752    0.8873    0.8812      1233\n",
      "          1     0.4794    0.4507    0.4646       284\n",
      "\n",
      "avg / total     0.8011    0.8055    0.8032      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.75-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.759581881533101\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35211267605633806\n",
      "Original f1: 0.1484375\n",
      "0.144076778301\n",
      "0.986554666046\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 170\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8443    0.8607    0.8524       926\n",
      "          1     0.3676    0.3378    0.3521       222\n",
      "\n",
      "avg / total     0.7521    0.7596    0.7557      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7798286090969018\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44333333333333336\n",
      "Original f1: 0.31182795698924726\n",
      "0.145518780048\n",
      "0.990344467738\n",
      "334\n",
      "0.220171390903\n",
      "Number of disagreement: 228\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8743    0.8516    0.8628      1233\n",
      "          1     0.4209    0.4683    0.4433       284\n",
      "\n",
      "avg / total     0.7894    0.7798    0.7843      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.75-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "1.09420076954e-12\n",
      "5.10455566705e-11\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.04473708305e-12\n",
      "8.95583919525e-11\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.75-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "2.98411679882e-11\n",
      "2.39814612613e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "2.03579938273e-11\n",
      "2.26548203808e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.75-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "3.04528123464e-12\n",
      "1.7517604034e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "2.87963296089e-12\n",
      "1.32070909764e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.75-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7639372822299652\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.2997416020671834\n",
      "Original f1: 0.1484375\n",
      "0.107025267268\n",
      "0.975701884427\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 131\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8332    0.8844    0.8580       926\n",
      "          1     0.3515    0.2613    0.2997       222\n",
      "\n",
      "avg / total     0.7400    0.7639    0.7501      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7936717205009888\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4420677361853832\n",
      "Original f1: 0.31182795698924726\n",
      "0.118839638103\n",
      "0.985480375859\n",
      "313\n",
      "0.206328279499\n",
      "Number of disagreement: 189\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8710    0.8759    0.8734      1233\n",
      "          1     0.4477    0.4366    0.4421       284\n",
      "\n",
      "avg / total     0.7917    0.7937    0.7927      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.75-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "4.25335758979e-12\n",
      "2.42361061775e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "6.24868369963e-12\n",
      "3.23373466893e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.75-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7639372822299652\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.33086419753086427\n",
      "Original f1: 0.1484375\n",
      "0.124189049736\n",
      "0.977222413572\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 149\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8394    0.8747    0.8567       926\n",
      "          1     0.3661    0.3018    0.3309       222\n",
      "\n",
      "avg / total     0.7479    0.7639    0.7550      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7910349373764007\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44677137870855155\n",
      "Original f1: 0.31182795698924726\n",
      "0.127287436637\n",
      "0.985480375572\n",
      "317\n",
      "0.208965062624\n",
      "Number of disagreement: 201\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8730    0.8694    0.8712      1233\n",
      "          1     0.4429    0.4507    0.4468       284\n",
      "\n",
      "avg / total     0.7925    0.7910    0.7917      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.75-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "1.2611344327e-05\n",
      "0.0144778010141\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8352010547132498\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.34210526315789475\n",
      "Original f1: 0.31182795698924726\n",
      "0.00363372928185\n",
      "0.864460541686\n",
      "250\n",
      "0.164798945287\n",
      "Number of disagreement: 8\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8459    0.9749    0.9058      1233\n",
      "          1     0.6771    0.2289    0.3421       284\n",
      "\n",
      "avg / total     0.8143    0.8352    0.8003      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.75-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7613240418118467\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3444976076555024\n",
      "Original f1: 0.1484375\n",
      "0.133848307444\n",
      "0.97722241417\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 162\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8424    0.8661    0.8541       926\n",
      "          1     0.3673    0.3243    0.3445       222\n",
      "\n",
      "avg / total     0.7506    0.7613    0.7556      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7824653922214898\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4425675675675676\n",
      "Original f1: 0.31182795698924726\n",
      "0.138160638478\n",
      "0.988402054144\n",
      "330\n",
      "0.217534607779\n",
      "Number of disagreement: 220\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8734    0.8564    0.8649      1233\n",
      "          1     0.4253    0.4613    0.4426       284\n",
      "\n",
      "avg / total     0.7896    0.7825    0.7858      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.75-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.823170731707317\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.26181818181818184\n",
      "Original f1: 0.1484375\n",
      "0.0125790295175\n",
      "0.954843622022\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 19\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8301    0.9816    0.8996       926\n",
      "          1     0.6792    0.1622    0.2618       222\n",
      "\n",
      "avg / total     0.8010    0.8232    0.7762      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8464073829927489\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4593967517401392\n",
      "Original f1: 0.31182795698924726\n",
      "0.0325449826971\n",
      "0.96317042287\n",
      "233\n",
      "0.153592617007\n",
      "Number of disagreement: 59\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8650    0.9611    0.9105      1233\n",
      "          1     0.6735    0.3486    0.4594       284\n",
      "\n",
      "avg / total     0.8291    0.8464    0.8260      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.75-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7621951219512195\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3515439429928741\n",
      "Original f1: 0.1484375\n",
      "0.138556851771\n",
      "0.986554666907\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 165\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8440    0.8650    0.8544       926\n",
      "          1     0.3719    0.3333    0.3515       222\n",
      "\n",
      "avg / total     0.7527    0.7622    0.7572      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7804878048780488\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44221105527638194\n",
      "Original f1: 0.31182795698924726\n",
      "0.143739573685\n",
      "0.988402054546\n",
      "333\n",
      "0.219512195122\n",
      "Number of disagreement: 225\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8738    0.8532    0.8634      1233\n",
      "          1     0.4217    0.4648    0.4422       284\n",
      "\n",
      "avg / total     0.7891    0.7805    0.7845      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.75-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8327526132404182\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.4181818181818182\n",
      "Original f1: 0.1484375\n",
      "0.0528714522791\n",
      "0.974713447498\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 74\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8529    0.9579    0.9023       926\n",
      "          1     0.6389    0.3108    0.4182       222\n",
      "\n",
      "avg / total     0.8115    0.8328    0.8087      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8253131179960448\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4731610337972167\n",
      "Original f1: 0.31182795698924726\n",
      "0.0765790624799\n",
      "0.985480371777\n",
      "265\n",
      "0.174686882004\n",
      "Number of disagreement: 131\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8729    0.9189    0.8953      1233\n",
      "          1     0.5434    0.4190    0.4732       284\n",
      "\n",
      "avg / total     0.8112    0.8253    0.8163      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.75-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7630662020905923\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35849056603773594\n",
      "Original f1: 0.1484375\n",
      "0.142516063871\n",
      "0.986554666783\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 168\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8457    0.8639    0.8547       926\n",
      "          1     0.3762    0.3423    0.3585       222\n",
      "\n",
      "avg / total     0.7549    0.7631    0.7587      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7798286090969018\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44147157190635455\n",
      "Original f1: 0.31182795698924726\n",
      "0.144887720144\n",
      "0.990344466944\n",
      "334\n",
      "0.220171390903\n",
      "Number of disagreement: 226\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8736    0.8524    0.8629      1233\n",
      "          1     0.4204    0.4648    0.4415       284\n",
      "\n",
      "avg / total     0.7888    0.7798    0.7840      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.75-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8022648083623694\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.39142091152815023\n",
      "Original f1: 0.1484375\n",
      "0.0881490870298\n",
      "0.974713448043\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 117\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8506    0.9158    0.8820       926\n",
      "          1     0.4834    0.3288    0.3914       222\n",
      "\n",
      "avg / total     0.7796    0.8023    0.7871      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8055372445616348\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.46460980036297644\n",
      "Original f1: 0.31182795698924726\n",
      "0.106083936128\n",
      "0.98548037567\n",
      "295\n",
      "0.194462755438\n",
      "Number of disagreement: 179\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8752    0.8873    0.8812      1233\n",
      "          1     0.4794    0.4507    0.4646       284\n",
      "\n",
      "avg / total     0.8011    0.8055    0.8032      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-0.75-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7604529616724739\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3559718969555036\n",
      "Original f1: 0.1484375\n",
      "0.14473467833\n",
      "0.986554666091\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 171\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8452    0.8607    0.8529       926\n",
      "          1     0.3707    0.3423    0.3560       222\n",
      "\n",
      "avg / total     0.7534    0.7605    0.7568      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7798286090969018\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44333333333333336\n",
      "Original f1: 0.31182795698924726\n",
      "0.146554054371\n",
      "0.990344467793\n",
      "334\n",
      "0.220171390903\n",
      "Number of disagreement: 228\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8743    0.8516    0.8628      1233\n",
      "          1     0.4209    0.4683    0.4433       284\n",
      "\n",
      "avg / total     0.7894    0.7798    0.7843      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.0-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "1.68538714549e-12\n",
      "5.10454456482e-11\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.36089960988e-12\n",
      "9.42208672194e-11\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.0-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "2.13752636079e-11\n",
      "2.30350627461e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "2.39547829759e-11\n",
      "2.26548203808e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.0-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "2.73052952412e-12\n",
      "9.65506286033e-11\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "2.42690425179e-12\n",
      "1.03228703363e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.0-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7639372822299652\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.30334190231362473\n",
      "Original f1: 0.1484375\n",
      "0.109387049538\n",
      "0.977222407773\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 133\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8338    0.8834    0.8579       926\n",
      "          1     0.3533    0.2658    0.3033       222\n",
      "\n",
      "avg / total     0.7409    0.7639    0.7507      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7930125247198417\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4412811387900356\n",
      "Original f1: 0.31182795698924726\n",
      "0.11987370852\n",
      "0.985480375255\n",
      "314\n",
      "0.20698747528\n",
      "Number of disagreement: 190\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8709    0.8751    0.8730      1233\n",
      "          1     0.4460    0.4366    0.4413       284\n",
      "\n",
      "avg / total     0.7913    0.7930    0.7922      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.0-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "5.56322971412e-12\n",
      "3.42379513629e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "7.06042590448e-12\n",
      "1.80615078449e-09\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.0-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7621951219512195\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.32923832923832924\n",
      "Original f1: 0.1484375\n",
      "0.125935643219\n",
      "0.977222414098\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 151\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8390    0.8726    0.8555       926\n",
      "          1     0.3622    0.3018    0.3292       222\n",
      "\n",
      "avg / total     0.7468    0.7622    0.7537      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7903757415952538\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.445993031358885\n",
      "Original f1: 0.31182795698924726\n",
      "0.12770056945\n",
      "0.985480375883\n",
      "318\n",
      "0.209624258405\n",
      "Number of disagreement: 202\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8729    0.8686    0.8707      1233\n",
      "          1     0.4414    0.4507    0.4460       284\n",
      "\n",
      "avg / total     0.7921    0.7904    0.7912      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.0-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "4.71509833793e-05\n",
      "0.0541293099574\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8352010547132498\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.34210526315789475\n",
      "Original f1: 0.31182795698924726\n",
      "0.00425456177387\n",
      "0.914491839452\n",
      "250\n",
      "0.164798945287\n",
      "Number of disagreement: 8\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8459    0.9749    0.9058      1233\n",
      "          1     0.6771    0.2289    0.3421       284\n",
      "\n",
      "avg / total     0.8143    0.8352    0.8003      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.0-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.759581881533101\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.34285714285714286\n",
      "Original f1: 0.1484375\n",
      "0.134912308969\n",
      "0.977222413911\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 164\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8421    0.8639    0.8529       926\n",
      "          1     0.3636    0.3243    0.3429       222\n",
      "\n",
      "avg / total     0.7496    0.7596    0.7543      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7818061964403428\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44182124789207416\n",
      "Original f1: 0.31182795698924726\n",
      "0.139207177005\n",
      "0.988402053887\n",
      "331\n",
      "0.21819380356\n",
      "Number of disagreement: 221\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8733    0.8556    0.8644      1233\n",
      "          1     0.4239    0.4613    0.4418       284\n",
      "\n",
      "avg / total     0.7892    0.7818    0.7853      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.0-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8222996515679443\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.25547445255474455\n",
      "Original f1: 0.1484375\n",
      "0.0122577423541\n",
      "0.953311608429\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 18\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8294    0.9816    0.8991       926\n",
      "          1     0.6731    0.1577    0.2555       222\n",
      "\n",
      "avg / total     0.7992    0.8223    0.7746      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8464073829927489\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4593967517401392\n",
      "Original f1: 0.31182795698924726\n",
      "0.0331328720964\n",
      "0.963170437849\n",
      "233\n",
      "0.153592617007\n",
      "Number of disagreement: 59\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8650    0.9611    0.9105      1233\n",
      "          1     0.6735    0.3486    0.4594       284\n",
      "\n",
      "avg / total     0.8291    0.8464    0.8260      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.0-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7604529616724739\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3498817966903073\n",
      "Original f1: 0.1484375\n",
      "0.140015137279\n",
      "0.986554666476\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 167\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8437    0.8629    0.8532       926\n",
      "          1     0.3682    0.3333    0.3499       222\n",
      "\n",
      "avg / total     0.7518    0.7605    0.7558      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7791694133157547\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44073455759599334\n",
      "Original f1: 0.31182795698924726\n",
      "0.144209039909\n",
      "0.98840205468\n",
      "335\n",
      "0.220830586684\n",
      "Number of disagreement: 227\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8735    0.8516    0.8624      1233\n",
      "          1     0.4190    0.4648    0.4407       284\n",
      "\n",
      "avg / total     0.7885    0.7792    0.7835      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.0-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8318815331010453\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.41337386018237077\n",
      "Original f1: 0.1484375\n",
      "0.0532954202557\n",
      "0.974713446683\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 73\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8521    0.9579    0.9019       926\n",
      "          1     0.6355    0.3063    0.4134       222\n",
      "\n",
      "avg / total     0.8102    0.8319    0.8074      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8220171390903098\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.468503937007874\n",
      "Original f1: 0.31182795698924726\n",
      "0.0781299205616\n",
      "0.985480374224\n",
      "270\n",
      "0.17798286091\n",
      "Number of disagreement: 136\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8724    0.9148    0.8931      1233\n",
      "          1     0.5312    0.4190    0.4685       284\n",
      "\n",
      "avg / total     0.8085    0.8220    0.8136      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.0-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7621951219512195\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3576470588235294\n",
      "Original f1: 0.1484375\n",
      "0.143508197406\n",
      "0.986554666934\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 169\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8455    0.8629    0.8541       926\n",
      "          1     0.3744    0.3423    0.3576       222\n",
      "\n",
      "avg / total     0.7544    0.7622    0.7581      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7791694133157547\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44073455759599334\n",
      "Original f1: 0.31182795698924726\n",
      "0.145240221296\n",
      "0.990344468446\n",
      "335\n",
      "0.220830586684\n",
      "Number of disagreement: 227\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8735    0.8516    0.8624      1233\n",
      "          1     0.4190    0.4648    0.4407       284\n",
      "\n",
      "avg / total     0.7885    0.7792    0.7835      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.0-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8031358885017421\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3924731182795699\n",
      "Original f1: 0.1484375\n",
      "0.0888444687175\n",
      "0.974713447718\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 116\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8507    0.9168    0.8825       926\n",
      "          1     0.4867    0.3288    0.3925       222\n",
      "\n",
      "avg / total     0.7803    0.8031    0.7878      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8042188529993408\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.46292947558770337\n",
      "Original f1: 0.31182795698924726\n",
      "0.106662046791\n",
      "0.98548037547\n",
      "297\n",
      "0.195781147001\n",
      "Number of disagreement: 181\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8750    0.8856    0.8803      1233\n",
      "          1     0.4758    0.4507    0.4629       284\n",
      "\n",
      "avg / total     0.8003    0.8042    0.8022      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.0-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7587108013937283\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35431235431235436\n",
      "Original f1: 0.1484375\n",
      "0.146255872378\n",
      "0.986554666722\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 173\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8448    0.8585    0.8516       926\n",
      "          1     0.3671    0.3423    0.3543       222\n",
      "\n",
      "avg / total     0.7525    0.7587    0.7555      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7791694133157547\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4425956738768719\n",
      "Original f1: 0.31182795698924726\n",
      "0.146923573687\n",
      "0.990344468262\n",
      "335\n",
      "0.220830586684\n",
      "Number of disagreement: 229\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8742    0.8508    0.8623      1233\n",
      "          1     0.4196    0.4683    0.4426       284\n",
      "\n",
      "avg / total     0.7891    0.7792    0.7837      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.0-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "1.48003947162e-12\n",
      "5.69427473923e-11\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.35912352291e-12\n",
      "9.42208672194e-11\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.0-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "2.61585896672e-11\n",
      "3.07643466257e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.46697736838e-11\n",
      "2.28518842738e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.0-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "3.55726527739e-12\n",
      "1.23637877714e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "2.41798168273e-12\n",
      "1.03228703363e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.0-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3076923076923077\n",
      "Original f1: 0.1484375\n",
      "0.110342168002\n",
      "0.975701884052\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 134\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8347    0.8834    0.8583       926\n",
      "          1     0.3571    0.2703    0.3077       222\n",
      "\n",
      "avg / total     0.7423    0.7648    0.7519      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7943309162821358\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44285714285714284\n",
      "Original f1: 0.31182795698924726\n",
      "0.120971665497\n",
      "0.985480375655\n",
      "312\n",
      "0.205669083718\n",
      "Number of disagreement: 188\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8711    0.8767    0.8739      1233\n",
      "          1     0.4493    0.4366    0.4429       284\n",
      "\n",
      "avg / total     0.7921    0.7943    0.7932      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.0-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "6.79274927628e-12\n",
      "3.86998266766e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "7.07547260431e-12\n",
      "1.80615078449e-09\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.0-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7630662020905923\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3300492610837439\n",
      "Original f1: 0.1484375\n",
      "0.126682314132\n",
      "0.977222413953\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 150\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8392    0.8737    0.8561       926\n",
      "          1     0.3641    0.3018    0.3300       222\n",
      "\n",
      "avg / total     0.7473    0.7631    0.7544      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7916941331575478\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44755244755244755\n",
      "Original f1: 0.31182795698924726\n",
      "0.129099300786\n",
      "0.985480375876\n",
      "316\n",
      "0.208305866842\n",
      "Number of disagreement: 200\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8731    0.8702    0.8716      1233\n",
      "          1     0.4444    0.4507    0.4476       284\n",
      "\n",
      "avg / total     0.7928    0.7917    0.7923      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.0-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "1.76989500883e-06\n",
      "0.00203181970047\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8352010547132498\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.34210526315789475\n",
      "Original f1: 0.31182795698924726\n",
      "0.003545919319\n",
      "0.790454225484\n",
      "250\n",
      "0.164798945287\n",
      "Number of disagreement: 8\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8459    0.9749    0.9058      1233\n",
      "          1     0.6771    0.2289    0.3421       284\n",
      "\n",
      "avg / total     0.8143    0.8352    0.8003      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.0-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7604529616724739\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3436754176610978\n",
      "Original f1: 0.1484375\n",
      "0.135686936509\n",
      "0.977222413472\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 163\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8423    0.8650    0.8535       926\n",
      "          1     0.3655    0.3243    0.3437       222\n",
      "\n",
      "avg / total     0.7501    0.7605    0.7549      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7831245880026367\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4433164128595601\n",
      "Original f1: 0.31182795698924726\n",
      "0.140713612055\n",
      "0.9884020536\n",
      "329\n",
      "0.216875411997\n",
      "Number of disagreement: 219\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8736    0.8573    0.8653      1233\n",
      "          1     0.4267    0.4613    0.4433       284\n",
      "\n",
      "avg / total     0.7899    0.7831    0.7863      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.0-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8214285714285714\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.24908424908424906\n",
      "Original f1: 0.1484375\n",
      "0.0123445024649\n",
      "0.969711219162\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 17\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8286    0.9816    0.8987       926\n",
      "          1     0.6667    0.1532    0.2491       222\n",
      "\n",
      "avg / total     0.7973    0.8214    0.7730      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8470665787738958\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.45794392523364486\n",
      "Original f1: 0.31182795698924726\n",
      "0.0319067489574\n",
      "0.963170436101\n",
      "232\n",
      "0.152933421226\n",
      "Number of disagreement: 56\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8645    0.9627    0.9110      1233\n",
      "          1     0.6806    0.3451    0.4579       284\n",
      "\n",
      "avg / total     0.8301    0.8471    0.8262      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.0-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7613240418118467\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3507109004739336\n",
      "Original f1: 0.1484375\n",
      "0.140919333402\n",
      "0.986554666401\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 166\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8439    0.8639    0.8538       926\n",
      "          1     0.3700    0.3333    0.3507       222\n",
      "\n",
      "avg / total     0.7522    0.7613    0.7565      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7804878048780488\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44221105527638194\n",
      "Original f1: 0.31182795698924726\n",
      "0.145572739298\n",
      "0.988402054927\n",
      "333\n",
      "0.219512195122\n",
      "Number of disagreement: 225\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8738    0.8532    0.8634      1233\n",
      "          1     0.4217    0.4648    0.4422       284\n",
      "\n",
      "avg / total     0.7891    0.7805    0.7845      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.0-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8318815331010453\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.41337386018237077\n",
      "Original f1: 0.1484375\n",
      "0.0533310735993\n",
      "0.974713447749\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 73\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8521    0.9579    0.9019       926\n",
      "          1     0.6355    0.3063    0.4134       222\n",
      "\n",
      "avg / total     0.8102    0.8319    0.8074      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8226763348714569\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.46942800788954636\n",
      "Original f1: 0.31182795698924726\n",
      "0.0786803776552\n",
      "0.985480372204\n",
      "269\n",
      "0.177323665129\n",
      "Number of disagreement: 135\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8725    0.9157    0.8935      1233\n",
      "          1     0.5336    0.4190    0.4694       284\n",
      "\n",
      "avg / total     0.8091    0.8227    0.8141      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.0-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7630662020905923\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35849056603773594\n",
      "Original f1: 0.1484375\n",
      "0.144336008998\n",
      "0.986554666976\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 168\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8457    0.8639    0.8547       926\n",
      "          1     0.3762    0.3423    0.3585       222\n",
      "\n",
      "avg / total     0.7549    0.7631    0.7587      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7804878048780488\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44221105527638194\n",
      "Original f1: 0.31182795698924726\n",
      "0.146579578287\n",
      "0.990344467774\n",
      "333\n",
      "0.219512195122\n",
      "Number of disagreement: 225\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8738    0.8532    0.8634      1233\n",
      "          1     0.4217    0.4648    0.4422       284\n",
      "\n",
      "avg / total     0.7891    0.7805    0.7845      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.0-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8013937282229965\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3903743315508021\n",
      "Original f1: 0.1484375\n",
      "0.0897241321015\n",
      "0.986554638058\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 118\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8504    0.9147    0.8814       926\n",
      "          1     0.4803    0.3288    0.3904       222\n",
      "\n",
      "avg / total     0.7788    0.8014    0.7864      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8048780487804879\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.463768115942029\n",
      "Original f1: 0.31182795698924726\n",
      "0.10660294698\n",
      "0.985480375752\n",
      "296\n",
      "0.19512195122\n",
      "Number of disagreement: 180\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8751    0.8865    0.8807      1233\n",
      "          1     0.4776    0.4507    0.4638       284\n",
      "\n",
      "avg / total     0.8007    0.8049    0.8027      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.0-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.759581881533101\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3551401869158879\n",
      "Original f1: 0.1484375\n",
      "0.147090668302\n",
      "0.986554666758\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 172\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8450    0.8596    0.8522       926\n",
      "          1     0.3689    0.3423    0.3551       222\n",
      "\n",
      "avg / total     0.7529    0.7596    0.7561      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7804878048780488\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44407345575959933\n",
      "Original f1: 0.31182795698924726\n",
      "0.148294391752\n",
      "0.990344467674\n",
      "333\n",
      "0.219512195122\n",
      "Number of disagreement: 227\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8744    0.8524    0.8632      1233\n",
      "          1     0.4222    0.4683    0.4441       284\n",
      "\n",
      "avg / total     0.7897    0.7805    0.7848      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.5-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "1.58431788999e-12\n",
      "5.10455566705e-11\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.38984387588e-12\n",
      "8.95583919525e-11\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.5-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "2.32925260785e-11\n",
      "2.80959561172e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "2.90707544511e-11\n",
      "6.39296948712e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.5-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "3.36812068841e-12\n",
      "7.28656579518e-11\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "2.43708246792e-12\n",
      "2.26777763235e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.5-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7656794425087108\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.31202046035805625\n",
      "Original f1: 0.1484375\n",
      "0.112780163869\n",
      "0.977222407532\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 135\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8355    0.8834    0.8588       926\n",
      "          1     0.3609    0.2748    0.3120       222\n",
      "\n",
      "avg / total     0.7438    0.7657    0.7531      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7930125247198417\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4412811387900356\n",
      "Original f1: 0.31182795698924726\n",
      "0.121255991473\n",
      "0.985480375696\n",
      "314\n",
      "0.20698747528\n",
      "Number of disagreement: 190\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8709    0.8751    0.8730      1233\n",
      "          1     0.4460    0.4366    0.4413       284\n",
      "\n",
      "avg / total     0.7913    0.7930    0.7922      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.5-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "6.05066589197e-12\n",
      "2.43314979276e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "6.9802124842e-12\n",
      "1.90631987973e-09\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.5-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7613240418118467\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.32843137254901966\n",
      "Original f1: 0.1484375\n",
      "0.128047546357\n",
      "0.977222413654\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 152\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8389    0.8715    0.8549       926\n",
      "          1     0.3602    0.3018    0.3284       222\n",
      "\n",
      "avg / total     0.7463    0.7613    0.7531      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7903757415952538\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.445993031358885\n",
      "Original f1: 0.31182795698924726\n",
      "0.129057064094\n",
      "0.985480375875\n",
      "318\n",
      "0.209624258405\n",
      "Number of disagreement: 202\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8729    0.8686    0.8707      1233\n",
      "          1     0.4414    0.4507    0.4460       284\n",
      "\n",
      "avg / total     0.7921    0.7904    0.7912      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.5-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "4.77281185892e-05\n",
      "0.0547918584049\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8352010547132498\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.34210526315789475\n",
      "Original f1: 0.31182795698924726\n",
      "0.00435756086003\n",
      "0.899363862732\n",
      "250\n",
      "0.164798945287\n",
      "Number of disagreement: 8\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8459    0.9749    0.9058      1233\n",
      "          1     0.6771    0.2289    0.3421       284\n",
      "\n",
      "avg / total     0.8143    0.8352    0.8003      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.5-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.759581881533101\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.34285714285714286\n",
      "Original f1: 0.1484375\n",
      "0.136784774889\n",
      "0.977222414015\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 164\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8421    0.8639    0.8529       926\n",
      "          1     0.3636    0.3243    0.3429       222\n",
      "\n",
      "avg / total     0.7496    0.7596    0.7543      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7818061964403428\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44182124789207416\n",
      "Original f1: 0.31182795698924726\n",
      "0.140689722704\n",
      "0.988402054354\n",
      "331\n",
      "0.21819380356\n",
      "Number of disagreement: 221\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8733    0.8556    0.8644      1233\n",
      "          1     0.4239    0.4613    0.4418       284\n",
      "\n",
      "avg / total     0.7892    0.7818    0.7853      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.5-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8214285714285714\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.24908424908424906\n",
      "Original f1: 0.1484375\n",
      "0.011669478741\n",
      "0.912734130291\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 17\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8286    0.9816    0.8987       926\n",
      "          1     0.6667    0.1532    0.2491       222\n",
      "\n",
      "avg / total     0.7973    0.8214    0.7730      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8477257745550428\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4640371229698376\n",
      "Original f1: 0.31182795698924726\n",
      "0.0327037988397\n",
      "0.968187442842\n",
      "231\n",
      "0.152274225445\n",
      "Number of disagreement: 59\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8657    0.9619    0.9113      1233\n",
      "          1     0.6803    0.3521    0.4640       284\n",
      "\n",
      "avg / total     0.8310    0.8477    0.8275      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.5-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.759581881533101\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3490566037735849\n",
      "Original f1: 0.1484375\n",
      "0.142299485002\n",
      "0.986554665152\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 168\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8436    0.8618    0.8526       926\n",
      "          1     0.3663    0.3333    0.3491       222\n",
      "\n",
      "avg / total     0.7513    0.7596    0.7552      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7798286090969018\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44147157190635455\n",
      "Original f1: 0.31182795698924726\n",
      "0.145562848608\n",
      "0.988402054791\n",
      "334\n",
      "0.220171390903\n",
      "Number of disagreement: 226\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8736    0.8524    0.8629      1233\n",
      "          1     0.4204    0.4648    0.4415       284\n",
      "\n",
      "avg / total     0.7888    0.7798    0.7840      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.5-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8310104529616724\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.4121212121212121\n",
      "Original f1: 0.1484375\n",
      "0.0531967483801\n",
      "0.974713448205\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 74\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8519    0.9568    0.9013       926\n",
      "          1     0.6296    0.3063    0.4121       222\n",
      "\n",
      "avg / total     0.8089    0.8310    0.8067      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8206987475280159\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4666666666666667\n",
      "Original f1: 0.31182795698924726\n",
      "0.0798157095446\n",
      "0.985480368742\n",
      "272\n",
      "0.179301252472\n",
      "Number of disagreement: 138\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8722    0.9132    0.8922      1233\n",
      "          1     0.5265    0.4190    0.4667       284\n",
      "\n",
      "avg / total     0.8075    0.8207    0.8126      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.5-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7613240418118467\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3568075117370892\n",
      "Original f1: 0.1484375\n",
      "0.145469855561\n",
      "0.98655466703\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 170\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8453    0.8618    0.8535       926\n",
      "          1     0.3725    0.3423    0.3568       222\n",
      "\n",
      "avg / total     0.7539    0.7613    0.7574      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7798286090969018\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44147157190635455\n",
      "Original f1: 0.31182795698924726\n",
      "0.146487667387\n",
      "0.990344467547\n",
      "334\n",
      "0.220171390903\n",
      "Number of disagreement: 226\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8736    0.8524    0.8629      1233\n",
      "          1     0.4204    0.4648    0.4415       284\n",
      "\n",
      "avg / total     0.7888    0.7798    0.7840      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.5-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8005226480836237\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3893333333333333\n",
      "Original f1: 0.1484375\n",
      "0.0903429858926\n",
      "0.986554651144\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 119\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8503    0.9136    0.8808       926\n",
      "          1     0.4771    0.3288    0.3893       222\n",
      "\n",
      "avg / total     0.7781    0.8005    0.7858      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8022412656558998\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4584837545126354\n",
      "Original f1: 0.31182795698924726\n",
      "0.107221667878\n",
      "0.985480372438\n",
      "300\n",
      "0.197758734344\n",
      "Number of disagreement: 182\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8741    0.8840    0.8790      1233\n",
      "          1     0.4704    0.4472    0.4585       284\n",
      "\n",
      "avg / total     0.7985    0.8022    0.8003      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.5-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7578397212543554\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35348837209302325\n",
      "Original f1: 0.1484375\n",
      "0.148497541963\n",
      "0.986554666658\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 174\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8447    0.8575    0.8510       926\n",
      "          1     0.3654    0.3423    0.3535       222\n",
      "\n",
      "avg / total     0.7520    0.7578    0.7548      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7791694133157547\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4425956738768719\n",
      "Original f1: 0.31182795698924726\n",
      "0.148224172251\n",
      "0.99034446854\n",
      "335\n",
      "0.220830586684\n",
      "Number of disagreement: 229\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8742    0.8508    0.8623      1233\n",
      "          1     0.4196    0.4683    0.4426       284\n",
      "\n",
      "avg / total     0.7891    0.7792    0.7837      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.5-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "1.60873042983e-12\n",
      "5.10455566705e-11\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.19179976145e-12\n",
      "8.95583919525e-11\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.5-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "3.20135770375e-11\n",
      "3.2733200872e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.50544898809e-11\n",
      "2.26548231563e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.5-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "2.80900165812e-12\n",
      "7.1464278939e-11\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "2.55237914961e-12\n",
      "2.26777763235e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.5-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3112244897959184\n",
      "Original f1: 0.1484375\n",
      "0.113519474448\n",
      "0.9757018849\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 136\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8354    0.8823    0.8582       926\n",
      "          1     0.3588    0.2748    0.3112       222\n",
      "\n",
      "avg / total     0.7432    0.7648    0.7524      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7936717205009888\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4420677361853832\n",
      "Original f1: 0.31182795698924726\n",
      "0.122568199474\n",
      "0.98548037589\n",
      "313\n",
      "0.206328279499\n",
      "Number of disagreement: 189\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8710    0.8759    0.8734      1233\n",
      "          1     0.4477    0.4366    0.4421       284\n",
      "\n",
      "avg / total     0.7917    0.7937    0.7927      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.5-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "4.90098713645e-12\n",
      "1.8833351545e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "8.40826933595e-12\n",
      "1.90631987973e-09\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.5-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7621951219512195\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.32923832923832924\n",
      "Original f1: 0.1484375\n",
      "0.12888788657\n",
      "0.977222413675\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 151\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8390    0.8726    0.8555       926\n",
      "          1     0.3622    0.3018    0.3292       222\n",
      "\n",
      "avg / total     0.7468    0.7622    0.7537      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7903757415952538\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.445993031358885\n",
      "Original f1: 0.31182795698924726\n",
      "0.13084087386\n",
      "0.988402029468\n",
      "318\n",
      "0.209624258405\n",
      "Number of disagreement: 202\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8729    0.8686    0.8707      1233\n",
      "          1     0.4414    0.4507    0.4460       284\n",
      "\n",
      "avg / total     0.7921    0.7904    0.7912      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.5-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "2.27535651727e-11\n",
      "1.1358311236e-08\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8358602504943968\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.3464566929133858\n",
      "Original f1: 0.31182795698924726\n",
      "0.00351919519192\n",
      "0.739770550841\n",
      "249\n",
      "0.164139749506\n",
      "Number of disagreement: 9\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8465    0.9749    0.9061      1233\n",
      "          1     0.6804    0.2324    0.3465       284\n",
      "\n",
      "avg / total     0.8154    0.8359    0.8014      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.5-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7604529616724739\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3436754176610978\n",
      "Original f1: 0.1484375\n",
      "0.137759852356\n",
      "0.986554654679\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 163\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8423    0.8650    0.8535       926\n",
      "          1     0.3655    0.3243    0.3437       222\n",
      "\n",
      "avg / total     0.7501    0.7605    0.7549      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7824653922214898\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4425675675675676\n",
      "Original f1: 0.31182795698924726\n",
      "0.142369961253\n",
      "0.988402054653\n",
      "330\n",
      "0.217534607779\n",
      "Number of disagreement: 220\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8734    0.8564    0.8649      1233\n",
      "          1     0.4253    0.4613    0.4426       284\n",
      "\n",
      "avg / total     0.7896    0.7825    0.7858      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.5-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8205574912891986\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.2426470588235294\n",
      "Original f1: 0.1484375\n",
      "0.0114955218515\n",
      "0.894827139508\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 16\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8279    0.9816    0.8982       926\n",
      "          1     0.6600    0.1486    0.2426       222\n",
      "\n",
      "avg / total     0.7954    0.8206    0.7714      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8457481872116018\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.45070422535211263\n",
      "Original f1: 0.31182795698924726\n",
      "0.0310587217157\n",
      "0.968187444151\n",
      "234\n",
      "0.154251812788\n",
      "Number of disagreement: 54\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8633    0.9627    0.9103      1233\n",
      "          1     0.6761    0.3380    0.4507       284\n",
      "\n",
      "avg / total     0.8282    0.8457    0.8242      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.5-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7604529616724739\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3498817966903073\n",
      "Original f1: 0.1484375\n",
      "0.143411253021\n",
      "0.98655466537\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 167\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8437    0.8629    0.8532       926\n",
      "          1     0.3682    0.3333    0.3499       222\n",
      "\n",
      "avg / total     0.7518    0.7605    0.7558      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7804878048780488\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44221105527638194\n",
      "Original f1: 0.31182795698924726\n",
      "0.14719433223\n",
      "0.988402054948\n",
      "333\n",
      "0.219512195122\n",
      "Number of disagreement: 225\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8738    0.8532    0.8634      1233\n",
      "          1     0.4217    0.4648    0.4422       284\n",
      "\n",
      "avg / total     0.7891    0.7805    0.7845      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.5-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8318815331010453\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.41337386018237077\n",
      "Original f1: 0.1484375\n",
      "0.0534086985962\n",
      "0.974713448065\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 73\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8521    0.9579    0.9019       926\n",
      "          1     0.6355    0.3063    0.4134       222\n",
      "\n",
      "avg / total     0.8102    0.8319    0.8074      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8193803559657218\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.46484374999999994\n",
      "Original f1: 0.31182795698924726\n",
      "0.0801066339028\n",
      "0.985480373047\n",
      "274\n",
      "0.180619644034\n",
      "Number of disagreement: 140\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8720    0.9116    0.8914      1233\n",
      "          1     0.5219    0.4190    0.4648       284\n",
      "\n",
      "avg / total     0.8065    0.8194    0.8115      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.5-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7621951219512195\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3576470588235294\n",
      "Original f1: 0.1484375\n",
      "0.146537957072\n",
      "0.986554667037\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 169\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8455    0.8629    0.8541       926\n",
      "          1     0.3744    0.3423    0.3576       222\n",
      "\n",
      "avg / total     0.7544    0.7622    0.7581      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7804878048780488\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44221105527638194\n",
      "Original f1: 0.31182795698924726\n",
      "0.148046222053\n",
      "0.99034446821\n",
      "333\n",
      "0.219512195122\n",
      "Number of disagreement: 225\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8738    0.8532    0.8634      1233\n",
      "          1     0.4217    0.4648    0.4422       284\n",
      "\n",
      "avg / total     0.7891    0.7805    0.7845      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.5-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7987804878048781\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.38400000000000006\n",
      "Original f1: 0.1484375\n",
      "0.0909126199119\n",
      "0.986554665452\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 119\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8492    0.9125    0.8798       926\n",
      "          1     0.4706    0.3243    0.3840       222\n",
      "\n",
      "avg / total     0.7760    0.7988    0.7839      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8029004614370469\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4593128390596745\n",
      "Original f1: 0.31182795698924726\n",
      "0.107323891196\n",
      "0.985480375059\n",
      "299\n",
      "0.197099538563\n",
      "Number of disagreement: 181\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8742    0.8848    0.8795      1233\n",
      "          1     0.4721    0.4472    0.4593       284\n",
      "\n",
      "avg / total     0.7989    0.8029    0.8008      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-1.5-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7587108013937283\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35431235431235436\n",
      "Original f1: 0.1484375\n",
      "0.149526419663\n",
      "0.986554666497\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 173\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8448    0.8585    0.8516       926\n",
      "          1     0.3671    0.3423    0.3543       222\n",
      "\n",
      "avg / total     0.7525    0.7587    0.7555      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7798286090969018\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44333333333333336\n",
      "Original f1: 0.31182795698924726\n",
      "0.149814084642\n",
      "0.990344468035\n",
      "334\n",
      "0.220171390903\n",
      "Number of disagreement: 228\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8743    0.8516    0.8628      1233\n",
      "          1     0.4209    0.4683    0.4433       284\n",
      "\n",
      "avg / total     0.7894    0.7798    0.7843      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-2.0-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "1.495942197e-12\n",
      "5.10455566705e-11\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.28976324626e-12\n",
      "8.95583850136e-11\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-2.0-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "2.88736851949e-11\n",
      "2.98223820638e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.6116187384e-11\n",
      "2.26548106663e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-2.0-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "3.0431008595e-12\n",
      "7.398533175e-11\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "2.11225815116e-12\n",
      "8.95583850136e-11\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-2.0-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7656794425087108\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.31202046035805625\n",
      "Original f1: 0.1484375\n",
      "0.113719633974\n",
      "0.977222404246\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 135\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8355    0.8834    0.8588       926\n",
      "          1     0.3609    0.2748    0.3120       222\n",
      "\n",
      "avg / total     0.7438    0.7657    0.7531      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7930125247198417\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4412811387900356\n",
      "Original f1: 0.31182795698924726\n",
      "0.121705335159\n",
      "0.98548037584\n",
      "314\n",
      "0.20698747528\n",
      "Number of disagreement: 190\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8709    0.8751    0.8730      1233\n",
      "          1     0.4460    0.4366    0.4413       284\n",
      "\n",
      "avg / total     0.7913    0.7930    0.7922      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-2.0-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "5.16633144421e-12\n",
      "2.08657924272e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "5.76620749839e-12\n",
      "1.42587767982e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-2.0-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7613240418118467\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.32843137254901966\n",
      "Original f1: 0.1484375\n",
      "0.128837582416\n",
      "0.977222412978\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 152\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8389    0.8715    0.8549       926\n",
      "          1     0.3602    0.3018    0.3284       222\n",
      "\n",
      "avg / total     0.7463    0.7613    0.7531      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7903757415952538\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.445993031358885\n",
      "Original f1: 0.31182795698924726\n",
      "0.129599786174\n",
      "0.985480375783\n",
      "318\n",
      "0.209624258405\n",
      "Number of disagreement: 202\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8729    0.8686    0.8707      1233\n",
      "          1     0.4414    0.4507    0.4460       284\n",
      "\n",
      "avg / total     0.7921    0.7904    0.7912      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-2.0-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "4.77289631957e-05\n",
      "0.054792835285\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8352010547132498\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.34210526315789475\n",
      "Original f1: 0.31182795698924726\n",
      "0.00437926705621\n",
      "0.884172838198\n",
      "250\n",
      "0.164798945287\n",
      "Number of disagreement: 8\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8459    0.9749    0.9058      1233\n",
      "          1     0.6771    0.2289    0.3421       284\n",
      "\n",
      "avg / total     0.8143    0.8352    0.8003      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-2.0-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.759581881533101\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.34285714285714286\n",
      "Original f1: 0.1484375\n",
      "0.137486632963\n",
      "0.977222413928\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 164\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8421    0.8639    0.8529       926\n",
      "          1     0.3636    0.3243    0.3429       222\n",
      "\n",
      "avg / total     0.7496    0.7596    0.7543      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7818061964403428\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44182124789207416\n",
      "Original f1: 0.31182795698924726\n",
      "0.141176140255\n",
      "0.988402053993\n",
      "331\n",
      "0.21819380356\n",
      "Number of disagreement: 221\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8733    0.8556    0.8644      1233\n",
      "          1     0.4239    0.4613    0.4418       284\n",
      "\n",
      "avg / total     0.7892    0.7818    0.7853      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-2.0-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8205574912891986\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.2426470588235294\n",
      "Original f1: 0.1484375\n",
      "0.0113850549534\n",
      "0.889449887814\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 16\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8279    0.9816    0.8982       926\n",
      "          1     0.6600    0.1486    0.2426       222\n",
      "\n",
      "avg / total     0.7954    0.8206    0.7714      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8457481872116018\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4558139534883721\n",
      "Original f1: 0.31182795698924726\n",
      "0.0325209012263\n",
      "0.968187395209\n",
      "234\n",
      "0.154251812788\n",
      "Number of disagreement: 58\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8643    0.9611    0.9101      1233\n",
      "          1     0.6712    0.3451    0.4558       284\n",
      "\n",
      "avg / total     0.8282    0.8457    0.8251      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-2.0-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.759581881533101\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3490566037735849\n",
      "Original f1: 0.1484375\n",
      "0.143193460508\n",
      "0.986554665146\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 168\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8436    0.8618    0.8526       926\n",
      "          1     0.3663    0.3333    0.3491       222\n",
      "\n",
      "avg / total     0.7513    0.7596    0.7552      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7798286090969018\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44147157190635455\n",
      "Original f1: 0.31182795698924726\n",
      "0.146047526711\n",
      "0.988402054742\n",
      "334\n",
      "0.220171390903\n",
      "Number of disagreement: 226\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8736    0.8524    0.8629      1233\n",
      "          1     0.4204    0.4648    0.4415       284\n",
      "\n",
      "avg / total     0.7888    0.7798    0.7840      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-2.0-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8318815331010453\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.41337386018237077\n",
      "Original f1: 0.1484375\n",
      "0.0529412639698\n",
      "0.974713447993\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 73\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8521    0.9579    0.9019       926\n",
      "          1     0.6355    0.3063    0.4134       222\n",
      "\n",
      "avg / total     0.8102    0.8319    0.8074      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8193803559657218\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.46484374999999994\n",
      "Original f1: 0.31182795698924726\n",
      "0.0803583241987\n",
      "0.985480362499\n",
      "274\n",
      "0.180619644034\n",
      "Number of disagreement: 140\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8720    0.9116    0.8914      1233\n",
      "          1     0.5219    0.4190    0.4648       284\n",
      "\n",
      "avg / total     0.8065    0.8194    0.8115      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-2.0-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7613240418118467\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3568075117370892\n",
      "Original f1: 0.1484375\n",
      "0.146256544054\n",
      "0.986554667034\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 170\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8453    0.8618    0.8535       926\n",
      "          1     0.3725    0.3423    0.3568       222\n",
      "\n",
      "avg / total     0.7539    0.7613    0.7574      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7798286090969018\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44147157190635455\n",
      "Original f1: 0.31182795698924726\n",
      "0.146929153528\n",
      "0.990344466929\n",
      "334\n",
      "0.220171390903\n",
      "Number of disagreement: 226\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8736    0.8524    0.8629      1233\n",
      "          1     0.4204    0.4648    0.4415       284\n",
      "\n",
      "avg / total     0.7888    0.7798    0.7840      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-2.0-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8005226480836237\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3893333333333333\n",
      "Original f1: 0.1484375\n",
      "0.0907790414708\n",
      "0.986554666186\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 119\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8503    0.9136    0.8808       926\n",
      "          1     0.4771    0.3288    0.3893       222\n",
      "\n",
      "avg / total     0.7781    0.8005    0.7858      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8022412656558998\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4584837545126354\n",
      "Original f1: 0.31182795698924726\n",
      "0.107519161369\n",
      "0.985480375731\n",
      "300\n",
      "0.197758734344\n",
      "Number of disagreement: 182\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8741    0.8840    0.8790      1233\n",
      "          1     0.4704    0.4472    0.4585       284\n",
      "\n",
      "avg / total     0.7985    0.8022    0.8003      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-2.0-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7578397212543554\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35348837209302325\n",
      "Original f1: 0.1484375\n",
      "0.149360281468\n",
      "0.986554666565\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 174\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8447    0.8575    0.8510       926\n",
      "          1     0.3654    0.3423    0.3535       222\n",
      "\n",
      "avg / total     0.7520    0.7578    0.7548      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7791694133157547\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4425956738768719\n",
      "Original f1: 0.31182795698924726\n",
      "0.148685921891\n",
      "0.990344468048\n",
      "335\n",
      "0.220830586684\n",
      "Number of disagreement: 229\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8742    0.8508    0.8623      1233\n",
      "          1     0.4196    0.4683    0.4426       284\n",
      "\n",
      "avg / total     0.7891    0.7792    0.7837      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-2.0-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "1.58239264915e-12\n",
      "5.10455566705e-11\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.40027364063e-12\n",
      "8.95583850136e-11\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-2.0-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "1.58157992984e-11\n",
      "2.08718292649e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.78196099006e-11\n",
      "2.74067213368e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-2.0-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "2.84436649248e-12\n",
      "7.398533175e-11\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "2.17862914705e-12\n",
      "8.95583850136e-11\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-2.0-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3112244897959184\n",
      "Original f1: 0.1484375\n",
      "0.114536291613\n",
      "0.975701884666\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 136\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8354    0.8823    0.8582       926\n",
      "          1     0.3588    0.2748    0.3112       222\n",
      "\n",
      "avg / total     0.7432    0.7648    0.7524      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7923533289386948\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4385026737967914\n",
      "Original f1: 0.31182795698924726\n",
      "0.123137884412\n",
      "0.985480375751\n",
      "315\n",
      "0.207646671061\n",
      "Number of disagreement: 189\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8702    0.8751    0.8726      1233\n",
      "          1     0.4440    0.4331    0.4385       284\n",
      "\n",
      "avg / total     0.7904    0.7924    0.7914      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-2.0-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "4.66201750851e-12\n",
      "1.85615300907e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "4.66972893601e-12\n",
      "1.42704584261e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-2.0-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7621951219512195\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.32923832923832924\n",
      "Original f1: 0.1484375\n",
      "0.129755784288\n",
      "0.977222412518\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 151\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8390    0.8726    0.8555       926\n",
      "          1     0.3622    0.3018    0.3292       222\n",
      "\n",
      "avg / total     0.7468    0.7622    0.7537      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7903757415952538\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.445993031358885\n",
      "Original f1: 0.31182795698924726\n",
      "0.131519975164\n",
      "0.988402053254\n",
      "318\n",
      "0.209624258405\n",
      "Number of disagreement: 202\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8729    0.8686    0.8707      1233\n",
      "          1     0.4414    0.4507    0.4460       284\n",
      "\n",
      "avg / total     0.7921    0.7904    0.7912      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-2.0-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "1.8975485362e-11\n",
      "5.67338193092e-09\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8358602504943968\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.3464566929133858\n",
      "Original f1: 0.31182795698924726\n",
      "0.0034960939845\n",
      "0.72045161565\n",
      "249\n",
      "0.164139749506\n",
      "Number of disagreement: 9\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8465    0.9749    0.9061      1233\n",
      "          1     0.6804    0.2324    0.3465       284\n",
      "\n",
      "avg / total     0.8154    0.8359    0.8014      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-2.0-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7604529616724739\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3436754176610978\n",
      "Original f1: 0.1484375\n",
      "0.138515951173\n",
      "0.986554662206\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 163\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8423    0.8650    0.8535       926\n",
      "          1     0.3655    0.3243    0.3437       222\n",
      "\n",
      "avg / total     0.7501    0.7605    0.7549      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7824653922214898\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4425675675675676\n",
      "Original f1: 0.31182795698924726\n",
      "0.142956254322\n",
      "0.988402054236\n",
      "330\n",
      "0.217534607779\n",
      "Number of disagreement: 220\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8734    0.8564    0.8649      1233\n",
      "          1     0.4253    0.4613    0.4426       284\n",
      "\n",
      "avg / total     0.7896    0.7825    0.7858      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-2.0-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8196864111498258\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.23616236162361623\n",
      "Original f1: 0.1484375\n",
      "0.0111915360191\n",
      "0.857905743947\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 15\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8271    0.9816    0.8978       926\n",
      "          1     0.6531    0.1441    0.2362       222\n",
      "\n",
      "avg / total     0.7935    0.8197    0.7698      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8457481872116018\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.45070422535211263\n",
      "Original f1: 0.31182795698924726\n",
      "0.030609038791\n",
      "0.968187435151\n",
      "234\n",
      "0.154251812788\n",
      "Number of disagreement: 54\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8633    0.9627    0.9103      1233\n",
      "          1     0.6761    0.3380    0.4507       284\n",
      "\n",
      "avg / total     0.8282    0.8457    0.8242      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-2.0-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7604529616724739\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3498817966903073\n",
      "Original f1: 0.1484375\n",
      "0.144378223697\n",
      "0.986554665781\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 167\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8437    0.8629    0.8532       926\n",
      "          1     0.3682    0.3333    0.3499       222\n",
      "\n",
      "avg / total     0.7518    0.7605    0.7558      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7804878048780488\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44221105527638194\n",
      "Original f1: 0.31182795698924726\n",
      "0.147750833936\n",
      "0.990344451835\n",
      "333\n",
      "0.219512195122\n",
      "Number of disagreement: 225\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8738    0.8532    0.8634      1233\n",
      "          1     0.4217    0.4648    0.4422       284\n",
      "\n",
      "avg / total     0.7891    0.7805    0.7845      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-2.0-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8327526132404182\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.4146341463414634\n",
      "Original f1: 0.1484375\n",
      "0.0531053644064\n",
      "0.974713447866\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 72\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8522    0.9590    0.9024       926\n",
      "          1     0.6415    0.3063    0.4146       222\n",
      "\n",
      "avg / total     0.8115    0.8328    0.8081      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8193803559657218\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.46484374999999994\n",
      "Original f1: 0.31182795698924726\n",
      "0.0804640194149\n",
      "0.985480374906\n",
      "274\n",
      "0.180619644034\n",
      "Number of disagreement: 140\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8720    0.9116    0.8914      1233\n",
      "          1     0.5219    0.4190    0.4648       284\n",
      "\n",
      "avg / total     0.8065    0.8194    0.8115      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-2.0-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7621951219512195\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3576470588235294\n",
      "Original f1: 0.1484375\n",
      "0.147419195145\n",
      "0.986554667044\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 169\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8455    0.8629    0.8541       926\n",
      "          1     0.3744    0.3423    0.3576       222\n",
      "\n",
      "avg / total     0.7544    0.7622    0.7581      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7804878048780488\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44221105527638194\n",
      "Original f1: 0.31182795698924726\n",
      "0.148564689173\n",
      "0.990344467675\n",
      "333\n",
      "0.219512195122\n",
      "Number of disagreement: 225\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8738    0.8532    0.8634      1233\n",
      "          1     0.4217    0.4648    0.4422       284\n",
      "\n",
      "avg / total     0.7891    0.7805    0.7845      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-2.0-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7987804878048781\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.38400000000000006\n",
      "Original f1: 0.1484375\n",
      "0.0912591681253\n",
      "0.986554658814\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 119\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8492    0.9125    0.8798       926\n",
      "          1     0.4706    0.3243    0.3840       222\n",
      "\n",
      "avg / total     0.7760    0.7988    0.7839      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8035596572181938\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.46209386281588444\n",
      "Original f1: 0.31182795698924726\n",
      "0.107683072347\n",
      "0.985480374863\n",
      "298\n",
      "0.196440342782\n",
      "Number of disagreement: 182\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8749    0.8848    0.8798      1233\n",
      "          1     0.4741    0.4507    0.4621       284\n",
      "\n",
      "avg / total     0.7999    0.8036    0.8016      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.1-2.0-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7587108013937283\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35431235431235436\n",
      "Original f1: 0.1484375\n",
      "0.150439157945\n",
      "0.986554666445\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 173\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8448    0.8585    0.8516       926\n",
      "          1     0.3671    0.3423    0.3543       222\n",
      "\n",
      "avg / total     0.7525    0.7587    0.7555      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7798286090969018\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.44333333333333336\n",
      "Original f1: 0.31182795698924726\n",
      "0.150356084225\n",
      "0.990344467695\n",
      "334\n",
      "0.220171390903\n",
      "Number of disagreement: 228\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8743    0.8516    0.8628      1233\n",
      "          1     0.4209    0.4683    0.4433       284\n",
      "\n",
      "avg / total     0.7894    0.7798    0.7843      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.5-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "1.22275040672e-12\n",
      "7.0124128726e-11\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.02300270974e-12\n",
      "1.42315839669e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.5-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8066202090592335\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.12598425196850394\n",
      "Original f1: 0.1484375\n",
      "0.00285576093366\n",
      "0.180249187033\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 4\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8154    0.9827    0.8913       926\n",
      "          1     0.5000    0.0721    0.1260       222\n",
      "\n",
      "avg / total     0.7544    0.8066    0.7433      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8299274884640738\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.28729281767955805\n",
      "Original f1: 0.31182795698924726\n",
      "0.00535987056092\n",
      "0.239005813767\n",
      "258\n",
      "0.170072511536\n",
      "Number of disagreement: 10\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8388    0.9789    0.9034      1233\n",
      "          1     0.6667    0.1831    0.2873       284\n",
      "\n",
      "avg / total     0.8066    0.8299    0.7881      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.5-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "3.47388684976e-12\n",
      "4.28802715557e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "4.96068265393e-05\n",
      "0.0752535516892\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.5-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7839721254355401\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.31868131868131866\n",
      "Original f1: 0.1484375\n",
      "0.0868984291837\n",
      "0.974713448258\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 112\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8370    0.9093    0.8716       926\n",
      "          1     0.4085    0.2613    0.3187       222\n",
      "\n",
      "avg / total     0.7541    0.7840    0.7647      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7969676994067239\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.40077821011673154\n",
      "Original f1: 0.31182795698924726\n",
      "0.0959925953574\n",
      "0.978437990888\n",
      "308\n",
      "0.203032300593\n",
      "Number of disagreement: 164\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8594    0.8970    0.8778      1233\n",
      "          1     0.4478    0.3627    0.4008       284\n",
      "\n",
      "avg / total     0.7823    0.7970    0.7885      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.5-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "8.64243112842e-06\n",
      "0.00899731562011\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "0.000161129803823\n",
      "0.244433902879\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.5-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7752613240418118\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3246073298429319\n",
      "Original f1: 0.1484375\n",
      "0.102889519019\n",
      "0.97722241093\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 128\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8381    0.8942    0.8652       926\n",
      "          1     0.3875    0.2793    0.3246       222\n",
      "\n",
      "avg / total     0.7509    0.7753    0.7607      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7890573500329597\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4244604316546763\n",
      "Original f1: 0.31182795698924726\n",
      "0.117861107947\n",
      "0.985480375431\n",
      "320\n",
      "0.210942649967\n",
      "Number of disagreement: 206\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8667    0.8751    0.8709      1233\n",
      "          1     0.4338    0.4155    0.4245       284\n",
      "\n",
      "avg / total     0.7856    0.7891    0.7873      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.5-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "0.000510800197574\n",
      "0.177862045143\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8325642715886619\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.324468085106383\n",
      "Original f1: 0.31182795698924726\n",
      "0.00293512563413\n",
      "0.668391762682\n",
      "254\n",
      "0.167435728411\n",
      "Number of disagreement: 4\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8435    0.9749    0.9044      1233\n",
      "          1     0.6630    0.2148    0.3245       284\n",
      "\n",
      "avg / total     0.8097    0.8326    0.7959      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.5-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3509615384615385\n",
      "Original f1: 0.1484375\n",
      "0.123374076203\n",
      "0.977222414186\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 162\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8438    0.8693    0.8564       926\n",
      "          1     0.3763    0.3288    0.3510       222\n",
      "\n",
      "avg / total     0.7534    0.7648    0.7586      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7791694133157547\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4194107452339688\n",
      "Original f1: 0.31182795698924726\n",
      "0.132865065188\n",
      "0.985480375768\n",
      "335\n",
      "0.220830586684\n",
      "Number of disagreement: 227\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8668    0.8605    0.8637      1233\n",
      "          1     0.4130    0.4261    0.4194       284\n",
      "\n",
      "avg / total     0.7819    0.7792    0.7805      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.5-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8205574912891986\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.23703703703703705\n",
      "Original f1: 0.1484375\n",
      "0.00880136874511\n",
      "0.953311614333\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 14\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8273    0.9827    0.8983       926\n",
      "          1     0.6667    0.1441    0.2370       222\n",
      "\n",
      "avg / total     0.7962    0.8206    0.7704      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8398154251812788\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.3970223325062035\n",
      "Original f1: 0.31182795698924726\n",
      "0.0196421783815\n",
      "0.962322967176\n",
      "243\n",
      "0.160184574819\n",
      "Number of disagreement: 31\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8541    0.9684    0.9076      1233\n",
      "          1     0.6723    0.2817    0.3970       284\n",
      "\n",
      "avg / total     0.8200    0.8398    0.8120      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.5-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7560975609756098\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3518518518518518\n",
      "Original f1: 0.1484375\n",
      "0.137653528646\n",
      "0.977222414153\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 178\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8443    0.8553    0.8498       926\n",
      "          1     0.3619    0.3423    0.3519       222\n",
      "\n",
      "avg / total     0.7511    0.7561    0.7535      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7712590639419907\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4168067226890756\n",
      "Original f1: 0.31182795698924726\n",
      "0.145730842235\n",
      "0.98548037553\n",
      "347\n",
      "0.228740936058\n",
      "Number of disagreement: 245\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8673    0.8483    0.8577      1233\n",
      "          1     0.3987    0.4366    0.4168       284\n",
      "\n",
      "avg / total     0.7796    0.7713    0.7752      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.5-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.828397212543554\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.34983498349834985\n",
      "Original f1: 0.1484375\n",
      "0.0353750958709\n",
      "0.974713447888\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 47\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8416    0.9698    0.9012       926\n",
      "          1     0.6543    0.2387    0.3498       222\n",
      "\n",
      "avg / total     0.8054    0.8284    0.7945      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8378378378378378\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4628820960698691\n",
      "Original f1: 0.31182795698924726\n",
      "0.0519344628841\n",
      "0.969010004953\n",
      "246\n",
      "0.162162162162\n",
      "Number of disagreement: 86\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8675    0.9448    0.9045      1233\n",
      "          1     0.6092    0.3732    0.4629       284\n",
      "\n",
      "avg / total     0.8191    0.8378    0.8218      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.5-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7543554006968641\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35909090909090907\n",
      "Original f1: 0.1484375\n",
      "0.148477543974\n",
      "0.977222413972\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 186\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8462    0.8499    0.8481       926\n",
      "          1     0.3624    0.3559    0.3591       222\n",
      "\n",
      "avg / total     0.7527    0.7544    0.7535      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7640079103493738\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4131147540983606\n",
      "Original f1: 0.31182795698924726\n",
      "0.153266657595\n",
      "0.985480375287\n",
      "358\n",
      "0.235992089651\n",
      "Number of disagreement: 260\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8673    0.8378    0.8523      1233\n",
      "          1     0.3865    0.4437    0.4131       284\n",
      "\n",
      "avg / total     0.7773    0.7640    0.7701      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.5-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8205574912891986\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3795180722891566\n",
      "Original f1: 0.1484375\n",
      "0.0585506965332\n",
      "0.974713448241\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 76\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8468    0.9492    0.8951       926\n",
      "          1     0.5727    0.2838    0.3795       222\n",
      "\n",
      "avg / total     0.7938    0.8206    0.7954      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8286090969017799\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4736842105263158\n",
      "Original f1: 0.31182795698924726\n",
      "0.0730287618909\n",
      "0.985480374316\n",
      "260\n",
      "0.171390903098\n",
      "Number of disagreement: 122\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8722    0.9246    0.8976      1233\n",
      "          1     0.5571    0.4120    0.4737       284\n",
      "\n",
      "avg / total     0.8132    0.8286    0.8183      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.5-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7526132404181185\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3688888888888889\n",
      "Original f1: 0.1484375\n",
      "0.156367061405\n",
      "0.977222414191\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 196\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8489    0.8434    0.8462       926\n",
      "          1     0.3640    0.3739    0.3689       222\n",
      "\n",
      "avg / total     0.7551    0.7526    0.7539      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7620303230059328\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4130081300813009\n",
      "Original f1: 0.31182795698924726\n",
      "0.15913064445\n",
      "0.985480375762\n",
      "361\n",
      "0.237969676994\n",
      "Number of disagreement: 265\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8676    0.8345    0.8508      1233\n",
      "          1     0.3837    0.4472    0.4130       284\n",
      "\n",
      "avg / total     0.7770    0.7620    0.7688      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.5-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "1.21113373879e-12\n",
      "7.0124128726e-11\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "9.71645444787e-13\n",
      "1.42315839669e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.5-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8083623693379791\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.13385826771653542\n",
      "Original f1: 0.1484375\n",
      "0.00264878964281\n",
      "0.179642440276\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 4\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8163    0.9838    0.8923       926\n",
      "          1     0.5312    0.0766    0.1339       222\n",
      "\n",
      "avg / total     0.7612    0.8084    0.7456      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8292682926829268\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.28254847645429365\n",
      "Original f1: 0.31182795698924726\n",
      "0.00527581652812\n",
      "0.238239638467\n",
      "259\n",
      "0.170731707317\n",
      "Number of disagreement: 11\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8382    0.9789    0.9031      1233\n",
      "          1     0.6623    0.1796    0.2825       284\n",
      "\n",
      "avg / total     0.8053    0.8293    0.7869      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.5-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "4.61318113198e-12\n",
      "4.28802715557e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "2.00758539498e-05\n",
      "0.0304550658987\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.5-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7839721254355401\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.31868131868131866\n",
      "Original f1: 0.1484375\n",
      "0.0869176194734\n",
      "0.974713448114\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 110\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8370    0.9093    0.8716       926\n",
      "          1     0.4085    0.2613    0.3187       222\n",
      "\n",
      "avg / total     0.7541    0.7840    0.7647      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7963085036255768\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.39766081871345027\n",
      "Original f1: 0.31182795698924726\n",
      "0.0971026378085\n",
      "0.985480373253\n",
      "309\n",
      "0.203691496374\n",
      "Number of disagreement: 165\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8587    0.8970    0.8774      1233\n",
      "          1     0.4454    0.3592    0.3977       284\n",
      "\n",
      "avg / total     0.7813    0.7963    0.7876      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.5-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "7.83508186169e-06\n",
      "0.00899466650273\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "0.000131570355342\n",
      "0.199592214697\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.5-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7770034843205574\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3263157894736842\n",
      "Original f1: 0.1484375\n",
      "0.102932442365\n",
      "0.974713447937\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 126\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8384    0.8963    0.8664       926\n",
      "          1     0.3924    0.2793    0.3263       222\n",
      "\n",
      "avg / total     0.7521    0.7770    0.7619      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7883981542518128\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.42162162162162165\n",
      "Original f1: 0.31182795698924726\n",
      "0.118667438414\n",
      "0.985480374634\n",
      "321\n",
      "0.211601845748\n",
      "Number of disagreement: 207\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8660    0.8751    0.8705      1233\n",
      "          1     0.4317    0.4120    0.4216       284\n",
      "\n",
      "avg / total     0.7847    0.7884    0.7865      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.5-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "0.000479058349882\n",
      "0.169959942709\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8325642715886619\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.324468085106383\n",
      "Original f1: 0.31182795698924726\n",
      "0.00271876071964\n",
      "0.553474276095\n",
      "254\n",
      "0.167435728411\n",
      "Number of disagreement: 4\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8435    0.9749    0.9044      1233\n",
      "          1     0.6630    0.2148    0.3245       284\n",
      "\n",
      "avg / total     0.8097    0.8326    0.7959      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.5-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3509615384615385\n",
      "Original f1: 0.1484375\n",
      "0.123268668894\n",
      "0.977222412155\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 162\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8438    0.8693    0.8564       926\n",
      "          1     0.3763    0.3288    0.3510       222\n",
      "\n",
      "avg / total     0.7534    0.7648    0.7586      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7798286090969018\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.41811846689895465\n",
      "Original f1: 0.31182795698924726\n",
      "0.133685965716\n",
      "0.985480375044\n",
      "334\n",
      "0.220171390903\n",
      "Number of disagreement: 226\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8663    0.8621    0.8642      1233\n",
      "          1     0.4138    0.4225    0.4181       284\n",
      "\n",
      "avg / total     0.7816    0.7798    0.7807      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.5-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8196864111498258\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.23048327137546465\n",
      "Original f1: 0.1484375\n",
      "0.00748615828785\n",
      "0.953311614011\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 13\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8265    0.9827    0.8979       926\n",
      "          1     0.6596    0.1396    0.2305       222\n",
      "\n",
      "avg / total     0.7942    0.8197    0.7688      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8404746209624259\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.400990099009901\n",
      "Original f1: 0.31182795698924726\n",
      "0.0187425122829\n",
      "0.962322967846\n",
      "242\n",
      "0.159525379038\n",
      "Number of disagreement: 32\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8547    0.9684    0.9080      1233\n",
      "          1     0.6750    0.2852    0.4010       284\n",
      "\n",
      "avg / total     0.8210    0.8405    0.8131      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.5-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7569686411149826\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3526682134570766\n",
      "Original f1: 0.1484375\n",
      "0.138119693924\n",
      "0.977222413551\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 177\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8445    0.8564    0.8504       926\n",
      "          1     0.3636    0.3423    0.3527       222\n",
      "\n",
      "avg / total     0.7515    0.7570    0.7542      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7719182597231378\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.41554054054054057\n",
      "Original f1: 0.31182795698924726\n",
      "0.146836929751\n",
      "0.985480375775\n",
      "346\n",
      "0.228081740277\n",
      "Number of disagreement: 244\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8668    0.8500    0.8583      1233\n",
      "          1     0.3994    0.4331    0.4155       284\n",
      "\n",
      "avg / total     0.7793    0.7719    0.7754      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.5-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.828397212543554\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.34983498349834985\n",
      "Original f1: 0.1484375\n",
      "0.0341914366285\n",
      "0.974713447833\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 47\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8416    0.9698    0.9012       926\n",
      "          1     0.6543    0.2387    0.3498       222\n",
      "\n",
      "avg / total     0.8054    0.8284    0.7945      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8384970336189849\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.46389496717724293\n",
      "Original f1: 0.31182795698924726\n",
      "0.0520109477751\n",
      "0.969010004321\n",
      "245\n",
      "0.161502966381\n",
      "Number of disagreement: 85\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8676    0.9457    0.9049      1233\n",
      "          1     0.6127    0.3732    0.4639       284\n",
      "\n",
      "avg / total     0.8199    0.8385    0.8224      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.5-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7534843205574913\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3582766439909297\n",
      "Original f1: 0.1484375\n",
      "0.149030750934\n",
      "0.977222414162\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 187\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8461    0.8488    0.8474       926\n",
      "          1     0.3607    0.3559    0.3583       222\n",
      "\n",
      "avg / total     0.7522    0.7535    0.7528      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7653263019116677\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4125412541254126\n",
      "Original f1: 0.31182795698924726\n",
      "0.154451625212\n",
      "0.985480375734\n",
      "356\n",
      "0.234673698088\n",
      "Number of disagreement: 258\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8669    0.8402    0.8534      1233\n",
      "          1     0.3882    0.4401    0.4125       284\n",
      "\n",
      "avg / total     0.7773    0.7653    0.7708      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.5-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8205574912891986\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3795180722891566\n",
      "Original f1: 0.1484375\n",
      "0.0589723143181\n",
      "0.974713448062\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 76\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8468    0.9492    0.8951       926\n",
      "          1     0.5727    0.2838    0.3795       222\n",
      "\n",
      "avg / total     0.7938    0.8206    0.7954      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8292682926829268\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4767676767676768\n",
      "Original f1: 0.31182795698924726\n",
      "0.0730569257041\n",
      "0.985480373845\n",
      "259\n",
      "0.170731707317\n",
      "Number of disagreement: 123\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8729    0.9246    0.8980      1233\n",
      "          1     0.5592    0.4155    0.4768       284\n",
      "\n",
      "avg / total     0.8142    0.8293    0.8191      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.5-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7526132404181185\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3688888888888889\n",
      "Original f1: 0.1484375\n",
      "0.1570140655\n",
      "0.977222414215\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 196\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8489    0.8434    0.8462       926\n",
      "          1     0.3640    0.3739    0.3689       222\n",
      "\n",
      "avg / total     0.7551    0.7526    0.7539      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7633487145682267\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4124386252045827\n",
      "Original f1: 0.31182795698924726\n",
      "0.160415345861\n",
      "0.985480375472\n",
      "359\n",
      "0.236651285432\n",
      "Number of disagreement: 263\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8672    0.8370    0.8518      1233\n",
      "          1     0.3853    0.4437    0.4124       284\n",
      "\n",
      "avg / total     0.7770    0.7633    0.7696      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.75-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "9.07386757377e-13\n",
      "6.38471497894e-11\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "7.74619625612e-13\n",
      "1.42315843138e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.75-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "0.00172912027254\n",
      "0.165878514244\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8292682926829268\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.2865013774104683\n",
      "Original f1: 0.31182795698924726\n",
      "0.00430469985854\n",
      "0.20499992301\n",
      "259\n",
      "0.170731707317\n",
      "Number of disagreement: 9\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8387    0.9781    0.9030      1233\n",
      "          1     0.6582    0.1831    0.2865       284\n",
      "\n",
      "avg / total     0.8049    0.8293    0.7876      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.75-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "3.9066987054e-12\n",
      "4.28979504696e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "4.86789350109e-12\n",
      "3.38493023888e-09\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.75-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.774390243902439\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.316622691292876\n",
      "Original f1: 0.1484375\n",
      "0.0996740127537\n",
      "0.974713448249\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 123\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8365    0.8952    0.8649       926\n",
      "          1     0.3822    0.2703    0.3166       222\n",
      "\n",
      "avg / total     0.7487    0.7744    0.7589      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7870797626895187\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4051565377532228\n",
      "Original f1: 0.31182795698924726\n",
      "0.114128918934\n",
      "0.981980903261\n",
      "323\n",
      "0.21292023731\n",
      "Number of disagreement: 191\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8617    0.8792    0.8703      1233\n",
      "          1     0.4247    0.3873    0.4052       284\n",
      "\n",
      "avg / total     0.7799    0.7871    0.7832      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.75-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "7.11494871077e-12\n",
      "7.50085826784e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "8.71607108945e-05\n",
      "0.132222782636\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.75-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7656794425087108\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3224181360201511\n",
      "Original f1: 0.1484375\n",
      "0.116147324638\n",
      "0.977222411963\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 141\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8376    0.8801    0.8583       926\n",
      "          1     0.3657    0.2883    0.3224       222\n",
      "\n",
      "avg / total     0.7464    0.7657    0.7547      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7752142386288727\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.41509433962264153\n",
      "Original f1: 0.31182795698924726\n",
      "0.134165010294\n",
      "0.985480375165\n",
      "341\n",
      "0.224785761371\n",
      "Number of disagreement: 231\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8662    0.8556    0.8609      1233\n",
      "          1     0.4047    0.4261    0.4151       284\n",
      "\n",
      "avg / total     0.7798    0.7752    0.7774      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.75-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "0.000573097624719\n",
      "0.15834974327\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8325642715886619\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.324468085106383\n",
      "Original f1: 0.31182795698924726\n",
      "0.00204039260554\n",
      "0.435491955991\n",
      "254\n",
      "0.167435728411\n",
      "Number of disagreement: 4\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8435    0.9749    0.9044      1233\n",
      "          1     0.6630    0.2148    0.3245       284\n",
      "\n",
      "avg / total     0.8097    0.8326    0.7959      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.75-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7534843205574913\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3433874709976798\n",
      "Original f1: 0.1484375\n",
      "0.137818863738\n",
      "0.977222414076\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 175\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8424    0.8542    0.8483       926\n",
      "          1     0.3541    0.3333    0.3434       222\n",
      "\n",
      "avg / total     0.7480    0.7535    0.7506      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7705998681608438\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.41216216216216217\n",
      "Original f1: 0.31182795698924726\n",
      "0.14654111762\n",
      "0.985480374898\n",
      "348\n",
      "0.229400131839\n",
      "Number of disagreement: 240\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8660    0.8491    0.8575      1233\n",
      "          1     0.3961    0.4296    0.4122       284\n",
      "\n",
      "avg / total     0.7780    0.7706    0.7741      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.75-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8196864111498258\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.23616236162361623\n",
      "Original f1: 0.1484375\n",
      "0.00913298313022\n",
      "0.95331161509\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 15\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8271    0.9816    0.8978       926\n",
      "          1     0.6531    0.1441    0.2362       222\n",
      "\n",
      "avg / total     0.7935    0.8197    0.7698      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8450889914304548\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4226044226044226\n",
      "Original f1: 0.31182795698924726\n",
      "0.0215396024713\n",
      "0.969009976828\n",
      "235\n",
      "0.15491100857\n",
      "Number of disagreement: 35\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8580    0.9700    0.9105      1233\n",
      "          1     0.6992    0.3028    0.4226       284\n",
      "\n",
      "avg / total     0.8282    0.8451    0.8192      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.75-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.75\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3579418344519016\n",
      "Original f1: 0.1484375\n",
      "0.150772334524\n",
      "0.977222413833\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 191\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8462    0.8434    0.8448       926\n",
      "          1     0.3556    0.3604    0.3579       222\n",
      "\n",
      "avg / total     0.7513    0.7500    0.7506      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7626895187870798\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.411764705882353\n",
      "Original f1: 0.31182795698924726\n",
      "0.158371641488\n",
      "0.985480375792\n",
      "360\n",
      "0.237310481213\n",
      "Number of disagreement: 260\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8671    0.8362    0.8514      1233\n",
      "          1     0.3841    0.4437    0.4118       284\n",
      "\n",
      "avg / total     0.7767    0.7627    0.7691      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.75-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.828397212543554\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3583061889250814\n",
      "Original f1: 0.1484375\n",
      "0.0372712441235\n",
      "0.974713447672\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 51\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8429    0.9676    0.9010       926\n",
      "          1     0.6471    0.2477    0.3583       222\n",
      "\n",
      "avg / total     0.8050    0.8284    0.7960      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8365194462755439\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4789915966386555\n",
      "Original f1: 0.31182795698924726\n",
      "0.0593357451266\n",
      "0.969010005488\n",
      "248\n",
      "0.163480553724\n",
      "Number of disagreement: 104\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8717    0.9367    0.9030      1233\n",
      "          1     0.5938    0.4014    0.4790       284\n",
      "\n",
      "avg / total     0.8197    0.8365    0.8237      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.75-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7491289198606271\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.36283185840707965\n",
      "Original f1: 0.1484375\n",
      "0.159859394746\n",
      "0.977222414109\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 196\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8475    0.8402    0.8438       926\n",
      "          1     0.3565    0.3694    0.3628       222\n",
      "\n",
      "avg / total     0.7526    0.7491    0.7508      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7600527356624918\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4110032362459547\n",
      "Original f1: 0.31182795698924726\n",
      "0.16515282856\n",
      "0.985480375683\n",
      "364\n",
      "0.239947264338\n",
      "Number of disagreement: 266\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8673    0.8321    0.8493      1233\n",
      "          1     0.3802    0.4472    0.4110       284\n",
      "\n",
      "avg / total     0.7761    0.7601    0.7673      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.75-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8196864111498258\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3893805309734513\n",
      "Original f1: 0.1484375\n",
      "0.0647076437329\n",
      "0.974713447959\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 83\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8487    0.9449    0.8942       926\n",
      "          1     0.5641    0.2973    0.3894       222\n",
      "\n",
      "avg / total     0.7937    0.8197    0.7966      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8200395517468688\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.47398843930635837\n",
      "Original f1: 0.31182795698924726\n",
      "0.0811718502499\n",
      "0.985480374063\n",
      "273\n",
      "0.179960448253\n",
      "Number of disagreement: 147\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8744    0.9092    0.8915      1233\n",
      "          1     0.5234    0.4331    0.4740       284\n",
      "\n",
      "avg / total     0.8087    0.8200    0.8133      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.75-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7508710801393729\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.37554585152838427\n",
      "Original f1: 0.1484375\n",
      "0.166268321923\n",
      "0.977222414226\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 202\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8509    0.8380    0.8444       926\n",
      "          1     0.3644    0.3874    0.3755       222\n",
      "\n",
      "avg / total     0.7568    0.7509    0.7537      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7541199736321688\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4069952305246423\n",
      "Original f1: 0.31182795698924726\n",
      "0.169919703906\n",
      "0.985480375894\n",
      "373\n",
      "0.245880026368\n",
      "Number of disagreement: 277\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8669    0.8240    0.8449      1233\n",
      "          1     0.3710    0.4507    0.4070       284\n",
      "\n",
      "avg / total     0.7741    0.7541    0.7629      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.75-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "8.33916385725e-13\n",
      "6.38471497894e-11\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "7.95320396463e-13\n",
      "1.42315843138e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.75-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "0.00179320879168\n",
      "0.165318464886\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8286090969017799\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.281767955801105\n",
      "Original f1: 0.31182795698924726\n",
      "0.00424847009881\n",
      "0.198414566558\n",
      "260\n",
      "0.171390903098\n",
      "Number of disagreement: 10\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8381    0.9781    0.9027      1233\n",
      "          1     0.6538    0.1796    0.2818       284\n",
      "\n",
      "avg / total     0.8036    0.8286    0.7864      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.75-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "3.45460727509e-12\n",
      "4.28979504696e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "3.39700287442e-12\n",
      "2.70920286205e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.75-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7726480836236934\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3149606299212599\n",
      "Original f1: 0.1484375\n",
      "0.100815855774\n",
      "0.974713447739\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 125\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8362    0.8931    0.8637       926\n",
      "          1     0.3774    0.2703    0.3150       222\n",
      "\n",
      "avg / total     0.7475    0.7726    0.7576      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7837837837837838\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.39705882352941174\n",
      "Original f1: 0.31182795698924726\n",
      "0.116166437829\n",
      "0.985480375396\n",
      "328\n",
      "0.216216216216\n",
      "Number of disagreement: 194\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8600    0.8767    0.8683      1233\n",
      "          1     0.4154    0.3803    0.3971       284\n",
      "\n",
      "avg / total     0.7767    0.7838    0.7801      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.75-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "4.80461467045e-12\n",
      "3.22894669336e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "5.88297407922e-05\n",
      "0.0892447036269\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.75-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7639372822299652\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.32080200501253137\n",
      "Original f1: 0.1484375\n",
      "0.117073437283\n",
      "0.974713448076\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 143\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8373    0.8780    0.8571       926\n",
      "          1     0.3616    0.2883    0.3208       222\n",
      "\n",
      "avg / total     0.7453    0.7639    0.7534      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7725774555042848\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.41025641025641024\n",
      "Original f1: 0.31182795698924726\n",
      "0.136544555686\n",
      "0.98548037504\n",
      "345\n",
      "0.227422544496\n",
      "Number of disagreement: 235\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8651    0.8532    0.8591      1233\n",
      "          1     0.3987    0.4225    0.4103       284\n",
      "\n",
      "avg / total     0.7778    0.7726    0.7751      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.75-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "0.000432575321555\n",
      "0.142436814566\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8325642715886619\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.320855614973262\n",
      "Original f1: 0.31182795698924726\n",
      "0.00168463635885\n",
      "0.42349285119\n",
      "254\n",
      "0.167435728411\n",
      "Number of disagreement: 2\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8430    0.9757    0.9045      1233\n",
      "          1     0.6667    0.2113    0.3209       284\n",
      "\n",
      "avg / total     0.8100    0.8326    0.7952      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.75-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7491289198606271\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.33333333333333337\n",
      "Original f1: 0.1484375\n",
      "0.138267442669\n",
      "0.977222412181\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 176\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8401    0.8510    0.8455       926\n",
      "          1     0.3429    0.3243    0.3333       222\n",
      "\n",
      "avg / total     0.7439    0.7491    0.7465      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7653263019116677\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.40468227424749165\n",
      "Original f1: 0.31182795698924726\n",
      "0.14868997986\n",
      "0.985480375742\n",
      "356\n",
      "0.234673698088\n",
      "Number of disagreement: 248\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8645    0.8435    0.8539      1233\n",
      "          1     0.3854    0.4261    0.4047       284\n",
      "\n",
      "avg / total     0.7748    0.7653    0.7698      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.75-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8179442508710801\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.2230483271375465\n",
      "Original f1: 0.1484375\n",
      "0.00781013087044\n",
      "0.953311614721\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 13\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8256    0.9816    0.8969       926\n",
      "          1     0.6383    0.1351    0.2230       222\n",
      "\n",
      "avg / total     0.7894    0.8179    0.7666      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8444297956493079\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.41584158415841577\n",
      "Original f1: 0.31182795698924726\n",
      "0.0201859453634\n",
      "0.969009985829\n",
      "236\n",
      "0.155570204351\n",
      "Number of disagreement: 32\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8568    0.9708    0.9103      1233\n",
      "          1     0.7000    0.2958    0.4158       284\n",
      "\n",
      "avg / total     0.8275    0.8444    0.8177      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.75-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7465156794425087\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35761589403973504\n",
      "Original f1: 0.1484375\n",
      "0.153014762122\n",
      "0.977222413894\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 197\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8462    0.8380    0.8421       926\n",
      "          1     0.3506    0.3649    0.3576       222\n",
      "\n",
      "avg / total     0.7504    0.7465    0.7484      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7587343441001978\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.40584415584415584\n",
      "Original f1: 0.31182795698924726\n",
      "0.160710747438\n",
      "0.985480375824\n",
      "366\n",
      "0.2412656559\n",
      "Number of disagreement: 266\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8658    0.8321    0.8486      1233\n",
      "          1     0.3765    0.4401    0.4058       284\n",
      "\n",
      "avg / total     0.7742    0.7587    0.7657      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.75-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8266550522648084\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.34323432343234317\n",
      "Original f1: 0.1484375\n",
      "0.0342588369953\n",
      "0.97471344738\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 47\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8407    0.9687    0.9002       926\n",
      "          1     0.6420    0.2342    0.3432       222\n",
      "\n",
      "avg / total     0.8023    0.8267    0.7925      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8365194462755439\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4745762711864407\n",
      "Original f1: 0.31182795698924726\n",
      "0.0594081007572\n",
      "0.969010005338\n",
      "248\n",
      "0.163480553724\n",
      "Number of disagreement: 100\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8706    0.9384    0.9032      1233\n",
      "          1     0.5957    0.3944    0.4746       284\n",
      "\n",
      "avg / total     0.8191    0.8365    0.8230      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.75-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7456445993031359\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35964912280701755\n",
      "Original f1: 0.1484375\n",
      "0.161883940092\n",
      "0.977222414234\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 200\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8468    0.8359    0.8413       926\n",
      "          1     0.3504    0.3694    0.3596       222\n",
      "\n",
      "avg / total     0.7508    0.7456    0.7482      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7528015820698748\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4019138755980861\n",
      "Original f1: 0.31182795698924726\n",
      "0.167358176017\n",
      "0.985480375467\n",
      "375\n",
      "0.24719841793\n",
      "Number of disagreement: 277\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8654    0.8240    0.8442      1233\n",
      "          1     0.3673    0.4437    0.4019       284\n",
      "\n",
      "avg / total     0.7722    0.7528    0.7614      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.75-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8162020905923345\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3848396501457726\n",
      "Original f1: 0.1484375\n",
      "0.0661478966883\n",
      "0.974713447622\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 87\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8481    0.9406    0.8920       926\n",
      "          1     0.5455    0.2973    0.3848       222\n",
      "\n",
      "avg / total     0.7896    0.8162    0.7939      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8200395517468688\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4760076775431862\n",
      "Original f1: 0.31182795698924726\n",
      "0.0805750264003\n",
      "0.985480375681\n",
      "273\n",
      "0.179960448253\n",
      "Number of disagreement: 149\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8750    0.9084    0.8914      1233\n",
      "          1     0.5232    0.4366    0.4760       284\n",
      "\n",
      "avg / total     0.8091    0.8200    0.8136      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-0.75-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7465156794425087\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3714902807775378\n",
      "Original f1: 0.1484375\n",
      "0.168317386171\n",
      "0.977222414087\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 207\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8501    0.8326    0.8412       926\n",
      "          1     0.3568    0.3874    0.3715       222\n",
      "\n",
      "avg / total     0.7547    0.7465    0.7504      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7495056031641397\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4006309148264984\n",
      "Original f1: 0.31182795698924726\n",
      "0.172317045381\n",
      "0.9854803759\n",
      "380\n",
      "0.250494396836\n",
      "Number of disagreement: 284\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8655    0.8191    0.8417      1233\n",
      "          1     0.3629    0.4472    0.4006       284\n",
      "\n",
      "avg / total     0.7714    0.7495    0.7591      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.0-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "8.44793357292e-13\n",
      "6.37898761591e-11\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "8.68898140375e-13\n",
      "1.42315843138e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.0-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8092334494773519\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1411764705882353\n",
      "Original f1: 0.1484375\n",
      "0.00181626265895\n",
      "0.184778480651\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 1\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8170    0.9838    0.8927       926\n",
      "          1     0.5455    0.0811    0.1412       222\n",
      "\n",
      "avg / total     0.7645    0.8092    0.7474      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8305866842452209\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.2958904109589041\n",
      "Original f1: 0.31182795698924726\n",
      "0.00422828855143\n",
      "0.190405046067\n",
      "257\n",
      "0.169413315755\n",
      "Number of disagreement: 7\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8398    0.9781    0.9037      1233\n",
      "          1     0.6667    0.1901    0.2959       284\n",
      "\n",
      "avg / total     0.8074    0.8306    0.7899      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.0-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "3.68777970348e-12\n",
      "4.28802715557e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "5.25985498862e-12\n",
      "8.99741642302e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.0-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.764808362369338\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3041237113402062\n",
      "Original f1: 0.1484375\n",
      "0.108115093426\n",
      "0.9747134482\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 134\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8340    0.8844    0.8585       926\n",
      "          1     0.3554    0.2658    0.3041       222\n",
      "\n",
      "avg / total     0.7415    0.7648    0.7513      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7831245880026367\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.41563055062166965\n",
      "Original f1: 0.31182795698924726\n",
      "0.124800336082\n",
      "0.981980907183\n",
      "329\n",
      "0.216875411997\n",
      "Number of disagreement: 207\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8651    0.8686    0.8669      1233\n",
      "          1     0.4194    0.4120    0.4156       284\n",
      "\n",
      "avg / total     0.7817    0.7831    0.7824      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.0-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "3.9337270118e-12\n",
      "3.72652519953e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "5.37493202457e-05\n",
      "0.0815377039133\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.0-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7552264808362369\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.31295843520782396\n",
      "Original f1: 0.1484375\n",
      "0.12465217882\n",
      "0.977222413122\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 155\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8356    0.8672    0.8511       926\n",
      "          1     0.3422    0.2883    0.3130       222\n",
      "\n",
      "avg / total     0.7402    0.7552    0.7470      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7725774555042848\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.41821247892074204\n",
      "Original f1: 0.31182795698924726\n",
      "0.142195597994\n",
      "0.985480375836\n",
      "345\n",
      "0.227422544496\n",
      "Number of disagreement: 235\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8675    0.8500    0.8587      1233\n",
      "          1     0.4013    0.4366    0.4182       284\n",
      "\n",
      "avg / total     0.7803    0.7726    0.7762      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.0-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "0.000557892923552\n",
      "0.183929968961\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8319050758075148\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.3163538873994638\n",
      "Original f1: 0.31182795698924726\n",
      "0.00164314638953\n",
      "0.423492850034\n",
      "255\n",
      "0.168094924192\n",
      "Number of disagreement: 1\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8424    0.9757    0.9042      1233\n",
      "          1     0.6629    0.2077    0.3164       284\n",
      "\n",
      "avg / total     0.8088    0.8319    0.7941      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.0-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7456445993031359\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.33333333333333337\n",
      "Original f1: 0.1484375\n",
      "0.147274656125\n",
      "0.977222413837\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 184\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8401    0.8456    0.8428       926\n",
      "          1     0.3380    0.3288    0.3333       222\n",
      "\n",
      "avg / total     0.7430    0.7456    0.7443      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7673038892551087\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4165289256198347\n",
      "Original f1: 0.31182795698924726\n",
      "0.153213601519\n",
      "0.985480375857\n",
      "353\n",
      "0.232696110745\n",
      "Number of disagreement: 247\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8679    0.8418    0.8547      1233\n",
      "          1     0.3925    0.4437    0.4165       284\n",
      "\n",
      "avg / total     0.7789    0.7673    0.7726      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.0-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.818815331010453\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.22962962962962963\n",
      "Original f1: 0.1484375\n",
      "0.00847037491786\n",
      "0.860602485789\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 14\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8264    0.9816    0.8973       926\n",
      "          1     0.6458    0.1396    0.2296       222\n",
      "\n",
      "avg / total     0.7915    0.8188    0.7682      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8470665787738958\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4313725490196078\n",
      "Original f1: 0.31182795698924726\n",
      "0.0211470910215\n",
      "0.951622708183\n",
      "232\n",
      "0.152933421226\n",
      "Number of disagreement: 36\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8593    0.9708    0.9117      1233\n",
      "          1     0.7097    0.3099    0.4314       284\n",
      "\n",
      "avg / total     0.8313    0.8471    0.8217      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.0-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7447735191637631\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35604395604395606\n",
      "Original f1: 0.1484375\n",
      "0.15979736768\n",
      "0.97722241395\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 201\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8459    0.8359    0.8408       926\n",
      "          1     0.3476    0.3649    0.3560       222\n",
      "\n",
      "avg / total     0.7495    0.7448    0.7471      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7580751483190508\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.41279999999999994\n",
      "Original f1: 0.31182795698924726\n",
      "0.164185692296\n",
      "0.985480375819\n",
      "367\n",
      "0.241924851681\n",
      "Number of disagreement: 267\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8682    0.8281    0.8477      1233\n",
      "          1     0.3783    0.4542    0.4128       284\n",
      "\n",
      "avg / total     0.7765    0.7581    0.7662      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.0-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8266550522648084\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.360128617363344\n",
      "Original f1: 0.1484375\n",
      "0.0376313582792\n",
      "0.974713448031\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 55\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8432    0.9644    0.8997       926\n",
      "          1     0.6292    0.2523    0.3601       222\n",
      "\n",
      "avg / total     0.8019    0.8267    0.7954      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8338826631509558\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.47933884297520657\n",
      "Original f1: 0.31182795698924726\n",
      "0.063147064361\n",
      "0.969010005341\n",
      "252\n",
      "0.166117336849\n",
      "Number of disagreement: 112\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8724    0.9319    0.9012      1233\n",
      "          1     0.5800    0.4085    0.4793       284\n",
      "\n",
      "avg / total     0.8177    0.8339    0.8222      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.0-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7412891986062717\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3557483731019523\n",
      "Original f1: 0.1484375\n",
      "0.167633527512\n",
      "0.977222414181\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 207\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8460    0.8305    0.8381       926\n",
      "          1     0.3431    0.3694    0.3557       222\n",
      "\n",
      "avg / total     0.7487    0.7413    0.7449      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7528015820698748\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4094488188976378\n",
      "Original f1: 0.31182795698924726\n",
      "0.171389177281\n",
      "0.985480375751\n",
      "375\n",
      "0.24719841793\n",
      "Number of disagreement: 277\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8679    0.8208    0.8437      1233\n",
      "          1     0.3704    0.4577    0.4094       284\n",
      "\n",
      "avg / total     0.7748    0.7528    0.7624      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.0-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8196864111498258\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.39650145772594747\n",
      "Original f1: 0.1484375\n",
      "0.0671106029662\n",
      "0.974713448243\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 87\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8500    0.9428    0.8940       926\n",
      "          1     0.5620    0.3063    0.3965       222\n",
      "\n",
      "avg / total     0.7943    0.8197    0.7978      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8160843770599868\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.47058823529411764\n",
      "Original f1: 0.31182795698924726\n",
      "0.0850653522311\n",
      "0.985480371434\n",
      "279\n",
      "0.18391562294\n",
      "Number of disagreement: 155\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8744    0.9035    0.8887      1233\n",
      "          1     0.5103    0.4366    0.4706       284\n",
      "\n",
      "avg / total     0.8062    0.8161    0.8104      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.0-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7421602787456446\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3675213675213675\n",
      "Original f1: 0.1484375\n",
      "0.173359487327\n",
      "0.986554666977\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 214\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8492    0.8272    0.8381       926\n",
      "          1     0.3496    0.3874    0.3675       222\n",
      "\n",
      "avg / total     0.7526    0.7422    0.7471      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7501647989452868\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.40873634945397813\n",
      "Original f1: 0.31182795698924726\n",
      "0.175556217336\n",
      "0.985480375884\n",
      "379\n",
      "0.249835201055\n",
      "Number of disagreement: 283\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8681    0.8167    0.8416      1233\n",
      "          1     0.3669    0.4613    0.4087       284\n",
      "\n",
      "avg / total     0.7743    0.7502    0.7606      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.0-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "8.25004062537e-13\n",
      "6.37898761591e-11\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "8.65846793799e-13\n",
      "1.42315843138e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.0-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8092334494773519\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1411764705882353\n",
      "Original f1: 0.1484375\n",
      "0.00188750501054\n",
      "0.187737201645\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 1\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8170    0.9838    0.8927       926\n",
      "          1     0.5455    0.0811    0.1412       222\n",
      "\n",
      "avg / total     0.7645    0.8092    0.7474      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8299274884640738\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.29120879120879123\n",
      "Original f1: 0.31182795698924726\n",
      "0.00420898561674\n",
      "0.17839243365\n",
      "258\n",
      "0.170072511536\n",
      "Number of disagreement: 8\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8392    0.9781    0.9034      1233\n",
      "          1     0.6625    0.1866    0.2912       284\n",
      "\n",
      "avg / total     0.8062    0.8299    0.7888      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.0-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "3.42847116206e-12\n",
      "4.28802715557e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "3.8837921757e-12\n",
      "3.17013450213e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.0-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7604529616724739\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.30025445292620867\n",
      "Original f1: 0.1484375\n",
      "0.110090036822\n",
      "0.974713448159\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 139\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8332    0.8790    0.8555       926\n",
      "          1     0.3450    0.2658    0.3003       222\n",
      "\n",
      "avg / total     0.7388    0.7605    0.7481      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7778510217534608\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.40142095914742454\n",
      "Original f1: 0.31182795698924726\n",
      "0.126883684253\n",
      "0.985480374743\n",
      "337\n",
      "0.222148978247\n",
      "Number of disagreement: 209\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8619    0.8654    0.8636      1233\n",
      "          1     0.4050    0.3979    0.4014       284\n",
      "\n",
      "avg / total     0.7763    0.7779    0.7771      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.0-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "4.85672621095e-12\n",
      "3.22894738725e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "3.03427521221e-05\n",
      "0.0460299404583\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.0-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7534843205574913\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.31143552311435524\n",
      "Original f1: 0.1484375\n",
      "0.126055923767\n",
      "0.9747134481\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 157\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8352    0.8650    0.8499       926\n",
      "          1     0.3386    0.2883    0.3114       222\n",
      "\n",
      "avg / total     0.7392    0.7535    0.7457      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7659854976928148\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4073455759599332\n",
      "Original f1: 0.31182795698924726\n",
      "0.145743927918\n",
      "0.98548037586\n",
      "355\n",
      "0.234014502307\n",
      "Number of disagreement: 245\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8652    0.8435    0.8542      1233\n",
      "          1     0.3873    0.4296    0.4073       284\n",
      "\n",
      "avg / total     0.7758    0.7660    0.7706      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.0-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "0.000383337189523\n",
      "0.130816754876\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8325642715886619\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.320855614973262\n",
      "Original f1: 0.31182795698924726\n",
      "0.00148752381633\n",
      "0.423492850034\n",
      "254\n",
      "0.167435728411\n",
      "Number of disagreement: 2\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8430    0.9757    0.9045      1233\n",
      "          1     0.6667    0.2113    0.3209       284\n",
      "\n",
      "avg / total     0.8100    0.8326    0.7952      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.0-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7421602787456446\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.32727272727272727\n",
      "Original f1: 0.1484375\n",
      "0.14993039349\n",
      "0.977222412275\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 186\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8387    0.8423    0.8405       926\n",
      "          1     0.3303    0.3243    0.3273       222\n",
      "\n",
      "avg / total     0.7404    0.7422    0.7413      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7633487145682267\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4085667215815486\n",
      "Original f1: 0.31182795698924726\n",
      "0.156674266937\n",
      "0.985480375856\n",
      "359\n",
      "0.236651285432\n",
      "Number of disagreement: 253\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8660    0.8386    0.8521      1233\n",
      "          1     0.3839    0.4366    0.4086       284\n",
      "\n",
      "avg / total     0.7757    0.7633    0.7690      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.0-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8162020905923345\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.20973782771535576\n",
      "Original f1: 0.1484375\n",
      "0.00641842454239\n",
      "0.617138564269\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 11\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8241    0.9816    0.8960       926\n",
      "          1     0.6222    0.1261    0.2097       222\n",
      "\n",
      "avg / total     0.7851    0.8162    0.7633      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8431114040870138\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.41089108910891087\n",
      "Original f1: 0.31182795698924726\n",
      "0.0199217608872\n",
      "0.962322723236\n",
      "238\n",
      "0.156888595913\n",
      "Number of disagreement: 32\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8561    0.9700    0.9095      1233\n",
      "          1     0.6917    0.2923    0.4109       284\n",
      "\n",
      "avg / total     0.8253    0.8431    0.8162      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.0-5-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.740418118466899\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3464912280701754\n",
      "Original f1: 0.1484375\n",
      "0.162856179854\n",
      "0.97722241412\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 202\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8435    0.8326    0.8380       926\n",
      "          1     0.3376    0.3559    0.3465       222\n",
      "\n",
      "avg / total     0.7457    0.7404    0.7430      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7528015820698748\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.40381558028616854\n",
      "Original f1: 0.31182795698924726\n",
      "0.1678096809\n",
      "0.985480375888\n",
      "375\n",
      "0.24719841793\n",
      "Number of disagreement: 275\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8660    0.8232    0.8441      1233\n",
      "          1     0.3681    0.4472    0.4038       284\n",
      "\n",
      "avg / total     0.7728    0.7528    0.7617      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.0-5-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8275261324041812\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.35294117647058826\n",
      "Original f1: 0.1484375\n",
      "0.0350204926189\n",
      "0.974713447966\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 50\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8421    0.9676    0.9005       926\n",
      "          1     0.6429    0.2432    0.3529       222\n",
      "\n",
      "avg / total     0.8036    0.8275    0.7946      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8332234673698088\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4718162839248434\n",
      "Original f1: 0.31182795698924726\n",
      "0.0621201285275\n",
      "0.982140777719\n",
      "253\n",
      "0.16677653263\n",
      "Number of disagreement: 107\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8707    0.9335    0.9010      1233\n",
      "          1     0.5795    0.3979    0.4718       284\n",
      "\n",
      "avg / total     0.8161    0.8332    0.8206      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.0-5-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.740418118466899\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.354978354978355\n",
      "Original f1: 0.1484375\n",
      "0.169930594717\n",
      "0.985840120735\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 208\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8458    0.8294    0.8375       926\n",
      "          1     0.3417    0.3694    0.3550       222\n",
      "\n",
      "avg / total     0.7483    0.7404    0.7442      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7501647989452868\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4050235478806907\n",
      "Original f1: 0.31182795698924726\n",
      "0.174214765278\n",
      "0.985480375877\n",
      "379\n",
      "0.249835201055\n",
      "Number of disagreement: 283\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8668    0.8183    0.8419      1233\n",
      "          1     0.3654    0.4542    0.4050       284\n",
      "\n",
      "avg / total     0.7730    0.7502    0.7601      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.0-5-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8162020905923345\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3919308357348703\n",
      "Original f1: 0.1484375\n",
      "0.0683344864264\n",
      "0.974713447916\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 91\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8495    0.9384    0.8917       926\n",
      "          1     0.5440    0.3063    0.3919       222\n",
      "\n",
      "avg / total     0.7904    0.8162    0.7951      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8147659854976929\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4667931688804554\n",
      "Original f1: 0.31182795698924726\n",
      "0.0842312455025\n",
      "0.985480375777\n",
      "281\n",
      "0.185234014502\n",
      "Number of disagreement: 155\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8736    0.9027    0.8879      1233\n",
      "          1     0.5062    0.4331    0.4668       284\n",
      "\n",
      "avg / total     0.8048    0.8148    0.8091      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.0-5-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7421602787456446\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3675213675213675\n",
      "Original f1: 0.1484375\n",
      "0.176238666769\n",
      "0.986554667001\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 214\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8492    0.8272    0.8381       926\n",
      "          1     0.3496    0.3874    0.3675       222\n",
      "\n",
      "avg / total     0.7526    0.7422    0.7471      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7468688200395518\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.40372670807453415\n",
      "Original f1: 0.31182795698924726\n",
      "0.178928036048\n",
      "0.985480375796\n",
      "384\n",
      "0.25313117996\n",
      "Number of disagreement: 290\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8669    0.8135    0.8393      1233\n",
      "          1     0.3611    0.4577    0.4037       284\n",
      "\n",
      "avg / total     0.7722    0.7469    0.7578      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.5-3-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "9.22628270543e-13\n",
      "6.8015044985e-11\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "9.35777963715e-13\n",
      "1.42315843138e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.5-3-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8092334494773519\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1411764705882353\n",
      "Original f1: 0.1484375\n",
      "0.00193637729407\n",
      "0.201925328081\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 1\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8170    0.9838    0.8927       926\n",
      "          1     0.5455    0.0811    0.1412       222\n",
      "\n",
      "avg / total     0.7645    0.8092    0.7474      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8305866842452209\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.2958904109589041\n",
      "Original f1: 0.31182795698924726\n",
      "0.00448267564853\n",
      "0.1818156018\n",
      "257\n",
      "0.169413315755\n",
      "Number of disagreement: 7\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8398    0.9781    0.9037      1233\n",
      "          1     0.6667    0.1901    0.2959       284\n",
      "\n",
      "avg / total     0.8074    0.8306    0.7899      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.5-3-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "4.9556479483e-12\n",
      "4.28979504696e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "3.84354536749e-12\n",
      "1.42315843138e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.5-3-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.759581881533101\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.31\n",
      "Original f1: 0.1484375\n",
      "0.117024097931\n",
      "0.974713448105\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 146\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8351    0.8747    0.8544       926\n",
      "          1     0.3483    0.2793    0.3100       222\n",
      "\n",
      "avg / total     0.7409    0.7596    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7758734344100198\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.411764705882353\n",
      "Original f1: 0.31182795698924726\n",
      "0.133146179079\n",
      "0.98198090662\n",
      "340\n",
      "0.22412656559\n",
      "Number of disagreement: 220\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8651    0.8581    0.8616      1233\n",
      "          1     0.4048    0.4190    0.4118       284\n",
      "\n",
      "avg / total     0.7789    0.7759    0.7774      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.5-3-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "8.40838391146e-06\n",
      "0.00965281859638\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "2.83499065897e-05\n",
      "0.043006796145\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.5-3-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.75\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3215130023640662\n",
      "Original f1: 0.1484375\n",
      "0.134597944264\n",
      "0.977222413699\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 169\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8374    0.8564    0.8468       926\n",
      "          1     0.3383    0.3063    0.3215       222\n",
      "\n",
      "avg / total     0.7409    0.7500    0.7452      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7673038892551087\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.41459369817578773\n",
      "Original f1: 0.31182795698924726\n",
      "0.148600944762\n",
      "0.985480374244\n",
      "353\n",
      "0.232696110745\n",
      "Number of disagreement: 245\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8673    0.8427    0.8548      1233\n",
      "          1     0.3918    0.4401    0.4146       284\n",
      "\n",
      "avg / total     0.7783    0.7673    0.7724      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.5-3-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "0.000567488735726\n",
      "0.20310623485\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8319050758075148\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.3163538873994638\n",
      "Original f1: 0.31182795698924726\n",
      "0.00181373840668\n",
      "0.390232364668\n",
      "255\n",
      "0.168094924192\n",
      "Number of disagreement: 1\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8424    0.9757    0.9042      1233\n",
      "          1     0.6629    0.2077    0.3164       284\n",
      "\n",
      "avg / total     0.8088    0.8319    0.7941      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.5-3-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7360627177700348\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.32516703786191536\n",
      "Original f1: 0.1484375\n",
      "0.155452493247\n",
      "0.977222414079\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 195\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8382    0.8337    0.8360       926\n",
      "          1     0.3216    0.3288    0.3252       222\n",
      "\n",
      "avg / total     0.7383    0.7361    0.7372      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7646671061305208\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4137931034482759\n",
      "Original f1: 0.31182795698924726\n",
      "0.15906309145\n",
      "0.985480375755\n",
      "357\n",
      "0.235332893869\n",
      "Number of disagreement: 251\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8674    0.8386    0.8528      1233\n",
      "          1     0.3877    0.4437    0.4138       284\n",
      "\n",
      "avg / total     0.7776    0.7647    0.7706      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.5-3-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8153310104529616\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.19696969696969696\n",
      "Original f1: 0.1484375\n",
      "0.00633736851903\n",
      "0.674330471989\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 8\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8228    0.9827    0.8957       926\n",
      "          1     0.6190    0.1171    0.1970       222\n",
      "\n",
      "avg / total     0.7834    0.8153    0.7606      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8457481872116018\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.415\n",
      "Original f1: 0.31182795698924726\n",
      "0.0194274189789\n",
      "0.951622711972\n",
      "234\n",
      "0.154251812788\n",
      "Number of disagreement: 28\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8565    0.9732    0.9112      1233\n",
      "          1     0.7155    0.2923    0.4150       284\n",
      "\n",
      "avg / total     0.8301    0.8457    0.8183      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.5-3-1.5-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.735191637630662\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3448275862068965\n",
      "Original f1: 0.1484375\n",
      "0.167619401074\n",
      "0.97722241407\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 210\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8433    0.8251    0.8341       926\n",
      "          1     0.3306    0.3604    0.3448       222\n",
      "\n",
      "avg / total     0.7441    0.7352    0.7395      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7554383651944627\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4082934609250398\n",
      "Original f1: 0.31182795698924726\n",
      "0.169092365622\n",
      "0.985480375466\n",
      "371\n",
      "0.244561634806\n",
      "Number of disagreement: 269\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8671    0.8256    0.8459      1233\n",
      "          1     0.3732    0.4507    0.4083       284\n",
      "\n",
      "avg / total     0.7746    0.7554    0.7639      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.5-3-1.75-1\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8257839721254355\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3464052287581699\n",
      "Original f1: 0.1484375\n",
      "0.0356601187997\n",
      "0.974713448222\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 50\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8412    0.9665    0.8995       926\n",
      "          1     0.6310    0.2387    0.3464       222\n",
      "\n",
      "avg / total     0.8005    0.8258    0.7925      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8292682926829268\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4681724845995893\n",
      "Original f1: 0.31182795698924726\n",
      "0.0654113190454\n",
      "0.969010005213\n",
      "259\n",
      "0.170731707317\n",
      "Number of disagreement: 115\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8706    0.9278    0.8983      1233\n",
      "          1     0.5616    0.4014    0.4682       284\n",
      "\n",
      "avg / total     0.8128    0.8293    0.8178      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.5-3-1.75-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7343205574912892\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3524416135881104\n",
      "Original f1: 0.1484375\n",
      "0.174728812984\n",
      "0.986554666885\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 217\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8454    0.8207    0.8329       926\n",
      "          1     0.3333    0.3739    0.3524       222\n",
      "\n",
      "avg / total     0.7464    0.7343    0.7400      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7468688200395518\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.40372670807453415\n",
      "Original f1: 0.31182795698924726\n",
      "0.17753527155\n",
      "0.985480375875\n",
      "384\n",
      "0.25313117996\n",
      "Number of disagreement: 286\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8669    0.8135    0.8393      1233\n",
      "          1     0.3611    0.4577    0.4037       284\n",
      "\n",
      "avg / total     0.7722    0.7469    0.7578      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.5-3-2.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8205574912891986\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.39766081871345027\n",
      "Original f1: 0.1484375\n",
      "0.0680428296815\n",
      "0.974713448236\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 86\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8502    0.9438    0.8946       926\n",
      "          1     0.5667    0.3063    0.3977       222\n",
      "\n",
      "avg / total     0.7954    0.8206    0.7985      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8134475939353988\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.46704331450094155\n",
      "Original f1: 0.31182795698924726\n",
      "0.0880090751157\n",
      "0.985480373284\n",
      "283\n",
      "0.186552406065\n",
      "Number of disagreement: 159\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8740    0.9002    0.8869      1233\n",
      "          1     0.5020    0.4366    0.4670       284\n",
      "\n",
      "avg / total     0.8044    0.8134    0.8083      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.5-3-2.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7369337979094077\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3682008368200837\n",
      "Original f1: 0.1484375\n",
      "0.179999730412\n",
      "0.986554666898\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 224\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8498    0.8186    0.8339       926\n",
      "          1     0.3438    0.3964    0.3682       222\n",
      "\n",
      "avg / total     0.7519    0.7369    0.7438      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7462096242584048\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.40494590417310666\n",
      "Original f1: 0.31182795698924726\n",
      "0.180758772372\n",
      "0.988402039745\n",
      "385\n",
      "0.253790375742\n",
      "Number of disagreement: 289\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8674    0.8118    0.8387      1233\n",
      "          1     0.3609    0.4613    0.4049       284\n",
      "\n",
      "avg / total     0.7726    0.7462    0.7575      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.5-5-0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "1.04965546574e-12\n",
      "6.8015044985e-11\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "1.15914423696e-12\n",
      "1.42315843138e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.5-5-0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8092334494773519\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1411764705882353\n",
      "Original f1: 0.1484375\n",
      "0.0020382436703\n",
      "0.206948590562\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 1\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8170    0.9838    0.8927       926\n",
      "          1     0.5455    0.0811    0.1412       222\n",
      "\n",
      "avg / total     0.7645    0.8092    0.7474      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.8299274884640738\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.29120879120879123\n",
      "Original f1: 0.31182795698924726\n",
      "0.00445421171066\n",
      "0.183279371077\n",
      "258\n",
      "0.170072511536\n",
      "Number of disagreement: 8\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8392    0.9781    0.9034      1233\n",
      "          1     0.6625    0.1866    0.2912       284\n",
      "\n",
      "avg / total     0.8062    0.8299    0.7888      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.5-5-0.8-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "3.65058342271e-12\n",
      "4.28979504696e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "3.0301020976e-12\n",
      "1.42315843138e-10\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.5-5-0.8-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7560975609756098\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.31034482758620685\n",
      "Original f1: 0.1484375\n",
      "0.117467427441\n",
      "0.974713447834\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 152\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8351    0.8693    0.8519       926\n",
      "          1     0.3424    0.2838    0.3103       222\n",
      "\n",
      "avg / total     0.7398    0.7561    0.7471      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7738958470665788\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.4034782608695653\n",
      "Original f1: 0.31182795698924726\n",
      "0.135162877849\n",
      "0.985480375488\n",
      "343\n",
      "0.226104152933\n",
      "Number of disagreement: 219\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8630    0.8581    0.8605      1233\n",
      "          1     0.3986    0.4085    0.4035       284\n",
      "\n",
      "avg / total     0.7760    0.7739    0.7750      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.5-5-1.0-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "4.6596734891e-12\n",
      "3.22894669336e-10\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8312458800263678\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.31182795698924726\n",
      "Original f1: 0.31182795698924726\n",
      "9.38624232722e-06\n",
      "0.0142389204781\n",
      "256\n",
      "0.168754119974\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.5-5-1.0-2\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.7447735191637631\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.3201856148491879\n",
      "Original f1: 0.1484375\n",
      "0.136409600802\n",
      "0.975701881919\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 177\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8371    0.8488    0.8429       926\n",
      "          1     0.3301    0.3108    0.3202       222\n",
      "\n",
      "avg / total     0.7390    0.7448    0.7418      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7600527356624918\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.40522875816993464\n",
      "Original f1: 0.31182795698924726\n",
      "0.1533936481\n",
      "0.985480375734\n",
      "364\n",
      "0.239947264338\n",
      "Number of disagreement: 256\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8654    0.8345    0.8497      1233\n",
      "          1     0.3780    0.4366    0.4052       284\n",
      "\n",
      "avg / total     0.7742    0.7601    0.7665      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.5-5-1.25-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.8101045296167247\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1484375\n",
      "Original f1: 0.1484375\n",
      "0.000388950334742\n",
      "0.124612378684\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 0\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.8325642715886619\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.320855614973262\n",
      "Original f1: 0.31182795698924726\n",
      "0.0016551763023\n",
      "0.390232364668\n",
      "254\n",
      "0.167435728411\n",
      "Number of disagreement: 2\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8430    0.9757    0.9045      1233\n",
      "          1     0.6667    0.2113    0.3209       284\n",
      "\n",
      "avg / total     0.8100    0.8326    0.7952      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.5-5-1.25-2\n",
      "************************************************************\n",
      "==========================dev================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted accuracy: 0.7360627177700348\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.33698030634573306\n",
      "Original f1: 0.1484375\n",
      "0.158590683209\n",
      "0.977222413835\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 203\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8412    0.8294    0.8352       926\n",
      "          1     0.3277    0.3468    0.3370       222\n",
      "\n",
      "avg / total     0.7419    0.7361    0.7389      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n",
      "Adjusted accuracy: 0.7554383651944627\n",
      "Original accuracy: 0.8312458800263678\n",
      "Adjusted f1: 0.404494382022472\n",
      "Original f1: 0.31182795698924726\n",
      "0.163668470956\n",
      "0.985480375781\n",
      "371\n",
      "0.244561634806\n",
      "Number of disagreement: 267\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8659    0.8273    0.8461      1233\n",
      "          1     0.3717    0.4437    0.4045       284\n",
      "\n",
      "avg / total     0.7734    0.7554    0.7634      1517\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8418    0.9757    0.9038      1233\n",
      "          1     0.6591    0.2042    0.3118       284\n",
      "\n",
      "avg / total     0.8076    0.8312    0.7930      1517\n",
      "\n",
      "************************************************************\n",
      "classifier:  GB\n",
      "rank propagation parameters:  0.5-1.5-5-1.5-1\n",
      "************************************************************\n",
      "==========================dev================================\n",
      "Adjusted accuracy: 0.813588850174216\n",
      "Original accuracy: 0.8101045296167247\n",
      "Adjusted f1: 0.1769230769230769\n",
      "Original f1: 0.1484375\n",
      "0.00468136517701\n",
      "0.436575035651\n",
      "1\n",
      "0.000871080139373\n",
      "Number of disagreement: 4\n",
      "Adjusted\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8207    0.9838    0.8949       926\n",
      "          1     0.6053    0.1036    0.1769       222\n",
      "\n",
      "avg / total     0.7791    0.8136    0.7561      1148\n",
      "\n",
      "Original\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8178    0.9838    0.8931       926\n",
      "          1     0.5588    0.0856    0.1484       222\n",
      "\n",
      "avg / total     0.7677    0.8101    0.7491      1148\n",
      "\n",
      "==========================test================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-41cccef7ca19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m                                   \u001b[0mraw_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpara\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpara\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpara\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpara\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                                   \u001b[0mloss_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpara\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                                   pair_similarity_type=2)\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0my_pred_adjusted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-30a28bd1f7da>\u001b[0m in \u001b[0;36mrank_propagation\u001b[0;34m(data_filepath, qn_match_filepath, qn_simweights_filepath, r, alpha, sigma, n_neighbors, gamma, loss_type, pair_similarity_type)\u001b[0m\n\u001b[1;32m     60\u001b[0m     for (count, L) in get_weight_matrix(data_filepath, \n\u001b[1;32m     61\u001b[0m                                         \u001b[0mn_neighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                                         p=pair_similarity_type):\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;31m# Skip question without candidate answers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-51262a2e28fa>\u001b[0m in \u001b[0;36mget_weight_matrix\u001b[0;34m(input_file, n_neighbors, sigma, eps, p)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0manswer_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_pairwise_distance_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m                 \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure W symmetric.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mW\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mW\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Apply gaussian kernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-51262a2e28fa>\u001b[0m in \u001b[0;36mcompute_pairwise_distance_matrix\u001b[0;34m(X, k, p)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkdtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# k+1 as one pt is the pt itself.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hongwei/anaconda3/lib/python3.6/site-packages/scipy/spatial/kdtree.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, x, k, eps, p, distance_upper_bound)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mii\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mhits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance_upper_bound\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdistance_upper_bound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhits\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhits\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hongwei/anaconda3/lib/python3.6/site-packages/scipy/spatial/kdtree.py\u001b[0m in \u001b[0;36m__query\u001b[0;34m(self, x, k, eps, p, distance_upper_bound)\u001b[0m\n\u001b[1;32m    353\u001b[0m                 \u001b[0;31m# brute-force\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                 \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminkowski_distance_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mdistance_upper_bound\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hongwei/anaconda3/lib/python3.6/site-packages/scipy/spatial/kdtree.py\u001b[0m in \u001b[0;36mminkowski_distance_p\u001b[0;34m(x, y, p)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hongwei/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   1832\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1833\u001b[0m     return _methods._sum(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 1834\u001b[0;31m                          out=out, **kwargs)\n\u001b[0m\u001b[1;32m   1835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hongwei/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_prod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# For testing\n",
    "\n",
    "# This file contains entries indicating whether answer has a entity matching type required by answer prediction\n",
    "# Line corresponding to entry has 1 if there is a match, else 0\n",
    "qn_match_filepath = \"../data/QuestionType/test_answer_type_match.txt\"\n",
    "\n",
    "#dev\n",
    "dev_qn_match_filepath = \"../data/QuestionType/dev_answer_type_match.txt\"\n",
    "\n",
    "# This file contains the cosine *distance* between question and answer\n",
    "qn_simweights_filepath = \"../data/features/glove_embedding_sentence_similarities_test_300.txt\"\n",
    "\n",
    "#dev\n",
    "dev_qn_simweights_filepath = \"../data/features/glove_embedding_sentence_similarities_dev_300.txt\"\n",
    "\n",
    "import itertools    \n",
    "for key in classifiers:\n",
    "    # Set this to one of the trained classifiers above (after training)\n",
    "    clf = classifiers[key]\n",
    "    \n",
    "    if \"SIM\" not in key:\n",
    "        dev_raw_scores = clf.predict_proba(X_dev)[:, 1]\n",
    "        dev_raw_full_scores = clf.predict_proba(X_dev)\n",
    "        y_dev_pred = clf.predict(X_dev)\n",
    "\n",
    "        raw_scores = clf.predict_proba(X_test)[:, 1]\n",
    "        raw_full_scores = clf.predict_proba(X_test)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "    elif \"SIM\" in key:\n",
    "        dev_raw_scores = clf.predict_proba(X_comb_scaledsim_dev)[:, 1]\n",
    "        dev_raw_full_scores = clf.predict_proba(X_comb_scaledsim_dev)\n",
    "        y_dev_pred = clf.predict(X_comb_scaledsim_dev)\n",
    "\n",
    "        raw_scores = clf.predict_proba(X_comb_scaledsim_test)[:, 1]\n",
    "        raw_full_scores = clf.predict_proba(X_comb_scaledsim_test)\n",
    "        y_pred = clf.predict(X_comb_scaledsim_test)\n",
    "\n",
    "# These are used with best model\n",
    "# raw_scores = clf.predict_proba(X_comb_scaledsim_test)[:, 1]\n",
    "# raw_full_scores = clf.predict_proba(X_comb_scaledsim_test)\n",
    "# y_pred = clf.predict(X_comb_scaledsim_test)\n",
    "\n",
    "# I think we have to keep the number of neighbors in the graph small because there are only a few\n",
    "# positive examples. We don't want to link them to too many negative ones.\n",
    "# This works well with 300 dim glove vector\n",
    "# scores = rank_propagation(test_file, qn_match_filepath, qn_simweights_filepath, \n",
    "#                           raw_scores, alpha=1, sigma=1.0, n_neighbors=3, gamma=1.5)\n",
    "\n",
    "# L2 loss for | r - y | gives 0.6377 and 0.755 \n",
    "# scores = rank_propagation(test_file, qn_match_filepath, qn_simweights_filepath, \n",
    "#                           raw_scores, alpha=0.5, sigma=1, n_neighbors=3, gamma=1.5,\n",
    "#                           loss_type=1,\n",
    "#                           pair_similarity_type=2)\n",
    "\n",
    "# MRR = 0.7474 vs 0.7399, MAP = 0.6462, 0.6272 for pair_similarity_type=2, sigma=1.0\n",
    "# Generated with LR trained with C = 100, max_iter = 10000\n",
    "# map            all 0.6448\n",
    "# recip_rank     all 0.7537\n",
    "# scores = rank_propagation(test_file, qn_match_filepath, qn_simweights_filepath, \n",
    "#                           raw_scores, alpha=0.5, sigma=2.0, n_neighbors=3, gamma=1.5,\n",
    "#                           loss_type=1, \n",
    "#                           pair_similarity_type=1)\n",
    "\n",
    "# This with a LR trained with C = 2 gives MRR = 0.7674 MAP = 0.6518\n",
    "# For this to work, we have to use X_comb_scaledsim_test\n",
    "# scores = rank_propagation(test_file, qn_match_filepath, qn_simweights_filepath, \n",
    "#                           raw_scores, alpha=2.0, sigma=1.0, n_neighbors=5, gamma=1.0,\n",
    "#                           loss_type=1, \n",
    "#                           pair_similarity_type=2)\n",
    "\n",
    "    alphas = [0.05, 0.1, 0.5, 1.0, 1.5, 2.0]\n",
    "    sigmas = [0.5, 0.75, 1.0, 1.5, 2.0]\n",
    "    neighbors = [3, 5]\n",
    "    gammas = [0, 0.8, 1.0, 1.25, 1.5, 1.75, 2.0]\n",
    "    loss_type = [1, 2]\n",
    "    para_list = [alphas, sigmas, neighbors, gammas, loss_type]\n",
    "    paras = list(itertools.product(*para_list))\n",
    "    \n",
    "    for para in paras:\n",
    "        para_string = \"-\".join([str(p) for p in para])\n",
    "        \n",
    "        print(\"************************************************************\")\n",
    "        print(\"classifier: \", key)\n",
    "        print(\"rank propagation parameters: \", para_string)\n",
    "        print(\"************************************************************\")\n",
    "\n",
    "        print(\"==========================dev================================\")\n",
    "        \n",
    "        dev_scores = rank_propagation(dev_file, dev_qn_match_filepath, dev_qn_simweights_filepath, \n",
    "                                  dev_raw_scores, alpha=para[0], sigma=para[1], n_neighbors=para[2], gamma=para[3],\n",
    "                                  loss_type=para[4], \n",
    "                                  pair_similarity_type=2)\n",
    "\n",
    "        y_dev_pred_adjusted = (dev_scores >= 0.5)\n",
    "\n",
    "        print(\"Adjusted accuracy: {}\".format(accuracy_score(y_dev, dev_scores >= 0.5)))\n",
    "        print(\"Original accuracy: {}\".format(accuracy_score(y_dev, y_dev_pred)))\n",
    "        print(\"Adjusted f1: {}\".format(f1_score(y_dev, dev_scores >= 0.5)))\n",
    "        print(\"Original f1: {}\".format(f1_score(y_dev, y_dev_pred)))\n",
    "        print(np.sum(np.abs(dev_raw_scores - dev_scores)) / len(dev_scores))  # Average difference between actual\n",
    "        print(np.max(np.abs(dev_raw_scores - dev_scores)))\n",
    "        print(np.sum(y_test != (dev_scores >= 0.5)))\n",
    "        print(np.sum(y_test != (dev_scores >= 0.5)) / float(len(dev_scores)))\n",
    "        print(\"Number of disagreement: {}\".format(np.sum(np.abs(y_dev_pred - y_dev_pred_adjusted))))\n",
    "        print(\"Adjusted\")\n",
    "        print(classification_report(y_dev, y_dev_pred_adjusted, digits=4))\n",
    "        print(\"Original\")\n",
    "        print(classification_report(y_dev, y_dev_pred, digits=4))\n",
    "    \n",
    "        # Convert dev to weka format\n",
    "        P_dev = np.hstack(((1 - dev_scores).reshape(-1, 1), dev_scores.reshape(-1, 1)))\n",
    "        dev_path = \"../myclassify/test_res/RP\" + key + \"-dev/\" + key + \"-\" + para_string + \".txt\"\n",
    "        \n",
    "        ensure_dir_exists(dev_path)\n",
    "        \n",
    "        predict_for_test(y_dev, y_dev_pred_adjusted, P_dev, dev_path)\n",
    "        #predict_for_test(y_test, y_dev_pred, dev_raw_full_scores, \"nb_no_adjust.txt\")\n",
    "\n",
    "        print(\"==========================test================================\")\n",
    "        \n",
    "        scores = rank_propagation(test_file, qn_match_filepath, qn_simweights_filepath, \n",
    "                                  raw_scores, alpha=para[0], sigma=para[1], n_neighbors=para[2], gamma=para[3],\n",
    "                                  loss_type=para[4], \n",
    "                                  pair_similarity_type=2)\n",
    "\n",
    "        y_pred_adjusted = (scores >= 0.5)\n",
    "    \n",
    "\n",
    "        print(\"Adjusted accuracy: {}\".format(accuracy_score(y_test, scores >= 0.5)))\n",
    "        print(\"Original accuracy: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "        print(\"Adjusted f1: {}\".format(f1_score(y_test, scores >= 0.5)))\n",
    "        print(\"Original f1: {}\".format(f1_score(y_test, y_pred)))\n",
    "        print(np.sum(np.abs(raw_scores - scores)) / len(scores))  # Average difference between actual\n",
    "        print(np.max(np.abs(raw_scores - scores)))\n",
    "        print(np.sum(y_test != (scores >= 0.5)))\n",
    "        print(np.sum(y_test != (scores >= 0.5)) / float(len(scores)))\n",
    "        print(\"Number of disagreement: {}\".format(np.sum(np.abs(y_pred - y_pred_adjusted))))\n",
    "        print(\"Adjusted\")\n",
    "        print(classification_report(y_test, y_pred_adjusted, digits=4))\n",
    "        print(\"Original\")\n",
    "        print(classification_report(y_test, y_pred, digits=4))\n",
    "    \n",
    "    \n",
    "        # Convert test to weka format\n",
    "        P = np.hstack(((1 - scores).reshape(-1, 1), scores.reshape(-1, 1)))\n",
    "        test_path = \"../myclassify/test_res/RP\" + key + \"-test/\" + key + \"-\" + para_string + \".txt\"\n",
    "        predict_for_test(y_test, y_pred_adjusted, P, test_path)\n",
    "        #predict_for_test(y_test, y_pred, raw_full_scores, \"nb_no_adjust.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LR with C = 1, max_iter = 10000\n",
    "scores = rank_propagation(test_file, qn_match_filepath, qn_simweights_filepath, \n",
    "                          raw_scores, alpha=0.5, sigma=1, n_neighbors=3, gamma=1.5,\n",
    "                          loss_type=1,\n",
    "                          pair_similarity_type=2)\n",
    "\n",
    "Adjusted\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          0       0.85      0.98      0.91      1233\n",
    "          1       0.74      0.26      0.38       284\n",
    "\n",
    "avg / total       0.83      0.84      0.81      1517\n",
    "\n",
    "Original\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          0       0.83      0.98      0.90      1233\n",
    "          1       0.69      0.15      0.24       284\n",
    "\n",
    "avg / total       0.81      0.83      0.78      1517"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MRR = 0.7474 vs 0.7399, MAP = 0.6462, 0.6272\n",
    "LR trained with C = 100, max_iter = 10000\n",
    "\n",
    "scores = rank_propagation(test_file, qn_match_filepath, qn_simweights_filepath, \n",
    "                          raw_scores, alpha=0.5, sigma=1, n_neighbors=3, gamma=1.5,\n",
    "                          loss_type=1, \n",
    "                          pair_similarity_type=2)\n",
    "                          \n",
    "Adjusted\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          0       0.85      0.98      0.91      1233\n",
    "          1       0.73      0.24      0.36       284\n",
    "\n",
    "avg / total       0.83      0.84      0.81      1517\n",
    "\n",
    "Original\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          0       0.83      0.98      0.90      1233\n",
    "          1       0.68      0.14      0.24       284\n",
    "\n",
    "avg / total       0.81      0.83      0.78      1517\n",
    "                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For training\n",
    "train_raw_scores = clf.predict_proba(X_train)[:, 1]\n",
    "scores = rank_propagation(train_file, train_raw_scores, alpha=2, sigma=2, n_neighbors=11)\n",
    "\n",
    "print(accuracy_score(y_train, scores >= 0.5))\n",
    "print(np.sum(np.abs(train_raw_scores - scores)) / len(scores))  # Average difference between actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_train, clf.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
