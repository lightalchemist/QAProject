{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Map each word to an index\n",
    "glove_path = \"../data/glove.6B.100d.txt\"\n",
    "with open(glove_path, \"rb\") as lines:\n",
    "    w2idx = {line.split()[0].decode(\"utf-8\"): i for i, line in enumerate(lines)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "￥\n",
      "ﬁrst\n",
      "ﬁnds\n",
      "ﬁgures\n",
      "ﬁeld\n",
      "행정동\n",
      "법정동\n",
      "鳳翔\n",
      "魏博\n",
      "門下省\n"
     ]
    }
   ],
   "source": [
    "for x in sorted(w2idx.keys(), reverse=True)[:10]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.array?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ndim = 100\n",
    "vectors = np.empty((len(w2idx), ndim), dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(glove_path, \"rb\") as lines:\n",
    "    for i, line in enumerate(lines):\n",
    "        vectors[i] = np.asarray(map(float, line.split()[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.038194, -0.24487 ,  0.72812 , -0.39961 ,  0.083172,  0.043953,\n",
       "       -0.39141 ,  0.3344  , -0.57545 ,  0.087459])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"awesome\" in w2idx.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tokenizer\n",
    "reload(tokenizer)\n",
    "from tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"../data/train_reviews_only.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'review\\n'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "line = f.readline().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I\\'ve been to The Greene House twice and really do love the atmosphere of this restaurant. That wasn\\'t unexpected for me though as it\\'s a Fox Restaurant and those folks have the game on LOCK!   The Greene House is cozy, bright, well-decorated, and airy- very \"West Coast\". I love it.  One my 1st visit I had the fresh pasta (it comes with spinach, tomato, and parm) and although I had high hopes, I was a little disappointed. The pasta wasn\\'t al dente and was actually somewhat mushy and overcooked. Also it was skimpy on the cheese and that is a cardinal sin in my world. For me, cheese = life.  On my 2nd visit I had the roasted sea bass with potato puree, spinach, broccoli, onion, and lemon vinaigrette. It was absolutely delicious but HOLY TINY PORTION SIZE BATMAN. This itsy bitsy ass portion of sea bass cost $25? Very, very disappointing. I most definitely did not get my money\\'s worth. For about $5 more I could go to Pappadeaux\\'s and get twice this amount of sea bass. And it tastes just as good TBH.  Also, I have to remark that my food came out cold on both visits. That\\'s a huge pet peeve of mine. I will give Greene House a 3rd chance though- the pineapple mango mule drink is to die for!'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_features(path, num_examples, ndim, word_index, wordvectors):\n",
    "    tokenizer = Tokenizer()\n",
    "\n",
    "    embeddings = np.zeros((num_examples, ndim), dtype=np.float)\n",
    "    with open(path) as infile:\n",
    "        infile.readline()  # Discard header\n",
    "        for i, line in enumerate(infile):\n",
    "            try:\n",
    "                words = tokenizer(line.strip())\n",
    "                embeddings[i] = np.mean([ wordvectors[w2idx[w]] for w in words if w in w2idx ] \n",
    "                                         or [np.zeros(n)], axis=0)\n",
    "            except UnicodeDecodeError:\n",
    "                print(line.strip())\n",
    "                raise\n",
    "                \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utils.save_obj(\"../data/glove_100_train.pkl\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_reviews_path = \"../data/test_reviews_only.txt\"\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "m = 40000\n",
    "n = 100\n",
    "embeddings = np.zeros((m, n), dtype=np.float)\n",
    "with open(test_reviews_path) as infile:\n",
    "    infile.readline()  # Discard header\n",
    "    for i, line in enumerate(infile):\n",
    "        try:\n",
    "            words = tokenizer(line.strip())\n",
    "            embeddings[i] = np.mean([ vectors[w2idx[w]] for w in words if w in w2idx ] \n",
    "                                     or [np.zeros(n)], axis=0)\n",
    "        except UnicodeDecodeError:\n",
    "            print(line.strip())\n",
    "            raise\n",
    "\n",
    "utils.save_obj(\"../data/glove_100_test.pkl\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 100)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.alltrue(np.zeros(3) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for i, v in enumerate(embeddings):\n",
    "    count = 0\n",
    "    if not np.any(v):\n",
    "        count += 1\n",
    "print(count)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
