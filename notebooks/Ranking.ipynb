{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For training classifiers to predict/rank answers\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import arff\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "#import data\n",
    "def importData(path):\n",
    "    dataset = arff.load(open(path, 'rb'))\n",
    "    data = np.array(dataset['data'])\n",
    "    #print data[:10]\n",
    "\n",
    "    #extract features and labels\n",
    "    features = []\n",
    "    labels = []\n",
    "    for d in data:\n",
    "        f = []\n",
    "        for i in range(len(d) - 1):\n",
    "            num = float(d[i])\n",
    "            if int(num) == num:\n",
    "                num = int(num)\n",
    "            f.append(num)\n",
    "        features.append(f)\n",
    "\n",
    "        if d[-1] == \"positive\":\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "    return np.asarray(features), np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_similarity_features(filepath):\n",
    "    features = []\n",
    "    labels = []\n",
    "    map_label = {\"positive\": 1, \"negative\": 0}\n",
    "    with open(filepath) as infile:\n",
    "        for line in infile:\n",
    "            label, score = line.strip().split(',')\n",
    "            score = float(score)\n",
    "            label = map_label[label]\n",
    "            features.append(score)\n",
    "            labels.append(label)\n",
    "            \n",
    "    return np.asarray(features).reshape(-1, 1), np.asarray(labels)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jacana features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import training data and test data\n",
    "train_datapath = \"../myclassify/qa.train.arff\"\n",
    "test_datapath = \"../myclassify/qa.test.arff\"\n",
    "\n",
    "X_train, y_train = importData(train_datapath)\n",
    "X_test, y_test = importData(test_datapath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add GloVe vectors question answer similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Qn answer similarity scores\n",
    "X_sim_train, y_sim_train = load_similarity_features(\"../data/features/glove_embedding_sentence_similarities_train_100.txt\")\n",
    "X_sim_test, y_sim_test = load_similarity_features(\"../data/features/glove_embedding_sentence_similarities_test_100.txt\")\n",
    "\n",
    "X_combined_train = np.hstack((X_train, X_sim_train))\n",
    "X_combined_test = np.hstack((X_test, X_sim_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add type features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize data\n",
    "\n",
    "NOTE: Might not want to do this for Random Forest-like classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Scale combined data\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(X_combined_train)\n",
    "X_comb_scaled_train = scaler.transform(X_combined_train)\n",
    "X_comb_scaled_test = scaler.transform(X_combined_test)\n",
    "\n",
    "# Scale Jacana features only\n",
    "# scaler = RobustScaler()\n",
    "# scaler.fit(X_train)\n",
    "# X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# Only normalize the similarity scores\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(X_sim_train)\n",
    "X_sim_train = scaler.transform(X_sim_train)\n",
    "X_sim_test = scaler.transform(X_sim_test)\n",
    "X_comb_scaledsim_train = np.hstack((X_train, X_sim_train))\n",
    "X_comb_scaledsim_test = np.hstack((X_test, X_sim_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply dim reduction to denoise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=30)\n",
    "pca.fit(X_combined_train)\n",
    "X_pca_train = pca.transform(X_combined_train)\n",
    "X_pca_test = pca.transform(X_combined_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x117762d90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEKCAYAAAACS67iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHydJREFUeJzt3X+cHHWd5/HXOwn5AYQQIJlAEgLxR0QEAyrIgdL8VlDC\n4Rp0TwVRdFcX3FsWDay7jO4tD/Fxnrjr+tBT5HL4iyBCgodHYJMGRQSEgBhC0MOEX8kEws8kQkjm\nc398q5lOZ3qmZ7p7errm/Xw86tHV1V1Vn0pNPvXtT9W3ShGBmZm1v1GtDsDMzBrDCd3MLCec0M3M\ncsIJ3cwsJ5zQzcxywgndzCwnnNCtLUiaJalbUr9/s5KOkbSqSXFcJenLzVh2L+u6SdJHh2Jdlg9O\n6COApDWStkh6UdK6LCntWvb5KZJuyz7vkrRc0vsrllHIEupFQ78Fr6mp00RE/CoiDmp2MM0WEadG\nxNWtjsPahxP6yBDAaRGxB3A48HbgiwCS/gJYBPwvYHpEdAD/BLyvYhkfAx7MXq3JJKnVMVj7cUIf\nOQQQEeuAXwBvyaZ/DfhSRFwVES9l3/llRHz6tRlTa/4vgL8C9pd0eJ8rkt4naYWk5yT9StIh2fTZ\nkjZKmpu930/SBknvzt4vl3SZpLskvSDpekl7VlnHOZIeyn5V/FHSp8o+O1bS42Xv/yTpQkkPZDH9\nWNLY/uLNPjtM0r1ZPD8BxleJZ2w2/5vLpu2T/TLaR9Kekm7MtndjNj697LvLJf23bP2bgQOzaeeW\n/dv9h6RnsmX8QNIeA9jGedk2viDpD5JOzqbvIel7kp6S9Likf/bBpH05oY8wkmYCpwL3SZoDzASu\n62e2DwBdEXEn8HPg7D6WfxhwJXAesBfwHWCJpF0i4lHg88APJE0ArgKuiojbyxbxUeAcYBqwHfi3\nKqvqAk7NfnV8HPh66UCRqSzPfBA4GTgQeGu2jj7jlbQLcD2wMPvs2uzfYicRsZX07/jhssnzgWJE\nPEP6v/Z90r/3/sAW4JsVi/kI8ElgIvBYxWcCLiP9uxwEzAA6a9zGI7JtuDAiJgHvBtZk8ywEtgKz\ngcOAk7IYrB1FhIecD8CfgBeBZ7PxfwPGAf+JlDTH9jP/LcC/ZONnkJLp6Crf/RapxV8+7WHgXWXv\nbwB+B9wP7FI2fTlwWdn7g4BXSMlsVhbrqCrrvR44Pxs/FnisYvs/XPb+cuBb/cWbDU9UfHYH8OUq\nMZwA/LHs/a+Aj1T57lxgY8W2d1Z8ZzlwbpX55wH31riN3wa+1ssypgIvA+PKpn0IWNbqv1kPgxvG\n1JDzLR/mRcTy8gmSNmaj+wJre5spa9EfB5ROhv5fYAJwGrCkl1lmAR+TdH5pEcAuwH5l3/kesBj4\nVES8WjH/42Xja7N59+klrveSav1vJLV+J5AOEtV0lY1vIW1zLfE+WbGcXv+dMsuBCZLeAWwgtZKv\nz+KdAFwBnALsma1nd0mKLJOy47bvQNJU4Bukg8zuwGjSAbqWbZwJ/J9eFjuLtK3rsiqLsqHy14G1\nCZdcRo6d6qIRsZqURHotI2Q+ms17k6R1pJbgOKqXXR4nteb3yobJEbF7RFwDIGk3UmK7EujspUY+\ns2x8Fqkc8MwOG5Jqwz8FvgpMiYjJpPMCg6n99hXvOmB6xff3r7agiOgmnWD+S1Lp5ecRsTn7+ELg\nDcA7ImJPUtmDipj7uornMqAbODib/yPUvr2PA6+rMv1lYO+ybd8zIg6tcbk2zDih24XAP0o6W9JE\nJcdI+nb2+cdItdq5pBbnW0knSE+TNLmX5X0X+Kusbouk3SSdmiVygH8F7o6ITwE3kWrW5T4i6U3Z\nidgvAdeWtWBLCWxsNjwTEd1Za/3kQW5/X/HeCWyTdL6kMZLOBI7oZ3k/Bs4iJfUflU2fCPwZeFHS\nXuxc/+7PRGAT8FJ2MnUgl49eCXxc0nHZ/t1P0pyIWA8sJZ1/KO372cpOUlv7cUIfGaq2/CLiOlIC\n+gSpvLAe+DKwWNKRpBbptyJiQ9lwI/AHdjwBWFrevaQTjN+U9CzwCFlrXtLppMT7mezrfwccJql8\nOVeTTtQ9RUran6vcjojYBFwAXJut40OkEs5gtr9qvFk56EzSSdeNpJOOfZ5Ajoi7gc2kcscvyj66\nAtiV9Gvj16SDWX8xlk/7EvA24Hngxl7i6Gsb78m24QrgBaBIzy+Nj5H+nR8ilXCuJZ14tTaknsZP\nH1+SPkfPme/vRsS/Zq2za0g/i9cA8yPihWYFavknaTlwdUR8v9WxmLWjWrpRH0xqvb2d9LP7fZJe\nBywAbo2IOcAy4OJmBmpmZn2rpeRyEHBXRLwSEduB20k/Q08n/TQmez2jOSHaCOLnIZrVod+Si6Q3\nka4bPop0TfCtwG9J19fuVfa9Z8vfm5nZ0Or3OvSIeFjS5aTOJZuAFaQOHjt9tcGxmZnZANTUsSgi\nriJ100bSv5CuX+2S1BERXZKmkTpS7ESSE72Z2SBExID6VtR02aKkKdnr/sB/Jl1fu4TsXhGky7yq\nXjbW6u6wzRwuvfTSlsfg7fO2efvyNwxGrV3/r8s6Q7wKfCYiXszKMIuyu8GtJd2IyMzMWqTWkstO\nPcci4lngxIZHZGZmg+KeonUqFAqtDqGp8rx9ed428PaNRDX1FK1rBTvcTM7MzGohiWjGSVEzMxv+\nnNDNzHLCCd3MLCec0M3McsIJ3cwsJ5zQzcxywgndzCwnnNDNzHLCCd3MLCec0M3McmJIEvr23h6H\nYWZmDTUkCf3pp4diLWZmI9uQJPT164diLWZmI9uQJPSurqFYi5nZyFbrI+gulrRS0u8k/VDSWEmT\nJS2VtFrSzZImVZvfLXQzs+brN6FLmgWcBxwWEYeSnnL0YWABcGtEzAGWARdXW4YTuplZ89XSQn8R\n2ArsJmkMMAF4EpgHLMy+sxA4o9oCXHIxM2u+fhN6RDwHfA14jJTIX4iIW4GOiOjKvrMemFptGW6h\nm5k1X78PiZY0G/ivwCzgBeBaSf8FqHyuXNXnzN15ZyednWm8UCj4WYBmZhWKxSLFYrGuZfT7TFFJ\n84GTIuK87P1HgXcCxwOFiOiSNA1YHhEH9TJ/vPnNwcqVdcVpZjaiNOuZoquBd0oaL0nACcBDwBLg\nnOw7ZwOLqy3AJRczs+brt4UOIOkiUvLeDqwAPglMBBYBM4G1wPyIeL6XeWPMmGDzZhg7toGRm5nl\n2GBa6DUl9HpIiv32C+66C2bMaOqqzMxyo1kll7pNm+ayi5lZsw1JQu/ocEI3M2s2t9DNzHJiyBK6\ne4uamTWXSy5mZjnhkouZWU645GJmlhNuoZuZ5YRr6GZmOTEkCX3SJNi6FbZsGYq1mZmNTEOS0CXX\n0c3Mmm1IEjq47GJm1mxDltDdQjcza64hTehuoZuZNY9LLmZmOeEWuplZTvSb0CW9UdIKSfdlry9I\nukDSZElLJa2WdLOkSX0txzV0M7Pm6jehR8QjEXFYRBwOvA3YDFwPLABujYg5wDLg4r6W45KLmVlz\nDbTkciLw/yLicWAesDCbvhA4o68ZXXIxM2uugSb0s4AfZeMdEdEFEBHrgal9zdjRkUouTX6EqZnZ\niDWm1i9K2gU4HfhCNqkyNVdN1Z2dnQBs2wY33VTgtNMKAwrSzCzvisUixWKxrmUoamwySzod+ExE\nvCd7vwooRESXpGnA8og4qJf5orSO178ebroJ3vjGumI2M8s9SUSEBjLPQEouHwZ+XPZ+CXBONn42\nsLi/BfhKFzOz5qkpoUvalXRC9Gdlky8HTpK0GjgB+Ep/y/GJUTOz5qmphh4RW4ApFdOeJSX5mvnS\nRTOz5hmynqLgFrqZWTMNeUJ3Dd3MrDmGNKG75GJm1jwuuZiZ5YRLLmZmOVFzx6JBr6CsY9Err8DE\nifDyyzBqSA8lZmbtpdkdi+o2bhzsths899xQrtXMbGQY8nayyy5mZs3RkoTuE6NmZo035Andly6a\nmTWHSy5mZjnhkouZWU645GJmlhNuoZuZ5YRr6GZmOeEWuplZTtT6xKJJkq6VtErSSklHSposaamk\n1ZJuljSplmVNmQIbN8L27fUFbmZmO6q1hf4N4KbsIdBvBR4GFgC3RsQcYBlwcS0LGjMGJk+GZ54Z\nTLhmZlZNvwld0h7AuyLiKoCI2BYRLwDzgIXZ1xYCZ9S6UpddzMwar5YW+oHAM5KuknSfpP+ZPTS6\nIyK6ACJiPTC11pX60kUzs8ar5SHRY4DDgc9GxG8lfZ1Ubqm8727V+/B2dna+Nl4oFJg2reArXczM\nyhSLRYrFYl3L6Pd+6JI6gDsjYnb2/hhSQn8dUIiILknTgOVZjb1y/qhcx0UXpZOjn/98XbGbmeVW\nU+6HnpVVHpf0xmzSCcBKYAlwTjbtbGBxrSt1ycXMrPFqKbkAXAD8UNIuwKPAx4HRwCJJ5wJrgfm1\nrnTaNFixYqChmplZX2pK6BHxAPCOXj46cTAr9VUuZmaN15Ine7rkYmbWeC1J6G6hm5k1Xr9XudS9\ngl6ucunuhvHjYdMmGDu2qas3M2tLTbnKpRlGjUqXLW7Y0Iq1m5nlU0sSOriObmbWaC1L6L4vuplZ\nY7U0obuFbmbWOC65mJnlhEsuZmY54ZKLmVlOuORiZpYTbqGbmeWEa+hmZjnRsoQ+aRK88gps2dKq\nCMzM8qVlCV1KdXS30s3MGqOmhC5pjaQHJK2QdHc2bbKkpZJWS7pZ0qSBrtxlFzOzxqm1hd5Nen7o\nYRFxRDZtAXBrRMwBlgEXD3TlPjFqZtY4tSZ09fLdecDCbHwhcMZAV+5LF83MGqfWhB7ALZLukfTJ\nbFpH9gBpImI9MHWgK3fJxcyscWp9SPTREbFO0hRgqaTVpCRfbsBPypg2DR58cKBzmZlZb2p9SPS6\n7PVpSTcARwBdkjoiokvSNKDq4yo6OztfGy8UChQKBSCVXG65ZdCxm5nlRrFYpFgs1rWMfh9BJ2lX\nYFREbJK0G7AU+BJwAvBsRFwu6QvA5IhY0Mv8Oz2CruSOO+Cii+DXv65rG8zMcmcwj6CrpYXeAVwv\nKbLv/zAilkr6LbBI0rnAWmD+QAP2VS5mZo3TkodEl2zaBFOnwubNqaORmZklbfOQ6JLdd08PjH7p\npVZGYWaWDy1N6OBLF83MGmVYJHTX0c3M6tfyhO7eomZmjdHyhO6Si5lZYwyLhO4WuplZ/Vqe0F1y\nMTNrjJYndJdczMwaY1gkdLfQzczq1/KE7pKLmVljtLTrP8DLL8Mee6QHRrv7v5lZ0nZd/wHGj4fd\ndoPnnmt1JGZm7a3lCR1cRzcza4RhkdBdRzczq9+wSOi+dNHMrH7DJqG7hW5mVp+aE7qkUZLuk7Qk\nez9Z0lJJqyXdLGnSYINwycXMrH4DaaF/Dnio7P0C4NaImAMsAy4ebBAuuZiZ1a+mhC5pBnAq8L2y\nyfOAhdn4QuCMwQbhkouZWf1qbaF/HbgIKO8h1BERXQARsR6YOtggXHIxM6tfvwld0mlAV0TcD/TV\na2nQXU5dcjEzq9+YGr5zNHC6pFOBCcBESVcD6yV1RESXpGnAhmoL6OzsfG28UChQKBR2+HzKFHjm\nGdi+HUaPHvhGmJm1u2KxSLFYrGsZA7qXi6RjgQsj4nRJXwU2RsTlkr4ATI6IBb3M0+e9XEqmTIHf\n/z6VX8zMRrqhvpfLV4CTJK0GTsjeD5pPjJqZ1aeWkstrIuI24LZs/FngxEYF4jq6mVl9hkVPUXAL\n3cysXsMmofvSRTOz+gybhO6Si5lZfYZNQn/d62DlylZHYWbWvlr+CLqSjRvhwAPT6y67NDUkM7Nh\nry0fQVey994wezb89retjsTMrD0Nm4QOcNxxsHx5q6MwM2tPTuhmZjkxbGroAM8/DzNnpvu6jBvX\n1LDMzIa1tq6hA+y5J8yZA3ff3epIzMzaz7BK6OCyi5nZYDmhm5nlxLCqoQO89BLsu2+qo48f38TA\nzMyGsbavoQNMnAhveQvceWerIzEzay/DLqGDyy5mZoPhhG5mlhP91tAljQNuB8Zmw+KIuETSZOAa\nYBawBpgfES/0Mv+AaugAmzen2+lu2AC77jqgWc3McqEpNfSIeAU4LiIOAw4Fjpd0NLAAuDUi5gDL\ngIsHEXOvdtsN5s6FO+5o1BLNzPKvppJLRGzJRsdl8zwHzAMWZtMXAmc0MjCXXczMBqamhC5plKQV\nwHqgGBEPAR0R0QUQEeuBqY0MzAndzGxganpIdER0A4dJ2gO4WVIBqCyMVy2Ud3Z2vjZeKBQoFAr9\nrvOoo+DBB9N16RMn1hKlmVn7KhaLFIvFupYx4I5Fkv4R+DPwCaAQEV2SpgHLI+KgXr4/4JOiJcce\nCwsWwHvfO6jZzczaVlNOikraR9KkbHwCcBKwAlgCnJN97Wxg8YCirYHLLmZmtaul5LIvsFCSSAeA\nqyPiP7Ka+iJJ5wJrgfmNDu644+Dv/77RSzUzy6dhdy+Xcq+8kh5N9+STMGlSgwMzMxvGcnEvl3Lj\nxsGRR8Ivf9nqSMzMhr9hndDBdXQzs1o5oZuZ5cSwrqEDbN0K++wDa9bAXns1Li4zs+EsdzV0gLFj\nUyej229vdSRmZsPbsE/o4LKLmVktnNDNzHJi2NfQAbZtS9ej//GPMGVKgwIzMxvGcllDBxgzBo45\nBm67rdWRmJkNX22R0MFlFzOz/jihm5nlRFvU0AG2b0/Xo69aBdOmNSAwM7NhLLc1dIDRo+Hd74Y6\n7/9uZpZbbZPQwWUXM7O+OKGbmeVEWyX0Qw6BZ59N90c3M7Md1fIIuhmSlklaKelBSRdk0ydLWipp\ntaSbS4+pa2qwo9JzRt1KNzPbWS0t9G3A30XEwcBRwGclvQlYANwaEXOAZcDFzQuzh8suZma96zeh\nR8T6iLg/G98ErAJmAPOAhdnXFgJnNCvIck7oZma9G1ANXdIBwFzgN0BHRHRBSvrA1EYH15s3vxk2\nb4a1a4dibWZm7WNMrV+UtDvwU+BzEbFJUmVvoaq9hzo7O18bLxQKFAqFgUW5QxxQKKRW+jnnDHox\nZmbDSrFYpFhnR5uaeopKGgP8HPhFRHwjm7YKKEREl6RpwPKIOKiXeRvSU7Tct78Nd9wBV1/d0MWa\nmQ0bzewp+n3goVIyzywBzsnGzwYWD2TF9Zg3L7XQr7pqqNZoZjb89dtCl3Q0cDvwIKmsEsAlwN3A\nImAmsBaYHxHP9zJ/w1voAKtXw4knQmcnfOITDV+8mVlLDaaF3jY35+rNH/4AJ5wAX/wifOpTTVmF\nmVlLDCah13xSdDh6wxtg2bKU1Ldvh7/+61ZHZGbWOm2d0AFe//pUTz/+eOjuhs9+ttURmZm1Rtsn\ndIDZs9NtdY87LrXUL7ig1RGZmQ29XCR0gAMO6Enq3d3wt3/b6ojMzIZWbhI6wKxZO7bUL7yw1RGZ\nmQ2dXCV0gP33T0n9+ONTUv/851sdkZnZ0MhdQgeYOXPHlvrFQ3IfSDOz1splQgeYPr2npR4Bl1zS\n6ojMzJqrrTsW1WLdOjjiCPjBD9LDMczM2kEz7+XStvbdF775Tfj0p+Hll1sdjZlZ8+Q+oUO6mdfB\nB8Nll7U6EjOz5sl9yaXkySdh7txUVz/44FZHY2bWN5dc+jB9Onz5y+kmXt3drY7GzKzxRkxCh1RH\nB/jOd1obh5lZM4yYkkvJypXpEXb3359a7WZmw5FLLjU4+OB0m13fwMvM8qbfhC7pSkldkn5XNm2y\npKWSVku6WdKk5obZWJdcklrqN9zQ6kjMzBqnlhb6VcApFdMWALdGxBxgGdBWnevHj0919PPPhxdf\nbHU0ZmaNUVMNXdIs4MaIODR7/zBwbER0SZoGFCPiTVXmHVY19HLnnQfjxqWOR2Zmw8lQ1tCnRkQX\nQESsB6YOcjkt9dWvws9+Bnfe2epIzMzq16ibc/XZBO/s7HxtvFAoUCgUGrTa+kyeDFdckVrq990H\nY8e2OiIzG6mKxSLFYrGuZQy25LIKKJSVXJZHxEFV5h22JRdId2J8//vhqKPgH/6h1dGYmSXNLLko\nG0qWAOdk42cDiwey0uFEgn//d/j61+GRR1odjZnZ4PXbQpf0I6AA7A10AZcCNwDXAjOBtcD8iHi+\nyvzDuoVecsUVsHgxLFuWkryZWSsNpoU+4nqKVrN9O7zznanT0bnntjoaMxvpBpPQc/vEooEaPRq+\n+1046SRYvx4+8AGYM6fVUZmZ1W7Edf3vy9y5cOON8NRT6XmkBx8M//RP8MAD6eSpmdlw5pJLFd3d\n8JvfpOvUr7suteDPPDO13I84wnV2M2su19CbJAJWrEiJ/brrYPPmlNzPPBOOPhrGuHBlZg3mhD4E\nIuChh1LL/Wc/gzVr4Pjj4ZRT4OST4YADWh2hmeWBE3oLrFsHt9wCS5emYfLklNhPOSXdd3333Vsd\noZm1Iyf0FuvuTidQb745Jfd77oG3v70nwR96qMszZlYbJ/RhZtMmuO22ntb7o4/CvvvCrFmpNFP+\nOmsWzJyZ7v5oZuaEPsxt3QqPPw5r16ZhzZodx596CvbZJyX3ww+Hs85KJ11H+eJSsxHHCb3Nbd+e\nkvqaNfDLX8I118DGjfDBD6bkfuSRvlzSbKRwQs+hVatg0SL4yU/gz3+G+fNTcj/8cCd3szxzQs+x\nCHjwwdRqv+aaNO2ss9JwyCFO7mZ544Q+QkSkB3IsWpSS+6uvwn77wdSp0NHR++vUqak+76tszNqD\nE/oIFAGPPQYbNkBXVxp6G9+wAZ59FvbeO11ZM3s2HHhgGkrjM2fCLru0eovMDJzQrR/btqXE/qc/\n7Tg8+mh6Xb8+tfRLiX7WrJ7H8kk9ZZ3KcUhX4kyZAjNmpAPD9OkwfvzQb6NZXgx5Qpf0HuAK0l0b\nr4yIy3v5jhN6m9i6NbX2S4n+scfSQSCi526TleOl1+7udLB44ok0PPkk7LFHSu4zZvQMpfeTJqVr\n7kvD2LE7vvelmjbSDWlClzQKeAQ4AXgKuAf4UEQ8XPG9XCf0YrE4bB563QyD3b7ubnj66Z4E/8QT\n6Rr80utLL8Err+w4bN3aMz569M6Jvr/xsWNhwoR0INljD5g4sWe88v3EiXDvvUVOOqmQ2xPK/tts\nb0P9gIsjgD9ExNps5T8B5gEP9zlXzuT9j2qw2zdqVDoh29EBb3vbwOaNSL8MKpN85fvePtuyJR0s\nXnwx/UpYtSqNl6aVhpdeguefLxJRYNSodO6gchgzZsf3o0ZVH6Qd348Z0zN/5XjltGq/Rno70Iwe\nneYZO7YnrtJ45bRFi4q8/HKB0aPTukaPZofx3qaNGtUzrdpQir3VB8K8/98bjHoS+nTg8bL3T5CS\nvFldpJ7E1EydnXDppalD16uv7jxs27bj+1JpqdpQ+nz79p5llpaxbVvv46XlVqo2rbTcLVvSAay0\njNJ4+bSVK9OJ8G3b0nyl1/Lxytfy+KsNpe+OHbvjUPqVVDmUDljlB4DKczDl52LKDyx9vT7wQOpl\nXTqn09t5nvKhtwNv+fvKz2qNo9b1S6mT4IQJdf/pVuWL2GxEk3panM38j9YKnZ1paIbu7p4DSOnX\nUeVQml5+3gV6PwdTei0dHMsPLtVen38e3vWunuVXnucpn1Z+wK08MJe/Lx00u7t3PshVe+1v/eWf\nzZvX3L+zemro7wQ6I+I92fsFQFSeGJWU3wK6mVkTDeVJ0dHAatJJ0XXA3cCHI2LVoBZoZmZ1GXTJ\nJSK2S/obYCk9ly06mZuZtUjTOxaZmdnQaFr3DUnvkfSwpEckfaFZ62kVSWskPSBphaS7Wx1PvSRd\nKalL0u/Kpk2WtFTSakk3S5rUyhjrUWX7LpX0hKT7suE9rYyxHpJmSFomaaWkByVdkE1v+33Yy7ad\nn03Pxf6TNE7SXVkuWSnpsmz6gPddU1rotXY6ameSHgXeFhHPtTqWRpB0DLAJ+N8RcWg27XJgY0R8\nNTsoT46IBa2Mc7CqbN+lwEsR8T9aGlwDSJoGTIuI+yXtDtxL6hfycdp8H/axbWeRn/23a0Rsyc5N\n3gFcCJzOAPdds1ror3U6iohXgVKnozwRTfyFM9Qi4ldA5cFpHrAwG18InDGkQTVQle2DtB/bXkSs\nj4j7s/FNwCpgBjnYh1W2bXr2cV7235ZsdBwprzzHIPZdsxJSb52Oplf5brsK4BZJ90g6r9XBNMnU\niOiC9J8KmNrieJrhbyTdL+l77ViO6I2kA4C5wG+Ajjztw7JtuyublIv9J2mUpBXAeqAYEQ8xiH2X\nmxZmCxwdEYcDpwKfzX7S513ezqB/C5gdEXNJ/5Hy8NN9d+CnwOey1mzlPmvbfdjLtuVm/0VEd0Qc\nRvpV9S5JBQax75qV0J8E9i97PyOblhsRsS57fRq4nnze9qBLUge8Vsfc0OJ4Gioini67c9x3gXe0\nMp56SRpDSnhXR8TibHIu9mFv25a3/QcQES8CNwFvZxD7rlkJ/R7g9ZJmSRoLfAhY0qR1DTlJu2at\nBSTtBpwM/L61UTWE2LEmuQQ4Jxs/G1hcOUOb2WH7sv8kJWfS/vvw+8BDEfGNsml52Yc7bVte9p+k\nfUrlIkkTgJOAFQxi3zXtOvTsEqJv0NPp6CtNWVELSDqQ1CoPUuesH7b79kn6EVAA9ga6gEuBG4Br\ngZnAWmB+RDzfqhjrUWX7jiPVY7uBNcCnSzXLdiPpaOB24EHS32UAl5B6cC+ijfdhH9v2l+Rg/0k6\nhHTSs3ShxdUR8d8l7cUA9507FpmZ5YRPipqZ5YQTuplZTjihm5nlhBO6mVlOOKGbmeWEE7qZWU44\noZuZ5YQTuplZTvx/KfjLSxiHaU8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1176ae450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pca.explained_variance_)\n",
    "plt.title(\"PCA explained variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.99      0.91      1233\n",
      "          1       0.82      0.17      0.28       284\n",
      "\n",
      "avg / total       0.83      0.84      0.79      1517\n",
      "\n",
      "[[1222   11]\n",
      " [ 235   49]]\n",
      "Accuracy: 0.837837837838\n"
     ]
    }
   ],
   "source": [
    "# Jacana features only\n",
    "logreg = linear_model.LogisticRegression(C=0.01,\n",
    "#                                          penalty=\"l1\"\n",
    "                                        )\n",
    "logreg = logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Compute metrics\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.98      0.91      1233\n",
      "          1       0.72      0.21      0.32       284\n",
      "\n",
      "avg / total       0.82      0.84      0.80      1517\n",
      "\n",
      "[[1210   23]\n",
      " [ 225   59]]\n",
      "Accuracy: 0.836519446276\n"
     ]
    }
   ],
   "source": [
    "#logistic regression with qn similarity features\n",
    "\n",
    "# Jacana + similarity features (no scaling)\n",
    "logreg = linear_model.LogisticRegression(C=0.2,\n",
    "                                         penalty=\"l1\"\n",
    "                                        )\n",
    "logreg = logreg.fit(X_combined_train, y_train)\n",
    "y_pred = logreg.predict(X_combined_test)\n",
    "\n",
    "# Compute metrics\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.98      0.91      1233\n",
      "          1       0.72      0.21      0.33       284\n",
      "\n",
      "avg / total       0.82      0.84      0.80      1517\n",
      "\n",
      "[[1209   24]\n",
      " [ 223   61]]\n",
      "Accuracy: 0.837178642057\n"
     ]
    }
   ],
   "source": [
    "#logistic regression with qn similarity features\n",
    "# Jacana + similarity features (scale similarity only)\n",
    "logreg = linear_model.LogisticRegression(C=2,\n",
    "                                        )\n",
    "logreg = logreg.fit(X_comb_scaledsim_train, y_train)\n",
    "y_pred = logreg.predict(X_comb_scaledsim_test)\n",
    "\n",
    "# Compute metrics\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.99      0.91      1233\n",
      "          1       0.86      0.15      0.26       284\n",
      "\n",
      "avg / total       0.84      0.84      0.79      1517\n",
      "\n",
      "[[1226    7]\n",
      " [ 241   43]]\n",
      "Accuracy: 0.836519446276\n"
     ]
    }
   ],
   "source": [
    "#logistic regression with qn similarity features\n",
    "# Jacana + similarity + PCA reduced\n",
    "\n",
    "clf = linear_model.LogisticRegression(C=0.002,\n",
    "                                        )\n",
    "clf.fit(X_pca_train, y_train)\n",
    "y_pred = clf.predict(X_pca_test)\n",
    "\n",
    "# Compute metrics\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 3.07 seconds for 10 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.932 (std: 0.006)\n",
      "Parameters: {'C': 0.01}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.930 (std: 0.014)\n",
      "Parameters: {'C': 0.1}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.930 (std: 0.016)\n",
      "Parameters: {'C': 0.5}\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.99      0.90      1233\n",
      "          1       0.73      0.11      0.20       284\n",
      "\n",
      "avg / total       0.81      0.83      0.77      1517\n",
      "\n",
      "[[1221   12]\n",
      " [ 252   32]]\n",
      "Accuracy: 0.825972313777\n"
     ]
    }
   ],
   "source": [
    "# Randomized search with cross validation to find best set of params\n",
    "\n",
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"C\": [10, 5, 2, 1, 0.5, 0.3, 0.1, 0.05, 0.03, 0.01, 0.005, 0.003, 0.001, 0.0005]}\n",
    "clf = linear_model.LogisticRegression()\n",
    "\n",
    "n_iter_search = 10\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search,\n",
    "                                   cv=5,\n",
    "                                   random_state=457319)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X_comb_scaledsim_train, y_train)\n",
    "y_pred = random_search.predict(X_comb_scaledsim_test)\n",
    "\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)\n",
    "\n",
    "\n",
    "# Compute metrics\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 2.61 seconds for 10 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.930 (std: 0.012)\n",
      "Parameters: {'C': 0.1}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.929 (std: 0.011)\n",
      "Parameters: {'C': 0.01}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.929 (std: 0.011)\n",
      "Parameters: {'C': 2}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.929 (std: 0.011)\n",
      "Parameters: {'C': 10}\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.98      0.90      1233\n",
      "          1       0.66      0.15      0.25       284\n",
      "\n",
      "avg / total       0.80      0.83      0.78      1517\n",
      "\n",
      "[[1210   23]\n",
      " [ 240   44]]\n",
      "Accuracy: 0.826631509558\n"
     ]
    }
   ],
   "source": [
    "# Randomized search with cross validation to find best set of params\n",
    "\n",
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"C\": [10, 5, 2, 1, 0.5, 0.3, 0.1, 0.05, 0.03, 0.01, 0.005, 0.003, 0.001, 0.0005]}\n",
    "clf = linear_model.LogisticRegression()\n",
    "\n",
    "n_iter_search = 10\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search,\n",
    "                                   cv=5,\n",
    "                                   random_state=457319)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X_pca_train, y_train)\n",
    "y_pred = random_search.predict(X_pca_test)\n",
    "\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)\n",
    "\n",
    "\n",
    "# Compute metrics\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.98      0.90      1233\n",
      "          1       0.68      0.18      0.28       284\n",
      "\n",
      "avg / total       0.81      0.83      0.79      1517\n",
      "\n",
      "Accuracy score: 0.830586684245\n"
     ]
    }
   ],
   "source": [
    "# Jacana only\n",
    "clf = RandomForestClassifier(n_estimators=300,\n",
    "                             max_depth=12,\n",
    "#                              min_samples_split=4,\n",
    "                             criterion=\"entropy\",\n",
    "                             random_state=3471,\n",
    "                             class_weight=\"balanced\"\n",
    "                            )\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy score: {}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.97      0.91      1233\n",
      "          1       0.67      0.24      0.35       284\n",
      "\n",
      "avg / total       0.81      0.84      0.80      1517\n",
      "\n",
      "Accuracy score: 0.835860250494\n"
     ]
    }
   ],
   "source": [
    "# Jacana with similarity scores features. Both types of features scaled.\n",
    "clf = RandomForestClassifier(n_estimators=400,\n",
    "                             max_depth=12,\n",
    "                             min_samples_split=4,\n",
    "                             criterion=\"entropy\",\n",
    "                             random_state=3471,\n",
    "                             class_weight=\"balanced_subsample\"\n",
    "                            )\n",
    "clf = clf.fit(X_combined_train, y_train)\n",
    "y_pred = clf.predict(X_combined_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy score: {}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use randomized search to find good parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 131.00 seconds for 10 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.929 (std: 0.009)\n",
      "Parameters: {'min_samples_leaf': 3, 'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 2, 'max_depth': 16, 'class_weight': 'balanced_subsample'}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.929 (std: 0.002)\n",
      "Parameters: {'min_samples_leaf': 2, 'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 6, 'max_depth': 8, 'class_weight': None}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.928 (std: 0.004)\n",
      "Parameters: {'min_samples_leaf': 2, 'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 2, 'max_depth': 16, 'class_weight': None}\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.97      0.91      1233\n",
      "          1       0.65      0.26      0.37       284\n",
      "\n",
      "avg / total       0.81      0.84      0.80      1517\n",
      "\n",
      "[[1194   39]\n",
      " [ 211   73]]\n",
      "Accuracy: 0.835201054713\n"
     ]
    }
   ],
   "source": [
    "# Jacana only\n",
    "from time import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": [8, 12, 16],\n",
    "              \"min_samples_split\": [2, 4, 6],\n",
    "              \"criterion\": [\"gini\", \"entropy\"],\n",
    "              \"min_samples_leaf\": [1, 2, 3],\n",
    "              \"n_estimators\": [200, 250, 300],\n",
    "              \"class_weight\": [None, \"balanced\", \"balanced_subsample\"]}\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "n_iter_search = 10\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search,\n",
    "                                   cv=5,\n",
    "                                   random_state=83716)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X_train, y_train)\n",
    "y_pred = random_search.predict(X_test)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)\n",
    "\n",
    "# Compute metrics\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 147.10 seconds for 10 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.929 (std: 0.004)\n",
      "Parameters: {'min_samples_leaf': 2, 'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 6, 'max_depth': 16, 'class_weight': None}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.927 (std: 0.002)\n",
      "Parameters: {'min_samples_leaf': 2, 'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 6, 'max_depth': 8, 'class_weight': None}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.927 (std: 0.011)\n",
      "Parameters: {'min_samples_leaf': 3, 'n_estimators': 250, 'criterion': 'gini', 'min_samples_split': 2, 'max_depth': 16, 'class_weight': 'balanced_subsample'}\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.99      0.90      1233\n",
      "          1       0.77      0.08      0.15       284\n",
      "\n",
      "avg / total       0.82      0.82      0.76      1517\n",
      "\n",
      "[[1226    7]\n",
      " [ 260   24]]\n",
      "Accuracy: 0.823994726434\n"
     ]
    }
   ],
   "source": [
    "# Jacana with similarity scores features. Only similarity scores are scaled.\n",
    "start = time()\n",
    "random_search.fit(X_comb_scaledsim_train, y_train)\n",
    "y_pred = random_search.predict(X_comb_scaledsim_test)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)\n",
    "\n",
    "# Compute metrics\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using GradientBoostingMachine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use RF to embed features then train using LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
